<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-04-11T11:08:52+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Legal Criticality Prediction Classifier in French</title><link href="/2023/03/28/legclf_critical_prediction_french_fr.html" rel="alternate" type="text/html" title="Legal Criticality Prediction Classifier in French" /><published>2023-03-28T00:00:00+00:00</published><updated>2023-03-28T00:00:00+00:00</updated><id>/2023/03/28/legclf_critical_prediction_french_fr</id><content type="html" xml:base="/2023/03/28/legclf_critical_prediction_french_fr.html">## Description

This is a Binary classification model which identifies two criticality labels(critical, non-critical) in French-based Court Cases.

## Predicted Entities

`critical`, `non-critical`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_french_fr_1.0.0_3.0_1680044769752.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_french_fr_1.0.0_3.0_1680044769752.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_french&quot;, &quot;fr&quot;, &quot;legal/models&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;class&quot;)

nlpPipeline = nlp.Pipeline(
      stages = [documentAssembler,
                tokenizer,
                classifier])
     
# Example text
example = spark.createDataFrame([[&quot;Par ces motifs, le Tribunal fédéral prononce : 1. Le recours est rejeté dans la mesure où il est recevable. 2. Les frais judiciaires, arrêtés à 2'000 fr., sont mis à la charge du recourant. 3. Le présent arrêt est communiqué au recourant, à la Commission du barreau ainsi qu'à la I e Cour administrative du Tribunal cantonal de l'Etat de Fribourg. Lausanne, le 19 janvier 2016 Au nom de la IIe Cour de droit public du Tribunal fédéral suisse Le Président : Zünd Le Greffier : Chatton&quot;]]).toDF(&quot;text&quot;)

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = nlpPipeline.fit(empty_data)

result = model.transform(example)

# result is a DataFrame
result.select(&quot;text&quot;, &quot;class.result&quot;).show(truncate=100)
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+--------------+
|                                                                                                text|        result|
+----------------------------------------------------------------------------------------------------+--------------+
|Par ces motifs, le Tribunal fédéral prononce : 1. Le recours est rejeté dans la mesure où il est ...|[non_critical]|
+----------------------------------------------------------------------------------------------------+--------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_critical_prediction_french|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|fr|
|Size:|415.9 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

Train dataset available [here](https://huggingface.co/datasets/rcds/legal_criticality_prediction)

## Benchmarking

```bash
label         precision  recall  f1-score  support 
critical      0.74       0.74    0.74      117     
non_critical  0.81       0.81    0.81      161     
accuracy      -          -       0.78      278     
macro-avg     0.77       0.77    0.77      278     
weighted-avg  0.78       0.78    0.78      278     
```</content><author><name>John Snow Labs</name></author><category term="fr" /><category term="licensed" /><category term="classification" /><category term="legal" /><category term="tensorflow" /><summary type="html">Description This is a Binary classification model which identifies two criticality labels(critical, non-critical) in French-based Court Cases. Predicted Entities critical, non-critical Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_french&quot;, &quot;fr&quot;, &quot;legal/models&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) nlpPipeline = nlp.Pipeline( stages = [documentAssembler, tokenizer, classifier]) # Example text example = spark.createDataFrame([[&quot;Par ces motifs, le Tribunal fédéral prononce : 1. Le recours est rejeté dans la mesure où il est recevable. 2. Les frais judiciaires, arrêtés à 2'000 fr., sont mis à la charge du recourant. 3. Le présent arrêt est communiqué au recourant, à la Commission du barreau ainsi qu'à la I e Cour administrative du Tribunal cantonal de l'Etat de Fribourg. Lausanne, le 19 janvier 2016 Au nom de la IIe Cour de droit public du Tribunal fédéral suisse Le Président : Zünd Le Greffier : Chatton&quot;]]).toDF(&quot;text&quot;) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) result = model.transform(example) # result is a DataFrame result.select(&quot;text&quot;, &quot;class.result&quot;).show(truncate=100) Results +----------------------------------------------------------------------------------------------------+--------------+ | text| result| +----------------------------------------------------------------------------------------------------+--------------+ |Par ces motifs, le Tribunal fédéral prononce : 1. Le recours est rejeté dans la mesure où il est ...|[non_critical]| +----------------------------------------------------------------------------------------------------+--------------+ Model Information Model Name: legclf_critical_prediction_french Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: fr Size: 415.9 MB Case sensitive: true Max sentence length: 512 References Train dataset available here Benchmarking label precision recall f1-score support critical 0.74 0.74 0.74 117 non_critical 0.81 0.81 0.81 161 accuracy - - 0.78 278 macro-avg 0.77 0.77 0.77 278 weighted-avg 0.78 0.78 0.78 278</summary></entry><entry><title type="html">legclf_critical_prediction_italian</title><link href="/2023/03/27/legclf_critical_prediction_italian_it.html" rel="alternate" type="text/html" title="legclf_critical_prediction_italian" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/legclf_critical_prediction_italian_it</id><content type="html" xml:base="/2023/03/27/legclf_critical_prediction_italian_it.html">## Description

Description: This is a Binary classification model which identifies two criticality labels(critical, non-critical) in Italian-based Court Cases.

## Predicted Entities

`critical`, `non-critical`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_italian_it_1.0.0_3.0_1679944691458.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_italian_it_1.0.0_3.0_1679944691458.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_italian&quot;, &quot;it&quot;, &quot;legal/models&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;class&quot;)

nlpPipeline = nlp.Pipeline(
      stages = [documentAssembler,
                tokenizer,
                classifier])
     
# Example text
example = spark.createDataFrame([[&quot;Per questi motivi, il Tribunale federale pronuncia: 1. Nella misura in cui è ammissibile, il ricorso è respinto. 2. Le spese giudiziarie di fr. 2'000.-- sono poste a carico del ricorrente. 3. Comunicazione ai patrocinatori delle parti, al patrocinatore di C._ e al Presidente della Camera di protezione del Tribunale d'appello del Cantone Ticino.&quot;]]).toDF(&quot;text&quot;)

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = nlpPipeline.fit(empty_data)

result = model.transform(example)

# result is a DataFrame
result.select(&quot;text&quot;, &quot;class.result&quot;).show(truncate=100)
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+----------+
|                                                                                                text|    result|
+----------------------------------------------------------------------------------------------------+----------+
|Per questi motivi, il Tribunale federale pronuncia: 1. Nella misura in cui è ammissibile, il rico...|[critical]|
+----------------------------------------------------------------------------------------------------+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_critical_prediction_italian|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|it|
|Size:|415.9 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

Train dataset available [here](https://huggingface.co/datasets/rcds/legal_criticality_prediction)

## Benchmarking

```bash
label         precision  recall  f1-score  support 
critical      0.82       0.90    0.86      10      
non_critical  0.95       0.91    0.93      23      
accuracy      -          -       0.91      33      
macro-avg     0.89       0.91    0.90      33      
weighted-avg  0.91       0.91    0.91      33    
```</content><author><name>John Snow Labs</name></author><category term="it" /><category term="licensed" /><category term="legal" /><category term="classification" /><category term="tensorflow" /><summary type="html">Description Description: This is a Binary classification model which identifies two criticality labels(critical, non-critical) in Italian-based Court Cases. Predicted Entities critical, non-critical Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_italian&quot;, &quot;it&quot;, &quot;legal/models&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) nlpPipeline = nlp.Pipeline( stages = [documentAssembler, tokenizer, classifier]) # Example text example = spark.createDataFrame([[&quot;Per questi motivi, il Tribunale federale pronuncia: 1. Nella misura in cui è ammissibile, il ricorso è respinto. 2. Le spese giudiziarie di fr. 2'000.-- sono poste a carico del ricorrente. 3. Comunicazione ai patrocinatori delle parti, al patrocinatore di C._ e al Presidente della Camera di protezione del Tribunale d'appello del Cantone Ticino.&quot;]]).toDF(&quot;text&quot;) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) result = model.transform(example) # result is a DataFrame result.select(&quot;text&quot;, &quot;class.result&quot;).show(truncate=100) Results +----------------------------------------------------------------------------------------------------+----------+ | text| result| +----------------------------------------------------------------------------------------------------+----------+ |Per questi motivi, il Tribunale federale pronuncia: 1. Nella misura in cui è ammissibile, il rico...|[critical]| +----------------------------------------------------------------------------------------------------+----------+ Model Information Model Name: legclf_critical_prediction_italian Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: it Size: 415.9 MB Case sensitive: true Max sentence length: 512 References Train dataset available here Benchmarking label precision recall f1-score support critical 0.82 0.90 0.86 10 non_critical 0.95 0.91 0.93 23 accuracy - - 0.91 33 macro-avg 0.89 0.91 0.90 33 weighted-avg 0.91 0.91 0.91 33</summary></entry><entry><title type="html">Legal Criticality Prediction Classifier (German)</title><link href="/2023/03/27/legclf_critical_prediction_legal_de.html" rel="alternate" type="text/html" title="Legal Criticality Prediction Classifier (German)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/legclf_critical_prediction_legal_de</id><content type="html" xml:base="/2023/03/27/legclf_critical_prediction_legal_de.html">## Description

This is a Binary classification model which identifies two criticality labels(critical, non-critical) in German-based Court Cases.

## Predicted Entities

`critical`, `non-critical`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_legal_de_1.0.0_3.0_1679923757236.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_legal_de_1.0.0_3.0_1679923757236.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_legal&quot;, &quot;de&quot;, &quot;legal/models&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;class&quot;)

nlpPipeline = nlp.Pipeline(
      stages = [documentAssembler,
                tokenizer,
                classifier])
     
# Example text
example = spark.createDataFrame([[&quot;erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtskosten erhoben. 3. Dieses Urteil wird den Parteien, dem Sozialversicherungsgericht des Kantons Zürich und dem Staatssekretariat für Wirtschaft (SECO) schriftlich mitgeteilt. Luzern, 5. Dezember 2016 Im Namen der I. sozialrechtlichen Abteilung des Schweizerischen Bundesgerichts Der Präsident: Maillard Der Gerichtsschreiber: Grünvogel&quot;]]).toDF(&quot;text&quot;)

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = nlpPipeline.fit(empty_data)

result = model.transform(example)

# result is a DataFrame
result.select(&quot;text&quot;, &quot;class.result&quot;).show()
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+--------------+
|                                                                                                text|        result|
+----------------------------------------------------------------------------------------------------+--------------+
|erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtsk...|[non_critical]|
+----------------------------------------------------------------------------------------------------+--------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_critical_prediction_legal|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|de|
|Size:|468.5 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

Train dataset available [here](https://huggingface.co/datasets/rcds/legal_criticality_prediction)

## Benchmarking

```bash
label         precision  recall  f1-score  support 
critical      0.76       0.87    0.81      249     
non_critical  0.87       0.76    0.81      293     
accuracy      -          -       0.81      542     
macro-avg     0.81       0.82    0.81      542     
weighted-avg  0.82       0.81    0.81      542     
```</content><author><name>John Snow Labs</name></author><category term="classification" /><category term="de" /><category term="licensed" /><category term="legal" /><category term="tensorflow" /><summary type="html">Description This is a Binary classification model which identifies two criticality labels(critical, non-critical) in German-based Court Cases. Predicted Entities critical, non-critical Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_legal&quot;, &quot;de&quot;, &quot;legal/models&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) nlpPipeline = nlp.Pipeline( stages = [documentAssembler, tokenizer, classifier]) # Example text example = spark.createDataFrame([[&quot;erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtskosten erhoben. 3. Dieses Urteil wird den Parteien, dem Sozialversicherungsgericht des Kantons Zürich und dem Staatssekretariat für Wirtschaft (SECO) schriftlich mitgeteilt. Luzern, 5. Dezember 2016 Im Namen der I. sozialrechtlichen Abteilung des Schweizerischen Bundesgerichts Der Präsident: Maillard Der Gerichtsschreiber: Grünvogel&quot;]]).toDF(&quot;text&quot;) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) result = model.transform(example) # result is a DataFrame result.select(&quot;text&quot;, &quot;class.result&quot;).show() Results +----------------------------------------------------------------------------------------------------+--------------+ | text| result| +----------------------------------------------------------------------------------------------------+--------------+ |erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtsk...|[non_critical]| +----------------------------------------------------------------------------------------------------+--------------+ Model Information Model Name: legclf_critical_prediction_legal Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: de Size: 468.5 MB Case sensitive: true Max sentence length: 512 References Train dataset available here Benchmarking label precision recall f1-score support critical 0.76 0.87 0.81 249 non_critical 0.87 0.76 0.81 293 accuracy - - 0.81 542 macro-avg 0.81 0.82 0.81 542 weighted-avg 0.82 0.81 0.81 542</summary></entry><entry><title type="html">Financial Company Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_company_sentiments_es.html" rel="alternate" type="text/html" title="Financial Company Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_company_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_company_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a company whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_company_sentiments_es_1.0.0_3.0_1679941143258.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_company_sentiments_es_1.0.0_3.0_1679941143258.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_company_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------------------------------------------------------------------------+---------+
|text                                                                         |result   |
+-----------------------------------------------------------------------------+---------+
|Leopoldo del Nogal abandona el consejo de administraciÃ³n de El Corte InglÃ©s|[neutral]|
+-----------------------------------------------------------------------------+---------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_company_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|408.7 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels            precision    recall  f1-score   support
    negative       0.51      0.52      0.52        44
     neutral       0.65      0.74      0.69        77
    positive       0.56      0.38      0.45        37
    accuracy        -         -        0.59       158
   macro avg       0.57      0.55      0.55       158
weighted avg       0.59      0.59      0.59       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a company whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_company_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-----------------------------------------------------------------------------+---------+ |text |result | +-----------------------------------------------------------------------------+---------+ |Leopoldo del Nogal abandona el consejo de administraciÃ³n de El Corte InglÃ©s|[neutral]| +-----------------------------------------------------------------------------+---------+ Model Information Model Name: finclf_bert_company_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 408.7 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.51 0.52 0.52 44 neutral 0.65 0.74 0.69 77 positive 0.56 0.38 0.45 37 accuracy - - 0.59 158 macro avg 0.57 0.55 0.55 158 weighted avg 0.59 0.59 0.59 158</summary></entry><entry><title type="html">Financial Consumer Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_consumer_sentiments_es.html" rel="alternate" type="text/html" title="Financial Consumer Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_consumer_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_consumer_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_consumer_sentiments_es_1.0.0_3.0_1679940812817.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_consumer_sentiments_es_1.0.0_3.0_1679940812817.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_consumer_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-------------------------------------------------------------------------+----------+
|text                                                                     |result    |
+-------------------------------------------------------------------------+----------+
|Renfe afronta maÃ±ana un nuevo dÃ­a de paros parciales de los maquinistas|[negative]|
+-------------------------------------------------------------------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_consumer_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|408.7 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels            precision    recall  f1-score   support
    negative       0.59      0.72      0.66        36
     neutral       0.77      0.79      0.80        80
    positive       0.72      0.55      0.64        42
    accuracy        -         -        0.73       158
   macro-avg       0.69      0.69      0.70       158
weighted-avg       0.71      0.71      0.72       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_consumer_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-------------------------------------------------------------------------+----------+ |text |result | +-------------------------------------------------------------------------+----------+ |Renfe afronta maÃ±ana un nuevo dÃ­a de paros parciales de los maquinistas|[negative]| +-------------------------------------------------------------------------+----------+ Model Information Model Name: finclf_bert_consumer_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 408.7 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.59 0.72 0.66 36 neutral 0.77 0.79 0.80 80 positive 0.72 0.55 0.64 42 accuracy - - 0.73 158 macro-avg 0.69 0.69 0.70 158 weighted-avg 0.71 0.71 0.72 158</summary></entry><entry><title type="html">Financial Target Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_target_sentiments_es.html" rel="alternate" type="text/html" title="Financial Target Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_target_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_target_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_target_sentiments_es_1.0.0_3.0_1679941309907.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_target_sentiments_es_1.0.0_3.0_1679941309907.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_target_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-------------------------------------------------------------------------------------------+----------+
|text                                                                                       |result    |
+-------------------------------------------------------------------------------------------+----------+
|La deuda de las familias cae en 25.000 millones en 2015 y marca niveles previos a la crisis|[positive]|
+-------------------------------------------------------------------------------------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_target_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|412.2 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels      precision    recall  f1-score   support
negative        0.81      0.66      0.73        44
neutral         1.00      0.22      0.36         9
positive        0.82      0.93      0.87       105
accuracy          -        -        0.82       158
macro-avg       0.87      0.60      0.65       158
weighted-avg    0.82      0.82      0.80       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_target_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-------------------------------------------------------------------------------------------+----------+ |text |result | +-------------------------------------------------------------------------------------------+----------+ |La deuda de las familias cae en 25.000 millones en 2015 y marca niveles previos a la crisis|[positive]| +-------------------------------------------------------------------------------------------+----------+ Model Information Model Name: finclf_bert_target_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 412.2 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.81 0.66 0.73 44 neutral 1.00 0.22 0.36 9 positive 0.82 0.93 0.87 105 accuracy - - 0.82 158 macro-avg 0.87 0.60 0.65 158 weighted-avg 0.82 0.82 0.80 158</summary></entry><entry><title type="html">Financial Target NER (Codalab)</title><link href="/2023/03/27/finner_bert_target_es.html" rel="alternate" type="text/html" title="Financial Target NER (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finner_bert_target_es</id><content type="html" xml:base="/2023/03/27/finner_bert_target_es.html">## Description

This  Spanish NER model will identify the label `TARGET` from a financial statement. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`TARGET`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_bert_target_es_1.0.0_3.0_1679942128323.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_bert_target_es_1.0.0_3.0_1679942128323.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_bert_target&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;label&quot;)\
  .setCaseSensitive(True)

converter = finance.NerConverterInternal()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\
    .setOutputCol(&quot;ner&quot;)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  tokenClassifier,
  converter
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------+------+
|chunk      |entity|
+-----------+------+
|Presupuesto|TARGET|
|populista  |TARGET|
+-----------+------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_bert_target|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[ner]|
|Language:|es|
|Size:|406.6 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels              precision    recall  f1-score   support
    B-TARGET       0.76      0.82      0.79       435
   micro-avg       0.76      0.82      0.79       435
   macro-avg       0.76      0.82      0.79       435
weighted-avg       0.76      0.82      0.79       435

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="ner" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish NER model will identify the label TARGET from a financial statement. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities TARGET Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_bert_target&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;label&quot;)\ .setCaseSensitive(True) converter = finance.NerConverterInternal()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\ .setOutputCol(&quot;ner&quot;) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, converter ] ) Results +-----------+------+ |chunk |entity| +-----------+------+ |Presupuesto|TARGET| |populista |TARGET| +-----------+------+ Model Information Model Name: finner_bert_target Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [ner] Language: es Size: 406.6 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support B-TARGET 0.76 0.82 0.79 435 micro-avg 0.76 0.82 0.79 435 macro-avg 0.76 0.82 0.79 435 weighted-avg 0.76 0.82 0.79 435</summary></entry><entry><title type="html">Broker Reports Financial NER (Specific, sm)</title><link href="/2023/03/27/finner_broker_reports_specific_sm_en.html" rel="alternate" type="text/html" title="Broker Reports Financial NER (Specific, sm)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finner_broker_reports_specific_sm_en</id><content type="html" xml:base="/2023/03/27/finner_broker_reports_specific_sm_en.html">## Description

This is a `sm` (small) version of a financial model trained on Broker Reports to detect financial entities (NER model).

## Predicted Entities

`LIABILITY_INCREASE`, `REVENUE_INCREASE`, `ASSET_DECREASE`, `AMOUNT`, `TICKER`, `TARGET_PRICE`, `ORG`, `DATE`, `LIABILITY_DECREASE`, `LIABILITY`, `CFO_INCREASE`, `ASSET_INCREASE`, `LOSS`, `CMP`, `ASSET`, `CF_DECREASE`, `EXPENSE`, `CF`, `PAD`, `CFO`, `FCF`, `PROFIT_INCREASE`, `REVENUE_DECLINE`, `CF_INCREASE`, `PERCENTAGE`, `RATING`, `STOCKHOLDERS_EQUITY`, `PROFIT_DECLINE`, `PROFIT`, `CURRENCY`, `FISCAL_YEAR`, `EXPENSE_INCREASE`, `EXPENSE_DECREASE`, `REVENUE`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_broker_reports_specific_sm_en_1.0.0_3.0_1679939860761.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_broker_reports_specific_sm_en_1.0.0_3.0_1679939860761.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_broker_reports_specific_sm&quot;,&quot;en&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;label&quot;)\
  .setCaseSensitive(True)

converter = finance.NerConverterInternal()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\
    .setOutputCol(&quot;ner_span&quot;)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  tokenClassifier,
  converter
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------------+----------+
|chunk            |entity    |
+-----------------+----------+
|revenue          |REVENUE   |
|$                |CURRENCY  |
|1.7 billion      |AMOUNT    |
|net profit margin|PROFIT    |
|13               |PERCENTAGE|
|net debt         |LIABILITY |
|Rs               |CURRENCY  |
|6.62bn           |AMOUNT    |
+-----------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_broker_reports_specific_sm|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|400.9 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

In-house annotated dataset

## Benchmarking

```bash
 
labels                     precision    recall  f1-score   support
   B-REVENUE_INCREASE       0.69      0.78      0.73       126
     I-ASSET_DECREASE       0.80      0.87      0.83        23
              B-ASSET       0.84      0.82      0.83        50
    B-REVENUE_DECLINE       0.81      0.79      0.80        28
I-STOCKHOLDERS_EQUITY       1.00      0.96      0.98        56
                 B-CF       0.77      0.94      0.85        18
               I-LOSS       0.92      0.92      0.92        25
            I-REVENUE       0.28      0.26      0.27        19
     I-PROFIT_DECLINE       0.80      0.94      0.86        17
             I-PROFIT       0.91      0.94      0.93       249
   I-EXPENSE_DECREASE       0.77      1.00      0.87        10
   I-REVENUE_INCREASE       0.58      0.68      0.63        56
             B-TICKER       0.65      0.81      0.72        73
            B-EXPENSE       0.76      0.90      0.83        63
        I-CF_DECREASE       0.90      1.00      0.95        38
             B-RATING       0.93      0.99      0.96       536
                B-FCF       1.00      1.00      1.00        18
        B-CF_INCREASE       1.00      1.00      1.00        20
           B-CURRENCY       0.98      1.00      0.99       936
     I-ASSET_INCREASE       0.76      1.00      0.86        16
                B-CFO       0.96      1.00      0.98        22
          I-LIABILITY       0.97      0.82      0.89        38
               B-LOSS       0.85      0.94      0.89        31
 I-LIABILITY_DECREASE       0.44      0.67      0.53        12
    B-PROFIT_INCREASE       0.81      0.77      0.79       173
   B-EXPENSE_DECREASE       0.90      1.00      0.95        26
       B-CFO_INCREASE       0.92      0.96      0.94        25
             B-AMOUNT       0.97      1.00      0.98      1999
       B-TARGET_PRICE       0.97      0.98      0.97       171
             B-PROFIT       0.85      0.92      0.88       437
             I-AMOUNT       0.97      0.97      0.97       464
     B-ASSET_INCREASE       0.69      0.78      0.73        23
   I-EXPENSE_INCREASE       0.88      0.79      0.84        29
 B-LIABILITY_DECREASE       0.85      0.88      0.86        40
     B-PROFIT_DECLINE       0.90      0.85      0.87        53
B-STOCKHOLDERS_EQUITY       1.00      0.93      0.96        27
            I-EXPENSE       0.91      0.87      0.89        61
         B-PERCENTAGE       0.95      0.99      0.97      1133
              I-ASSET       0.97      0.73      0.83        44
         I-PERCENTAGE       0.33      1.00      0.50         2
       I-TARGET_PRICE       0.94      1.00      0.97       119
                B-CMP       0.89      1.00      0.94        33
    I-PROFIT_INCREASE       0.75      0.75      0.75        48
               I-DATE       0.40      0.57      0.47        14
            B-REVENUE       0.78      0.83      0.80       128
     B-ASSET_DECREASE       0.87      0.91      0.89        22
        I-CF_INCREASE       1.00      1.00      1.00        42
        I-FISCAL_YEAR       0.98      0.89      0.93       110
                I-CFO       0.97      1.00      0.99        75
                I-FCF       1.00      1.00      1.00        32
                B-ORG       0.95      0.98      0.96      1310
                I-ORG       0.95      0.98      0.97      1005
   B-EXPENSE_INCREASE       1.00      0.68      0.81        34
    I-REVENUE_DECLINE       0.67      0.38      0.48        21
             I-RATING       0.00      0.00      0.00         1
               B-DATE       0.98      0.99      0.98       358
                I-CMP       0.97      1.00      0.98        29
 B-LIABILITY_INCREASE       1.00      0.93      0.96        41
        B-FISCAL_YEAR       0.96      0.89      0.93        28
           I-CURRENCY       0.96      1.00      0.98        72
       I-CFO_INCREASE       0.89      0.97      0.93        72
        B-CF_DECREASE       0.96      1.00      0.98        23
             I-TICKER       1.00      0.40      0.57         5
 I-LIABILITY_INCREASE       1.00      0.94      0.97        31
          B-LIABILITY       0.96      0.92      0.94        26
                 I-CF       0.80      0.85      0.83        39
            micro-avg       0.93      0.96      0.95     10905
            macro-avg       0.85      0.87      0.85     10905
         weighted-avg       0.93      0.96      0.95     10905

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="broker_reports" /><category term="ner" /><category term="en" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This is a sm (small) version of a financial model trained on Broker Reports to detect financial entities (NER model). Predicted Entities LIABILITY_INCREASE, REVENUE_INCREASE, ASSET_DECREASE, AMOUNT, TICKER, TARGET_PRICE, ORG, DATE, LIABILITY_DECREASE, LIABILITY, CFO_INCREASE, ASSET_INCREASE, LOSS, CMP, ASSET, CF_DECREASE, EXPENSE, CF, PAD, CFO, FCF, PROFIT_INCREASE, REVENUE_DECLINE, CF_INCREASE, PERCENTAGE, RATING, STOCKHOLDERS_EQUITY, PROFIT_DECLINE, PROFIT, CURRENCY, FISCAL_YEAR, EXPENSE_INCREASE, EXPENSE_DECREASE, REVENUE Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_broker_reports_specific_sm&quot;,&quot;en&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;label&quot;)\ .setCaseSensitive(True) converter = finance.NerConverterInternal()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\ .setOutputCol(&quot;ner_span&quot;) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, converter ] ) Results +-----------------+----------+ |chunk |entity | +-----------------+----------+ |revenue |REVENUE | |$ |CURRENCY | |1.7 billion |AMOUNT | |net profit margin|PROFIT | |13 |PERCENTAGE| |net debt |LIABILITY | |Rs |CURRENCY | |6.62bn |AMOUNT | +-----------------+----------+ Model Information Model Name: finner_broker_reports_specific_sm Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [ner] Language: en Size: 400.9 MB Case sensitive: true Max sentence length: 128 References In-house annotated dataset Benchmarking labels precision recall f1-score support B-REVENUE_INCREASE 0.69 0.78 0.73 126 I-ASSET_DECREASE 0.80 0.87 0.83 23 B-ASSET 0.84 0.82 0.83 50 B-REVENUE_DECLINE 0.81 0.79 0.80 28 I-STOCKHOLDERS_EQUITY 1.00 0.96 0.98 56 B-CF 0.77 0.94 0.85 18 I-LOSS 0.92 0.92 0.92 25 I-REVENUE 0.28 0.26 0.27 19 I-PROFIT_DECLINE 0.80 0.94 0.86 17 I-PROFIT 0.91 0.94 0.93 249 I-EXPENSE_DECREASE 0.77 1.00 0.87 10 I-REVENUE_INCREASE 0.58 0.68 0.63 56 B-TICKER 0.65 0.81 0.72 73 B-EXPENSE 0.76 0.90 0.83 63 I-CF_DECREASE 0.90 1.00 0.95 38 B-RATING 0.93 0.99 0.96 536 B-FCF 1.00 1.00 1.00 18 B-CF_INCREASE 1.00 1.00 1.00 20 B-CURRENCY 0.98 1.00 0.99 936 I-ASSET_INCREASE 0.76 1.00 0.86 16 B-CFO 0.96 1.00 0.98 22 I-LIABILITY 0.97 0.82 0.89 38 B-LOSS 0.85 0.94 0.89 31 I-LIABILITY_DECREASE 0.44 0.67 0.53 12 B-PROFIT_INCREASE 0.81 0.77 0.79 173 B-EXPENSE_DECREASE 0.90 1.00 0.95 26 B-CFO_INCREASE 0.92 0.96 0.94 25 B-AMOUNT 0.97 1.00 0.98 1999 B-TARGET_PRICE 0.97 0.98 0.97 171 B-PROFIT 0.85 0.92 0.88 437 I-AMOUNT 0.97 0.97 0.97 464 B-ASSET_INCREASE 0.69 0.78 0.73 23 I-EXPENSE_INCREASE 0.88 0.79 0.84 29 B-LIABILITY_DECREASE 0.85 0.88 0.86 40 B-PROFIT_DECLINE 0.90 0.85 0.87 53 B-STOCKHOLDERS_EQUITY 1.00 0.93 0.96 27 I-EXPENSE 0.91 0.87 0.89 61 B-PERCENTAGE 0.95 0.99 0.97 1133 I-ASSET 0.97 0.73 0.83 44 I-PERCENTAGE 0.33 1.00 0.50 2 I-TARGET_PRICE 0.94 1.00 0.97 119 B-CMP 0.89 1.00 0.94 33 I-PROFIT_INCREASE 0.75 0.75 0.75 48 I-DATE 0.40 0.57 0.47 14 B-REVENUE 0.78 0.83 0.80 128 B-ASSET_DECREASE 0.87 0.91 0.89 22 I-CF_INCREASE 1.00 1.00 1.00 42 I-FISCAL_YEAR 0.98 0.89 0.93 110 I-CFO 0.97 1.00 0.99 75 I-FCF 1.00 1.00 1.00 32 B-ORG 0.95 0.98 0.96 1310 I-ORG 0.95 0.98 0.97 1005 B-EXPENSE_INCREASE 1.00 0.68 0.81 34 I-REVENUE_DECLINE 0.67 0.38 0.48 21 I-RATING 0.00 0.00 0.00 1 B-DATE 0.98 0.99 0.98 358 I-CMP 0.97 1.00 0.98 29 B-LIABILITY_INCREASE 1.00 0.93 0.96 41 B-FISCAL_YEAR 0.96 0.89 0.93 28 I-CURRENCY 0.96 1.00 0.98 72 I-CFO_INCREASE 0.89 0.97 0.93 72 B-CF_DECREASE 0.96 1.00 0.98 23 I-TICKER 1.00 0.40 0.57 5 I-LIABILITY_INCREASE 1.00 0.94 0.97 31 B-LIABILITY 0.96 0.92 0.94 26 I-CF 0.80 0.85 0.83 39 micro-avg 0.93 0.96 0.95 10905 macro-avg 0.85 0.87 0.85 10905 weighted-avg 0.93 0.96 0.95 10905</summary></entry><entry><title type="html">Sentence Entity Resolver for HGNC</title><link href="/2023/03/26/sbiobertresolve_hgnc_en.html" rel="alternate" type="text/html" title="Sentence Entity Resolver for HGNC" /><published>2023-03-26T00:00:00+00:00</published><updated>2023-03-26T00:00:00+00:00</updated><id>/2023/03/26/sbiobertresolve_hgnc_en</id><content type="html" xml:base="/2023/03/26/sbiobertresolve_hgnc_en.html">## Description

This model maps extracted gene names and their short-form abbreviations to HGNC codes using `sbiobert_base_cased_mli` Sentence Bert Embeddings. Also, it returns the locus groups and locus types of the genes as aux labels separated by || under the metadata.

## Predicted Entities

`HGNC Codes`, `Locus Group`, `Locus Type`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/sbiobertresolve_hgnc_en_4.3.2_3.0_1679847290330.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/sbiobertresolve_hgnc_en_4.3.2_3.0_1679847290330.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)


sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
  .setInputCols([&quot;document&quot;])\
  .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
  .setInputCols([&quot;sentence&quot;])\
  .setOutputCol(&quot;token&quot;)


word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
  .setInputCols([&quot;sentence&quot;,&quot;token&quot;])\
  .setOutputCol(&quot;embeddings&quot;)


clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
  .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;])\
  .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
  .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\
  .setOutputCol(&quot;ner_chunk&quot;)\
  .setWhiteList(['GENE'])

chunk2doc = Chunk2Doc()\
  .setInputCols(&quot;ner_chunk&quot;)\
  .setOutputCol(&quot;ner_chunk_doc&quot;)

sbert_embedder = BertSentenceEmbeddings\
  .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
  .setInputCols([&quot;ner_chunk_doc&quot;])\
  .setOutputCol(&quot;sbert_embeddings&quot;)

resolver = SentenceEntityResolverModel\
  .pretrained(&quot;sbiobertresolve_hgnc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) \
  .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) \
  .setOutputCol(&quot;resolution&quot;)\
  .setDistanceFunction(&quot;EUCLIDEAN&quot;)

nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver])


clinical_note = [&quot;Recent studies have suggested a potential link between the double homeobox 4 like 20 (pseudogene), also known as DUX4L20, and FBXO48 and RNA guanine-7 methyltransferase &quot;]


data= spark.createDataFrame([clinical_note]).toDF('text')
results = nlpPipeline.fit(data).transform(data)

```

```scala
val document_assembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)


val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
  .setInputCols(Array(&quot;document&quot;))
  .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
  .setInputCols(Array(&quot;sentence&quot;))
  .setOutputCol(&quot;token&quot;)


val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;))
  .setOutputCol(&quot;embeddings&quot;)


val clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;))
  .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;))
  .setOutputCol(&quot;ner_chunk&quot;)
  .setWhiteList(Array(&quot;GENE&quot;))

val chunk2doc = new Chunk2Doc()
  .setInputCols(&quot;ner_chunk&quot;)
  .setOutputCol(&quot;ner_chunk_doc&quot;)

val sbert_embedder = BertSentenceEmbeddings
  .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
  .setInputCols(Array(&quot;ner_chunk_doc&quot;))
  .setOutputCol(&quot;sbert_embeddings&quot;)

val resolver = SentenceEntityResolverModel
  .pretrained(&quot;sbiobertresolve_hgnc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) 
  .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;)) 
  .setOutputCol(&quot;resolution&quot;)
  .setDistanceFunction(&quot;EUCLIDEAN&quot;)

val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver))

val data = Seq(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus, associated with an acute hepatitis and obesity with a body mass index (BMI) of 33.5 kg/m2&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)

```
&lt;/div&gt;

## Results

```bash
|   sent_id | ner_chunk   | entity   | HGNC Code    | all_codes                                                               | resolutions                                                                                                                    | AUX                                                                                                                             |
|----------:|:------------|:---------|:-------------|:------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------|
|         0 | DUX4L20     | GENE     | HGNC:50801   | ['HGNC:50801', 'HGNC:31982', 'HGNC:42423', 'HGNC:39776', 'HGNC:42023'...| ['DUX4L20 [double homeobox 4 like 20 (pseudogene)]', 'ANKRD20A4P [ankyrin repeat domain 20 family member A4, pseudogene]', ...| [pseudogene :: pseudogene, pseudogene :: pseudogene, non-coding RNA :: RNA, long non-coding, pseudogene :: pseudogene...|
|         0 | FBXO48      | GENE     | HGNC:33857   | ['HGNC:33857', 'HGNC:4930', 'HGNC:16653', 'HGNC:13114', 'HGNC:23535' ...| ['FBXO48 [F-box protein 48]', 'ZBTB48 [zinc finger and BTB domain containing 48]', 'MRPL48 [mitochondrial ribosomal protein' ...| [protein-coding gene :: gene with protein product, protein-coding gene :: gene with protein product, protein-coding gene...|
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|sbiobertresolve_hgnc|
|Compatibility:|Healthcare NLP 4.3.2+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[hgnc_code]|
|Language:|en|
|Size:|251.9 MB|
|Case sensitive:|false|

## References

https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/</content><author><name>John Snow Labs</name></author><category term="hgnc" /><category term="entity_resolution" /><category term="clinical" /><category term="en" /><category term="licensed" /><summary type="html">Description This model maps extracted gene names and their short-form abbreviations to HGNC codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Also, it returns the locus groups and locus types of the genes as aux labels separated by   under the metadata. Predicted Entities HGNC Codes, Locus Group, Locus Type Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ .setWhiteList(['GENE']) chunk2doc = Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings\ .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;ner_chunk_doc&quot;])\ .setOutputCol(&quot;sbert_embeddings&quot;) resolver = SentenceEntityResolverModel\ .pretrained(&quot;sbiobertresolve_hgnc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) \ .setOutputCol(&quot;resolution&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver]) clinical_note = [&quot;Recent studies have suggested a potential link between the double homeobox 4 like 20 (pseudogene), also known as DUX4L20, and FBXO48 and RNA guanine-7 methyltransferase &quot;] data= spark.createDataFrame([clinical_note]).toDF('text') results = nlpPipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val clinical_ner = MedicalNerModel.pretrained(&quot;ner_human_phenotype_gene_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(Array(&quot;GENE&quot;)) val chunk2doc = new Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunk_doc&quot;)) .setOutputCol(&quot;sbert_embeddings&quot;) val resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_hgnc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver)) val data = Seq(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus, associated with an acute hepatitis and obesity with a body mass index (BMI) of 33.5 kg/m2&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results | sent_id | ner_chunk | entity | HGNC Code | all_codes | resolutions | AUX | |----------:|:------------|:---------|:-------------|:------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------| | 0 | DUX4L20 | GENE | HGNC:50801 | ['HGNC:50801', 'HGNC:31982', 'HGNC:42423', 'HGNC:39776', 'HGNC:42023'...| ['DUX4L20 [double homeobox 4 like 20 (pseudogene)]', 'ANKRD20A4P [ankyrin repeat domain 20 family member A4, pseudogene]', ...| [pseudogene :: pseudogene, pseudogene :: pseudogene, non-coding RNA :: RNA, long non-coding, pseudogene :: pseudogene...| | 0 | FBXO48 | GENE | HGNC:33857 | ['HGNC:33857', 'HGNC:4930', 'HGNC:16653', 'HGNC:13114', 'HGNC:23535' ...| ['FBXO48 [F-box protein 48]', 'ZBTB48 [zinc finger and BTB domain containing 48]', 'MRPL48 [mitochondrial ribosomal protein' ...| [protein-coding gene :: gene with protein product, protein-coding gene :: gene with protein product, protein-coding gene...| Model Information Model Name: sbiobertresolve_hgnc Compatibility: Healthcare NLP 4.3.2+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [hgnc_code] Language: en Size: 251.9 MB Case sensitive: false References https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/</summary></entry><entry><title type="html">Sentence Entity Resolver for NCI-t</title><link href="/2023/03/26/sbiobertresolve_ncit_en.html" rel="alternate" type="text/html" title="Sentence Entity Resolver for NCI-t" /><published>2023-03-26T00:00:00+00:00</published><updated>2023-03-26T00:00:00+00:00</updated><id>/2023/03/26/sbiobertresolve_ncit_en</id><content type="html" xml:base="/2023/03/26/sbiobertresolve_ncit_en.html">## Description

This model maps extracted medical entities related to clinical care, translational and basic research, public information and administrative activities to NCI-t codes using `sbiobert_base_cased_mli` Sentence Bert Embeddings.

## Predicted Entities

`NCI-t codes`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/sbiobertresolve_ncit_en_4.3.2_3.0_1679843528109.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/sbiobertresolve_ncit_en_4.3.2_3.0_1679843528109.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
		.setInputCol(&quot;text&quot;)\
		.setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
		.setInputCols([&quot;document&quot;]) \
		.setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
		.setInputCols([&quot;sentence&quot;])\
		.setOutputCol(&quot;token&quot;)
	
word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
		.setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
		.setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
		.setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \
		.setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal() \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) \
    .setOutputCol(&quot;ner_chunk&quot;)\
    .setPreservePosition(False)

chunk2doc = Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;)

sbert_embedder = BertSentenceEmbeddings\
    .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;ner_chunk_doc&quot;])\
    .setOutputCol(&quot;sbert_embeddings&quot;)

resolver = SentenceEntityResolverModel\
    .pretrained(&quot;sbiobertresolve_ncit&quot;,&quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) \
    .setOutputCol(&quot;resolution&quot;)\
    .setDistanceFunction(&quot;EUCLIDEAN&quot;)


nlpPipeline = Pipeline(stages=[document_assembler, 
                               sentence_detector, 
                               tokenizer, 
                               word_embeddings, 
                               ner_model, 
                               ner_converter, 
                               chunk2doc, 
                               sbert_embedder, 
                               resolver])

data = spark.createDataFrame([[&quot;&quot;&quot;45 years old patient had Percutaneous mitral valve repair. He had Pericardiectomy 2 years ago. He has left cardiac ventricular systolic dysfunction in his history.&quot;&quot;&quot;]]).toDF(&quot;text&quot;)

results = nlpPipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)


val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
  .setInputCols(Array(&quot;document&quot;))
  .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
  .setInputCols(Array(&quot;sentence&quot;))
  .setOutputCol(&quot;token&quot;)


val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;))
  .setOutputCol(&quot;embeddings&quot;)


val clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;))
  .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverter()
  .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;))
  .setOutputCol(&quot;ner_chunk&quot;)

val chunk2doc = new Chunk2Doc()
  .setInputCols(&quot;ner_chunk&quot;)
  .setOutputCol(&quot;ner_chunk_doc&quot;)

val sbert_embedder = BertSentenceEmbeddings
  .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
  .setInputCols(Array(&quot;ner_chunk_doc&quot;))
  .setOutputCol(&quot;sbert_embeddings&quot;)

val resolver = SentenceEntityResolverModel
  .pretrained(&quot;sbiobertresolve_ncit&quot;,&quot;en&quot;, &quot;clinical/models&quot;) 
  .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;)) 
  .setOutputCol(&quot;resolution&quot;)
  .setDistanceFunction(&quot;EUCLIDEAN&quot;)

val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver))

val data = Seq(&quot;45 years old patient had Percutaneous mitral valve repair. He had Pericardiectomy 2 years ago. He has left cardiac ventricular systolic dysfunction in his history.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
|   sent_id | ner_chunk                                     | entity    | NCI-t Code   | all_codes                                          | resolutions                                                                                                                              |
|----------:|:----------------------------------------------|:----------|:-------------|:---------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
|         0 | Percutaneous mitral valve repair              | TREATMENT | C100003      | ['C100003', 'C158019', 'C80449', 'C50818', 'C80448'| ['percutaneous mitral valve repair [percutaneous mitral valve repair]', 'transcatheter mitral valve repair [transcatheter mitral valve...|
|         1 | Pericardiectomy                               | TREATMENT | C51643       | ['C51643', 'C51618', 'C100004', 'C62550', 'C51791' | ['pericardiectomy [pericardiectomy]', 'pericardiostomy [pericardiostomy]', 'pericardial stripping [pericardial stripping]', 'pulpectom...|
|         2 | left cardiac ventricular systolic dysfunction | PROBLEM   | C64251       | ['C64251', 'C146719', 'C55062', 'C50629', 'C111655'| ['left cardiac ventricular systolic dysfunction [left cardiac ventricular systolic dysfunction]', 'left ventricular systolic dysfuncti...|
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|sbiobertresolve_ncit|
|Compatibility:|Healthcare NLP 4.3.2+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[nci-t_code]|
|Language:|en|
|Size:|1.5 GB|
|Case sensitive:|false|

## References

https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/</content><author><name>John Snow Labs</name></author><category term="entity_resolution" /><category term="clinical" /><category term="en" /><category term="licensed" /><category term="ncit" /><summary type="html">Description This model maps extracted medical entities related to clinical care, translational and basic research, public information and administrative activities to NCI-t codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Predicted Entities NCI-t codes Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal() \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) \ .setOutputCol(&quot;ner_chunk&quot;)\ .setPreservePosition(False) chunk2doc = Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings\ .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;ner_chunk_doc&quot;])\ .setOutputCol(&quot;sbert_embeddings&quot;) resolver = SentenceEntityResolverModel\ .pretrained(&quot;sbiobertresolve_ncit&quot;,&quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) \ .setOutputCol(&quot;resolution&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, ner_model, ner_converter, chunk2doc, sbert_embedder, resolver]) data = spark.createDataFrame([[&quot;&quot;&quot;45 years old patient had Percutaneous mitral valve repair. He had Pericardiectomy 2 years ago. He has left cardiac ventricular systolic dysfunction in his history.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) results = nlpPipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverter() .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val chunk2doc = new Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunk_doc&quot;)) .setOutputCol(&quot;sbert_embeddings&quot;) val resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_ncit&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, resolver)) val data = Seq(&quot;45 years old patient had Percutaneous mitral valve repair. He had Pericardiectomy 2 years ago. He has left cardiac ventricular systolic dysfunction in his history.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results | sent_id | ner_chunk | entity | NCI-t Code | all_codes | resolutions | |----------:|:----------------------------------------------|:----------|:-------------|:---------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------| | 0 | Percutaneous mitral valve repair | TREATMENT | C100003 | ['C100003', 'C158019', 'C80449', 'C50818', 'C80448'| ['percutaneous mitral valve repair [percutaneous mitral valve repair]', 'transcatheter mitral valve repair [transcatheter mitral valve...| | 1 | Pericardiectomy | TREATMENT | C51643 | ['C51643', 'C51618', 'C100004', 'C62550', 'C51791' | ['pericardiectomy [pericardiectomy]', 'pericardiostomy [pericardiostomy]', 'pericardial stripping [pericardial stripping]', 'pulpectom...| | 2 | left cardiac ventricular systolic dysfunction | PROBLEM | C64251 | ['C64251', 'C146719', 'C55062', 'C50629', 'C111655'| ['left cardiac ventricular systolic dysfunction [left cardiac ventricular systolic dysfunction]', 'left ventricular systolic dysfuncti...| Model Information Model Name: sbiobertresolve_ncit Compatibility: Healthcare NLP 4.3.2+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [nci-t_code] Language: en Size: 1.5 GB Case sensitive: false References https://evs.nci.nih.gov/ftp1/NCI_Thesaurus/</summary></entry></feed>