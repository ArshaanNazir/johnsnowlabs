{
  "0": {
    "id": "0",
    "title": "404",
    "content": "404 Page not found :( &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;script async src=https://www.googletagmanager.com/gtag/js?id=UA-70312582-1&gt;&lt;/script&gt; SDOH Under Treatment For Classification HomeDocsLearnModelsDemo Edit on GitHub John Snow Labs Apr 10, 2023 SDOH Under Treatment For Classificationenlicencedclinicalsdohgeneric_classifierunder_treatmentbiobertlicensed Description This Generic Classifier model is intended for detecting if the patient is under treatment or not. If under treatment is not mentioned in the text, it is regarded as “not under treatment”. The model is trained by using GenericClassifierApproach annotator. Under_Treatment: The patient is under treatment. Not_Under_Treatment_Or_Not_Mentioned: The patient is not under treatment or it is not mentioned in the clinical notes. Predicted Entities Under_Treatment, Not_Under_Treatment_Or_Not_Mentioned Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) features_asm = FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;features&quot;) generic_classifier = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_under_treatment_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_embeddings, features_asm, generic_classifier ]) text_list = [&quot;&quot;&quot;Sarah, a 55-year-old woman with a history of high cholesterol and a family history of heart disease, presented to her primary care physician with complaints of chest pain and shortness of breath. After a thorough evaluation, Sarah was diagnosed with coronary artery disease (CAD), a condition that can lead to heart attacks and other serious complications. To manage her CAD, Sarah was started on a treatment plan that included medication to lower her cholesterol and blood pressure, as well as aspirin to prevent blood clots. In addition to medication, Sarah was advised to make lifestyle modifications such as improving her diet, quitting smoking, and increasing physical activity. Over the course of several months, Sarah&#39;s symptoms improved, and follow-up tests showed that her cholesterol and blood pressure were within the target range. However, Sarah continued to experience occasional chest pain, and her medication regimen was adjusted accordingly. With regular follow-up appointments and adherence to her treatment plan, Sarah&#39;s CAD remained under control, and she was able to resume her normal activities with improved quality of life. &quot;&quot;&quot;, &quot;&quot;&quot;John, a 60-year-old man with a history of smoking and high blood pressure, presented to his primary care physician with complaints of chest pain and shortness of breath. Further tests revealed that John had a blockage in one of his coronary arteries, which required urgent intervention. However, John was hesitant to undergo treatment, citing concerns about potential complications and side effects of medications and procedures. Despite the physician&#39;s recommendations and attempts to educate John about the risks of leaving the blockage untreated, John ultimately chose not to pursue any treatment. Over the next several months, John continued to experience symptoms, which progressively worsened, and he ultimately required hospitalization for a heart attack. The medical team attempted to intervene at that point, but the damage to John&#39;s heart was severe, and his prognosis was poor. &quot;&quot;&quot;] df = spark.createDataFrame(text_list, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(df).transform(df) result.select(&quot;text&quot;, &quot;class.result&quot;).show(truncate=100) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val features_asm = new FeaturesAssembler() .setInputCols(&quot;sentence_embeddings&quot;) .setOutputCol(&quot;features&quot;) val generic_classifier = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_under_treatment_sbiobert_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;class&quot;) val pipeline = new PipelineModel().setStages(Array( document_assembler, sentence_embeddings, features_asm, generic_classifier)) val data = Seq(Array(&quot;&quot;&quot;Sarah, a 55-year-old woman with a history of high cholesterol and a family history of heart disease, presented to her primary care physician with complaints of chest pain and shortness of breath. After a thorough evaluation, Sarah was diagnosed with coronary artery disease (CAD), a condition that can lead to heart attacks and other serious complications. To manage her CAD, Sarah was started on a treatment plan that included medication to lower her cholesterol and blood pressure, as well as aspirin to prevent blood clots. In addition to medication, Sarah was advised to make lifestyle modifications such as improving her diet, quitting smoking, and increasing physical activity. Over the course of several months, Sarah&#39;s symptoms improved, and follow-up tests showed that her cholesterol and blood pressure were within the target range. However, Sarah continued to experience occasional chest pain, and her medication regimen was adjusted accordingly. With regular follow-up appointments and adherence to her treatment plan, Sarah&#39;s CAD remained under control, and she was able to resume her normal activities with improved quality of life. &quot;&quot;&quot;, &quot;&quot;&quot;John, a 60-year-old man with a history of smoking and high blood pressure, presented to his primary care physician with complaints of chest pain and shortness of breath. Further tests revealed that John had a blockage in one of his coronary arteries, which required urgent intervention. However, John was hesitant to undergo treatment, citing concerns about potential complications and side effects of medications and procedures. Despite the physician&#39;s recommendations and attempts to educate John about the risks of leaving the blockage untreated, John ultimately chose not to pursue any treatment. Over the next several months, John continued to experience symptoms, which progressively worsened, and he ultimately required hospitalization for a heart attack. The medical team attempted to intervene at that point, but the damage to John&#39;s heart was severe, and his prognosis was poor. &quot;&quot;&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-+--+ | text| result| +-+--+ |Sarah, a 55-year-old woman with a history of high cholesterol and a family history of heart disea...| [Under_Treatment]| |John, a 60-year-old man with a history of smoking and high blood pressure, presented to his prima...|[Not_Under_Treatment_Or_Not_Mentioned]| +-+--+ Model Information Model Name: genericclassifier_sdoh_under_treatment_sbiobert_cased_mli Compatibility: Healthcare NLP 4.3.2+ License: Licensed Edition: Official Input Labels: [features] Output Labels: [prediction] Language: en Size: 3.4 MB Dependencies: sbiobert_base_cased_mli References Internal SDOH Project Benchmarking label precision recall f1-score support Not_Under_Treatment_Or_Not_Mentioned 0.86 0.68 0.76 222 Under_Treatment 0.86 0.94 0.90 450 accuracy - - 0.86 672 macro-avg 0.86 0.81 0.83 672 weighted-avg 0.86 0.86 0.85 672 PREVIOUSSDOH Mental Health For Classification © John Snow Labs Inc. Terms of Service | Privacy Policy &lt;/html&gt;",
    "url": "/404.html",
    "relUrl": "/404.html"
  },
  "1": {
    "id": "1",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSAnonymousCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSAnonymousCredentials.html"
  },
  "2": {
    "id": "2",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSBasicCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSBasicCredentials.html"
  },
  "3": {
    "id": "3",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSCredentialsProvider.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSCredentialsProvider.html"
  },
  "4": {
    "id": "4",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSGateway.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSGateway.html"
  },
  "5": {
    "id": "5",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSProfileCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSProfileCredentials.html"
  },
  "6": {
    "id": "6",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/AWSTokenCredentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/AWSTokenCredentials.html"
  },
  "7": {
    "id": "7",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ActivationFunction$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ActivationFunction$.html"
  },
  "8": {
    "id": "8",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/AgeToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/AgeToken.html"
  },
  "9": {
    "id": "9",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton$Node.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton$Node.html"
  },
  "10": {
    "id": "10",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/AhoCorasickAutomaton.html"
  },
  "11": {
    "id": "11",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings$.html"
  },
  "12": {
    "id": "12",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.html"
  },
  "13": {
    "id": "13",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering$.html"
  },
  "14": {
    "id": "14",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering.html"
  },
  "15": {
    "id": "15",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification$.html"
  },
  "16": {
    "id": "16",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification.html"
  },
  "17": {
    "id": "17",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification$.html"
  },
  "18": {
    "id": "18",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification.html"
  },
  "19": {
    "id": "19",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Alphabet.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Alphabet.html"
  },
  "20": {
    "id": "20",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated$.html"
  },
  "21": {
    "id": "21",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Annotated.html"
  },
  "22": {
    "id": "22",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$AnnotationContainer.html"
  },
  "23": {
    "id": "23",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$$AnnotationData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$$AnnotationData.html"
  },
  "24": {
    "id": "24",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$$extractors$.html"
  },
  "25": {
    "id": "25",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation$.html"
  },
  "26": {
    "id": "26",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Annotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Annotation.html"
  },
  "27": {
    "id": "27",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AnnotationContainer.html"
  },
  "28": {
    "id": "28",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AudioFields.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$$AudioFields.html"
  },
  "29": {
    "id": "29",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio$.html"
  },
  "30": {
    "id": "30",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationAudio.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationAudio.html"
  },
  "31": {
    "id": "31",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$$AnnotationContainer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$$AnnotationContainer.html"
  },
  "32": {
    "id": "32",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$$ImageFields.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$$ImageFields.html"
  },
  "33": {
    "id": "33",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage$.html"
  },
  "34": {
    "id": "34",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotationImage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotationImage.html"
  },
  "35": {
    "id": "35",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorApproach.html"
  },
  "36": {
    "id": "36",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorModel.html"
  },
  "37": {
    "id": "37",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$$SerializableDateFormat.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$$SerializableDateFormat.html"
  },
  "38": {
    "id": "38",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam$SerializableFormat$.html"
  },
  "39": {
    "id": "39",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/AnnotatorParam.html"
  },
  "40": {
    "id": "40",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AnnotatorType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AnnotatorType$.html"
  },
  "41": {
    "id": "41",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/ArrayFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/ArrayFeature.html"
  },
  "42": {
    "id": "42",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Attr.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Attr.html"
  },
  "43": {
    "id": "43",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/AttrFeature.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/AttrFeature.html"
  },
  "44": {
    "id": "44",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/AttrStat.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/AttrStat.html"
  },
  "45": {
    "id": "45",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AudioAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AudioAssembler$.html"
  },
  "46": {
    "id": "46",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/AudioAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/AudioAssembler.html"
  },
  "47": {
    "id": "47",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/AveragedPerceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/AveragedPerceptron.html"
  },
  "48": {
    "id": "48",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Benchmark$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Benchmark$.html"
  },
  "49": {
    "id": "49",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings$.html"
  },
  "50": {
    "id": "50",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.html"
  },
  "51": {
    "id": "51",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering$.html"
  },
  "52": {
    "id": "52",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.html"
  },
  "53": {
    "id": "53",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification$.html"
  },
  "54": {
    "id": "54",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification.html"
  },
  "55": {
    "id": "55",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification$.html"
  },
  "56": {
    "id": "56",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification.html"
  },
  "57": {
    "id": "57",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings$.html"
  },
  "58": {
    "id": "58",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html"
  },
  "59": {
    "id": "59",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher$.html"
  },
  "60": {
    "id": "60",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher.html"
  },
  "61": {
    "id": "61",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel$.html"
  },
  "62": {
    "id": "62",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel.html"
  },
  "63": {
    "id": "63",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/BpeTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/BpeTokenizer$.html"
  },
  "64": {
    "id": "64",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Build$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Build$.html"
  },
  "65": {
    "id": "65",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/BytesKey.html",
    "relUrl": "/api/com/johnsnowlabs/storage/BytesKey.html"
  },
  "66": {
    "id": "66",
    "title": "CPU NER Benchmarks",
    "content": "CPU NER Benchmarks NER (BiLSTM-CNN-Char Architecture) CPU Benchmark Experiment Dataset : 1000 Clinical Texts from MTSamples Oncology Dataset, approx. 500 tokens per text. Versions : spark-nlp Version: v3.4.4 spark-nlp-jsl Version : v3.5.2 Spark Version : v3.1.2 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings_clinical, clinical_ner, ner_converter ]) NOTE: Spark NLP Pipeline output data frame (except word_embeddings column) was written as parquet format in transform benchmarks. Plarform Process Repartition Time 2 CPU cores, 13 GB RAM (Google COLAB) LP (fullAnnotate) - 16min 52s Transform (parquet) 10 4min 47s 100 4min 16s 1000 5min 4s 16 CPU cores, 27 GB RAM (AWS EC2 machine) LP (fullAnnotate) - 14min 28s Transform (parquet) 10 1min 5s 100 1min 1s 1000 1min 19s",
    "url": "/docs/en/cpu-ner-benchmark",
    "relUrl": "/docs/en/cpu-ner-benchmark"
  },
  "67": {
    "id": "67",
    "title": "GPU vs CPU benchmark",
    "content": "",
    "url": "/docs/en/CPUvsGPUbenchmark",
    "relUrl": "/docs/en/CPUvsGPUbenchmark"
  },
  "68": {
    "id": "68",
    "title": "GPU vs CPU benchmark",
    "content": "This section includes a benchmark for MedicalNerApproach(), comparing its performance when running in m5.8xlarge CPU vs a Tesla V100 SXM2 GPU, as described in the Machine Specs section below. Big improvements have been carried out from version 3.3.4, so please, make sure you use at least that version to fully levearge Spark NLP capabilities on GPU. Machine specs CPU An AWS m5.8xlarge machine was used for the CPU benchmarking. This machine consists of 32 vCPUs and 128 GB of RAM, as you can check in the official specification webpage available here GPU A Tesla V100 SXM2 GPU with 32GB of memory was used to calculate the GPU benchmarking. Versions The benchmarking was carried out with the following Spark NLP versions: Spark version: 3.0.2 Hadoop version: 3.2.0 SparkNLP version: 3.3.4 SparkNLP for Healthcare version: 3.3.4 Spark nodes: 1 Benchmark on MedicalNerDLApproach() This experiment consisted of training a Name Entity Recognition model (token-level), using our class NerDLApproach(), using Bert Word Embeddings and a Char-CNN-BiLSTM Neural Network. Only 1 Spark node was used for the training. We used the Spark NLP class MedicalNer and it’s method Approach() as described in the documentation. The pipeline looks as follows: Dataset The size of the dataset was small (17K), consisting of: Training (rows): 14041 Test (rows): 3250 Training params Different batch sizes were tested to demonstrate how GPU performance improves with bigger batches compared to CPU, for a constant number of epochs and learning rate. Epochs: 10 Learning rate: 0.003 Batch sizes: 32, 64, 256, 512, 1024, 2048 Results Even for this small dataset, we can observe that GPU is able to beat the CPU machine by a 62% in training time and a 68% in inference times. It’s important to mention that the batch size is very relevant when using GPU, since CPU scales much worse with bigger batch sizes than GPU. Training times depending on batch (in minutes) Batch size CPU GPU 32 9.5 10 64 8.1 6.5 256 6.9 3.5 512 6.7 3 1024 6.5 2.5 2048 6.5 2.5 Inference times (in minutes) Although CPU times in inference remain more or less constant regardless the batch sizes, GPU time experiment good improvements the bigger the batch size is. CPU times: ~29 min Batch size GPU 32 10 64 6.5 256 3.5 512 3 1024 2.5 2048 2.5 Performance metrics A macro F1-score of about 0.92 (0.90 in micro) was achieved, with the following charts extracted from the MedicalNerApproach() logs: Takeaways: How to get the best of the GPU You will experiment big GPU improvements in the following cases: Embeddings and Transformers are used in your pipeline. Take into consideration that GPU will performance very well in Embeddings / Transformer components, but other components of your pipeline may not leverage as well GPU capabilities; Bigger batch sizes get the best of GPU, while CPU does not scale with bigger batch sizes; Bigger dataset sizes get the best of GPU, while may be a bottleneck while running in CPU and lead to performance drops; MultiGPU Inference on Databricks In this part, we will give you an idea on how to choose appropriate hardware specifications for Databricks. Here is a few different hardwares, their prices, as well as their performance: Apparently, GPU hardware is the cheapest among them although it performs the best. Let’s see how overall performance looks like: Figure above clearly shows us that GPU should be the first option of ours. In conclusion, please find the best specifications for your use case since these benchmarks might depend on dataset size, inference batch size, quickness, pricing and so on. Please refer to this video for further info: https://events.johnsnowlabs.com/webinar-speed-optimization-benchmarks-in-spark-nlp-3-making-the-most-of-modern-hardware?hsCtaTracking=a9bb6358-92bd-4cf3-b97c-e76cb1dfb6ef%7C4edba435-1adb-49fc-83fd-891a7506a417 MultiGPU training Currently, we don’t support multiGPU training, meaning training 1 model in different GPUs in parallel. However, you can train different models in different GPUs. MultiGPU inference Spark NLP can carry out MultiGPU inference if GPUs are in different cluster nodes. For example, if you have a cluster with different GPUs, you can repartition your data to match the number of GPU nodes and then coalesce to retrieve the results back to the master node. Currently, inference on multiple GPUs on the same machine is not supported. Where to look for more information about Training Please, take a look at the Spark NLP and Spark NLP for Healthcare Training sections, and feel free to reach us out in case you want to maximize the performance on your GPU.",
    "url": "/docs/en/CPUvsGPUbenchmark_healthcare",
    "relUrl": "/docs/en/CPUvsGPUbenchmark_healthcare"
  },
  "69": {
    "id": "69",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings$.html"
  },
  "70": {
    "id": "70",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings.html"
  },
  "71": {
    "id": "71",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering$.html"
  },
  "72": {
    "id": "72",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering.html"
  },
  "73": {
    "id": "73",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification$.html"
  },
  "74": {
    "id": "74",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification.html"
  },
  "75": {
    "id": "75",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification$.html"
  },
  "76": {
    "id": "76",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification.html"
  },
  "77": {
    "id": "77",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/CanBeLazy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/CanBeLazy.html"
  },
  "78": {
    "id": "78",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/CandidateStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/CandidateStrategy$.html"
  },
  "79": {
    "id": "79",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc$.html"
  },
  "80": {
    "id": "80",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunk2Doc.html"
  },
  "81": {
    "id": "81",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings$.html"
  },
  "82": {
    "id": "82",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings.html"
  },
  "83": {
    "id": "83",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/ChunkSplit$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/ChunkSplit$.html"
  },
  "84": {
    "id": "84",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer$.html"
  },
  "85": {
    "id": "85",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer.html"
  },
  "86": {
    "id": "86",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel$.html"
  },
  "87": {
    "id": "87",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel.html"
  },
  "88": {
    "id": "88",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunker$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunker$.html"
  },
  "89": {
    "id": "89",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Chunker.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Chunker.html"
  },
  "90": {
    "id": "90",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach$.html"
  },
  "91": {
    "id": "91",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.html"
  },
  "92": {
    "id": "92",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel$.html"
  },
  "93": {
    "id": "93",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.html"
  },
  "94": {
    "id": "94",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoder.html"
  },
  "95": {
    "id": "95",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoderParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ClassifierDatasetEncoderParams.html"
  },
  "96": {
    "id": "96",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierEncoder.html"
  },
  "97": {
    "id": "97",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierMetrics.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierMetrics.html"
  },
  "98": {
    "id": "98",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLL.html"
  },
  "99": {
    "id": "99",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLL2003NerReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLL2003NerReader.html"
  },
  "100": {
    "id": "100",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLDocument.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLDocument.html"
  },
  "101": {
    "id": "101",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/CoNLLGenerator$.html",
    "relUrl": "/api/com/johnsnowlabs/util/CoNLLGenerator$.html"
  },
  "102": {
    "id": "102",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLSentenceCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLSentenceCols.html"
  },
  "103": {
    "id": "103",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLTokenCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$$CoNLLTokenCols.html"
  },
  "104": {
    "id": "104",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLHelper$.html"
  },
  "105": {
    "id": "105",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLU.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLU.html"
  },
  "106": {
    "id": "106",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLUCols$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLUCols$.html"
  },
  "107": {
    "id": "107",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/CoNLLUDocument.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/CoNLLUDocument.html"
  },
  "108": {
    "id": "108",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Collector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Collector.html"
  },
  "109": {
    "id": "109",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/Comet.html",
    "relUrl": "/api/python/third_party/Comet.html"
  },
  "110": {
    "id": "110",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ConfigHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ConfigHelper$.html"
  },
  "111": {
    "id": "111",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ConfigLoader$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ConfigLoader$.html"
  },
  "112": {
    "id": "112",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/Conll09Reader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/Conll09Reader.html"
  },
  "113": {
    "id": "113",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ConllData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ConllData.html"
  },
  "114": {
    "id": "114",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/ConllSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/ConllSentence.html"
  },
  "115": {
    "id": "115",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllUReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllUReader.html"
  },
  "116": {
    "id": "116",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/ConllWriter.html"
  },
  "117": {
    "id": "117",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach$ArrayHelper.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach$ArrayHelper.html"
  },
  "118": {
    "id": "118",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.html"
  },
  "119": {
    "id": "119",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$.html"
  },
  "120": {
    "id": "120",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$StringTools.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel$StringTools.html"
  },
  "121": {
    "id": "121",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.html"
  },
  "122": {
    "id": "122",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/CredentialParams.html",
    "relUrl": "/api/com/johnsnowlabs/client/CredentialParams.html"
  },
  "123": {
    "id": "123",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/Credentials.html",
    "relUrl": "/api/com/johnsnowlabs/client/aws/Credentials.html"
  },
  "124": {
    "id": "124",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/CrfDataset.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/CrfDataset.html"
  },
  "125": {
    "id": "125",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/CrfParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/CrfParams.html"
  },
  "126": {
    "id": "126",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/CustomPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/CustomPragmaticMethod.html"
  },
  "127": {
    "id": "127",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/Database$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/Database$.html"
  },
  "128": {
    "id": "128",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/Database.html",
    "relUrl": "/api/com/johnsnowlabs/storage/Database.html"
  },
  "129": {
    "id": "129",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetEncoder.html"
  },
  "130": {
    "id": "130",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/DatasetEncoderParams.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/DatasetEncoderParams.html"
  },
  "131": {
    "id": "131",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$$DataFrameHelper.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$$DataFrameHelper.html"
  },
  "132": {
    "id": "132",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DatasetHelpers$.html"
  },
  "133": {
    "id": "133",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetMetadata.html"
  },
  "134": {
    "id": "134",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/DatasetReader$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/DatasetReader$.html"
  },
  "135": {
    "id": "135",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk$.html"
  },
  "136": {
    "id": "136",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Date2Chunk.html"
  },
  "137": {
    "id": "137",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher$.html"
  },
  "138": {
    "id": "138",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcher.html"
  },
  "139": {
    "id": "139",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslator.html"
  },
  "140": {
    "id": "140",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslatorPolicy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherTranslatorPolicy.html"
  },
  "141": {
    "id": "141",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DateMatcherUtils.html"
  },
  "142": {
    "id": "142",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/DateToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/DateToken.html"
  },
  "143": {
    "id": "143",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/DeBerta.html",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/DeBerta.html"
  },
  "144": {
    "id": "144",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings$.html"
  },
  "145": {
    "id": "145",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings.html"
  },
  "146": {
    "id": "146",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering$.html"
  },
  "147": {
    "id": "147",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering.html"
  },
  "148": {
    "id": "148",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification$.html"
  },
  "149": {
    "id": "149",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification.html"
  },
  "150": {
    "id": "150",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification$.html"
  },
  "151": {
    "id": "151",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification.html"
  },
  "152": {
    "id": "152",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/DefaultPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/DefaultPragmaticMethod.html"
  },
  "153": {
    "id": "153",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyArcList.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyArcList.html"
  },
  "154": {
    "id": "154",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyInstance.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyInstance.html"
  },
  "155": {
    "id": "155",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DependencyLabel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DependencyLabel.html"
  },
  "156": {
    "id": "156",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$.html"
  },
  "157": {
    "id": "157",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$CurrentState.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$CurrentState.html"
  },
  "158": {
    "id": "158",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$ParseState.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker$ParseState.html"
  },
  "159": {
    "id": "159",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/DependencyMaker.html"
  },
  "160": {
    "id": "160",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsed$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsed$.html"
  },
  "161": {
    "id": "161",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/DependencyParsedSentence.html"
  },
  "162": {
    "id": "162",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach$.html"
  },
  "163": {
    "id": "163",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.html"
  },
  "164": {
    "id": "164",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel$.html"
  },
  "165": {
    "id": "165",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.html"
  },
  "166": {
    "id": "166",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyPipe.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/DependencyPipe.html"
  },
  "167": {
    "id": "167",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/DependencyReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/DependencyReader.html"
  },
  "168": {
    "id": "168",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Dictionary.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Dictionary.html"
  },
  "169": {
    "id": "169",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures$.html"
  },
  "170": {
    "id": "170",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/DictionaryFeatures.html"
  },
  "171": {
    "id": "171",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DictionarySet.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/DictionarySet.html"
  },
  "172": {
    "id": "172",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings$.html"
  },
  "173": {
    "id": "173",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings.html"
  },
  "174": {
    "id": "174",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering$.html"
  },
  "175": {
    "id": "175",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering.html"
  },
  "176": {
    "id": "176",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification$.html"
  },
  "177": {
    "id": "177",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification.html"
  },
  "178": {
    "id": "178",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification$.html"
  },
  "179": {
    "id": "179",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification.html"
  },
  "180": {
    "id": "180",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Doc2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Doc2Chunk$.html"
  },
  "181": {
    "id": "181",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Doc2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Doc2Chunk.html"
  },
  "182": {
    "id": "182",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach$.html"
  },
  "183": {
    "id": "183",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach.html"
  },
  "184": {
    "id": "184",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel$.html"
  },
  "185": {
    "id": "185",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel.html"
  },
  "186": {
    "id": "186",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/DocumentAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/DocumentAssembler$.html"
  },
  "187": {
    "id": "187",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/DocumentAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/DocumentAssembler.html"
  },
  "188": {
    "id": "188",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer$.html"
  },
  "189": {
    "id": "189",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.html"
  },
  "190": {
    "id": "190",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/EdgeCalculator$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/EdgeCalculator$.html"
  },
  "191": {
    "id": "191",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings$.html"
  },
  "192": {
    "id": "192",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.html"
  },
  "193": {
    "id": "193",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage$CoverageResult.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage$CoverageResult.html"
  },
  "194": {
    "id": "194",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/EmbeddingsCoverage.html"
  },
  "195": {
    "id": "195",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher$.html"
  },
  "196": {
    "id": "196",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/EmbeddingsFinisher.html"
  },
  "197": {
    "id": "197",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/EmbeddingsWithSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/EmbeddingsWithSentence$.html"
  },
  "198": {
    "id": "198",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/EnglishStemmer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/EnglishStemmer$.html"
  },
  "199": {
    "id": "199",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityPattern.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityPattern.html"
  },
  "200": {
    "id": "200",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach.html"
  },
  "201": {
    "id": "201",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerFeatures.html"
  },
  "202": {
    "id": "202",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel$.html"
  },
  "203": {
    "id": "203",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel.html"
  },
  "204": {
    "id": "204",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerUtil$.html"
  },
  "205": {
    "id": "205",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/EvaluationDLParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/EvaluationDLParams.html"
  },
  "206": {
    "id": "206",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource$.html"
  },
  "207": {
    "id": "207",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ExternalResource.html"
  },
  "208": {
    "id": "208",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/ExternalResourceParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/ExternalResourceParam.html"
  },
  "209": {
    "id": "209",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/FbCalculator.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/FbCalculator.html"
  },
  "210": {
    "id": "210",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/Feature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/Feature.html"
  },
  "211": {
    "id": "211",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator$TokenType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator$TokenType$.html"
  },
  "212": {
    "id": "212",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/FeatureGenerator.html"
  },
  "213": {
    "id": "213",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/FeatureTemplate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/FeatureTemplate.html"
  },
  "214": {
    "id": "214",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/FeatureVector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/FeatureVector.html"
  },
  "215": {
    "id": "215",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/FeaturesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/FeaturesReader.html"
  },
  "216": {
    "id": "216",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/FeaturesWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/FeaturesWriter.html"
  },
  "217": {
    "id": "217",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/FileHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/FileHelper$.html"
  },
  "218": {
    "id": "218",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Finisher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Finisher$.html"
  },
  "219": {
    "id": "219",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/Finisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/Finisher.html"
  },
  "220": {
    "id": "220",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/FinisherUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/FinisherUtil$.html"
  },
  "221": {
    "id": "221",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/FlattenEntityPattern.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/FlattenEntityPattern.html"
  },
  "222": {
    "id": "222",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/gcp/GCPGateway.html",
    "relUrl": "/api/com/johnsnowlabs/client/gcp/GCPGateway.html"
  },
  "223": {
    "id": "223",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer$.html"
  },
  "224": {
    "id": "224",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.html"
  },
  "225": {
    "id": "225",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericRegexParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericRegexParser.html"
  },
  "226": {
    "id": "226",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericVocabParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/GenericVocabParser.html"
  },
  "227": {
    "id": "227",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/Gpt2Tokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/Gpt2Tokenizer.html"
  },
  "228": {
    "id": "228",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/GraphBuilder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/GraphBuilder.html"
  },
  "229": {
    "id": "229",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/GraphExtraction.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/GraphExtraction.html"
  },
  "230": {
    "id": "230",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/GraphFinisher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/GraphFinisher.html"
  },
  "231": {
    "id": "231",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/GreedyTransitionApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/GreedyTransitionApproach$.html"
  },
  "232": {
    "id": "232",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasAudioFeatureProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasAudioFeatureProperties.html"
  },
  "233": {
    "id": "233",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotate.html"
  },
  "234": {
    "id": "234",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateAudio.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateAudio.html"
  },
  "235": {
    "id": "235",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateImage.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasBatchedAnnotateImage.html"
  },
  "236": {
    "id": "236",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasCaseSensitiveProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasCaseSensitiveProperties.html"
  },
  "237": {
    "id": "237",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasClassifierActivationProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasClassifierActivationProperties.html"
  },
  "238": {
    "id": "238",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasConnection.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasConnection.html"
  },
  "239": {
    "id": "239",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/HasEmbeddingsProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/HasEmbeddingsProperties.html"
  },
  "240": {
    "id": "240",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasEnableCachingProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasEnableCachingProperties.html"
  },
  "241": {
    "id": "241",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasEngine.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasEngine.html"
  },
  "242": {
    "id": "242",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasFeatures.html"
  },
  "243": {
    "id": "243",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasImageFeatureProperties.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasImageFeatureProperties.html"
  },
  "244": {
    "id": "244",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasInputAnnotationCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasInputAnnotationCols.html"
  },
  "245": {
    "id": "245",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasMultipleInputAnnotationCols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasMultipleInputAnnotationCols.html"
  },
  "246": {
    "id": "246",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasOutputAnnotationCol.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasOutputAnnotationCol.html"
  },
  "247": {
    "id": "247",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasOutputAnnotatorType.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasOutputAnnotatorType.html"
  },
  "248": {
    "id": "248",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasPretrained.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasPretrained.html"
  },
  "249": {
    "id": "249",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasRecursiveFit.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasRecursiveFit.html"
  },
  "250": {
    "id": "250",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasRecursiveTransform.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasRecursiveTransform.html"
  },
  "251": {
    "id": "251",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/HasSimpleAnnotate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/HasSimpleAnnotate.html"
  },
  "252": {
    "id": "252",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorage.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorage.html"
  },
  "253": {
    "id": "253",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageModel.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageModel.html"
  },
  "254": {
    "id": "254",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageOptions.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageOptions.html"
  },
  "255": {
    "id": "255",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageReader.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageReader.html"
  },
  "256": {
    "id": "256",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageRef$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageRef$.html"
  },
  "257": {
    "id": "257",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/HasStorageRef.html",
    "relUrl": "/api/com/johnsnowlabs/storage/HasStorageRef.html"
  },
  "258": {
    "id": "258",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/HasTransducerFeatures.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/HasTransducerFeatures.html"
  },
  "259": {
    "id": "259",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC$.html"
  },
  "260": {
    "id": "260",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC.html"
  },
  "261": {
    "id": "261",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/IAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/IAnnotation.html"
  },
  "262": {
    "id": "262",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ImageAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ImageAssembler$.html"
  },
  "263": {
    "id": "263",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ImageAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ImageAssembler.html"
  },
  "264": {
    "id": "264",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedTaggedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedTaggedWord.html"
  },
  "265": {
    "id": "265",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/IndexedToken.html"
  },
  "266": {
    "id": "266",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken$.html"
  },
  "267": {
    "id": "267",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/InfixToken.html"
  },
  "268": {
    "id": "268",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Instance.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Instance.html"
  },
  "269": {
    "id": "269",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/InstanceLabels.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/InstanceLabels.html"
  },
  "270": {
    "id": "270",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/JavaAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/JavaAnnotation.html"
  },
  "271": {
    "id": "271",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/JsonParser$.html",
    "relUrl": "/api/com/johnsnowlabs/util/JsonParser$.html"
  },
  "272": {
    "id": "272",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/L2DecayStrategy.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/L2DecayStrategy.html"
  },
  "273": {
    "id": "273",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$$DependencyInfo.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$$DependencyInfo.html"
  },
  "274": {
    "id": "274",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/LabeledDependency$.html"
  },
  "275": {
    "id": "275",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/LangModelSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/LangModelSentence.html"
  },
  "276": {
    "id": "276",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL$.html"
  },
  "277": {
    "id": "277",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.html"
  },
  "278": {
    "id": "278",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer$.html"
  },
  "279": {
    "id": "279",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Lemmatizer.html"
  },
  "280": {
    "id": "280",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel$.html"
  },
  "281": {
    "id": "281",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html"
  },
  "282": {
    "id": "282",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$CachedItem.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$CachedItem.html"
  },
  "283": {
    "id": "283",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$DoubleLinked.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$DoubleLinked.html"
  },
  "284": {
    "id": "284",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache$FrequencyList.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache$FrequencyList.html"
  },
  "285": {
    "id": "285",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LfuCache.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LfuCache.html"
  },
  "286": {
    "id": "286",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/LightPipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/LightPipeline.html"
  },
  "287": {
    "id": "287",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/LinearChainCrf.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/LinearChainCrf.html"
  },
  "288": {
    "id": "288",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/LinearChainCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/LinearChainCrfModel.html"
  },
  "289": {
    "id": "289",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/LoadExternalModel$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/util/LoadExternalModel$.html"
  },
  "290": {
    "id": "290",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/LoadsContrib$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/LoadsContrib$.html"
  },
  "291": {
    "id": "291",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LocalFeatureData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LocalFeatureData.html"
  },
  "292": {
    "id": "292",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/LocationClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/LocationClass.html"
  },
  "293": {
    "id": "293",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/Logging.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/Logging.html"
  },
  "294": {
    "id": "294",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/LongMapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/LongMapAccumulator.html"
  },
  "295": {
    "id": "295",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings$.html"
  },
  "296": {
    "id": "296",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings.html"
  },
  "297": {
    "id": "297",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering$.html"
  },
  "298": {
    "id": "298",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering.html"
  },
  "299": {
    "id": "299",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification$.html"
  },
  "300": {
    "id": "300",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification.html"
  },
  "301": {
    "id": "301",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification$.html"
  },
  "302": {
    "id": "302",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification.html"
  },
  "303": {
    "id": "303",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/LookAroundManager$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/LookAroundManager$.html"
  },
  "304": {
    "id": "304",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LowRankTensor.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/LowRankTensor.html"
  },
  "305": {
    "id": "305",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriority.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriority.html"
  },
  "306": {
    "id": "306",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriorityOrdering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap$KeyPriorityOrdering$.html"
  },
  "307": {
    "id": "307",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/LruMap.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/LruMap.html"
  },
  "308": {
    "id": "308",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/MLflow.html",
    "relUrl": "/api/python/third_party/MLflow.html"
  },
  "309": {
    "id": "309",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MainVocab.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MainVocab.html"
  },
  "310": {
    "id": "310",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/MapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/MapAccumulator.html"
  },
  "311": {
    "id": "311",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/MapFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/MapFeature.html"
  },
  "312": {
    "id": "312",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer$.html"
  },
  "313": {
    "id": "313",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.html"
  },
  "314": {
    "id": "314",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/MatchStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/MatchStrategy$.html"
  },
  "315": {
    "id": "315",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MedicationClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/MedicationClass.html"
  },
  "316": {
    "id": "316",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/MergeTokenStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/MergeTokenStrategy$.html"
  },
  "317": {
    "id": "317",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/Metrics.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/Metrics.html"
  },
  "318": {
    "id": "318",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/MixedPragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/MixedPragmaticMethod.html"
  },
  "319": {
    "id": "319",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/ModelEngine$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/util/ModelEngine$.html"
  },
  "320": {
    "id": "320",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/ModelMetrics$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/ModelMetrics$.html"
  },
  "321": {
    "id": "321",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ModelSignature.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ModelSignature.html"
  },
  "322": {
    "id": "322",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMask$.html"
  },
  "323": {
    "id": "323",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMaskV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AttentionMaskV1$.html"
  },
  "324": {
    "id": "324",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AudioValuesInput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$AudioValuesInput$.html"
  },
  "325": {
    "id": "325",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DType$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DType$.html"
  },
  "326": {
    "id": "326",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderAttentionMask$.html"
  },
  "327": {
    "id": "327",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderAttentionMask$.html"
  },
  "328": {
    "id": "328",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderEncoderInputIds$.html"
  },
  "329": {
    "id": "329",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderInputIds$.html"
  },
  "330": {
    "id": "330",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DecoderOutput$.html"
  },
  "331": {
    "id": "331",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DimCount$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$DimCount$.html"
  },
  "332": {
    "id": "332",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderAttentionMask$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderAttentionMask$.html"
  },
  "333": {
    "id": "333",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderInputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderInputIds$.html"
  },
  "334": {
    "id": "334",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EncoderOutput$.html"
  },
  "335": {
    "id": "335",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EndLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$EndLogitsOutput$.html"
  },
  "336": {
    "id": "336",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIds$.html"
  },
  "337": {
    "id": "337",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIdsV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$InputIdsV1$.html"
  },
  "338": {
    "id": "338",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenState$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenState$.html"
  },
  "339": {
    "id": "339",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenStateV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LastHiddenStateV1$.html"
  },
  "340": {
    "id": "340",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$LogitsOutput$.html"
  },
  "341": {
    "id": "341",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$Name$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$Name$.html"
  },
  "342": {
    "id": "342",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PixelValuesInput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PixelValuesInput$.html"
  },
  "343": {
    "id": "343",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutput$.html"
  },
  "344": {
    "id": "344",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutputV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$PoolerOutputV1$.html"
  },
  "345": {
    "id": "345",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$SerializedSize$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$SerializedSize$.html"
  },
  "346": {
    "id": "346",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$ShapeDimList$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$ShapeDimList$.html"
  },
  "347": {
    "id": "347",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$StartLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$StartLogitsOutput$.html"
  },
  "348": {
    "id": "348",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoDescriptor.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoDescriptor.html"
  },
  "349": {
    "id": "349",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoNameMapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TFInfoNameMapper.html"
  },
  "350": {
    "id": "350",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsAggregationOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsAggregationOutput$.html"
  },
  "351": {
    "id": "351",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsOutput$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TapasLogitsOutput$.html"
  },
  "352": {
    "id": "352",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIds$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIds$.html"
  },
  "353": {
    "id": "353",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIdsV1$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$$TokenTypeIdsV1$.html"
  },
  "354": {
    "id": "354",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureConstants$.html"
  },
  "355": {
    "id": "355",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureManager$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/ModelSignatureManager$.html"
  },
  "356": {
    "id": "356",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach.html"
  },
  "357": {
    "id": "357",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel$.html"
  },
  "358": {
    "id": "358",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.html"
  },
  "359": {
    "id": "359",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher$.html"
  },
  "360": {
    "id": "360",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.html"
  },
  "361": {
    "id": "361",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/MultiDatePolicy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/MultiDatePolicy$.html"
  },
  "362": {
    "id": "362",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler$.html"
  },
  "363": {
    "id": "363",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/MultiDocumentAssembler.html"
  },
  "364": {
    "id": "364",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator$.html"
  },
  "365": {
    "id": "365",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NGramGenerator.html"
  },
  "366": {
    "id": "366",
    "title": "NLU under the hood",
    "content": "This page acts as reference on the internal working and implementation of NLU. It acts as a reference for internal development and open source contributers. How do NLU internals work? NLU defines a universe of components which act as building blocks of user definable machine learning pipelines. The possibilities of creating unique and useful pipelines with NLU are only limited by onces imagination and RAM. The NLU component universe There are many different types of Components in the NLU universe. Each of the components acts as a wrapper around multiple different Spark NLP transformers. NLU spellbook NLU defines a mapping for every of its model references to a specific Spark NLP model, pipeline or annotator. You can view the mapping in the [TODO] file . If no model is found, NLU will ping the John Snow Labs modelhub for any new models. If the modelhub cannot resolve a Spark NLP reference for a NLU reference. NLU whill throw an exception, indicating that a component could not be resolved. If the NLU reference points to a Spark NLP pipeline, it will unpack each model from the Spark NLP pipeline and and package it inside of corrosponding NLU components. NLU pipeline building steps A NLU pipeline object cann either be created via the nlu.load(‘nlu.reference’) API or alternatively via the nlu.build([Component1,Component2]) API. The pipeline will not start its building steps until the .predict() function is called for the first time on it. When .predict() is called, the following steps occur Check for every NLU component, wether all its inputs are satisfied. I.e. if a user builds a pipeline with a classifier model in it but does not provide any embeddings. NLU will auto resolve the correct embeddings for the passed model Check and fix for every model if the input names align with the output names of the components they depend on. Check and fix for every model that it is in the correct order in the pipeline. I.e. a sentence classifier must come after the sentence embeddings are generated in the pipeline, not before. NLU output generation steps The .predict() method invokes a series of steps to ensure that the generated output is in the most usable format for further downstream ML tasks. The steps are the following : NLU converts the input data to a Spark Dataframe and lets the pipeline transform it to a new Spark Dataframe which contains all the features If the output level is not set by the user, it will check what is the last component of the pipe and the infer from that what the output level should be. Each components default output level can be viewed in its corrosponding component.json file. Some components output level depend on their input, i.e classifiers can classify on sentences or documents. NLU does additional steps to infer the output level for these kinds of components. Decide which columns to keep and which to drop All the output columns that are at the same outputlevel as the pipe will be zipped and exploded. All columns which are at diferent output level will be selected from the Spark Dataframe, which results in lists in the final output. After all these steps the final pandas dataframe will be returned from the .predict() method",
    "url": "/docs/en/jsl/under_the_hood",
    "relUrl": "/docs/en/jsl/under_the_hood"
  },
  "367": {
    "id": "367",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NamedEntity.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NamedEntity.html"
  },
  "368": {
    "id": "368",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NamesClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NamesClass.html"
  },
  "369": {
    "id": "369",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerApproach.html"
  },
  "370": {
    "id": "370",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch$.html"
  },
  "371": {
    "id": "371",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerBatch.html"
  },
  "372": {
    "id": "372",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter$.html"
  },
  "373": {
    "id": "373",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html"
  },
  "374": {
    "id": "374",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach$.html"
  },
  "375": {
    "id": "375",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.html"
  },
  "376": {
    "id": "376",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel$.html"
  },
  "377": {
    "id": "377",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.html"
  },
  "378": {
    "id": "378",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach$.html"
  },
  "379": {
    "id": "379",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.html"
  },
  "380": {
    "id": "380",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel$.html"
  },
  "381": {
    "id": "381",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.html"
  },
  "382": {
    "id": "382",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModelPythonReader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModelPythonReader$.html"
  },
  "383": {
    "id": "383",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/NerDatasetEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/NerDatasetEncoder.html"
  },
  "384": {
    "id": "384",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter$.html"
  },
  "385": {
    "id": "385",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter.html"
  },
  "386": {
    "id": "386",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/NerTagged$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/NerTagged$.html"
  },
  "387": {
    "id": "387",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/NerTagsEncoding$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/NerTagsEncoding$.html"
  },
  "388": {
    "id": "388",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Normalizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Normalizer$.html"
  },
  "389": {
    "id": "389",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Normalizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Normalizer.html"
  },
  "390": {
    "id": "390",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$.html"
  },
  "391": {
    "id": "391",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$TokenizerAndNormalizerMap.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel$TokenizerAndNormalizerMap.html"
  },
  "392": {
    "id": "392",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/NormalizerModel.html"
  },
  "393": {
    "id": "393",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach$.html"
  },
  "394": {
    "id": "394",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.html"
  },
  "395": {
    "id": "395",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel$.html"
  },
  "396": {
    "id": "396",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.html"
  },
  "397": {
    "id": "397",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingParams.html"
  },
  "398": {
    "id": "398",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NumberToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/NumberToken.html"
  },
  "399": {
    "id": "399",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Options.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Options.html"
  },
  "400": {
    "id": "400",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/OutputHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/OutputHelper$.html"
  },
  "401": {
    "id": "401",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/POS.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/POS.html"
  },
  "402": {
    "id": "402",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Parameters.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/Parameters.html"
  },
  "403": {
    "id": "403",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesReadable.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesReadable.html"
  },
  "404": {
    "id": "404",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesWritable.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/ParamsAndFeaturesWritable.html"
  },
  "405": {
    "id": "405",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReadWriter.html"
  },
  "406": {
    "id": "406",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/PatternsReader.html"
  },
  "407": {
    "id": "407",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron$WeightLearner.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron$WeightLearner.html"
  },
  "408": {
    "id": "408",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Perceptron.html"
  },
  "409": {
    "id": "409",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach$.html"
  },
  "410": {
    "id": "410",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.html"
  },
  "411": {
    "id": "411",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed$.html"
  },
  "412": {
    "id": "412",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproachDistributed.html"
  },
  "413": {
    "id": "413",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel$.html"
  },
  "414": {
    "id": "414",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.html"
  },
  "415": {
    "id": "415",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronPredictionUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronPredictionUtils.html"
  },
  "416": {
    "id": "416",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronTrainingUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronTrainingUtils.html"
  },
  "417": {
    "id": "417",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronUtils.html"
  },
  "418": {
    "id": "418",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/PipelineModels$.html",
    "relUrl": "/api/com/johnsnowlabs/util/PipelineModels$.html"
  },
  "419": {
    "id": "419",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$$AnnotatorType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$$AnnotatorType$.html"
  },
  "420": {
    "id": "420",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/PoolingStrategy$.html"
  },
  "421": {
    "id": "421",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PosTagged$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PosTagged$.html"
  },
  "422": {
    "id": "422",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter$.html"
  },
  "423": {
    "id": "423",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter.html"
  },
  "424": {
    "id": "424",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticDictionaries$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticDictionaries$.html"
  },
  "425": {
    "id": "425",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticMethod.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticMethod.html"
  },
  "426": {
    "id": "426",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticScorer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticScorer.html"
  },
  "427": {
    "id": "427",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSentenceExtractor.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSentenceExtractor.html"
  },
  "428": {
    "id": "428",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSymbols$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticSymbols$.html"
  },
  "429": {
    "id": "429",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/PredictionParameters.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/PredictionParameters.html"
  },
  "430": {
    "id": "430",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken$.html"
  },
  "431": {
    "id": "431",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PrefixedToken.html"
  },
  "432": {
    "id": "432",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/PreprocessingParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/PreprocessingParser.html"
  },
  "433": {
    "id": "433",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/PretrainedAnnotations$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/PretrainedAnnotations$.html"
  },
  "434": {
    "id": "434",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline$.html"
  },
  "435": {
    "id": "435",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PretrainedPipeline.html"
  },
  "436": {
    "id": "436",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/PubTator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/PubTator.html"
  },
  "437": {
    "id": "437",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/PythonResourceDownloader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/PythonResourceDownloader$.html"
  },
  "438": {
    "id": "438",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RawAnnotator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RawAnnotator.html"
  },
  "439": {
    "id": "439",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadAlbertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadAlbertDLModel.html"
  },
  "440": {
    "id": "440",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForQuestionAnsweringDLModel.html"
  },
  "441": {
    "id": "441",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForSequenceDLModel.html"
  },
  "442": {
    "id": "442",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadAlbertForTokenDLModel.html"
  },
  "443": {
    "id": "443",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ReadAs$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ReadAs$.html"
  },
  "444": {
    "id": "444",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertDLModel.html"
  },
  "445": {
    "id": "445",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForQuestionAnsweringDLModel.html"
  },
  "446": {
    "id": "446",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForSequenceDLModel.html"
  },
  "447": {
    "id": "447",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadBertForTokenDLModel.html"
  },
  "448": {
    "id": "448",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadBertSentenceDLModel.html"
  },
  "449": {
    "id": "449",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadCamemBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadCamemBertDLModel.html"
  },
  "450": {
    "id": "450",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForQADLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForQADLModel.html"
  },
  "451": {
    "id": "451",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForSequenceDLModel.html"
  },
  "452": {
    "id": "452",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadCamemBertForTokenDLModel.html"
  },
  "453": {
    "id": "453",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadClassifierDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadClassifierDLTensorflowModel.html"
  },
  "454": {
    "id": "454",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadDeBertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadDeBertaDLModel.html"
  },
  "455": {
    "id": "455",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForQuestionAnsweringDLModel.html"
  },
  "456": {
    "id": "456",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForSequenceDLModel.html"
  },
  "457": {
    "id": "457",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDeBertaForTokenDLModel.html"
  },
  "458": {
    "id": "458",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadDistilBertDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadDistilBertDLModel.html"
  },
  "459": {
    "id": "459",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForQuestionAnsweringDLModel.html"
  },
  "460": {
    "id": "460",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForSequenceDLModel.html"
  },
  "461": {
    "id": "461",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadDistilBertForTokenDLModel.html"
  },
  "462": {
    "id": "462",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadElmoDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadElmoDLModel.html"
  },
  "463": {
    "id": "463",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadGPT2TransformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadGPT2TransformerDLModel.html"
  },
  "464": {
    "id": "464",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadHubertForAudioDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadHubertForAudioDLModel.html"
  },
  "465": {
    "id": "465",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadLanguageDetectorDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadLanguageDetectorDLTensorflowModel.html"
  },
  "466": {
    "id": "466",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadLongformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadLongformerDLModel.html"
  },
  "467": {
    "id": "467",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForQuestionAnsweringDLModel.html"
  },
  "468": {
    "id": "468",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForSequenceDLModel.html"
  },
  "469": {
    "id": "469",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadLongformerForTokenDLModel.html"
  },
  "470": {
    "id": "470",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadMarianMTDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadMarianMTDLModel.html"
  },
  "471": {
    "id": "471",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadMultiClassifierDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadMultiClassifierDLTensorflowModel.html"
  },
  "472": {
    "id": "472",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForQuestionAnsweringDLModel.html"
  },
  "473": {
    "id": "473",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForSequenceDLModel.html"
  },
  "474": {
    "id": "474",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadRoBertaForTokenDLModel.html"
  },
  "475": {
    "id": "475",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaDLModel.html"
  },
  "476": {
    "id": "476",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadRobertaSentenceDLModel.html"
  },
  "477": {
    "id": "477",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/ReadSentencePieceModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/ReadSentencePieceModel.html"
  },
  "478": {
    "id": "478",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadSentimentDLTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadSentimentDLTensorflowModel.html"
  },
  "479": {
    "id": "479",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadSpanBertCorefTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadSpanBertCorefTensorflowModel.html"
  },
  "480": {
    "id": "480",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadSwinForImageDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadSwinForImageDLModel.html"
  },
  "481": {
    "id": "481",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadT5TransformerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadT5TransformerDLModel.html"
  },
  "482": {
    "id": "482",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadTapasForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadTapasForQuestionAnsweringDLModel.html"
  },
  "483": {
    "id": "483",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/ReadTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/ReadTensorflowModel.html"
  },
  "484": {
    "id": "484",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadUSEDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadUSEDLModel.html"
  },
  "485": {
    "id": "485",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadViTForImageDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadViTForImageDLModel.html"
  },
  "486": {
    "id": "486",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadWav2Vec2ForAudioDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadWav2Vec2ForAudioDLModel.html"
  },
  "487": {
    "id": "487",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForQuestionAnsweringDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForQuestionAnsweringDLModel.html"
  },
  "488": {
    "id": "488",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForSequenceDLModel.html"
  },
  "489": {
    "id": "489",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlmRoBertaForTokenDLModel.html"
  },
  "490": {
    "id": "490",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaDLModel.html"
  },
  "491": {
    "id": "491",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaSentenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlmRobertaSentenceDLModel.html"
  },
  "492": {
    "id": "492",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlnetDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadXlnetDLModel.html"
  },
  "493": {
    "id": "493",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForSequenceDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForSequenceDLModel.html"
  },
  "494": {
    "id": "494",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForTokenDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadXlnetForTokenDLModel.html"
  },
  "495": {
    "id": "495",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadZeroShotNerDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadZeroShotNerDLModel.html"
  },
  "496": {
    "id": "496",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForQAModel.html"
  },
  "497": {
    "id": "497",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForSequenceModel.html"
  },
  "498": {
    "id": "498",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedAlbertForTokenModel.html"
  },
  "499": {
    "id": "499",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedAlbertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedAlbertModel.html"
  },
  "500": {
    "id": "500",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForQAModel.html"
  },
  "501": {
    "id": "501",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForSequenceModel.html"
  },
  "502": {
    "id": "502",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedBertForTokenModel.html"
  },
  "503": {
    "id": "503",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertModel.html"
  },
  "504": {
    "id": "504",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedBertSentenceModel.html"
  },
  "505": {
    "id": "505",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/ReadablePretrainedBigTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/ReadablePretrainedBigTextMatcher.html"
  },
  "506": {
    "id": "506",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForQAModel.html"
  },
  "507": {
    "id": "507",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForSequenceModel.html"
  },
  "508": {
    "id": "508",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedCamemBertForTokenModel.html"
  },
  "509": {
    "id": "509",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedCamemBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedCamemBertModel.html"
  },
  "510": {
    "id": "510",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedClassifierDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedClassifierDL.html"
  },
  "511": {
    "id": "511",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadablePretrainedContextSpell.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadablePretrainedContextSpell.html"
  },
  "512": {
    "id": "512",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForQAModel.html"
  },
  "513": {
    "id": "513",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForSequenceModel.html"
  },
  "514": {
    "id": "514",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDeBertaForTokenModel.html"
  },
  "515": {
    "id": "515",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDeBertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDeBertaModel.html"
  },
  "516": {
    "id": "516",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/ReadablePretrainedDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/ReadablePretrainedDependency.html"
  },
  "517": {
    "id": "517",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForQAModel.html"
  },
  "518": {
    "id": "518",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForSequenceModel.html"
  },
  "519": {
    "id": "519",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedDistilBertForTokenModel.html"
  },
  "520": {
    "id": "520",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDistilBertModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDistilBertModel.html"
  },
  "521": {
    "id": "521",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDoc2Vec.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedDoc2Vec.html"
  },
  "522": {
    "id": "522",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedElmoModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedElmoModel.html"
  },
  "523": {
    "id": "523",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/ReadablePretrainedEntityRuler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/ReadablePretrainedEntityRuler.html"
  },
  "524": {
    "id": "524",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedGPT2TransformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedGPT2TransformerModel.html"
  },
  "525": {
    "id": "525",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedHubertForAudioModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedHubertForAudioModel.html"
  },
  "526": {
    "id": "526",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadablePretrainedLanguageDetectorDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/ReadablePretrainedLanguageDetectorDLModel.html"
  },
  "527": {
    "id": "527",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedLemmatizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedLemmatizer.html"
  },
  "528": {
    "id": "528",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForQAModel.html"
  },
  "529": {
    "id": "529",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForSequenceModel.html"
  },
  "530": {
    "id": "530",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedLongformerForTokenModel.html"
  },
  "531": {
    "id": "531",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedLongformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedLongformerModel.html"
  },
  "532": {
    "id": "532",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMarianMTModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMarianMTModel.html"
  },
  "533": {
    "id": "533",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedMultiClassifierDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedMultiClassifierDL.html"
  },
  "534": {
    "id": "534",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/ReadablePretrainedNerCrf.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/ReadablePretrainedNerCrf.html"
  },
  "535": {
    "id": "535",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedNerDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedNerDL.html"
  },
  "536": {
    "id": "536",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/ReadablePretrainedNorvig.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/ReadablePretrainedNorvig.html"
  },
  "537": {
    "id": "537",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/ReadablePretrainedPerceptron.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/ReadablePretrainedPerceptron.html"
  },
  "538": {
    "id": "538",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForQAModel.html"
  },
  "539": {
    "id": "539",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForSequenceModel.html"
  },
  "540": {
    "id": "540",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedRoBertaForTokenModel.html"
  },
  "541": {
    "id": "541",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaModel.html"
  },
  "542": {
    "id": "542",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedRobertaSentenceModel.html"
  },
  "543": {
    "id": "543",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadablePretrainedSentenceDetectorDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadablePretrainedSentenceDetectorDL.html"
  },
  "544": {
    "id": "544",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedSentimentDL.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedSentimentDL.html"
  },
  "545": {
    "id": "545",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadablePretrainedSpanBertCorefModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/ReadablePretrainedSpanBertCorefModel.html"
  },
  "546": {
    "id": "546",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedStopWordsCleanerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedStopWordsCleanerModel.html"
  },
  "547": {
    "id": "547",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedSwinForImageModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedSwinForImageModel.html"
  },
  "548": {
    "id": "548",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/ReadablePretrainedSymmetric.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/ReadablePretrainedSymmetric.html"
  },
  "549": {
    "id": "549",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedT5TransformerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedT5TransformerModel.html"
  },
  "550": {
    "id": "550",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedTapasForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedTapasForQAModel.html"
  },
  "551": {
    "id": "551",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTextMatcher.html"
  },
  "552": {
    "id": "552",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ReadablePretrainedTokenizer.html"
  },
  "553": {
    "id": "553",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ReadablePretrainedTypedDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/ReadablePretrainedTypedDependency.html"
  },
  "554": {
    "id": "554",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedUSEModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedUSEModel.html"
  },
  "555": {
    "id": "555",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedViTForImageModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ReadablePretrainedViTForImageModel.html"
  },
  "556": {
    "id": "556",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ReadablePretrainedVivekn.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ReadablePretrainedVivekn.html"
  },
  "557": {
    "id": "557",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedWav2Vec2ForAudioModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/ReadablePretrainedWav2Vec2ForAudioModel.html"
  },
  "558": {
    "id": "558",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWord2Vec.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWord2Vec.html"
  },
  "559": {
    "id": "559",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWordEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedWordEmbeddings.html"
  },
  "560": {
    "id": "560",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/ReadablePretrainedWordSegmenter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/ReadablePretrainedWordSegmenter.html"
  },
  "561": {
    "id": "561",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForQAModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForQAModel.html"
  },
  "562": {
    "id": "562",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForSequenceModel.html"
  },
  "563": {
    "id": "563",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlmRoBertaForTokenModel.html"
  },
  "564": {
    "id": "564",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaModel.html"
  },
  "565": {
    "id": "565",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaSentenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlmRobertaSentenceModel.html"
  },
  "566": {
    "id": "566",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForSequenceModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForSequenceModel.html"
  },
  "567": {
    "id": "567",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForTokenModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ReadablePretrainedXlnetForTokenModel.html"
  },
  "568": {
    "id": "568",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlnetModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadablePretrainedXlnetModel.html"
  },
  "569": {
    "id": "569",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedZeroShotNer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadablePretrainedZeroShotNer.html"
  },
  "570": {
    "id": "570",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/ReadsFromBytes.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/ReadsFromBytes.html"
  },
  "571": {
    "id": "571",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadsLanguageModelGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/ReadsLanguageModelGraph.html"
  },
  "572": {
    "id": "572",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadsNERGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ReadsNERGraph.html"
  },
  "573": {
    "id": "573",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadsSentenceDetectorDLGraph.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/ReadsSentenceDetectorDLGraph.html"
  },
  "574": {
    "id": "574",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RecursivePipeline.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RecursivePipeline.html"
  },
  "575": {
    "id": "575",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/RecursivePipelineModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/RecursivePipelineModel.html"
  },
  "576": {
    "id": "576",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer.html"
  },
  "577": {
    "id": "577",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel$.html"
  },
  "578": {
    "id": "578",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel.html"
  },
  "579": {
    "id": "579",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher$.html"
  },
  "580": {
    "id": "580",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcher.html"
  },
  "581": {
    "id": "581",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel$.html"
  },
  "582": {
    "id": "582",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.html"
  },
  "583": {
    "id": "583",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/RegexParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/RegexParser.html"
  },
  "584": {
    "id": "584",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReadWriter.html"
  },
  "585": {
    "id": "585",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/RegexPatternsReader.html"
  },
  "586": {
    "id": "586",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RegexRule.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RegexRule.html"
  },
  "587": {
    "id": "587",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer$.html"
  },
  "588": {
    "id": "588",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer.html"
  },
  "589": {
    "id": "589",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/RepositoryMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/RepositoryMetadata.html"
  },
  "590": {
    "id": "590",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader$.html"
  },
  "591": {
    "id": "591",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceDownloader.html"
  },
  "592": {
    "id": "592",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$$SourceStream.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$$SourceStream.html"
  },
  "593": {
    "id": "593",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/ResourceHelper$.html"
  },
  "594": {
    "id": "594",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata$.html"
  },
  "595": {
    "id": "595",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceMetadata.html"
  },
  "596": {
    "id": "596",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceRequest.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceRequest.html"
  },
  "597": {
    "id": "597",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/ResourceType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/ResourceType$.html"
  },
  "598": {
    "id": "598",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings$.html"
  },
  "599": {
    "id": "599",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings.html"
  },
  "600": {
    "id": "600",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering$.html"
  },
  "601": {
    "id": "601",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering.html"
  },
  "602": {
    "id": "602",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification$.html"
  },
  "603": {
    "id": "603",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification.html"
  },
  "604": {
    "id": "604",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification$.html"
  },
  "605": {
    "id": "605",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification.html"
  },
  "606": {
    "id": "606",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings$.html"
  },
  "607": {
    "id": "607",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings.html"
  },
  "608": {
    "id": "608",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/RobertaTokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/RobertaTokenizer.html"
  },
  "609": {
    "id": "609",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/RocksDBConnection$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/RocksDBConnection$.html"
  },
  "610": {
    "id": "610",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/RocksDBConnection.html",
    "relUrl": "/api/com/johnsnowlabs/storage/RocksDBConnection.html"
  },
  "611": {
    "id": "611",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$$RuleMatch.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$$RuleMatch.html"
  },
  "612": {
    "id": "612",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory$.html"
  },
  "613": {
    "id": "613",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/RuleFactory.html"
  },
  "614": {
    "id": "614",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/RuleSymbols.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/RuleSymbols.html"
  },
  "615": {
    "id": "615",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/S3ResourceDownloader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/S3ResourceDownloader.html"
  },
  "616": {
    "id": "616",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/ScoreCollector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/ScoreCollector.html"
  },
  "617": {
    "id": "617",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/SearchTrie$.html",
    "relUrl": "/api/com/johnsnowlabs/collections/SearchTrie$.html"
  },
  "618": {
    "id": "618",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/SearchTrie.html",
    "relUrl": "/api/com/johnsnowlabs/collections/SearchTrie.html"
  },
  "619": {
    "id": "619",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence$.html"
  },
  "620": {
    "id": "620",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Sentence.html"
  },
  "621": {
    "id": "621",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector$.html"
  },
  "622": {
    "id": "622",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.html"
  },
  "623": {
    "id": "623",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.html"
  },
  "624": {
    "id": "624",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder$.html"
  },
  "625": {
    "id": "625",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoder.html"
  },
  "626": {
    "id": "626",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoderParam.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLEncoderParam.html"
  },
  "627": {
    "id": "627",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel$.html"
  },
  "628": {
    "id": "628",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel.html"
  },
  "629": {
    "id": "629",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/SentenceDetectorParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/SentenceDetectorParams.html"
  },
  "630": {
    "id": "630",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings$.html"
  },
  "631": {
    "id": "631",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.html"
  },
  "632": {
    "id": "632",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/SentenceGrouper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/SentenceGrouper.html"
  },
  "633": {
    "id": "633",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceException.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceException.html"
  },
  "634": {
    "id": "634",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceProcessor.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceProcessor.html"
  },
  "635": {
    "id": "635",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceWrapper$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/SentencePieceWrapper$.html"
  },
  "636": {
    "id": "636",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SentenceSplit$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SentenceSplit$.html"
  },
  "637": {
    "id": "637",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentApproach$.html"
  },
  "638": {
    "id": "638",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach.html"
  },
  "639": {
    "id": "639",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel$.html"
  },
  "640": {
    "id": "640",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.html"
  },
  "641": {
    "id": "641",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector$.html"
  },
  "642": {
    "id": "642",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.html"
  },
  "643": {
    "id": "643",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel$.html"
  },
  "644": {
    "id": "644",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.html"
  },
  "645": {
    "id": "645",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SerializableClass.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SerializableClass.html"
  },
  "646": {
    "id": "646",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/SerializedAnnotatorComponent.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/SerializedAnnotatorComponent.html"
  },
  "647": {
    "id": "647",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SerializedDatasetMetadata.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SerializedDatasetMetadata.html"
  },
  "648": {
    "id": "648",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/SerializedExternalResource.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/SerializedExternalResource.html"
  },
  "649": {
    "id": "649",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SerializedLinearChainCrfModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SerializedLinearChainCrfModel.html"
  },
  "650": {
    "id": "650",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/SetFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/SetFeature.html"
  },
  "651": {
    "id": "651",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/SingleDatePolicy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/SingleDatePolicy$.html"
  },
  "652": {
    "id": "652",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/SpacyToAnnotation.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/SpacyToAnnotation.html"
  },
  "653": {
    "id": "653",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel$.html"
  },
  "654": {
    "id": "654",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel.html"
  },
  "655": {
    "id": "655",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/SparkNLP$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/SparkNLP$.html"
  },
  "656": {
    "id": "656",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/SparkNlpConfigKeys$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/SparkNlpConfigKeys$.html"
  },
  "657": {
    "id": "657",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/SparkUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/util/spark/SparkUtil$.html"
  },
  "658": {
    "id": "658",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray$$SeqWrapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray$$SeqWrapper.html"
  },
  "659": {
    "id": "659",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray$.html"
  },
  "660": {
    "id": "660",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/SparseArray.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/SparseArray.html"
  },
  "661": {
    "id": "661",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SpecialClassParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/SpecialClassParser.html"
  },
  "662": {
    "id": "662",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/SpecialToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/SpecialToken.html"
  },
  "663": {
    "id": "663",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Stemmer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Stemmer$.html"
  },
  "664": {
    "id": "664",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Stemmer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Stemmer.html"
  },
  "665": {
    "id": "665",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner$.html"
  },
  "666": {
    "id": "666",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.html"
  },
  "667": {
    "id": "667",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageBatchWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageBatchWriter.html"
  },
  "668": {
    "id": "668",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageFormat.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageFormat.html"
  },
  "669": {
    "id": "669",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageHelper$.html"
  },
  "670": {
    "id": "670",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageLocator$.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageLocator$.html"
  },
  "671": {
    "id": "671",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageLocator.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageLocator.html"
  },
  "672": {
    "id": "672",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReadWriter.html"
  },
  "673": {
    "id": "673",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReadable.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReadable.html"
  },
  "674": {
    "id": "674",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageReader.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageReader.html"
  },
  "675": {
    "id": "675",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/StorageSearchTrie$.html",
    "relUrl": "/api/com/johnsnowlabs/collections/StorageSearchTrie$.html"
  },
  "676": {
    "id": "676",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/StorageSearchTrie.html",
    "relUrl": "/api/com/johnsnowlabs/collections/StorageSearchTrie.html"
  },
  "677": {
    "id": "677",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/StorageWriter.html",
    "relUrl": "/api/com/johnsnowlabs/storage/StorageWriter.html"
  },
  "678": {
    "id": "678",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/StringMapStringDoubleAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/StringMapStringDoubleAccumulator.html"
  },
  "679": {
    "id": "679",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/StructFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/StructFeature.html"
  },
  "680": {
    "id": "680",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken$.html"
  },
  "681": {
    "id": "681",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/SuffixedToken.html"
  },
  "682": {
    "id": "682",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification$.html"
  },
  "683": {
    "id": "683",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification.html"
  },
  "684": {
    "id": "684",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach$.html"
  },
  "685": {
    "id": "685",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.html"
  },
  "686": {
    "id": "686",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$.html"
  },
  "687": {
    "id": "687",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$SuggestedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel$SuggestedWord.html"
  },
  "688": {
    "id": "688",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.html"
  },
  "689": {
    "id": "689",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteParams.html"
  },
  "690": {
    "id": "690",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/SyntacticFeatureFactory.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/SyntacticFeatureFactory.html"
  },
  "691": {
    "id": "691",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer$.html"
  },
  "692": {
    "id": "692",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.html"
  },
  "693": {
    "id": "693",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReadWriter.html"
  },
  "694": {
    "id": "694",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMEdgesReader.html"
  },
  "695": {
    "id": "695",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesReader.html"
  },
  "696": {
    "id": "696",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMNodesWriter.html"
  },
  "697": {
    "id": "697",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReadWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReadWriter.html"
  },
  "698": {
    "id": "698",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TMVocabReader.html"
  },
  "699": {
    "id": "699",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TableAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TableAssembler$.html"
  },
  "700": {
    "id": "700",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TableAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TableAssembler.html"
  },
  "701": {
    "id": "701",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TableData$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TableData$.html"
  },
  "702": {
    "id": "702",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TableData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TableData.html"
  },
  "703": {
    "id": "703",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/TagDictionary$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/TagDictionary$.html"
  },
  "704": {
    "id": "704",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/Tagged.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/Tagged.html"
  },
  "705": {
    "id": "705",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence$.html"
  },
  "706": {
    "id": "706",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedSentence.html"
  },
  "707": {
    "id": "707",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedWord.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TaggedWord.html"
  },
  "708": {
    "id": "708",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger$.html"
  },
  "709": {
    "id": "709",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/Tagger.html"
  },
  "710": {
    "id": "710",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/TagsType$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/TagsType$.html"
  },
  "711": {
    "id": "711",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate$.html"
  },
  "712": {
    "id": "712",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellDate.html"
  },
  "713": {
    "id": "713",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue$.html"
  },
  "714": {
    "id": "714",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasCellValue.html"
  },
  "715": {
    "id": "715",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasEncoder.html"
  },
  "716": {
    "id": "716",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering$.html"
  },
  "717": {
    "id": "717",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering.html"
  },
  "718": {
    "id": "718",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasInputData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasInputData.html"
  },
  "719": {
    "id": "719",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericRelation$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericRelation$.html"
  },
  "720": {
    "id": "720",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan$.html"
  },
  "721": {
    "id": "721",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/TapasNumericValueSpan.html"
  },
  "722": {
    "id": "722",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources$.html"
  },
  "723": {
    "id": "723",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorResources.html"
  },
  "724": {
    "id": "724",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowClassifier.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowClassifier.html"
  },
  "725": {
    "id": "725",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper$.html"
  },
  "726": {
    "id": "726",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/TensorflowWrapper.html"
  },
  "727": {
    "id": "727",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher$.html"
  },
  "728": {
    "id": "728",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcher.html"
  },
  "729": {
    "id": "729",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel$.html"
  },
  "730": {
    "id": "730",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel.html"
  },
  "731": {
    "id": "731",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/TextSentenceAttrs.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/TextSentenceAttrs.html"
  },
  "732": {
    "id": "732",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/TextSentenceLabels.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/TextSentenceLabels.html"
  },
  "733": {
    "id": "733",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Token.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Token.html"
  },
  "734": {
    "id": "734",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk$.html"
  },
  "735": {
    "id": "735",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Token2Chunk.html"
  },
  "736": {
    "id": "736",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TokenAssembler$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TokenAssembler$.html"
  },
  "737": {
    "id": "737",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/TokenAssembler.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/TokenAssembler.html"
  },
  "738": {
    "id": "738",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPiece.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPiece.html"
  },
  "739": {
    "id": "739",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings$.html"
  },
  "740": {
    "id": "740",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenPieceEmbeddings.html"
  },
  "741": {
    "id": "741",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedSentence.html"
  },
  "742": {
    "id": "742",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedWithSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/TokenizedWithSentence$.html"
  },
  "743": {
    "id": "743",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer$.html"
  },
  "744": {
    "id": "744",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/Tokenizer.html"
  },
  "745": {
    "id": "745",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel$.html"
  },
  "746": {
    "id": "746",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/TokenizerModel.html"
  },
  "747": {
    "id": "747",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainDependencies.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainDependencies.html"
  },
  "748": {
    "id": "748",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainFile.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TrainFile.html"
  },
  "749": {
    "id": "749",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/TrainingHelper$.html",
    "relUrl": "/api/com/johnsnowlabs/util/TrainingHelper$.html"
  },
  "750": {
    "id": "750",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TrainingPerceptronLegacy.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TrainingPerceptronLegacy.html"
  },
  "751": {
    "id": "751",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/TransducerFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/TransducerFeature.html"
  },
  "752": {
    "id": "752",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/TransducerSeqFeature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/TransducerSeqFeature.html"
  },
  "753": {
    "id": "753",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/TransformStrategy$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/TransformStrategy$.html"
  },
  "754": {
    "id": "754",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/Transition.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/Transition.html"
  },
  "755": {
    "id": "755",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/TrieNode.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/TrieNode.html"
  },
  "756": {
    "id": "756",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TupleKeyLongDoubleMapAccumulator.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/TupleKeyLongDoubleMapAccumulator.html"
  },
  "757": {
    "id": "757",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParser.html"
  },
  "758": {
    "id": "758",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach$.html"
  },
  "759": {
    "id": "759",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.html"
  },
  "760": {
    "id": "760",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel$.html"
  },
  "761": {
    "id": "761",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.html"
  },
  "762": {
    "id": "762",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/UnitToken.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/UnitToken.html"
  },
  "763": {
    "id": "763",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder$.html"
  },
  "764": {
    "id": "764",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.html"
  },
  "765": {
    "id": "765",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Utilities$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/Utilities$.html"
  },
  "766": {
    "id": "766",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/util/Utilities$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/util/Utilities$.html"
  },
  "767": {
    "id": "767",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Utils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/Utils.html"
  },
  "768": {
    "id": "768",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/Variables.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/Variables.html"
  },
  "769": {
    "id": "769",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/VectorMath$.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/VectorMath$.html"
  },
  "770": {
    "id": "770",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/Verbose$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/Verbose$.html"
  },
  "771": {
    "id": "771",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Version$.html",
    "relUrl": "/api/com/johnsnowlabs/util/Version$.html"
  },
  "772": {
    "id": "772",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/Version.html",
    "relUrl": "/api/com/johnsnowlabs/util/Version.html"
  },
  "773": {
    "id": "773",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification$.html"
  },
  "774": {
    "id": "774",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification.html"
  },
  "775": {
    "id": "775",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.html"
  },
  "776": {
    "id": "776",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel$.html"
  },
  "777": {
    "id": "777",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.html"
  },
  "778": {
    "id": "778",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentUtils.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentUtils.html"
  },
  "779": {
    "id": "779",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/VocabParser.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/VocabParser.html"
  },
  "780": {
    "id": "780",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC$.html"
  },
  "781": {
    "id": "781",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC.html"
  },
  "782": {
    "id": "782",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/WeightedLevenshtein.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/WeightedLevenshtein.html"
  },
  "783": {
    "id": "783",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/WithGraphResolver.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/WithGraphResolver.html"
  },
  "784": {
    "id": "784",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach$.html"
  },
  "785": {
    "id": "785",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach.html"
  },
  "786": {
    "id": "786",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel$.html"
  },
  "787": {
    "id": "787",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel.html"
  },
  "788": {
    "id": "788",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/WordAttrs.html",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/WordAttrs.html"
  },
  "789": {
    "id": "789",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings$.html"
  },
  "790": {
    "id": "790",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.html"
  },
  "791": {
    "id": "791",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsBinaryIndexer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsBinaryIndexer$.html"
  },
  "792": {
    "id": "792",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel$.html"
  },
  "793": {
    "id": "793",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.html"
  },
  "794": {
    "id": "794",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsReader.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsReader.html"
  },
  "795": {
    "id": "795",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTextIndexer$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTextIndexer$.html"
  },
  "796": {
    "id": "796",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsWriter.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsWriter.html"
  },
  "797": {
    "id": "797",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach$.html"
  },
  "798": {
    "id": "798",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach.html"
  },
  "799": {
    "id": "799",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel$.html"
  },
  "800": {
    "id": "800",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.html"
  },
  "801": {
    "id": "801",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordWithDependency.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordWithDependency.html"
  },
  "802": {
    "id": "802",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence$.html"
  },
  "803": {
    "id": "803",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceEmbeddingsSentence.html"
  },
  "804": {
    "id": "804",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenized$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenized$.html"
  },
  "805": {
    "id": "805",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenizedSentence.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/WordpieceTokenizedSentence.html"
  },
  "806": {
    "id": "806",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/WritableAnnotatorComponent.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/WritableAnnotatorComponent.html"
  },
  "807": {
    "id": "807",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/WriteSentencePieceModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/WriteSentencePieceModel.html"
  },
  "808": {
    "id": "808",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/WriteTensorflowModel.html",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/WriteTensorflowModel.html"
  },
  "809": {
    "id": "809",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings$.html"
  },
  "810": {
    "id": "810",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings.html"
  },
  "811": {
    "id": "811",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering$.html"
  },
  "812": {
    "id": "812",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering.html"
  },
  "813": {
    "id": "813",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification$.html"
  },
  "814": {
    "id": "814",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification.html"
  },
  "815": {
    "id": "815",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification$.html"
  },
  "816": {
    "id": "816",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification.html"
  },
  "817": {
    "id": "817",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings$.html"
  },
  "818": {
    "id": "818",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings.html"
  },
  "819": {
    "id": "819",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings$.html"
  },
  "820": {
    "id": "820",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.html"
  },
  "821": {
    "id": "821",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification$.html"
  },
  "822": {
    "id": "822",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification.html"
  },
  "823": {
    "id": "823",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification$.html"
  },
  "824": {
    "id": "824",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification.html"
  },
  "825": {
    "id": "825",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction$.html"
  },
  "826": {
    "id": "826",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction.html"
  },
  "827": {
    "id": "827",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeParams.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeParams.html"
  },
  "828": {
    "id": "828",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel$.html"
  },
  "829": {
    "id": "829",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel.html"
  },
  "830": {
    "id": "830",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/ZipArchiveUtil$.html",
    "relUrl": "/api/com/johnsnowlabs/util/ZipArchiveUtil$.html"
  },
  "831": {
    "id": "831",
    "title": "Active Learning",
    "content": "Project Owners or Managers can enable the Active Learning feature by clicking on the corresponding Switch available on Model Training tab. If this feature is enabled, the NER training gets triggered automatically on every 50/100/200 new completions. It is possible to change the target completions number by dropdown which is visible only when Active Learning is enabled. While enabling this feature, users are asked whether they want to deploy the newly trained model right after the training process or not. If the user chooses not to automatically deploy the newly trained model, this can be done on demand by navigating to the target project Setup &gt; Configuration &gt; 3. Predefined Labels. Search for the new model by name of the project, select it and add it to your configuration. This will update the Project Configuration (the name of the model is changed in the corresponding label tags). Training date and time of each trained model is also displayed in the predefined labels widget. If the user opts to deploy the model after the training, the Project Configuration is automatically updated for each label that is included in the newly trained model. The value of the model param is updated with the name of the new model. If there is any mistake in the name of models, the validation error is displayed in the Interface Preview Section present on the right side of the Labeling Config area.",
    "url": "/docs/en/alab/active_learning",
    "relUrl": "/docs/en/alab/active_learning"
  },
  "832": {
    "id": "832",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/albert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/albert_embeddings.html"
  },
  "833": {
    "id": "833",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_question_answering.html"
  },
  "834": {
    "id": "834",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_sequence_classification.html"
  },
  "835": {
    "id": "835",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/albert_for_token_classification.html"
  },
  "836": {
    "id": "836",
    "title": "Analytics Permission",
    "content": "By default, dashboards in the Analytics page is disabled for a project. Users can request the admin to enable the Analytics page. The request is then listed on the Analytics Request page under the Settings menu. This page is only accessible to the admin user. After the admin user approves the request, the user can access the various dashboards in the Analytics page. Analytics Requests The Analytics Requests page lists all the pending requests for the Analytics page from one or more users. The admin user can grant or deny the permission to the requests as needed. It is accessible from Settings &gt; Analytics Requests. Each request contains information such as the name of project for which the analytics request was made, the user who initiated the request, and the date when the request was made. Granting a request All the requests granted by the admin user is listed under this tab. The table shows information about the granted requests, like the name of the project for which the analytics request was made, the user who initiated the request, the user who granted the request, the date when the request was granted, the latest date when the analytics were updated. The admin user can also revoke an already granted request from this list. Denying/Revoking a request All the requests denied or revoked by the admin user is listed under this tab. The table shows information about the denied/revoked requests, like the name of the project for which the analytics request was made, the user who initiated the request, the user who denied/revoked the request, the date when the request was denied/revoked, the latest date when the analytics were updated.",
    "url": "/docs/en/alab/analytics_permission",
    "relUrl": "/docs/en/alab/analytics_permission"
  },
  "837": {
    "id": "837",
    "title": "Analyze Clinical Notes - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_clinical_notes",
    "relUrl": "/analyze_clinical_notes"
  },
  "838": {
    "id": "838",
    "title": "Analyze Medical Texts in Spanish - Medical NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_medical_text_spanish",
    "relUrl": "/analyze_medical_text_spanish"
  },
  "839": {
    "id": "839",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/analyze_non_english_medical_text",
    "relUrl": "/analyze_non_english_medical_text"
  },
  "840": {
    "id": "840",
    "title": "Analyze Non-English Text & Documents - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_non_english_text_documents",
    "relUrl": "/analyze_non_english_text_documents"
  },
  "841": {
    "id": "841",
    "title": "Analyze Spelling & Grammar - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/analyze_spelling_grammar",
    "relUrl": "/analyze_spelling_grammar"
  },
  "842": {
    "id": "842",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/annotation.html",
    "relUrl": "/api/python/user_guide/annotation.html"
  },
  "843": {
    "id": "843",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation.html",
    "relUrl": "/api/python/modules/sparknlp/annotation.html"
  },
  "844": {
    "id": "844",
    "title": "Manual Annotation",
    "content": "The Annotation Lab keeps a human expert as productive as possible. It minimizes the number of mouse clicks, keystrokes, and eye movements in the main workflow. The continuous improvement in the UI and the UX is from iterative feedback from the users. Annotation Lab supports keyboard shortcuts for all types of annotations. It enables having one hand on the keyboard, one hand on the mouse, and both eyes on the screen at all times. One-click completion and automatic switching to the next task keep experts in the loop. On the header of the Labeling area, you can find the list of labels defined for the project. In the center, it displays the content of the task. On the right, there are several widgets categorized into different groups. Annotations Versions Progress Labeling Widgets Completions A completion is a list of annotations manually defined by a user for a given task. After completing annotation on a task (e.g., all entities highlighted in the text, or one or more classes is assigned to the task in the case of classification projects) user clicks on the Save button to save their progress or Submit button to submit the completion. A submitted completion is no longer editable, and the user cannot delete it. Creating a new copy of the submitted completion is the only option to edit it. An annotator can modify or delete their completions only if completions are not submitted yet. Dedicated action icons are available on the completions widgets to allow users to quickly run actions like delete, copy, set ground-truth. It is an important to ensure a complete audit trail of all user actions. Annotation Lab tracks the history and details of any deleted completions. It means it is possible to see the name of the completion creator, date of creation, and deletion. Predictions A prediction is a list of annotations created automatically by Spark NLP pre-trained models or from the rules. A project owner/manager can create predictions using the Pre-Annotate button from the Tasks page. Predictions are read-only, which means users can see the predictions but cannot modify those. To reuse a prediction to bootstrap the annotation process, users can copy it to a new completion. This new completion bootstrapped from the prediction is editable. Confidence From version 3.3.0, running pre-annotations on a text project provides one extra piece of information for the automatic annotations - the confidence score. This score shows the confidence the model has for each of the labeled chunks it predicts. It is calculated based on the benchmarking information of the model used to pre-annotate and the score of each prediction. The confidence score is available when working on Named Entity Recognition, Relation Extraction, Assertion, and Classification projects and is also generated when using Rules. On the Labeling page, when selecting the Prediction widget, users can see all preannotation in the Annotations section with a score assigned to them. Using the confidence slider, users can filter out low confidence labels before starting to edit/correct the labels. Both Accept Prediction and Add a new completion based on this prediction operation apply to the filtered annotations from the confidence slider. Annotations The Annotations widget has two sections. Regions Gives a list overview of all annotated chunks. When you click on any annotation, it gets automatically highlighted in the labeling editor. We can edit or remove annotations from here. Relations Lists all the relations that have been created. When the user moves the mouse over any one relation, it is highlighted in the labeling editor. Progress Annotator/Reviewer can see their overall work progress from within the labeling page. The status is calculated for their assigned work. For Annotator View: For Reviewer View: Text Annotation Named Entity Recognition To extract information using NER labels, we first click on the label to select it or press the shortcut key assigned to it, and then, with the mouse, select the relevant part of the text. We can easily edit the incorrect labeling by clicking on the labeled text and then selecting the new label you want to assign to this text. To delete the label from the text, we first click on the text on the labeling editor and then press backspace. Trim leading and ending special characters in annotated chunks When annotating text, it is possible and probable that the annotation is not very precise and the chunks contain leading/trailing spaces and punctuation marks. By default all the leading/trailing spaces and punctuation marks are excluded from the annotated chunk. The labeling editor settings has a new configuration option that can be used to enable/disable this feature if necessary. Assertion Labels To add an assertion label to an extracted entity, select the assertion label and select the labeled entity (from NER) in the labeling editor. After this, the extracted entity will have two labels - one for NER and one for assertion. In the example below, the chunks heart disease, kidney disease, stroke etc., were extracted first using the NER label - Symptom (pink color) and then the assertion label - Absent (green color). Relation Extraction Creating relations with the Annotation Lab is very simple. First, click on any one labeled entity, then press the r key and click on the second labeled entity. You can add a label to the relation, change its direction or delete it using the contextual menu displayed next to the relation arrow or from the relation box. Cross page Annotation From version 2.8.0, Annotation Lab supports cross-page NER annotation for Text projects. It means that Annotators can annotate a chunk starting at the bottom of one page and finishing on the next page. This feature is also available for Relations. Previously, relations were created between chunks located on the same page. But now, relations can be created among tokens located on different pages. The way to do this is to first change the pagination settings to include the tokens to be linked on the same page, then create the relation annotation between the tokens and finally go back to the original pagination settings. The annotation is presented through connectors after updating the pagination. Visual NER Annotation Annotating text included in image documents (e.g., scanned documents) is a common use case in many verticals but comes with several challenges. With the Visual NER labeling config, we aim to ease the work of annotators by allowing them to select text from an image and assign the corresponding label to it. This feature is powered by Visual NLP library; hence a valid Visual NLP license is required to get access to it. Here is how we can use it: Upload a valid [Visual NLP](/docs/en/ocr) license. See how to do this here. Create a new project, specify a name for your project, add team members if necessary, and from the list of predefined templates (Default Project Configs) choose Visual NER Labeling under IMAGE content type. Update the configuration if necessary. This might be useful if you want to use other labels than the default ones. Click the Save Config button. While saving the project, a confirmation dialog is displayed to ask if you want to deploy the OCR pipeline. Select Yes from the confirmation dialog. Import the tasks you want to annotate (images or PDF documents). Start annotating text on top of the image by clicking on the text tokens, or by drawing bounding boxes on top of chunks or image areas. Export annotations in your preferred format. The entire process is illustrated below: Support for multi-page PDF documents When a valid Visual NLP license is available, Annotation Lab offers support for multi-page PDF annotation. We can import, annotate, and export multi-page PDF files easily. Users have two options for importing a new PDF file into the Visual NER project: Import PDF file from local storage. Add a link to the PDF file in the file attribute. After import, the task becomes available on the Tasks Page. The title of the new task is the name of the imported file. On the labeling page, the PDF viewer has pagination support so that annotators can annotate on the PDF document one page at a time. Users can also jump to a specific page in multi-page task, instead of passing through all pages to reach a target section of a PDF document. Support for multiple OCR servers Just like for Preannotation servers, Annotation Lab supports deployment of multiple OCR servers. If a user has uploaded a Visual NLP license, OCR inference is enabled. To work on a Visual NER project, users have to deploy at least one OCR server. Any OCR server can perform preannotation. To select the OCR server, users need to go to the Import page, click on the OCR Server button on the top-right corner and from the popup, choose one of the available OCR servers. If no suitable OCR server is present, you can create a new server by selecting the Create Server option and then clicking on the Deploy button.",
    "url": "/docs/en/alab/annotation",
    "relUrl": "/docs/en/alab/annotation"
  },
  "845": {
    "id": "845",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation_audio.html",
    "relUrl": "/api/python/modules/sparknlp/annotation_audio.html"
  },
  "846": {
    "id": "846",
    "title": "Configurations",
    "content": "Simplified workflow Direct Submit Using the classical annotation workflow, when an annotator works on a task, a series of actions are necessary for creating a new annotation and submitting it as ground truth: Create the completion Save the completion Submit the completion Confirm submission Load next task This process is adapted for more complex workflows and large tasks. For simple projects with smaller tasks, Annotation Lab now offers a simplified workflow. Annotators can submit a completion with just one click. The Project Owner/Manager can activate this option from the Settings dialog (Customize Labels) in the Configuration step of the Setup page. Once enabled, annotators can see the submit button on the labeling page. A second option is available on the same dialog for Project Owner/Manager: Serve next task after completion submission. Once enabled, annotators can see the next task on the labeling page after submitting the completion for the current task. Note: Annotator can Save/Update completion using CTRL+Enter Annotator can Submit completion using ALT+Enter Accept Prediction When predictions are available for a task, Annotator can accept the predictions with just one click and navigate automatically to the next task. When users click on Accept Prediction, a new completion is created based on the prediction, then submitted as ground truth, and the next task in line (assigned to the current annotator/reviewer and with Incomplete or In Progress status) is automatically served. NOTE: Press backspace key (on windows) or delete key (on mac) to delete the selected relation from the labeling editor or use the delete action icon on the Relations widget. Labeling editor Settings The labeling editor offers some configurable features. For example, you can modify the editor’s layout, show or hide predictions, annotations, or the confidence panel, show or hide various controls and information. It is also possible to keep a label selected after creating a region, display labels on bounding boxes, polygons and other regions while labeling, and show line numbers for text labeling. Enable labeling hotkeys This option enables/disable the hotkeys assigned to taxonomy labels to use the hotkeys during the annotation process. Show hotkey tooltips This option shows/hides the hotkey and tooltip on the taxonomy label and the control buttons. Enable labeling hotkeys must be enabled for this option to work. Show labels inside the regions When you enable this option, the labels assigned to each annotated region are displayed on the respective region. Keep label selected after creating a region This option helps users quickly annotate sequences of the same label by keeping the label selected after the annotation of a region. With the option unchecked: With the option checked: Select regions after creating This option keeps the annotated region selected after annotation. In this way, it will be easier for users to quickly change the assigned label for the last selected region if necessary. Show line numbers for Text This option adds line numbers to the text content to annotate in the labeling editor. Label all occurrences of selected text When checked, this option allow users to annotate all occurences of a text in the current task in one step. Labeling editor Customizations The Labeling editor is highly customizable. Project Owners and Managers can change the layout of their projects based on their needs. Search filter for a large number of labels When a project has a large number of NER/Assertion labels in the taxonomy, the display of the taxonomy takes a lot of screen space, and it is difficult for annotators to navigate through all labels. To tackle this challenge, Annotation Lab supports search for labels in NER projects (an autocomplete search option). To add the search bar for NER Labels or Choices, use the Filter tag as shown in the following XML configuration. &lt;Filter /&gt; &lt;View&gt; *** enclose labels tags here *** &lt;/View&gt; &lt;View&gt; *** enclose text tags here *** &lt;/View&gt; Parameters: The following parameters/attributes can be used within the Filter tag. Param Type Default Description placeholder string Quick Filter Placeholder text for filter minlength number 3 Size of the filter style string   CSS style of the string hotkey string   Hotkey to use to focus on the filter text area Usage Example: &lt;Filter placeholder=&quot;Quick Filter&quot;/&gt; For obtaining the above display on a NER project, the config should look as follows: &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;CARDINAL&quot; model=&quot;ner_onto_100&quot; background=&quot;#af906b&quot;/&gt; &lt;Label value=&quot;EVENT&quot; model=&quot;ner_onto_100&quot; background=&quot;#f384e1&quot;/&gt; ... &lt;Label value=&quot;LANGUAGE&quot; model=&quot;ner_onto_100&quot; background=&quot;#c0dad2&quot;/&gt; &lt;/Labels&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; Notice how users can search for the desired label using the filter bar: Resizable label and text container While annotating longer text documents annotators may need to scroll to the top of the document for selecting the label to use, and then scroll down to create a label. Also, if the text is large, annotators have to scroll to a certain section because the textbox size is fixed. In those cases, the annotation experience can be improved by creating a scrollable labeling area and textbox area. To add the scroll bar, the View tag with a fixed height and overflow-y:scroll style property can be used as shown in the following XML config structure: &lt;View style=&quot;background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot;&gt; *** enclose labels tags here *** &lt;/View&gt; &lt;View style=&quot;resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot;&gt; **** enclose text tags here** &lt;/View&gt; Once it has been added and saved to the Project Configuration, the scroll bar should be visible. Example Using the following Project Configuration &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;View style=&quot;background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot;&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;CARDINAL&quot; model=&quot;ner_onto_100&quot; background=&quot;#af906b&quot;/&gt; &lt;Label value=&quot;EVENT&quot; model=&quot;ner_onto_100&quot; background=&quot;#f384e1&quot;/&gt; &lt;Label value=&quot;WORK_OF_ART&quot; model=&quot;ner_onto_100&quot; background=&quot;#0fbca4&quot;/&gt; ... &lt;Label value=&quot;LANGUAGE&quot; model=&quot;ner_onto_100&quot; background=&quot;#c0dad2&quot;/&gt; &lt;/Labels&gt; &lt;/View&gt; &lt;View style=&quot;resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;&gt;&lt;/Text&gt; &lt;/View&gt; &lt;/View&gt; we’ll obtain the output illustrated below: Toggle Preview Window Label configuration editor and Preview Window covers 50/50 part of the screen. It can make editing larger XML configurations difficult. For a better editing experience, we can use the Toggle Preview Window button to have the editor use full screen width. Switch Role For users having multiple roles (Annotator/Reviewer/Manager) the labeling page can get confusing. Switch Role filter present on the top-right corner can help address this problem. This filter was introduced in Annotation Lab from version 2.6.0, previously refered to as View As filter. When selecting Annotator option, the view changes to facilitate annotating the task. Similar changes to the view applies when switching to Reviewer or Manager option. The selection persists even when the tab is closed or refreshed.",
    "url": "/docs/en/alab/annotation_configurations",
    "relUrl": "/docs/en/alab/annotation_configurations"
  },
  "847": {
    "id": "847",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotation_image.html",
    "relUrl": "/api/python/modules/sparknlp/annotation_image.html"
  },
  "848": {
    "id": "848",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_approach.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_approach.html"
  },
  "849": {
    "id": "849",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/annotator_java_ml.html",
    "relUrl": "/api/python/modules/sparknlp/internal/annotator_java_ml.html"
  },
  "850": {
    "id": "850",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_model.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_model.html"
  },
  "851": {
    "id": "851",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/annotator_properties.html",
    "relUrl": "/api/python/modules/sparknlp/common/annotator_properties.html"
  },
  "852": {
    "id": "852",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/annotator_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/internal/annotator_transformer.html"
  },
  "853": {
    "id": "853",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/annotators.html",
    "relUrl": "/api/python/user_guide/annotators.html"
  },
  "854": {
    "id": "854",
    "title": "Annotators",
    "content": "",
    "url": "/docs/en/annotators",
    "relUrl": "/docs/en/annotators"
  },
  "855": {
    "id": "855",
    "title": "API Integration",
    "content": "All features provided by the Annotation Lab via UI are also accessible via API. The complete API documentation is available on the SWAGGER page of the Annotation Lab. It is available under Settings &gt; API Integration. Concrete query examples are provided for each available endpoint. Example of creating a new project via API Get Client Secret Get CLIENT_ID and CLIENT_SECRET by following the steps illustrated in the video. Annotation Lab: Collect the Client Secret Call API endpoint For creating a new project via API you can use the following python script. import requests import json # URL to Annotation Lab API_URL = &quot;https://123.45.67.89&quot; # Add user credentials USERNAME = &quot;user&quot; PASSWORD = &quot;password&quot; # The above video shows how to get CLIENT_ID and CLIENT_SECRET CLIENT_ID = &quot;...&quot; CLIENT_SECRET = &quot;...&quot; PROJECT_NAME = &quot;sample_project&quot; IDENTITY_MANAGEMENT_URL = API_URL + &quot;/auth/&quot; IDENTITY_MANAGEMENT_REALM = &quot;master&quot; HEADERS = { &quot;Host&quot;: API_URL.replace(&quot;http://&quot;, &quot;&quot;).replace(&quot;https://&quot;, &quot;&quot;), &quot;Origin&quot;: API_URL, &quot;Content-Type&quot;: &quot;application/json&quot;, } def get_cookies(): url = f&quot;{IDENTITY_MANAGEMENT_URL}realms/{IDENTITY_MANAGEMENT_REALM}/protocol/openid-connect/token&quot; data = { &quot;grant_type&quot;: &quot;password&quot;, &quot;username&quot;: USERNAME, &quot;password&quot;: PASSWORD, &quot;client_id&quot;: CLIENT_ID, &quot;client_secret&quot;: CLIENT_SECRET, } auth_info = requests.post(url, data=data).json() cookies = { &quot;access_token&quot;: f&quot;Bearer {auth_info[&#39;access_token&#39;]}&quot;, &quot;refresh_token&quot;: auth_info[&quot;refresh_token&quot;], } return cookies def create_project(): # GET THIS FROM SWAGGER DOC url = f&quot;{API_URL}/api/projects/create&quot; data = { &quot;project_name&quot;: PROJECT_NAME, &quot;project_description&quot;: &quot;&quot;, &quot;project_sampling&quot;: &quot;uniform&quot;, &quot;project_instruction&quot;: &quot;&quot;, } r = requests.post( url, headers=HEADERS, data=json.dumps(data), cookies=get_cookies() ) return r create_project()",
    "url": "/docs/en/alab/api",
    "relUrl": "/docs/en/alab/api"
  },
  "856": {
    "id": "856",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/audio_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/audio_assembler.html"
  },
  "857": {
    "id": "857",
    "title": "Audit Trail",
    "content": "Annotation Lab is designed to handle Personal Identifying Information (PII) and Protected Health Information (PHI). It keeps a full audit trail for all created completions, where each entry is stored with an authenticated user and a timestamp. It is not possible for Annotators or Reviewers to delete any completions, and only Managers and Project Owners can remove tasks.",
    "url": "/docs/en/alab/audit_trail",
    "relUrl": "/docs/en/alab/audit_trail"
  },
  "858": {
    "id": "858",
    "title": "Helper functions",
    "content": "",
    "url": "/docs/en/auxiliary",
    "relUrl": "/docs/en/auxiliary"
  },
  "859": {
    "id": "859",
    "title": "Backup and Restore",
    "content": "Backup You can enable daily backups by adding several variables with --set option to helm command in annotationlab-updater.sh: backup.enable=true backup.files=true backup.s3_access_key=&quot;&lt;ACCESS_KEY&gt;&quot; backup.s3_secret_key=&quot;&lt;SECRET_KEY&gt;&quot; backup.s3_bucket_fullpath=&quot;&lt;FULL_PATH&gt;&quot; &lt;ACCESS_KEY&gt; - your access key for AWS S3 access &lt;SECRET_KEY&gt; - your secret key for AWS S3 access &lt;FULL_PATH&gt; - full path to your backup in s3 bucket (f.e. s3://example.com/path/to/my/backup/dir) Note: File backup is enabled by default. If you don’t need to backup files, you have to change backup.files=true to backup.files=false Configure Backup from the UI In 2.8.0 release, Annotation Lab added support for defining database and files backups via the UI. An admin user can view and edit the backup settings under the Settings menu. Users can select different backup periods and can specify a target S3 bucket for storing the backup files. New backups will be automatically generated and saved to the S3 bucket following the defined schedule. Restore Database To restore Annotation Lab from a backup you need a fresh installation of Annotation Lab. Install it using annotationlab-install.sh. Now, download the latest backup from your S3 bucket and move the archive to restore/database/ directory. Next, go to the restore/database/ directory and execute script restore_all_databases.sh with the name of your backup archive as the argument. For example: cd restore/database/ sudo ./restore_all_databases.sh 2022-04-14-annotationlab-all-databases.tar.xz Note: You need xz and bash installed to execute this script. This script works only with backups created by Annotation Lab backup system. Run this script with sudo command After database restore complete you can check logs in restore_log directory created by restore script. Files Download your files backup and move it to restore/files/ directory. Go to restore/files/ directory and execute script restore_files.sh with the name of your backup archive as the argument. For example: cd restore/files/ sudo ./restore_files.sh 2022-04-14-annotationlab-files.tar Note: You need bash installed to execute this script. This script works only with backups created by Annotation Lab backup system. Run this script with sudo command Reboot After restoring database and files, reboot Annotation Lab: sudo reboot",
    "url": "/docs/en/alab/backup_restore",
    "relUrl": "/docs/en/alab/backup_restore"
  },
  "860": {
    "id": "860",
    "title": "Developers Guideline",
    "content": "Cluster Speed Benchmarks NER (BiLSTM-CNN-Char Architecture) Benchmark Experiment Dataset : 1000 Clinical Texts from MTSamples Oncology Dataset, approx. 500 tokens per text. Driver : Standard_D4s_v3 - 16 GB Memory - 4 Cores Enable Autoscaling : False Cluster Mode : Standart Worker : Standard_D4s_v3 - 16 GB Memory - 4 Cores Standard_D4s_v2 - 28 GB Memory - 8 Cores Versions : Databricks Runtime Version : 8.3(Scala 2.12, Spark 3.1.1) spark-nlp Version: v3.2.3 spark-nlp-jsl Version : v3.2.3 Spark Version : v3.1.1 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings_clinical, clinical_ner, ner_converter ]) NOTES : The first experiment with 5 different cluster configurations : ner_chunk as a column in Spark NLP Pipeline (ner_converter) output data frame, exploded (lazy evaluation) as ner_chunk and ner_label. Then results were written as parquet and delta formats. A second experiment with 2 different cluster configuration : Spark NLP Pipeline output data frame (except word_embeddings column) was written as parquet and delta formats. In the first experiment with the most basic driver node and worker (1 worker x 4 cores) configuration selection, it took 4.64 mins and 4.53 mins to write 4 partitioned data as parquet and delta formats respectively. With basic driver node and 8 workers (x8 cores) configuration selection, it took 40 seconds and 22 seconds to write 1000 partitioned data as parquet and delta formats respectively. In the second experiment with basic driver node and 4 workers (x 4 cores) configuration selection, it took 1.41 mins as parquet and 1.42 mins as delta format to write 16 partitioned (exploded results) data. Without explode it took 1.08 mins as parquet and 1.12 mins as delta format to write the data frame. Since given computation durations are highly dependent on different parameters including driver node and worker node configurations as well as partitions, results show that explode method increases duration %10-30 on chosen configurations. NER Benchmark Tables driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 64 36 sec 1.14 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 64 19 sec 1.13 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 100 21 sec 50 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 100 41 sec 51 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_parquet 8 64 1000 40 sec 54 sec Standard_D4s_v3 16 GB 4 Standard_D4s_v2 28 GB 8 1000 78000 write_deltalake 8 64 1000 22 sec 46 sec driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition duration NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 32 1.21 mins 2.05 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 32 55.8 sec 1.91 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 100 41 sec 1.64 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 100 48 sec 1.61 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 8 32 1000 1.36 min 1.83 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 8 32 1000 48 sec 1.70 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 10 1.4 mins 3.78 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 10 1.76 mins 3.93 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 16 1.41 mins 3.97 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 16 1.42 mins 3.82 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 32 1.36 mins 3.70 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 32 1.35 mins 3.65 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 100 1.21 mins 3.18 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 100 1.24 mins 3.15 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 4 16 1000 1.42 mins 3.51 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 4 16 1000 1.46 mins 3.48 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 10 2.82 mins 5.91 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 10 2.82 mins 5.99 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 100 2.27 mins 5.29 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 100 2.25 min 5.26 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 2 8 1000 2.65 mins 5.78 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 2 8 1000 2.7 mins 5.81 mins driver_name driver_memory driver_cores worker_name worker_memory worker_cores input_data_rows output_data_rows action total_worker_number total_cores partition NER timing NER+RE timing Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 4 4.64 mins 13.97 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 4 4.53 mins 13.88 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 10 4.42 mins 14.13 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 10 4.55 mins 14.63 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 100 4.19 mins 14.68 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 100 4.18 mins 14.89 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_parquet 1 4 1000 5.01 mins 16.38 mins Standard_D4s_v3 16 GB 4 Standard_D4s_v3 16 GB 4 1000 78000 write_deltalake 1 4 1000 4.99 mins 16.52 mins Clinical Bert For Token Classification Benchmark Experiment Dataset : 7537 Clinical Texts from PubMed Dataset Driver : Standard_DS3_v2 - 14GB Memory - 4 Cores Enable Autoscaling : True Cluster Mode : Standart Worker : Standard_DS3_v2 - 14GB Memory - 4 Cores Versions : Databricks Runtime Version : 10.0 (Apache Spark 3.2.0, Scala 2.12) spark-nlp Version: v3.4.0 spark-nlp-jsl Version : v3.4.0 Spark Version : v3.2.0 Spark NLP Pipeline : nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, ner_jsl_slim_tokenClassifier, ner_converter, finisher]) NOTES : In this experiment, the bert_token_classifier_ner_jsl_slim model was used to measure the inference time of clinical bert for token classification models in the databricks environment. In the first experiment, the data read from the parquet file is saved as parquet after processing. In the second experiment, the data read from the delta table was written to the delta table after it was processed. Bert For Token Classification Benchmark Table Repartition Time Read data from parquet 2 26.03 mins 64 10.84 mins 128 7.53 mins 1000 8.93 mins Read data from delta table 2 40.50 mins 64 11.84 mins 128 6.79 mins 1000 6.92 mins NER speed benchmarks across various Spark NLP and PySpark versions This experiment compares the ClinicalNER runtime for different versions of PySpark and Spark NLP. In this experiment, all reports went through the pipeline 10 times and repeated execution 5 times, so we ran each report 50 times and averaged it, %timeit -r 5 -n 10 run_model(spark, model). Driver : Standard Google Colab environment Spark NLP Pipeline : nlpPipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter ]) Dataset : File sizes: report_1: ~5.34kb report_2: ~8.51kb report_3: ~11.05kb report_4: ~15.67kb report_5: ~35.23kb   Spark NLP 4.0.0 (PySpark 3.1.2) Spark NLP 4.2.1 (PySpark 3.3.1) Spark NLP 4.2.1 (PySpark 3.1.2) Spark NLP 4.2.2 (PySpark 3.1.2) Spark NLP 4.2.2 (PySpark 3.3.1) Spark NLP 4.2.3 (PySpark 3.3.1) Spark NLP 4.2.3 (PySpark 3.1.2) report_1 2.36066 3.33056 2.23723 2.27243 2.11513 2.19655 2.23915 report_2 2.2179 3.31328 2.15578 2.23432 2.07259 2.07567 2.16776 report_3 2.77923 2.6134 2.69023 2.76358 2.55306 2.4424 2.72496 report_4 4.41064 4.07398 4.66656 4.59879 3.98586 3.92184 4.6145 report_5 9.54389 7.79465 9.25499 9.42764 8.02252 8.11318 9.46555 Results show that the different versions can have some variance in the execution time, but the difference is not too relevant.",
    "url": "/docs/en/benchmark",
    "relUrl": "/docs/en/benchmark"
  },
  "861": {
    "id": "861",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/bert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/bert_embeddings.html"
  },
  "862": {
    "id": "862",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_question_answering.html"
  },
  "863": {
    "id": "863",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_sequence_classification.html"
  },
  "864": {
    "id": "864",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/bert_for_token_classification.html"
  },
  "865": {
    "id": "865",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/bert_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/bert_sentence_embeddings.html"
  },
  "866": {
    "id": "866",
    "title": "Best Practices Using Pretrained Models Together",
    "content": "Entity Resolver Models and Features In the table below, all Entity Resolver models, their features, appropriate embeddings, and AUX info are illustrated. For instance, features of sbertresolve_ner_model_finder are under FEATURES column and it is trained using sbert_jsl_medium_uncased embeddings. Auxiliary info can be found under the AUX column if it is present. NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. NO MODEL NAME FEATURES EMBEDDINGS LANGUAGE AUX 1 sbertresolve_ner_model_finder • Maps clinical entities (NER) to the most appropriate NER model• sbert_jsl_medium_uncased embeddings• Returns a list of pretrained NER models sbert_jsl_medium_uncased EN   2 sbiobertresolve_clinical_abbreviation_acronym • Maps  clinical abbreviations and acronyms to their meanings• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   3 sbiobertresolve_cpt • CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   4 sbiobertresolve_cpt_augmented • Augmented version of sbiobertresolve_cpt model• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   5 sbiobertresolve_cpt_procedures_augmented • Procedures to CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   6 sbiobertresolve_cpt_procedures_measurements_augmented • Procedure and Measurements to CPT Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   7 sbiobertresolve_hcc_augmented • HCC Codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   8 sbiobertresolve_icd10cm • ICD-10-CM codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   9 sbertresolve_icd10gm • German ICD10-GM Codes• sent_bert_base_cased (DE) sent_bert_base_cased (DE) DE   10 sbiobertresolve_icd10cm_augmented • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Augmented version of sbiobertresolve_icd10cm model with synonyms, four times richer. sbiobert_base_cased_mli EN   11 sbiobertresolve_icd10cm_augmented_billable_hcc • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Provides HCC information of the codes in all_k_aux_labels column• This column can be divided to get further details: billable status - hcc status - hcc score. sbiobert_base_cased_mli EN HCC and Billable Information 12 sbiobertresolve_icd10cm_generalised • ICD-10-CM codes up to 3 Characters (general type of injury or disease)• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   13 sbiobertresolve_icd10cm_slim_billable_hcc • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets• Provides  HCC information of the codes in all_k_aux_labels column.• This column can be divided to get further details: billable status - hcc status - hcc score. sbiobert_base_cased_mli EN HCC and Billable Information 14 sbertresolve_icd10cm_slim_billable_hcc_med • ICD-10-CM codes• sbert_jsl_medium_uncased embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets inside the metadata.• Provides  HCC information of the codes in all_k_aux_labels column• This column can be divided to get further details: billable status - hcc status - hcc score. sbert_jsl_medium_uncased EN HCC and Billable Information 15 sbiobertresolve_icd10cm_slim_normalized • ICD-10-CM codes• sbiobert_base_cased_mli embeddings• Slim version (synonyms having low cosine similarity to unnormalized terms are dropped)• Provides  the official resolution text within the brackets inside the metadata. sbiobert_base_cased_mli EN   16 sbiobertresolve_icd10pcs • ICD-10-PCS codes• sbiobert_base_cased_mli embeddings sbiobert_base_cased_mli EN   17 sbiobertresolve_icdo • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 18 sbiobertresolve_icdo_base • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 19 sbiobertresolve_icdo_augmented • ICD-O Codes (International Classification of Diseases for Oncology code)• Provides topography codes and morphology codes comprising of Histology and Behavior codes in all_k_aux_labels columns• sbiobert_base_cased_mli embeddings• More granularity with respect to body parts• Augmented using the site information coming from ICD10 and synonyms coming from SNOMED vocabularies. sbiobert_base_cased_mli EN Topography codes, Morphology codes comprising of Histology and Behavior codes 20 sbiobertresolve_rxnorm • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   21 sbiobertresolve_rxnorm_augmented • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbiobert_base_cased_mli EN Concept classes of the drugs 22 sbiobertresolve_rxnorm_augmented_cased • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Cased (unlowered) concept names• Augmented version of sbiobertresolve_rxnorm model sbiobert_base_cased_mli EN Concept classes of the drugs 23 sbiobertresolve_rxnorm_disposition • RxNorm Codes for Drugs/ Ingredients• sbiobert_base_cased_mli  embeddings• Provides dispositions of the RxNorm codes in all_k_aux_labels column. sbiobert_base_cased_mli EN Provides dispositions of the RxNorm codes in all_k_aux_labels column. 24 sbertresolve_rxnorm_disposition • Medication entities (like drugs/ingredients) to RxNorm codes• Provides the dispositions of the codes in all_k_aux_labels column• sbert_jsl_medium_uncased embeddings (light) sbert_jsl_medium_uncased EN Disposition Information 25 sbiobertresolve_jsl_rxnorm_augmented • RxNorm Codes for Drugs/ Ingredients• sbiobert_jsl_rxnorm_cased  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbiobert_jsl_rxnorm_cased EN Concept classes of the drugs 26 sbluebertresolve_rxnorm_augmented_uncased • RxNorm Codes for Drugs/ Ingredients• sbluebert_base_uncased_mli  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbluebert_base_uncased_mli EN Concept classes of the drugs 27 sbertresolve_jsl_rxnorm_augmented_med • RxNorm Codes for Drugs/ Ingredients• sbert_jsl_medium_rxnorm_uncased  embeddings• Provides concept classes of the drugs in all_k_aux_labels column.• Augmented version of sbiobertresolve_rxnorm model sbert_jsl_medium_rxnorm_uncased EN Concept classes of the drugs 28 sbiobertresolve_rxcui • RxCUI Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   29 sbluebertresolve_loinc • LOINC Codes• sbluebert_base_uncased_mli  embeddings sbluebert_base_uncased_mli EN   30 sbiobertresolve_loinc • LOINC Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   31 sbiobertresolve_loinc_augmented • LOINC Codes• sbiobert_base_cased_mli  embeddings• Augmented version of sbiobertresolve_loinc sbiobert_base_cased_mli EN   32 sbiobertresolve_loinc_cased • LOINC Codes• sbiobert_base_cased_mli  embeddings• Cased (unlowered) concept names• Augmented version of sbiobertresolve_loinc sbiobert_base_cased_mli EN   33 sbluebertresolve_loinc_uncased • LOINC Codes• sbluebert_base_uncased_mli  embeddings• Uncased (lowercased) concept names• Augmented version of sbiobertresolve_loinc sbluebert_base_uncased_mli EN   34 sbiobertresolve_mesh • MeSH Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   35 sbiobertresolve_ndc • NDC Codes• sbiobert_base_cased_mli  embeddings• If a drug has more than one NDC code, it returns all other codes in the all_k_aux_label column sbiobert_base_cased_mli EN If drugs have multiple NDC code, it returns all other codes in the all_k_aux_label column 36 sbiobertresolve_hcpcs • HCPCS Codes• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN Domain Information 37 sbiobertresolve_HPO • Maps phenotypic abnormalities encountered in human diseases to Human Phenotype Ontology (HPO)• Provides associated codes from the following vocabularies for each HPO code: - MeSH (Medical Subject Headings)- SNOMED- UMLS (Unified Medical Language System ) - ORPHA (international reference resource for information on rare diseases and orphan drugs) - OMIM (Online Mendelian Inheritance in Man) in all_k_aux_labels column sbiobert_base_cased_mli EN SNOMED, MeSH, UMLS, ORPHA, OMIM Codes 38 sbiobertresolve_snomed_auxConcepts • SNOMED Codes• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes sbiobert_base_cased_mli EN   39 sbiobertresolve_snomed_auxConcepts_int • SNOMED Codes (INT Version)• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes sbiobert_base_cased_mli EN   40 sbiobertresolve_snomed_bodyStructure • SNOMED Codes for body structure• sbiobert_base_cased_mli  embeddings• Anatomical structures to body structure SNOMED codes sbiobert_base_cased_mli EN   41 sbertresolve_snomed_bodyStructure_med • SNOMED Codes for body structure• sbert_jsl_medium_uncased  embeddings• Anatomical structures to body structure SNOMED codes sbert_jsl_medium_uncased EN   42 sbiobertresolve_snomed_drug • SNOMED Codes (drug version)• sbiobert_base_cased_mli  embeddings• Drug entities to SNOMED codes sbiobert_base_cased_mli EN   43 sbiobertresolve_snomed_findings • SNOMED Codes (CT version)• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   44 sbiobertresolve_snomed_findings_int • SNOMED Codes (INT version)• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   45 sbiobertresolve_snomed_findings_aux_concepts • SNOMED Codes• sbiobert_base_cased_mli  embeddings• Capable of extracting Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure concepts of Snomed codes• Both Aux and CT versions together sbiobert_base_cased_mli EN   46 sbiobertresolve_snomed_procedures_measurements • SNOMED Codes for procedure and measurements• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   47 sbiobertresolve_clinical_snomed_procedures_measurements • SNOMED Codes for procedure and measurements• sbiobert_base_cased_mli  embeddings sent_biobert_clinical_base_cased EN   48 sbertresolve_snomed_conditions • Conditions to SNOMED Codes• sbert_jsl_medium_uncased embeddings sbert_jsl_medium_uncased EN   49 robertaresolve_snomed • Spanish SNOMED Codes• Roberta Clinical Word Embeddings (roberta_base_biomedical_es)• averaged with SentenceEmbeddings. roberta_base_biomedical_es ES   50 sbertresolve_snomed • German SNOMED Codes• sent_bert_base_cased (DE) sent_bert_base_cased (DE) DE   51 sbiobertresolve_umls_clinical_drugs • UMLS CUI Codes for Clinical Drugs• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   52 sbiobertresolve_umls_disease_syndrome • UMLS CUI Codes for Disease and Syndrom entities• sbiobert_base_cased_mli  embeddings sbiobert_base_cased_mli EN   53 sbiobertresolve_umls_drug_substance • UMLS CUI Codes for Drug and Substance entities• sbiobert_base_cased_mli  embeddings• Clinical Drugs, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance to UMLS CUI Codes sbiobert_base_cased_mli EN   54 sbiobertresolve_umls_findings • UMLS CUI Codes for clinical entities and concepts• sbiobert_base_cased_mli  embeddings• 4 major categories of UMLS CUI codes sbiobert_base_cased_mli EN   55 sbiobertresolve_umls_major_concepts • UMLS CUI Codes for clinical entities and concepts• sbiobert_base_cased_mli  embeddings• 4 major categories (Clinical Findings, Medical Devices, Anatomical Structures, and Injuries &amp; Poisoning terms) of UMLS CUI codes sbiobert_base_cased_mli EN               Entity Resolver Model and NER Model Pairs In the table below, you can find Entity Resolver models as well as its appropriate NER models and labels, that can return optimal results. For instance, sbiobertresolve_hcc_augmented resolver model must be used with sbiobert_base_cased_mli as embeddings, ner_clinical as NER model, PROBLEM set in setWhiteList(). NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. ENTITY RESOLVER MODEL SENTENCE EMBEDDINGS NER MODEL NER MODEL WHITELIST LABEL MERGE CHUNKS (ChunkMergeApproach) sbiobertresolve_HPO sbiobert_base_cased_mli ner_human_phenotype_gene_clinical No need to set whiteList sbiobertresolve_cpt_procedures_measurements_augmented sbiobert_base_cased_mli ner_jsl Procedure Merge ner_jsl and ner_measurements_clinical model chunks ner_measurements_clinical Measurements sbiobertresolve_hcc_augmented sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_hcpcs sbiobert_base_cased_mli ner_jsl Procedure sbiobertresolve_icd10cm_augmented_billable_hcc sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_icd10cm_generalised sbiobert_base_cased_mli ner_clinical PROBLEM sbiobertresolve_icd10pcs sbiobert_base_cased_mli ner_jsl Procedure sbiobertresolve_icdo_base sbiobert_base_cased_mli ner_jsl Oncological sbiobertresolve_loinc_augmented sbiobert_base_cased_mli ner_jsl TestBMIHDLLDLMedical_DeviceTemperatureTotal_CholesterolTriglyceridesBlood_Pressure sbiobertresolve_mesh sbiobert_base_cased_mli ner_clinical No need to set whiteList sbiobertresolve_rxcui sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_rxnorm_augmented sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_rxnorm_disposition sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_snomed_bodyStructure sbiobert_base_cased_mli ner_jsl Disease_Syndrome_DisorderExternal_body_part_or_region Merge ner_jsl and ner_anatomy_coarse model chunks ner_anatomy_coarse No need to set whiteList sbiobertresolve_snomed_procedures_measurements sbiobert_base_cased_mli ner_jsl ProcedureTestBMIHDLLDLTemperatureTotal_CholesterolTriglyceridesBlood_Pressure Merge ner_jsl and ner_measurements_clinical model chunks ner_measurements_clinical Measurements sbiobertresolve_snomed_findings sbiobert_base_cased_mli ner_clinical No need to set whiteList sbiobertresolve_umls_disease_syndrome sbiobert_base_cased_mli ner_jsl Cerebrovascular_DiseaseCommunicable_DiseaseDiabetesDisease_Syndrome_DisorderHeart_DiseaseHyperlipidemiaHypertensionInjury_or_PoisoningKidney_DiseaseObesityOncologicalOverweightPsychological_ConditionSymptomVS_FindingImagingFindingsEKG_Findings sbiobertresolve_umls_clinical_drugs sbiobert_base_cased_mli ner_posology DRUG sbiobertresolve_umls_major_concepts sbiobert_base_cased_mli ner_jsl Cerebrovascular_DiseaseCommunicable_DiseaseDiabetesDisease_Syndrome_DisorderHeart_DiseaseHyperlipidemiaHypertensionInjury_or_PoisoningKidney_DiseaseMedical-DeviceObesityOncologicalOverweightPsychological_ConditionSymptomVS_FindingImagingFindingsEKG_Findings sbiobertresolve_ndc sbiobert_base_cased_mli ner_posology_greedy DRUG Relation Extraction Models and Relation Pairs Table In the table below, available Relation Extraction models, its labels, optimal NER model, and meaningful relation pairs are illustrated. For instance, re_bodypart_proceduretest RE model returns (0,1) labels (binary), works optimally with ner_jsl NER model, and outputs relation pairs under the RE PAIRS column. NOTE: This table is shared just to give you a rough idea about which pretrained models can be used together. You can get better or worse performance by playing out with different models. NO RE MODEL RE MODEL LABELS NER MODEL RE PAIRS 1 re_bodypart_proceduretest 0,1 ner_jsl [“external_body_part_or_region-test”, ”test-external_body_part_or_region”,“internal_organ_or_component-test”,“test-internal_organ_or_component”,“external_body_part_or_region-procedure”,“procedure-external_body_part_or_region”,“procedure-internal_organ_or_component”,“internal_organ_or_component-procedure”] 2 re_ade_clinical 0,1 ner_ade_clinical [“ade-drug”, ”drug-ade”] 3 redl_chemprot_biobert CPR:1, CPR:2, CPR:3, CPR:4, CPR:5, CPR:6, CPR:7, CPR:8, CPR:9, CPR:10 ner_chemprot_clinical [“No need to set pairs.”] 4 re_human_phenotype_gene_clinical 0,1 ner_human_phenotype_gene_clinical [“No need to set pairs.”] 5 re_bodypart_directions 0,1 ner_jsl [“direction-external_body_part_or_region”,“external_body_part_or_region-direction”,“direction-internal_organ_or_component”,“internal_organ_or_component-direction”] 6 re_bodypart_problem 0,1 ner_jsl [“internal_organ_or_component-cerebrovascular_disease”, “cerebrovascular_disease-internal_organ_or_component”,“internal_organ_or_component-communicable_disease”, “communicable_disease-internal_organ_or_component”,“internal_organ_or_component-diabetes”, “diabetes-internal_organ_or_component”,“internal_organ_or_component-disease_syndrome_disorder”, “disease_syndrome_disorder-internal_organ_or_component”,“internal_organ_or_component-ekg_findings”, “ekg_findings-internal_organ_or_component”,“internal_organ_or_component-heart_disease”, “heart_disease-internal_organ_or_component”,“internal_organ_or_component-hyperlipidemia”, “hyperlipidemia-internal_organ_or_component”,“internal_organ_or_component-hypertension”, “hypertension-internal_organ_or_component”,“internal_organ_or_component-imagingfindings”, “imagingfindings-internal_organ_or_component”,“internal_organ_or_component-injury_or_poisoning”, “injury_or_poisoning-internal_organ_or_component”,“internal_organ_or_component-kidney_disease”, “kidney_disease-internal_organ_or_component”,“internal_organ_or_component-oncological”, “oncological-internal_organ_or_component”,“internal_organ_or_component-psychological_condition”, “psychological_condition-internal_organ_or_component”,“internal_organ_or_component-symptom”, “symptom-internal_organ_or_component”,“internal_organ_or_component-vs_finding”, “vs_finding-internal_organ_or_component”,“external_body_part_or_region-communicable_disease”, “communicable_disease-external_body_part_or_region”,“external_body_part_or_region-diabetes”, “diabetes-external_body_part_or_region”,“external_body_part_or_region-disease_syndrome_disorder”, “disease_syndrome_disorder-external_body_part_or_region”,“external_body_part_or_region-hypertension”, “hypertension-external_body_part_or_region”,“external_body_part_or_region-imagingfindings”, “imagingfindings-external_body_part_or_region”,“external_body_part_or_region-injury_or_poisoning”, “injury_or_poisoning-external_body_part_or_region”,“external_body_part_or_region-obesity”, “obesity-external_body_part_or_region”,“external_body_part_or_region-oncological”, “oncological-external_body_part_or_region”,“external_body_part_or_region-overweight”, “overweight-external_body_part_or_region”,“external_body_part_or_region-symptom”, “symptom-external_body_part_or_region”,“external_body_part_or_region-vs_finding”, “vs_finding-external_body_part_or_region”] 7 re_drug_drug_interaction_clinical DDI-advise, DDI-effect, DDI-mechanism, DDI-int, DDI-false ner_posology [“drug-drug”] 8 re_clinical TrIP, TrWP, TrCP, TrAP, TrAP, TeRP, TeCP, PIP ner_clinical [“No need to set pairs.”] 9 re_temporal_events_clinical AFTER, BEFORE, OVERLAP ner_events_clinical [“No need to set pairs.”] 10 re_temporal_events_enriched_clinical BEFORE, AFTER, SIMULTANEOUS, BEGUN_BY, ENDED_BY, DURING, BEFORE_OVERLAP ner_events_clinical [“No need to set pairs.”] 11 re_test_problem_finding 0,1 ner_jsl [“test-cerebrovascular_disease”, “cerebrovascular_disease-test”,“test-communicable_disease”, “communicable_disease-test”,“test-diabetes”, “diabetes-test”,“test-disease_syndrome_disorder”, “disease_syndrome_disorder-test”,“test-heart_disease”, “heart_disease-test”,“test-hyperlipidemia”, “hyperlipidemia-test”,“test-hypertension”, “hypertension-test”,“test-injury_or_poisoning”, “injury_or_poisoning-test”,“test-kidney_disease”, “kidney_disease-test”,“test-obesity”, “obesity-test”,“test-oncological”, “oncological-test”,“test-psychological_condition”, “psychological_condition-test”,“test-symptom”, “symptom-test”,“ekg_findings-disease_syndrome_disorder”, “disease_syndrome_disorder-ekg_findings”,“ekg_findings-heart_disease”, “heart_disease-ekg_findings”,“ekg_findings-symptom”, “symptom-ekg_findings”,“imagingfindings-cerebrovascular_disease”, “cerebrovascular_disease-imagingfindings”,“imagingfindings-communicable_disease”, “communicable_disease-imagingfindings”,“imagingfindings-disease_syndrome_disorder”, “disease_syndrome_disorder-imagingfindings”,“imagingfindings-heart_disease”, “heart_disease-imagingfindings”,“imagingfindings-hyperlipidemia”, “hyperlipidemia-imagingfindings”,“imagingfindings-hypertension”, “hypertension-imagingfindings”,“imagingfindings-injury_or_poisoning”, “injury_or_poisoning-imagingfindings”,“imagingfindings-kidney_disease”, “kidney_disease-imagingfindings”,“imagingfindings-oncological”, “oncological-imagingfindings”,“imagingfindings-psychological_condition”, “psychological_condition-imagingfindings”,“imagingfindings-symptom”, “symptom-imagingfindings”,“vs_finding-cerebrovascular_disease”, “cerebrovascular_disease-vs_finding”,“vs_finding-communicable_disease”, “communicable_disease-vs_finding”,“vs_finding-diabetes”, “diabetes-vs_finding”,“vs_finding-disease_syndrome_disorder”, “disease_syndrome_disorder-vs_finding”,“vs_finding-heart_disease”, “heart_disease-vs_finding”,“vs_finding-hyperlipidemia”, “hyperlipidemia-vs_finding”,“vs_finding-hypertension”, “hypertension-vs_finding”,“vs_finding-injury_or_poisoning”, “injury_or_poisoning-vs_finding”,“vs_finding-kidney_disease”, “kidney_disease-vs_finding”,“vs_finding-obesity”, “obesity-vs_finding”,“vs_finding-oncological”, “oncological-vs_finding”,“vs_finding-overweight”, “overweight-vs_finding”,“vs_finding-psychological_condition”, “psychological_condition-vs_finding”,“vs_finding-symptom”, “symptom-vs_finding”] 12 re_test_result_date is_finding_of, is_result_of, is_date_of, O ner_jsl [“test-test_result”, “test_result-test”,“test-date”, “date-test”,“test-imagingfindings”, “imagingfindings-test”,“test-ekg_findings”, “ekg_findings-test”,“date-test_result”, “test_result-date”,“date-imagingfindings”, “imagingfindings-date”,“date-ekg_findings”, “ekg_findings-date”] 13 re_date_clinical 0,1 ner_jsl [“date-admission_discharge”, “admission_discharge-date”,“date-alcohol”, “alcohol-date”,“date-allergen”, “allergen-date”,“date-bmi”, “bmi-date”,“date-birth_entity”, “birth_entity-date”,“date-blood_pressure”, “blood_pressure-date”,“date-cerebrovascular_disease”, “cerebrovascular_disease-date”,“date-clinical_dept”, “clinical_dept-date”,“date-communicable_disease”, “communicable_disease-date”,“date-death_entity”, “death_entity-date”,“date-diabetes”, “diabetes-date”,“date-diet”, “diet-date”,“date-disease_syndrome_disorder”, “disease_syndrome_disorder-date”,“date-drug_brandname”, “drug_brandname-date”,“date-drug_ingredient”, “drug_ingredient-date”,“date-ekg_findings”, “ekg_findings-date”,“date-external_body_part_or_region”, “external_body_part_or_region-date”,“date-fetus_newborn”, “fetus_newborn-date”,“date-hdl”, “hdl-date”,“date-heart_disease”, “heart_disease-date”,“date-height”, “height-date”,“date-hyperlipidemia”, “hyperlipidemia-date”,“date-hypertension”, “hypertension-date”,“date-imagingfindings”, “imagingfindings-date”,“date-imaging_technique”, “imaging_technique-date”,“date-injury_or_poisoning”, “injury_or_poisoning-date”,“date-internal_organ_or_component”, “internal_organ_or_component-date”,“date-kidney_disease”, “kidney_disease-date”,“date-ldl”, “ldl-date”,“date-modifier”, “modifier-date”,“date-o2_saturation”, “o2_saturation-date”,“date-obesity”, “obesity-date”,“date-oncological”, “oncological-date”,“date-overweight”, “overweight-date”,“date-oxygen_therapy”, “oxygen_therapy-date”,“date-pregnancy”, “pregnancy-date”,“date-procedure”, “procedure-date”,“date-psychological_condition”, “psychological_condition-date”,“date-pulse”, “pulse-date”,“date-respiration”, “respiration-date”,“date-smoking”, “smoking-date”,“date-substance”, “substance-date”,“date-substance_quantity”, “substance_quantity-date”,“date-symptom”, “symptom-date”,“date-temperature”, “temperature-date”,“date-test”, “test-date”,“date-test_result”, “test_result-date”,“date-total_cholesterol”, “total_cholesterol-date”,“date-treatment”, “treatment-date”,“date-triglycerides”, “triglycerides-date”,“date-vs_finding”, “vs_finding-date”,“date-vaccine”, “vaccine-date”,“date-vital_signs_header”, “vital_signs_header-date”,“date-weight”, “weight-date”,“time-admission_discharge”, “admission_discharge-time”,“time-alcohol”, “alcohol-time”,“time-allergen”, “allergen-time”,“time-bmi”, “bmi-time”,“time-birth_entity”, “birth_entity-time”,“time-blood_pressure”, “blood_pressure-time”,“time-cerebrovascular_disease”, “cerebrovascular_disease-time”,“time-clinical_dept”, “clinical_dept-time”,“time-communicable_disease”, “communicable_disease-time”,“time-death_entity”, “death_entity-time”,“time-diabetes”, “diabetes-time”,“time-diet”, “diet-time”,“time-disease_syndrome_disorder”, “disease_syndrome_disorder-time”,“time-drug_brandname”, “drug_brandname-time”,“time-drug_ingredient”, “drug_ingredient-time”,“time-ekg_findings”, “ekg_findings-time”,“time-external_body_part_or_region”, “external_body_part_or_region-time”,“time-fetus_newborn”, “fetus_newborn-time”,“time-hdl”, “hdl-time”,“time-heart_disease”, “heart_disease-time”,“time-height”, “height-time”,“time-hyperlipidemia”, “hyperlipidemia-time”,“time-hypertension”, “hypertension-time”,“time-imagingfindings”, “imagingfindings-time”,“time-imaging_technique”, “imaging_technique-time”,“time-injury_or_poisoning”, “injury_or_poisoning-time”,“time-internal_organ_or_component”, “internal_organ_or_component-time”,“time-kidney_disease”, “kidney_disease-time”,“time-ldl”, “ldl-time”,“time-modifier”, “modifier-time”,“time-o2_saturation”, “o2_saturation-time”,“time-obesity”, “obesity-time”,“time-oncological”, “oncological-time”,“time-overweight”, “overweight-time”,“time-oxygen_therapy”, “oxygen_therapy-time”,“time-pregnancy”, “pregnancy-time”,“time-procedure”, “procedure-time”,“time-psychological_condition”, “psychological_condition-time”,“time-pulse”, “pulse-time”,“time-respiration”, “respiration-time”,“time-smoking”, “smoking-time”,“time-substance”, “substance-time”,“time-substance_quantity”, “substance_quantity-time”,“time-symptom”, “symptom-time”,“time-temperature”, “temperature-time”,“time-test”, “test-time”,“time-test_result”, “test_result-time”,“time-total_cholesterol”, “total_cholesterol-time”,“time-treatment”, “treatment-time”,“time-triglycerides”, “triglycerides-time”,“time-vs_finding”, “vs_finding-time”,“time-vaccine”, “vaccine-time”,“time-vital_signs_header”, “vital_signs_header-time”,“time-weight”, “weight-time”,“relativedate-admission_discharge”, “admission_discharge-relativedate”,“relativedate-alcohol”, “alcohol-relativedate”,“relativedate-allergen”, “allergen-relativedate”,“relativedate-bmi”, “bmi-relativedate”,“relativedate-birth_entity”, “birth_entity-relativedate”,“relativedate-blood_pressure”, “blood_pressure-relativedate”,“relativedate-cerebrovascular_disease”, “cerebrovascular_disease-relativedate”,“relativedate-clinical_dept”, “clinical_dept-relativedate”,“relativedate-communicable_disease”, “communicable_disease-relativedate”,“relativedate-death_entity”, “death_entity-relativedate”,“relativedate-diabetes”, “diabetes-relativedate”,“relativedate-diet”, “diet-relativedate”,“relativedate-disease_syndrome_disorder”, “disease_syndrome_disorder-relativedate”,“relativedate-drug_brandname”, “drug_brandname-relativedate”,“relativedate-drug_ingredient”, “drug_ingredient-relativedate”,“relativedate-ekg_findings”, “ekg_findings-relativedate”,“relativedate-external_body_part_or_region”, “external_body_part_or_region-relativedate”,“relativedate-fetus_newborn”, “fetus_newborn-relativedate”,“relativedate-hdl”, “hdl-relativedate”,“relativedate-heart_disease”, “heart_disease-relativedate”,“relativedate-height”, “height-relativedate”,“relativedate-hyperlipidemia”, “hyperlipidemia-relativedate”,“relativedate-hypertension”, “hypertension-relativedate”,“relativedate-imagingfindings”, “imagingfindings-relativedate”,“relativedate-imaging_technique”, “imaging_technique-relativedate”,“relativedate-injury_or_poisoning”, “injury_or_poisoning-relativedate”,“relativedate-internal_organ_or_component”, “internal_organ_or_component-relativedate”,“relativedate-kidney_disease”, “kidney_disease-relativedate”,“relativedate-ldl”, “ldl-relativedate”,“relativedate-modifier”, “modifier-relativedate”,“relativedate-o2_saturation”, “o2_saturation-relativedate”,“relativedate-obesity”, “obesity-relativedate”,“relativedate-oncological”, “oncological-relativedate”,“relativedate-overweight”, “overweight-relativedate”,“relativedate-oxygen_therapy”, “oxygen_therapy-relativedate”,“relativedate-pregnancy”, “pregnancy-relativedate”,“relativedate-procedure”, “procedure-relativedate”,“relativedate-psychological_condition”, “psychological_condition-relativedate”,“relativedate-pulse”, “pulse-relativedate”,“relativedate-respiration”, “respiration-relativedate”,“relativedate-smoking”, “smoking-relativedate”,“relativedate-substance”, “substance-relativedate”,“relativedate-substance_quantity”, “substance_quantity-relativedate”,“relativedate-symptom”, “symptom-relativedate”,“relativedate-temperature”, “temperature-relativedate”,“relativedate-test”, “test-relativedate”,“relativedate-test_result”, “test_result-relativedate”,“relativedate-total_cholesterol”, “total_cholesterol-relativedate”,“relativedate-treatment”, “treatment-relativedate”,“relativedate-triglycerides”, “triglycerides-relativedate”,“relativedate-vs_finding”, “vs_finding-relativedate”,“relativedate-vaccine”, “vaccine-relativedate”,“relativedate-vital_signs_header”, “vital_signs_header-relativedate”,“relativedate-weight”, “weight-relativedate”,“relativetime-admission_discharge”, “admission_discharge-relativetime”,“relativetime-alcohol”, “alcohol-relativetime”,“relativetime-allergen”, “allergen-relativetime”,“relativetime-bmi”, “bmi-relativetime”,“relativetime-birth_entity”, “birth_entity-relativetime”,“relativetime-blood_pressure”, “blood_pressure-relativetime”,“relativetime-cerebrovascular_disease”, “cerebrovascular_disease-relativetime”,“relativetime-clinical_dept”, “clinical_dept-relativetime”,“relativetime-communicable_disease”, “communicable_disease-relativetime”,“relativetime-death_entity”, “death_entity-relativetime”,“relativetime-diabetes”, “diabetes-relativetime”,“relativetime-diet”, “diet-relativetime”,“relativetime-disease_syndrome_disorder”, “disease_syndrome_disorder-relativetime”,“relativetime-drug_brandname”, “drug_brandname-relativetime”,“relativetime-drug_ingredient”, “drug_ingredient-relativetime”,“relativetime-ekg_findings”, “ekg_findings-relativetime”,“relativetime-external_body_part_or_region”, “external_body_part_or_region-relativetime”,“relativetime-fetus_newborn”, “fetus_newborn-relativetime”,“relativetime-hdl”, “hdl-relativetime”,“relativetime-heart_disease”, “heart_disease-relativetime”,“relativetime-height”, “height-relativetime”,“relativetime-hyperlipidemia”, “hyperlipidemia-relativetime”,“relativetime-hypertension”, “hypertension-relativetime”,“relativetime-imagingfindings”, “imagingfindings-relativetime”,“relativetime-imaging_technique”, “imaging_technique-relativetime”,“relativetime-injury_or_poisoning”, “injury_or_poisoning-relativetime”,“relativetime-internal_organ_or_component”, “internal_organ_or_component-relativetime”,“relativetime-kidney_disease”, “kidney_disease-relativetime”,“relativetime-ldl”, “ldl-relativetime”,“relativetime-modifier”, “modifier-relativetime”,“relativetime-o2_saturation”, “o2_saturation-relativetime”,“relativetime-obesity”, “obesity-relativetime”,“relativetime-oncological”, “oncological-relativetime”,“relativetime-overweight”, “overweight-relativetime”,“relativetime-oxygen_therapy”, “oxygen_therapy-relativetime”,“relativetime-pregnancy”, “pregnancy-relativetime”,“relativetime-procedure”, “procedure-relativetime”,“relativetime-psychological_condition”, “psychological_condition-relativetime”,“relativetime-pulse”, “pulse-relativetime”,“relativetime-respiration”, “respiration-relativetime”,“relativetime-smoking”, “smoking-relativetime”,“relativetime-substance”, “substance-relativetime”,“relativetime-substance_quantity”, “substance_quantity-relativetime”,“relativetime-symptom”, “symptom-relativetime”,“relativetime-temperature”, “temperature-relativetime”,“relativetime-test”, “test-relativetime”,“relativetime-test_result”, “test_result-relativetime”,“relativetime-total_cholesterol”, “total_cholesterol-relativetime”,“relativetime-treatment”, “treatment-relativetime”,“relativetime-triglycerides”, “triglycerides-relativetime”,“relativetime-vs_finding”, “vs_finding-relativetime”,“relativetime-vaccine”, “vaccine-relativetime”,“relativetime-vital_signs_header”, “vital_signs_header-relativetime”,“relativetime-weight”, “weight-relativetime”] 14 redl_drugprot_biobert  INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST ner_drugprot_clinical [“checmical-gene”, “chemical-gene_and_chemical”, “gene_and_chemical-gene”] 15 re_drugprot_clinical  INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST ner_drugprot_clinical [“checmical-gene”, “chemical-gene_and_chemical”, “gene_and_chemical-gene”] 16 redl_nihss_biobert Has_Value, 0 ner_nihss [“No need to set pairs.”]",
    "url": "/docs/en/best_practices_pretrained_models",
    "relUrl": "/docs/en/best_practices_pretrained_models"
  },
  "867": {
    "id": "867",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/big_text_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/big_text_matcher.html"
  },
  "868": {
    "id": "868",
    "title": "Biomedical Research  - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/biomedical_research",
    "relUrl": "/biomedical_research"
  },
  "869": {
    "id": "869",
    "title": "License Management",
    "content": "By default, the Annotation Lab allows access to community pre-trained models and embeddings. Those are available on the Models Hub page. To gain access to licensed resources (e.g. pre-trained models and embeddings) admin user can import a license (Healthcare, Finance, Legal, or Visual NLP) which will activate additional features: Access to licensed models for pre-annotation Access to healthcare, finance, and legal embeddings Access to rules Access to optimized annotators Access to training custom models using licensed embeddings The admin user can upload a Spark NLP license JSON file by visiting the License page. The license is generated by the John Snow Labs license server and is available on my.JohnSnowLabs.com. Once a valid license is uploaded, all the licensed (Healthcare, Finance, Legal, and Visual NLP) models and embeddings become available for download. The License page shows the history of license uploads with detailed information like License Info, Status, Renewal Date, and License Secrets. Support for Floating Licenses Annotation Lab supports floating licenses with different scopes (ocr: training, ocr: inference, healthcare: inference, healthcare: training, finance: inference, finance: training, legal: inference, legal: training). Depending on the scope of the available license, users can perform model training and/or deploy pre-annotation servers. Licenses are a must for training Healthcare, Finance, and Legal models and deploying these models as pre-annotation servers. Floating licenses can be acquired on self-service via my.JohnSnowLabs.com. One floating license is bound to only one server (pre-annotation server, OCR server, training job) at a time. To run multiple model training jobs and/or pre-annotations servers, users must provide multiple floating licenses. Annotation Lab supports either floating licenses or air-gapped licenses. Mixing floating and air-gapped licenses on the same Annotation Lab instance is not allowed. Usage of NLP Licenses The number of available floating licenses can influence the creation of multiple training and pre-annotation servers. For example, to deploy 5 pre-annotation servers using Spark NLP for Healthcare models or embeddings, across 5 different projects, you will need 5 floating licenses. Since one floating license can only be used for one server, it is not possible to deploy a pre-annotation server and then trigger training from the same project when only one license is available. In this case, the pre-annotation server has to be deleted first, and then the training can be started. Those restrictions do not apply when using Spark NLP models and embeddings.",
    "url": "/docs/en/alab/byol",
    "relUrl": "/docs/en/alab/byol"
  },
  "870": {
    "id": "870",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/camembert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/camembert_embeddings.html"
  },
  "871": {
    "id": "871",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_question_answering.html"
  },
  "872": {
    "id": "872",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification.html"
  },
  "873": {
    "id": "873",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/camembert_for_token_classification.html"
  },
  "874": {
    "id": "874",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/chunk2_doc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/chunk2_doc.html"
  },
  "875": {
    "id": "875",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/chunk_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/chunk_embeddings.html"
  },
  "876": {
    "id": "876",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/chunk_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/chunk_tokenizer.html"
  },
  "877": {
    "id": "877",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/chunker.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/chunker.html"
  },
  "878": {
    "id": "878",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/classifier_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/classifier_dl.html"
  },
  "879": {
    "id": "879",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/param/classifier_encoder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/param/classifier_encoder.html"
  },
  "880": {
    "id": "880",
    "title": "Classify Documents - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/classify_documents",
    "relUrl": "/classify_documents"
  },
  "881": {
    "id": "881",
    "title": "Classify Financial Documents - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/classify_financial_documents",
    "relUrl": "/classify_financial_documents"
  },
  "882": {
    "id": "882",
    "title": "Clinical Trials - Healthcare NLP Demos & Notebooks",
    "content": "",
    "url": "/clinical_trials",
    "relUrl": "/clinical_trials"
  },
  "883": {
    "id": "883",
    "title": "Cluster Management",
    "content": "Management of Preannotation and Training Servers Annotation Lab gives users the ability to view the list of all active servers. Any user can access the Clusters page by navigating to Settings &gt; Clusters. This page provides the following details. A summary of the status/limitations of the current infrastructure to run Spark NLP for Healthcare training jobs and/or pre-annotation servers. Ability to delete a server and free up resources when required, so that another training job and/or pre-annotation server can be started. Shows details of the server Server Name: The name of server that can help identify it while running pre-annotation or importing files. License Used/Scope: The license that is being used in the server and its scope. Usage: Let the user know the usage of the server. A server can be used for pre-annotation, training, or OCR. Status: Status of training and pre-annotation servers. Deployed By: The user who deployed the server. This information might be useful for contacting the user who deployed a server before deleting it. Deployed At: Shows when the server was deployed. By default, only 1 server can be initialized for either pre-annotation or training even if there are multiple licenses present. To enable more than 1 servers to be initialized update the below configuration parameter in annotationlab-updater.sh script inside the artifacts folder and then re-run it. model_server.count=&lt;NUMBER_OF_SERVER_TO_INITIALIZE&gt; airflow.model_server.count=&lt;NUMBER_OF_SERVER_TO_INITIALIZE&gt; To run the script: sudo ./annotationlab-updater.sh Status of Training and Preannotation Server A new column, status, is added to the Clusters page that gives the status of training and pre-annotation servers. The available pre-annotation server statuses are: Idle Busy Stopped Users can visualize which servers are busy and which are idle. It is very useful information when the user intends to deploy a new server in replacement of an idle one. In this situation, the user can delete an idle server and deploy another pre-annotation/ training server. This information is also available on the pre-annotation popup when the user selects the deployed server to use for pre-annotation. Also, if any issues are encountered during server initialization, those are displayed on the tooltip accessible via mouse-over. Depending on the issue, changes might be required in the infrastructure settings, and the user will have to manually redeploy the training/pre-annotation server.",
    "url": "/docs/en/alab/cluster_management",
    "relUrl": "/docs/en/alab/cluster_management"
  },
  "884": {
    "id": "884",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/logging/comet.html",
    "relUrl": "/api/python/modules/sparknlp/logging/comet.html"
  },
  "885": {
    "id": "885",
    "title": "Quick Start",
    "content": "Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. when building a load&amp;predict based model you will follow these steps: Pick a model/pipeline/component you want to create from the Namespace Call the model = nlp.load(component) method which will return an auto-completed pipeline Call model.predict(&#39;that was easy&#39;) on some String input These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&#39;How does this witchcraft work?&#39;) jsl.load() defines 18 components types usable in 1-liners, some can be prefixed with .train for training models Any of the actions for the component types can be passed as a string to nlp.load() and will return you the default model for that component type for the English language. You can further specify your model selection by placing a ‘.’ behind your component selection. After the ‘.’ you can specify the model you want via specifying a dataset or model version. See the Models Hub, the Components Namespace and The load function for more infos. Component type nlp.load() base Named Entity Recognition(NER) nlp.load(&#39;ner&#39;) Part of Speech (POS) nlp.load(&#39;pos&#39;) Classifiers nlp.load(&#39;classify&#39;) Word embeddings nlp.load(&#39;embed&#39;) Sentence embeddings nlp.load(&#39;embed_sentence&#39;) Chunk embeddings nlp.load(&#39;embed_chunk&#39;) Labeled dependency parsers nlp.load(&#39;dep&#39;) Unlabeled dependency parsers nlp.load(&#39;dep.untyped&#39;) Legitimatizes nlp.load(&#39;lemma&#39;) Matchers nlp.load(&#39;match&#39;) Normalizers nlp.load(&#39;norm&#39;) Sentence detectors nlp.load(&#39;sentence_detector&#39;) Chunkers nlp.load(&#39;chunk&#39;) Spell checkers nlp.load(&#39;spell&#39;) Stemmers nlp.load(&#39;stem&#39;) Stopwords cleaners nlp.load(&#39;stopwords&#39;) Cleaner nlp.load(&#39;clean&#39;) N-Grams nlp.load(&#39;ngram&#39;) Tokenizers nlp.load(&#39;tokenize&#39;) Annotator &amp; PretrainedPipeline based pipelines You can create Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the nlp module. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp from pprint import pprint nlp.start() explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) annotations = explain_document_pipeline.annotate(&quot;We are very happy about SparkNLP&quot;) pprint(annotations) OUTPUT: { &#39;stem&#39;: [&#39;we&#39;, &#39;ar&#39;, &#39;veri&#39;, &#39;happi&#39;, &#39;about&#39;, &#39;sparknlp&#39;], &#39;checked&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;lemma&#39;: [&#39;We&#39;, &#39;be&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;document&#39;: [&#39;We are very happy about SparkNLP&#39;], &#39;pos&#39;: [&#39;PRP&#39;, &#39;VBP&#39;, &#39;RB&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;NNP&#39;], &#39;token&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;sentence&#39;: [&#39;We are very happy about SparkNLP&#39;] } Custom Pipes Alternatively you can compose Annotators into a pipeline which offers the highest degree of customization from johnsnowlabs import nlp spark = nlp.start(nlp=False) pipe = nlp.Pipeline(stages= [ nlp.DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;doc&#39;), nlp.Tokenizer().setInputCols(&#39;doc&#39;).setOutputCol(&#39;tok&#39;) ]) spark_df = spark.createDataFrame([[&#39;Hello NLP World&#39;]]).toDF(&quot;text&quot;) pipe.fit(spark_df).transform(spark_df).show()",
    "url": "/docs/en/jsl/concepts",
    "relUrl": "/docs/en/jsl/concepts"
  },
  "886": {
    "id": "886",
    "title": "General Concepts",
    "content": "",
    "url": "/docs/en/concepts",
    "relUrl": "/docs/en/concepts"
  },
  "887": {
    "id": "887",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/conll.html",
    "relUrl": "/api/python/modules/sparknlp/training/conll.html"
  },
  "888": {
    "id": "888",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/conllu.html",
    "relUrl": "/api/python/modules/sparknlp/training/conllu.html"
  },
  "889": {
    "id": "889",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/context_spell_checker.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/context_spell_checker.html"
  },
  "890": {
    "id": "890",
    "title": "Contribute",
    "content": "Refer to our GitHub page to take a look at the GH Issues, as the project is yet small. You can create in there your own issues to either work on them yourself or simply propose them. Feel free to clone the repository locally and submit pull requests so we can review them and work together. feedback, ideas and bug reports testing and development training and testing nlp corpora documentation and research Help is always welcome, for any further questions, contact nlp@johnsnowlabs.com. Your own annotator model Creating your first annotator transformer should not be hard, here are a few guidelines to get you started. Lets assume we want a wrapper annotator, which puts a character surrounding tokens provided by a Tokenizer WordWrapper uid is utilized for transformer serialization, AnnotatorModel[MyAnnotator] will contain the common annotator logic We need to use standard constructor for java and python compatibility class WordWrapper(override val uid: String) extends AnnotatorModel[WordWrapper] { def this() = this(Identifiable.randomUID(&quot;WORD_WRAPPER&quot;)) } Annotator attributes This annotator is not flexible if we don’t provide parameters import com.johnsnowlabs.nlp.AnnotatorType._ override val annotatorType: AnnotatorType = TOKEN override val requiredAnnotatorTypes: Array[AnnotatorType] = Array[AnnotatorType](TOKEN) Annotator parameters This annotator is not flexible if we don’t provide parameters protected val character: Param[String] = new Param(this, &quot;character&quot;, &quot;this is the character used to wrap a token&quot;) def setCharacter(value: String): this.type = set(pattern, value) def getCharacter: String = $(pattern) setDefault(character, &quot;@&quot;) Annotator logic Here is how we act, annotations will automatically provide our required annotations We generally use annotatorType for metadata keys override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = { annotations.map(annotation =&gt; { Annotation( annotatorType, annotation.begin, annotation.end, Map(annotatorType -&gt; $(character) + annotation.result + $(character)) }) }",
    "url": "/contribute",
    "relUrl": "/contribute"
  },
  "891": {
    "id": "891",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/custom_pipelines.html",
    "relUrl": "/api/python/user_guide/custom_pipelines.html"
  },
  "892": {
    "id": "892",
    "title": "Databricks Solution Accelerators",
    "content": "",
    "url": "/databricks_solution_accelerators",
    "relUrl": "/databricks_solution_accelerators"
  },
  "893": {
    "id": "893",
    "title": "Utilities for Databricks",
    "content": "Submit a Task with jsl.run_in_databricks Easily run Python code in a Databricks cluster, using the John Snow Labs library. The fastest way to test this out, is to create a cluster with jsl.install() and then use jsl.run_in_databricks to start a task. # Execute a Raw Python string as script on Databricks from johnsnowlabs import * script = &quot;&quot;&quot; import nlu print(nlu.load(&#39;sentiment&#39;).predict(&#39;That was easy!&#39;))&quot;&quot;&quot; cluster_id = jsl.install(json_license_path=my_license, databricks_host=my_host,databricks_token=my_token) jsl.run_in_databricks(script, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Python Code String Example&#39;) This will start a Job Run which you can view in the Workflows tab And after a while you can see the results Run a Python Function in Databricks Define a function, which will be written to a local file, copied to HDFS and executed by the Databricks cluster. def my_function(): import nlu medical_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&quot;&quot;&quot; df = nlu.load(&#39;en.med_ner.diseases&#39;).predict(medical_text) for c in df.columns: print(df[c]) # my_function will run on databricks jsl.run_in_databricks(my_function, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Function test&#39;) This example will print all columns of the resulting dataframe which contains emdical NER predictions. Run a Raw Python Code String in Databricks Provide a string which must be valid Python Syntax. It will be written to string, copied to HDFS and executed by the Databricks Cluster. script = &quot;&quot;&quot; import nlu print(nlu.load(&#39;sentiment&#39;).predict(&#39;That was easy!&#39;))&quot;&quot;&quot; jsl.run_in_databricks(script, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Python Code String Example&#39;) Run a Python Script in Databricks Provide the path to a script on your machine. It will be copied to the Databricks HDFS and executed as task. jsl.run_in_databricks(&#39;path/to/my/script.py&#39;, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;Script test &#39;) Run a Python Module in Databricks Provide a module accessible to the john snow labs library. It’s content’s will be written to a local file, copied to HDFS and executed by the databricks cluster. import johnsnowlabs.auto_install.health_checks.nlp_test as nlp_test jsl.run_in_databricks(nlp_test, databricks_cluster_id=cluster_id, databricks_host=my_host, databricks_token=my_token, run_name=&#39;nlp_test&#39;)",
    "url": "/docs/en/jsl/databricks-utils",
    "relUrl": "/docs/en/jsl/databricks-utils"
  },
  "894": {
    "id": "894",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/date2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/date2_chunk.html"
  },
  "895": {
    "id": "895",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/date_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/date_matcher.html"
  },
  "896": {
    "id": "896",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/deberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/deberta_embeddings.html"
  },
  "897": {
    "id": "897",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_question_answering.html"
  },
  "898": {
    "id": "898",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification.html"
  },
  "899": {
    "id": "899",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/deberta_for_token_classification.html"
  },
  "900": {
    "id": "900",
    "title": "De-Identification - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/deidentification",
    "relUrl": "/deidentification"
  },
  "901": {
    "id": "901",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/demo",
    "relUrl": "/demo"
  },
  "902": {
    "id": "902",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/demos",
    "relUrl": "/demos"
  },
  "903": {
    "id": "903",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/dependency/dependency_parser.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/dependency/dependency_parser.html"
  },
  "904": {
    "id": "904",
    "title": "Detect Sentiment & Emotion - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/detect_sentiment_emotion",
    "relUrl": "/detect_sentiment_emotion"
  },
  "905": {
    "id": "905",
    "title": "Developers Guideline",
    "content": "",
    "url": "/docs/en/developers",
    "relUrl": "/docs/en/developers"
  },
  "906": {
    "id": "906",
    "title": "Diagnoses & Procedures - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/diagnoses_procedures",
    "relUrl": "/diagnoses_procedures"
  },
  "907": {
    "id": "907",
    "title": "Spark NLP Display",
    "content": "",
    "url": "/docs/en/display",
    "relUrl": "/docs/en/display"
  },
  "908": {
    "id": "908",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/distil_bert_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/distil_bert_embeddings.html"
  },
  "909": {
    "id": "909",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering.html"
  },
  "910": {
    "id": "910",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification.html"
  },
  "911": {
    "id": "911",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification.html"
  },
  "912": {
    "id": "912",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/doc2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/base/doc2_chunk.html"
  },
  "913": {
    "id": "913",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/doc2vec.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/doc2vec.html"
  },
  "914": {
    "id": "914",
    "title": "John Snow Labs - NLP Documentation",
    "content": "",
    "url": "/docs",
    "relUrl": "/docs"
  },
  "915": {
    "id": "915",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/document_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/document_assembler.html"
  },
  "916": {
    "id": "916",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/document_normalizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/document_normalizer.html"
  },
  "917": {
    "id": "917",
    "title": "Drugs & Adverse Events - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/drug_adverse_events",
    "relUrl": "/drug_adverse_events"
  },
  "918": {
    "id": "918",
    "title": "East Asian Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/east_asian_languages",
    "relUrl": "/east_asian_languages"
  },
  "919": {
    "id": "919",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/elmo_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/elmo_embeddings.html"
  },
  "920": {
    "id": "920",
    "title": "Embeddings",
    "content": "All the embeddings available in the Annotation Lab are listed on this page. General information about the embeddings like the name, version, source, and date of upload/download is available. Like models, any compatible embeddings can be downloaded from NLP Models Hub. By default, glove_100d, bert_base_cased, tfhub_use embeddings are included in every fresh installation of Annotation Lab. Custom Embeddings Upload Custom embeddings can be uploaded using the Upload button present in the top right corner of the page. Note: The embeddings to upload need to be Spark NLP compatible.",
    "url": "/docs/en/alab/embeddings",
    "relUrl": "/docs/en/alab/embeddings"
  },
  "921": {
    "id": "921",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/embeddings_finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/embeddings_finisher.html"
  },
  "922": {
    "id": "922",
    "title": "Enhance Low-Quality Images - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/enhance_low_quality_images",
    "relUrl": "/enhance_low_quality_images"
  },
  "923": {
    "id": "923",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/er/entity_ruler.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/er/entity_ruler.html"
  },
  "924": {
    "id": "924",
    "title": "European Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/european_languages",
    "relUrl": "/european_languages"
  },
  "925": {
    "id": "925",
    "title": "Evaluation",
    "content": "Spark NLP Evaluation This module includes tools to evaluate the accuracy of annotators and visualize the parameters used on training. It includes specific metrics for each annotator and its training time. The results will display on the console or to an MLflow tracking UI. Just with a simple import you can start using eval module. Check how to setup MLflow UI See here on eval folder if you want to check specific running examples. Example: PythonScala from sparknlp_jsl.eval import * import com.johnsnowlabs.nlp.eval._ Evaluating Norvig Spell Checker You can evaluate this spell checker either by training an annotator or by using a pretrained model. spark: Spark session. trainFile: A corpus of documents with correctly spell words. testFile: A corpus of documents with misspells words. groundTruthFile: The same corpus used on testFile but with correctly spell words. Train File Example: Any document that you prefer with correctly spell words. Test File Example: My siter go to Munich. Ground Truth File Example: My sister goes to Munich. Example for annotator: PythonScala spell = NorvigSweetingApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) norvigSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) norvigSpellEvaluation.computeAccuracyAnnotator(train_file, spell) val spell = new NorvigSweetingApproach() .setInputCols(Array(&quot;token&quot;)) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) val norvigSpellEvaluation = new NorvigSpellEvaluation(spark, testFile, groundTruthFile) norvigSpellEvaluation.computeAccuracyAnnotator(trainFile, spell) Example for pretrained model: PythonScala spell = NorvigSweetingModel.pretrained() norvigSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) norvigSpellEvaluation.computeAccuracyModel(spell) val spell = NorvigSweetingModel.pretrained() val norvigSpellEvaluation = new NorvigSpellEvaluation(spark, testFile, groundTruthFile) norvigSpellEvaluation.computeAccuracyModel(spell) Evaluating Symmetric Spell Checker You can evaluate this spell checker either by training an annotator or by using a pretrained model. spark: Spark session trainFile: A corpus of documents with correctly spell words. testFile: A corpus of documents with misspells words. groundTruthFile: The same corpus used on testFile but with correctly spell words. Train File Example: Any document that you prefer with correctly spell words. Test File Example: My siter go to Munich. Ground Truth File Example: My sister goes to Munich. Example for annotator: PythonScala spell = SymmetricDeleteApproach() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;checked&quot;) .setDictionary(dictionary_file) symSpellEvaluation = SymSpellEvaluation(spark, test_file, ground_truth_file) symSpellEvaluation.computeAccuracyAnnotator(train_file, spell) val spell = new SymmetricDeleteApproach() .setInputCols(Array(&quot;token&quot;)) .setOutputCol(&quot;checked&quot;) val symSpellEvaluation = new SymSpellEvaluation(spark, testFile, groundTruthFile) symSpellEvaluation.computeAccuracyAnnotator(trainFile, spell) Example for pretrained model: PythonScala spell = SymmetricDeleteModel.pretrained() symSpellEvaluation = NorvigSpellEvaluation(spark, test_file, ground_truth_file) symSpellEvaluation.computeAccuracyModel(spell) val spell = SymmetricDeleteModel.pretrained() val symSpellEvaluation = new SymSpellEvaluation(spark, testFile, groundTruthFile) symSpellEvaluation.computeAccuracyModel(spell) Evaluating NER DL You can evaluate NER DL when training an annotator. spark: Spark session. trainFile: Files with labeled NER entities for training. testFile: Files with labeled NER entities for testing. These files are used to evaluate the model. So, it’s used for prediction and the labels as ground truth. tagLevel: The granularity of tagging when measuring accuracy on entities. Set “IOB” to include inside and beginning, empty to ignore it. For example to display accuracy for entity I-PER and B-PER set “IOB” whereas just for entity PER set it as an empty string. Example: PythonScala embeddings = WordEmbeddings() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, &quot;TEXT&quot;) ner_approach = NerDLApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) nerDLEvaluation = NerDLEvaluation(spark, test_File, tag_level) nerDLEvaluation.computeAccuracyAnnotator(train_file, ner_approach, embeddings) val embeddings = new WordEmbeddings() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, WordEmbeddingsFormat.TEXT) val nerApproach = new NerDLApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) val nerDLEvaluation = new NerDLEvaluation(spark, testFile, tagLevel) nerDLEvaluation.computeAccuracyAnnotator(trainFile, nerApproach, embeddings) Example for pretrained model: PythonScala ner_dl = NerDLModel.pretrained() nerDlEvaluation = NerDLEvaluation(spark, test_File, tag_level) nerDlEvaluation.computeAccuracyModel(ner_dl) val nerDl = NerDLModel.pretrained() val nerDlEvaluation = NerDLEvaluation(spark, testFile, tagLevel) nerDlEvaluation.computeAccuracyModel(nerDl) Evaluating NER CRF You can evaluate NER CRF when training an annotator. spark: Spark session. trainFile: Files with labeled NER entities for training. testFile: Files with labeled NER entities for testing. These files are used to evaluate the model. So, it’s used for prediction and the labels as ground truth. format: The granularity of tagging when measuring accuracy on entities. Set “IOB” to include inside and beginning, empty to ignore it. For example to display accuracy for entity I-PER and B-PER set “IOB” whereas just for entity PER set it as an empty string. Example: PythonScala embeddings = WordEmbeddings() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;glove.6B.100d.txt&quot;, 100, &quot;TEXT&quot;) ner_approach = NerCrfApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;pos&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) .setRandomSeed(0) nerCrfEvaluation = NerCrfEvaluation(spark, test_File, tag_level) nerCrfEvaluation.computeAccuracyAnnotator(train_file, ner_approach, embeddings) val embeddings = new WordEmbeddings() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setEmbeddingsSource(&quot;./glove.6B.100d.txt &quot;, 100, WordEmbeddingsFormat.TEXT) .setCaseSensitive(true) val nerTagger = new NerCrfApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;pos&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(10) val nerCrfEvaluation = new NerCrfEvaluation(testFile, format) nerCrfEvaluation.computeAccuracyAnnotator(trainFile, nerTagger, embeddings) Example for pretrained model: PythonScala ner_crf = NerCrfModel.pretrained() nerCrfEvaluation = NerCrfEvaluation(spark, test_File, tag_level) nerCrfEvaluation.computeAccuracyModel(ner_crf) nerCrf = NerCrfModel.pretrained() nerCrfEvaluation = NerCrfEvaluation(spark, testFile, tagLevel) nerCrfEvaluation.computeAccuracyModel(nerCrf) Evaluating POS Tagger You can evaluate POS either by training an annotator or by using a pretrained model. spark: Spark session. trainFile: A labeled POS file see and example here. testFile: A CoNLL-U format file. Example for annotator: PythonScala pos_tagger = PerceptronApproach() .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) .setNIterations(2) posEvaluation = POSEvaluation(spark, test_file) posEvaluation.computeAccuracyAnnotator(train_file, pos_tagger) val posTagger = new PerceptronApproach() .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) .setNIterations(2) val posEvaluation = new POSEvaluation(spark, testFile) posEvaluation.computeAccuracyAnnotator(trainFile, posTagger)",
    "url": "/docs/en/evaluation",
    "relUrl": "/docs/en/evaluation"
  },
  "926": {
    "id": "926",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/param/evaluation_dl_params.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/param/evaluation_dl_params.html"
  },
  "927": {
    "id": "927",
    "title": "1-liners reference",
    "content": "Usage examples of nlp.load() The following examples demonstrate how to use nlu’s load api accompanied by the outputs generated by it. It enables loading any model or pipeline in one line You need to pass one NLU reference to the load method. You can also pass multiple whitespace separated references. You can find all NLU references here Named Entity Recognition (NER) 18 class NER ONTO example Predicts the following 18 NER classes from the ONTO dataset : Type Description PERSON People, including fictional like Harry Potter NORP Nationalities or religious or political groups like the Germans FAC Buildings, airports, highways, bridges, etc. like New York Airport ORG Companies, agencies, institutions, etc. like Microsoft GPE Countries, cities, states. like Germany LOC Non-GPE locations, mountain ranges, bodies of water. Like the Sahara desert PRODUCT Objects, vehicles, foods, etc. (Not services.) like playstation EVENT Named hurricanes, battles, wars, sports events, etc. like hurricane Katrina WORK_OF_ART Titles of books, songs, etc. Like Mona Lisa LAW Named documents made into laws. Like : Declaration of Independence LANGUAGE Any named language. Like Turkish DATE Absolute or relative dates or periods. Like every second friday TIME Times smaller than a day. Like every minute PERCENT Percentage, including ”%“. Like 55% of workers enjoy their work MONEY Monetary values, including unit. Like 50$ for those pants QUANTITY Measurements, as of weight or distance. Like this person weights 50kg ORDINAL “first”, “second”, etc. Like David placed first in the tournament CARDINAL Numerals that do not fall under another type. Like hundreds of models are avaiable in NLU nlp.load(&#39;ner&#39;).predict(&#39;Angela Merkel from Germany and the American Donald Trump dont share many opinions&#39;) embeddings ner_tag entities [[-0.563759982585907, 0.26958999037742615, 0.3… PER Angela Merkel [[-0.563759982585907, 0.26958999037742615, 0.3… GPE Germany [[-0.563759982585907, 0.26958999037742615, 0.3… NORP American [[-0.563759982585907, 0.26958999037742615, 0.3… PER Donald Trump Named Entity Recognition (NER) 5 Class NER CONLL example Predicts the following NER classes from the CONLL dataset : Tag Description B-PER A person like Jim or Joe B-ORG An organisation like Microsoft or PETA B-LOC A location like Germany B-MISC Anything else like Playstation O Everything that is not an entity. nlp.load(&#39;ner.conll&#39;).predict(&#39;Angela Merkel from Germany and the American Donald Trump dont share many opinions&#39;) embeddings ner_tag entities [[-0.563759982585907, 0.26958999037742615, 0.3… PER Angela Merkel [[-0.563759982585907, 0.26958999037742615, 0.3… LOC Germany [[-0.563759982585907, 0.26958999037742615, 0.3… MISC American [[-0.563759982585907, 0.26958999037742615, 0.3… PER Donald Trump Part of speech (POS) POS Classifies each token with one of the following tags Part of Speech example Tag Description Example CC Coordinating conjunction This batch of mushroom stew is savory and delicious CD Cardinal number Here are five coins DT Determiner The bunny went home EX Existential there There is a storm coming FW Foreign word I’m having a déjà vu IN Preposition or subordinating conjunction He is cleverer than I am JJ Adjective She wore a beautiful dress JJR Adjective, comparative My house is bigger than yours JJS Adjective, superlative I am the shortest person in my family LS List item marker A number of things need to be considered before starting a business , such as premises , finance , product demand , staffing and access to customers MD Modal You must stop when the traffic lights turn red NN Noun, singular or mass The dog likes to run NNS Noun, plural The cars are fast NNP Proper noun, singular I ordered the chair from Amazon NNPS Proper noun, plural We visted the Kennedys PDT Predeterminer Both the children had a toy POS Possessive ending I built the dog’s house PRP Personal pronoun You need to stop PRP$ Possessive pronoun Remember not to judge a book by its cover RB Adverb The dog barks loudly RBR Adverb, comparative Could you sing more quietly please? RBS Adverb, superlative Everyone in the race ran fast, but John ran the fastest of all RP Particle He ate up all his dinner SYM Symbol What are you doing ? TO to Please send it back to me UH Interjection Wow! You look gorgeous VB Verb, base form We play soccer VBD Verb, past tense I worked at a restaurant VBG Verb, gerund or present participle Smoking kills people VBN Verb, past participle She has done her homework VBP Verb, non-3rd person singular present You flit from place to place VBZ Verb, 3rd person singular present He never calls me WDT Wh-determiner The store honored the complaints, which were less than 25 days old WP Wh-pronoun Who can help me? WP$ Possessive wh-pronoun Whose fault is it? WRB Wh-adverb Where are you going? nlp.load(&#39;pos&#39;).predict(&#39;Part of speech assigns each token in a sentence a grammatical label&#39;) token pos Part NN of IN speech NN assigns NNS each DT token NN in IN a DT sentence NN a DT grammatical JJ label NN Emotion Classifier Emotion Classifier example Classifies text as one of 4 categories (joy, fear, surprise, sadness) nlp.load(&#39;emotion&#39;).predict(&#39;I love NLU!&#39;) sentence_embeddings emotion_confidence sentence emotion [0.027570432052016258, -0.052647676318883896, …] 0.976017 I love NLU! joy Sentiment Classifier Sentiment Classifier Example Classifies binary sentiment for every sentence, either positive or negative. nlp.load(&#39;sentiment&#39;).predict(&quot;I hate this guy Sami&quot;) sentiment_confidence sentence sentiment checked 0.5778 I hate this guy Sami negative [I, hate, this, guy, Sami] Question Classifier 50 class 50 Class Questions Classifier example Classifies between 50 different types of questions trained on the Trec50 dataset When setting predict(meta=True) nlu will output the probabilities for all other 49 question classes. The classes are the following : Abbreviation question classes: Class Definition abb abbreviation exp expression abbreviated Entities question classes: Class Definition animal animals body organs of body color colors creative inventions, books and other creative pieces currency currency names dis .med. diseases and medicine event events food food instrument musical instrument lang languages letter letters like a-z other other entities plant plants product products religion religions sport sports substance elements and substances symbol symbols and signs technique techniques and methods term equivalent terms vehicle vehicles word words with a special property Description and abstract concepts question classes: Class Definition definition definition of sth. description description of sth. manner manner of an action reason reasons Human being question classes: Class Definition group a group or organization of persons ind an individual title title of a person description description of a person Location question classes: Class Definition city cities country countries mountain mountains other other locations state states Numeric question classes: Class Definition code postcodes or other codes count number of sth. date dates distance linear measures money prices order ranks other other numbers period the lasting time of sth. percent fractions speed speed temp temperature size size, area and volume weight weight nlp.load(&#39;en.classify.trec50&#39;).predict(&#39;How expensive is the Watch?&#39;) sentence_embeddings question_confidence sentence question [0.051809534430503845, 0.03128402680158615, -0…] 0.919436 How expensive is the watch? NUM_count Fake News Classifier Fake News Classifier example nlp.load(&#39;en.classify.fakenews&#39;).predict(&#39;Unicorns have been sighted on Mars!&#39;) sentence_embeddings fake_confidence sentence fake [-0.01756167598068714, 0.015006818808615208, -…] 1.000000 Unicorns have been sighted on Mars! FAKE Cyberbullying Classifier Cyberbullying Classifier example Classifies sexism and racism nlp.load(&#39;en.classify.cyberbullying&#39;).predict(&#39;Women belong in the kitchen.&#39;) # sorry we really don&#39;t mean it sentence_embeddings cyberbullying_confidence sentence cyberbullying [-0.054944973438978195, -0.022223370149731636,…] 0.999998 Women belong in the kitchen. sexism Spam Classifier Spam Classifier example nlp.load(&#39;en.classify.spam&#39;).predict(&#39;Please sign up for this FREE membership it costs $$NO MONEY$$ just your mobile number!&#39;) sentence_embeddings spam_confidence sentence spam [0.008322705514729023, 0.009957313537597656, 0…] 1.000000 Please sign up for this FREE membership it cos… spam Sarcasm Classifier Sarcasm Classifier example nlp.load(&#39;en.classify.sarcasm&#39;).predict(&#39;gotta love the teachers who give exams on the day after halloween&#39;) sentence_embeddings sarcasm_confidence sentence sarcasm [-0.03146284446120262, 0.04071342945098877, 0….] 0.999985 gotta love the teachers who give exams on the… sarcasm IMDB Movie Sentiment Classifier Movie Review Sentiment Classifier example nlp.load(&#39;en.sentiment.imdb&#39;).predict(&#39;The Matrix was a pretty good movie&#39;) document sentence_embeddings sentiment_negative sentiment_negative sentiment_positive sentiment The Matrix was a pretty good movie [[0.04629608988761902, -0.020867452025413513, … ] [2.7235753918830596e-07] [2.7235753918830596e-07] [0.9999997615814209] [positive] Twitter Sentiment Classifier Twitter Sentiment Classifier Example nlp.load(&#39;en.sentiment.twitter&#39;).predict(&#39;@elonmusk Tesla stock price is too high imo&#39;) document sentence_embeddings sentiment_negative sentiment_negative sentiment_positive sentiment @elonmusk Tesla stock price is too high imo [[0.08604438602924347, 0.04703635722398758, -0…] [1.0] [1.0] [1.692714735043349e-36] [negative] Language Classifier Languages Classifier example Classifies the following 20 languages : Bulgarian, Czech, German, Greek, English, Spanish, Finnish, French, Croatian, Hungarian, Italy, Norwegian, Polish, Portuguese, Romanian, Russian, Slovak, Swedish, Turkish, and Ukrainian nlp.load(&#39;lang&#39;).predict([&#39;NLU is an open-source text processing library for advanced natural language processing for the Python.&#39;,&#39;NLU est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python.&#39;]) language_confidence document language 0.985407 NLU is an open-source text processing library …] en 0.999822 NLU est une bibliothèque de traitement de text…] fr E2E Classifier E2E Classifier example This is a multi class classifier trained on the E2E dataset for Natural language generation nlp.load(&#39;e2e&#39;).predict(&#39;E2E is a dataset for training generative models&#39;) sentence_embeddings e2e e2e_confidence sentence [0.021445205435156822, -0.039284929633140564, …,] customer rating[high] 0.703248 E2E is a dataset for training generative models None name[The Waterman] 0.703248 None None eatType[restaurant] 0.703248 None None priceRange[£20-25] 0.703248 None None familyFriendly[no] 0.703248 None None familyFriendly[yes] 0.703248 None Toxic Classifier Toxic Text Classifier example nlp.load(&#39;en.classify.toxic&#39;).predict(&#39;You are to stupid&#39;) toxic_confidence toxic sentence_embeddings document 0.978273 [toxic,insult] [[-0.03398505970835686, 0.0007853527786210179,…,] You are to stupid YAKE Unsupervised Keyword Extractor YAKE Keyword Extraction Example nlp.load(&#39;yake&#39;).predict(&quot;NLU is a Python Library for beginners and experts in NLP&quot;) keywords_score_confidence keywords sentence 0.454232 [nlu, nlp, python library] NLU is a Python Library for beginners and expe… Word Embeddings Bert BERT Word Embeddings example nlp.load(&#39;bert&#39;).predict(&#39;NLU offers the latest embeddings in one line &#39;) token bert_embeddings NLU [0.3253086805343628, -0.574441134929657, -0.08…] offers [-0.6660361886024475, -0.1494743824005127, -0…] the [-0.6587662696838379, 0.3323703110218048, 0.16…] latest [0.7552685737609863, 0.17207926511764526, 1.35…] embeddings [-0.09838500618934631, -1.1448147296905518, -1…] in [-0.4635896384716034, 0.38369956612586975, 0.0…] one [0.26821616291999817, 0.7025910019874573, 0.15…] line [-0.31930840015411377, -0.48271292448043823, 0…] Word Embeddings Biobert BIOBERT Word Embeddings example Bert model pretrained on Bio dataset nlp.load(&#39;biobert&#39;).predict(&#39;Biobert was pretrained on a medical dataset&#39;) token biobert_embeddings NLU [0.3253086805343628, -0.574441134929657, -0.08…] offers [-0.6660361886024475, -0.1494743824005127, -0…] the [-0.6587662696838379, 0.3323703110218048, 0.16…] latest [0.7552685737609863, 0.17207926511764526, 1.35…] embeddings [-0.09838500618934631, -1.1448147296905518, -1…] in [-0.4635896384716034, 0.38369956612586975, 0.0…] one [0.26821616291999817, 0.7025910019874573, 0.15…] line [-0.31930840015411377, -0.48271292448043823, 0…] Word Embeddings Covidbert COVIDBERT Word Embeddings Bert model pretrained on COVID dataset nlp.load(&#39;covidbert&#39;).predict(&#39;Albert uses a collection of many berts to generate embeddings&#39;) token covid_embeddings He [-1.0551927089691162, -1.534174919128418, 1.29…,] was [-0.14796507358551025, -1.3928604125976562, 0….,] suprised [1.0647121667861938, -0.3664901852607727, 0.54…,] by [-0.15271103382110596, -0.6812090277671814, -0…,] the [-0.45744237303733826, -1.4266574382781982, -0…,] diversity [-0.05339818447828293, -0.5118572115898132, 0….,] of [-0.2971905767917633, -1.0936176776885986, -0….,] NLU [-0.9573594331741333, -0.18001675605773926, -1…,] Word Embeddings Albert ALBERT Word Embeddings examle nlp.load(&#39;albert&#39;).predict(&#39;Albert uses a collection of many berts to generate embeddings&#39;) token albert_embeddings Albert [-0.08257609605789185, -0.8017427325248718, 1…] uses [0.8256351947784424, -1.5144840478897095, 0.90…] a [-0.22089454531669617, -0.24295514822006226, 3…] collection [-0.2136894017457962, -0.8225528597831726, -0…] of [1.7623294591903687, -1.113651156425476, 0.800…] many [0.6415284872055054, -0.04533941298723221, 1.9…] berts [-0.5591965317726135, -1.1773797273635864, -0…] to [1.0956681966781616, -1.4180747270584106, -0.2…] generate [-0.6759272813796997, -1.3546931743621826, 1.6…] embeddings [-0.0035803020000457764, -0.35928264260292053,…] Electra Embeddings ELECTRA Word Embeddings example nlp.load(&#39;electra&#39;).predict(&#39;He was suprised by the diversity of NLU&#39;) token electra_embeddings He [0.29674115777015686, -0.21371933817863464, -0…,] was [-0.4278327524662018, -0.5352768898010254, -0….,] suprised [-0.3090559244155884, 0.8737565279006958, -1.0…,] by [-0.07821277529001236, 0.13081523776054382, 0….,] the [0.5462881922721863, 0.0683358758687973, -0.41…,] diversity [0.1381239891052246, 0.2956242859363556, 0.250…,] of [-0.5667567253112793, -0.3955455720424652, -0….,] NLU [0.5597224831581116, -0.703249454498291, -1.08…,] Word Embeddings Elmo ELMO Word Embeddings example nlp.load(&#39;elmo&#39;).predict(&#39;Elmo was trained on Left to right masked to learn its embeddings&#39;) token elmo_embeddings Elmo [0.6083735227584839, 0.20089012384414673, 0.42…] was [0.2980785369873047, -0.07382500916719437, -0…] trained [-0.39923471212387085, 0.17155063152313232, 0…] on [0.04337821900844574, 0.1392083466053009, -0.4…] Left [0.4468783736228943, -0.623046875, 0.771505534…] to [-0.18209676444530487, 0.03812692314386368, 0…] right [0.23305709660053253, -0.6459438800811768, 0.5…] masked [-0.7243442535400391, 0.10247116535902023, 0.1…] to [-0.18209676444530487, 0.03812692314386368, 0…] learn [1.2942464351654053, 0.7376189231872559, -0.58…] its [0.055951207876205444, 0.19218483567237854, -0…] embeddings [-1.31377112865448, 0.7727609872817993, 0.6748…] Word Embeddings Xlnet XLNET Word Embeddings example nlp.load(&#39;xlnet&#39;).predict(&#39;XLNET computes contextualized word representations using combination of Autoregressive Language Model and Permutation Language Model&#39;) token xlnet_embeddings XLNET [-0.02719488926231861, -1.7693557739257812, -0…] computes [-1.8262947797775269, 0.8455266356468201, 0.57…] contextualized [2.8446314334869385, -0.3564329445362091, -2.1…] word [-0.6143839359283447, -1.7368144989013672, -0…] representations [-0.30445945262908936, -1.2129613161087036, 0…] using [0.07423821836709976, -0.02561005763709545, -0…] combination [-0.5387097597122192, -1.1827564239501953, 0.5…] of [-1.403516411781311, 0.3108177185058594, -0.32…] Autoregressive [-1.0869172811508179, 0.7135171890258789, -0.2…] Language [-0.33215752243995667, -1.4108021259307861, -0…] Model [-1.6097160577774048, -0.2548254430294037, 0.0…] and [0.7884324789047241, -1.507911205291748, 0.677…] Permutation [0.6049966812133789, -0.157279372215271, -0.06…] Language [-0.33215752243995667, -1.4108021259307861, -0…] Model [-1.6097160577774048, -0.2548254430294037, 0.0…] Word Embeddings Glove GLOVE Word Embeddings example nlp.load(&#39;glove&#39;).predict(&#39;Glove embeddings are generated by aggregating global word-word co-occurrence matrix from a corpus&#39;) token glove_embeddings Glove [0.3677999973297119, 0.37073999643325806, 0.32…] embeddings [0.732479989528656, 0.3734700083732605, 0.0188…] are [-0.5153300166130066, 0.8318600058555603, 0.22…] generated [-0.35510000586509705, 0.6115900278091431, 0.4…] by [-0.20874999463558197, -0.11739999800920486, 0…] aggregating [-0.5133699774742126, 0.04489300027489662, 0.1…] global [0.24281999468803406, 0.6170300245285034, 0.66…] word-word [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …] co-occurrence [0.16384999454021454, -0.3178800046443939, 0.1…] matrix [-0.2663800120353699, 0.4449099898338318, 0.32…] from [0.30730998516082764, 0.24737000465393066, 0.6…] a [-0.2708599865436554, 0.04400600120425224, -0…] corpus [0.39937999844551086, 0.15894000232219696, -0…] Multiple Token Embeddings at once Compare 6 Embeddings at once with NLU and T-SNE example #This takes around 10GB RAM, watch out! nlp.load(&#39;bert albert electra elmo xlnet use glove&#39;).predict(&#39;Get all of them at once! Watch your RAM tough!&#39;) xlnet_embeddings use_embeddings elmo_embeddings electra_embeddings glove_embeddings sentence albert_embeddings biobert_embeddings bert_embeddings [[-0.003953204490244389, -1.5821468830108643, …,] [-0.019299551844596863, -0.04762779921293259, …,] [[0.04002974182367325, -0.43536433577537537, -…,] [[0.19559216499328613, -0.46693214774131775, -…,] [[0.1443299949169159, 0.4395099878311157, 0.58…,] Get all of them at once, watch your RAM tough! [[-0.4743960201740265, -0.581386387348175, 0.7…,] [[-0.00012563914060592651, -1.372296929359436,…,] [[-0.7687976360321045, 0.8489367961883545, -0….,] Bert Sentence Embeddings BERT Sentence Embeddings example sentence bert_sentence_embeddings He was suprised by the diversity of NLU [-1.0726687908172607, 0.4481312036514282, -0.0…,] Electra Sentence Embeddings ELECTRA Sentence Embeddings example nlp.load(&#39;embed_sentence.electra&#39;).predict(&#39;He was suprised by the diversity of NLU&#39;) sentence electra_sentence_embeddings He was suprised by the diversity of NLU [0.005376118700951338, 0.18036000430583954, -0…,] Sentence Embeddings Use USE Sentence Embeddings example nlp.load(&#39;use&#39;).predict(&#39;USE is designed to encode whole sentences and documents into vectors that can be used for text classification, semantic similarity, clustering or oder NLP tasks&#39;) sentence use_embeddings USE is designed to encode whole sentences and …] [0.03302069380879402, -0.004255455918610096, -…] Spell Checking Spell checking example nlp.load(&#39;spell&#39;).predict(&#39;I liek pentut buttr ant jely&#39;) token checked I I liek like peantut pentut buttr buttr and and jelli jely Dependency Parsing Unlabeled Untyped Dependency Parsing example nlp.load(&#39;dep.untyped&#39;).predict(&#39;Untyped Dependencies represent a grammatical tree structure.md&#39;) token pos dependency Untyped NNP ROOT Dependencies NNP represent represent VBD Untyped a DT structure grammatical JJ structure tree NN structure structure NN represent Dependency Parsing Labeled Typed Dependency Parsing example nlp.load(&#39;dep&#39;).predict(&#39;Typed Dependencies represent a grammatical tree structure.md where every edge has a label&#39;) token pos dependency labled_dependency Typed NNP ROOT root Dependencies NNP represent nsubj represent VBD Typed parataxis a DT structure nsubj grammatical JJ structure amod tree NN structure flat structure NN represent nsubj where WRB structure mark every DT edge nsubj edge NN where nsubj has VBZ ROOT root a DT label nsubj label NN has nsubj Tokenization Tokenization example nlp.load(&#39;tokenize&#39;).predict(&#39;Each word and symbol in a sentence will generate token.&#39;) token Each word and symbol will generate a token . Stemmer Stemmer example nlp.load(&#39;stem&#39;).predict(&#39;NLU can get you the stem of a word&#39;) token stem NLU nlu can can get get you you the the stem stem of of a a word word Stopwords Removal Stopwords Removal example nlp.load(&#39;stopwords&#39;).predict(&#39;I want you to remove stopwords from this sentence please&#39;) token cleanTokens I remove want stopwords you sentence to None remove None stopwords None from None this None sentence None please None Lemmatization Lemmatization example nlp.load(&#39;lemma&#39;).predict(&#39;Lemmatizing generates a less noisy version of the inputted tokens&#39;) token lemma Lemmatizing Lemmatizing generates generate a a less less noisy noisy version version of of the the inputted input tokens token Normalizers Normalizing example nlp.load(&#39;norm&#39;).predict(&#39;@CKL_IT says that #normalizers are pretty useful to clean #structured_strings in #NLU like tweets&#39;) normalized token CKLIT @CKL_IT says says that that normalizers #normalizers are are pretty pretty useful useful to to clean clean structuredstrings #structured_strings in in NLU #NLU like like tweets tweets NGrams NGrams example nlp.load(&#39;ngram&#39;).predict(&#39;Wht a wondful day!&#39;) document ngrams pos To be or not to be [To, be, or, not, to, be, To be, be or, or not…] [TO, VB, CC, RB, TO, VB] Date Matching Date Matching example nlp.load(&#39;match.datetime&#39;).predict(&#39;In the years 2000/01/01 to 2010/01/01 a lot of things happened&#39;) document date In the years 2000/01/01 to 2010/01/01 a lot of things happened [2000/01/01, 2001/01/01] Entity Chunking Checkout see here for all possible POS labels or Splits text into rows based on matched grammatical entities. Entity Chunking Example # First we load the pipeline pipe = nlp.load(&#39;match.chunks&#39;) # Now we print the info to see at which index which com,ponent is and what parameters we can configure on them pipe.generate_class_metadata_table() # Lets set our Chunker to only match NN pipe[&#39;default_chunker&#39;].setRegexParsers([&#39;&lt;NN&gt;+&#39;, &#39;&lt;JJ&gt;+&#39;]) # Now we can predict with the configured pipeline pipe.predict(&quot;Jim and Joe went to the big blue market next to the town hall&quot;) # the outputs of component_list.print_info() The following parameters are configurable for this NLU pipeline (You can copy paste the examples) : &gt;&gt;&gt; component_list[&#39;document_assembler&#39;] has settable params: component_list[&#39;document_assembler&#39;].setCleanupMode(&#39;disabled&#39;) | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : disabled &gt;&gt;&gt; component_list[&#39;sentence_detector&#39;] has settable params: component_list[&#39;sentence_detector&#39;].setCustomBounds([]) | Info: characters used to explicitly mark sentence bounds | Currently set to : [] component_list[&#39;sentence_detector&#39;].setDetectLists(True) | Info: whether detect lists during sentence detection | Currently set to : True component_list[&#39;sentence_detector&#39;].setExplodeSentences(False) | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False component_list[&#39;sentence_detector&#39;].setMaxLength(99999) | Info: Set the maximum allowed length for each sentence | Currently set to : 99999 component_list[&#39;sentence_detector&#39;].setMinLength(0) | Info: Set the minimum allowed length for each sentence. | Currently set to : 0 component_list[&#39;sentence_detector&#39;].setUseAbbreviations(True) | Info: whether to apply abbreviations at sentence detection | Currently set to : True component_list[&#39;sentence_detector&#39;].setUseCustomBoundsOnly(False) | Info: Only utilize custom bounds in sentence detection | Currently set to : False &gt;&gt;&gt; component_list[&#39;regex_matcher&#39;] has settable params: component_list[&#39;regex_matcher&#39;].setCaseSensitiveExceptions(True) | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True component_list[&#39;regex_matcher&#39;].setTargetPattern(&#39; S+&#39;) | Info: pattern to grab from text as token candidates. Defaults S+ | Currently set to : S+ component_list[&#39;regex_matcher&#39;].setMaxLength(99999) | Info: Set the maximum allowed length for each token | Currently set to : 99999 component_list[&#39;regex_matcher&#39;].setMinLength(0) | Info: Set the minimum allowed length for each token | Currently set to : 0 &gt;&gt;&gt; component_list[&#39;sentiment_dl&#39;] has settable params: &gt;&gt;&gt; component_list[&#39;default_chunker&#39;] has settable params: component_list[&#39;default_chunker&#39;].setRegexParsers([&#39;&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;+&#39;]) | Info: an array of grammar based chunk parsers | Currently set to : [&#39;&lt;DT&gt;?&lt;JJ&gt;*&lt;NN&gt;+&#39;] chunk pos market [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… town hall [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… big blue [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… next [NNP, CC, NNP, VBD, TO, DT, JJ, JJ, NN, JJ, TO… Sentence Detection Sentence Detection example nlp.load(&#39;sentence_detector&#39;).predict(&#39;NLU can detect things. Like beginning and endings of sentences. It can also do much more!&#39;, output_level =&#39;sentence&#39;) sentence word_embeddings pos ner NLU can detect things. [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN… ] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] Like beginning and endings of sentences. [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN…] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] It can also do much more! [[0.4970400035381317, -0.013454999774694443, 0…] [NNP, MD, VB, NNS, ., IN, VBG, CC, NNS, IN, NN…] [O, O, O, O, O, B-sent, O, O, O, O, O, O, B-se…] Document Normalization Document Normalizer example The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters pipe = nlp.load(&#39;norm_document&#39;) data = &#39;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;&#39; df = pipe.predict(data,output_level=&#39;document&#39;) df text normalized_text &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; Example This is an example of a simple HTML page with one paragraph. Word Segmenter Word Segmenter Example The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean pipe = nlp.load(&#39;ja.segment_words&#39;) # japanese for &#39;Donald Trump and Angela Merkel dont share many opinions&#39; ja_data = [&#39;ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません&#39;] df = pipe.predict(ja_data, output_level=&#39;token&#39;) df token ドナルド ・ トランプ と アンゲラ ・ メルケル は 多く の 意見 を 共有 し て い ませ ん Translation Translation example You can translate between more than 192 Languages pairs with the Marian Models You need to specify the language your data is in as start_language and the language you want to translate to as target_language. The language references must be ISO language codes nlp.load(&#39;xx.&lt;start_language&gt;.translate_to.&lt;target_language&gt;&#39;) Translate Turkish to English: nlp.load(&#39;xx.tr.translate_to.fr&#39;) Translate English to French: nlp.load(&#39;xx.en.translate_to.fr&#39;) Translate French to Hebrew: nlp.load(&#39;xx.en.translate_to.fr&#39;) translate_pipe = nlp.load(&#39;xx.en.translate_to.de&#39;) df = translate_pipe.predict(&#39;Billy likes to go to the mall every sunday&#39;) df sentence translation Billy likes to go to the mall every sunday Billy geht gerne jeden Sonntag ins Einkaufszentrum Automatic Speech Recognition (ASR) with HuBERT ASR Demo Notebook Recognize speech in Audio files with HuBERT # Let&#39;s download an audio file !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/audio/samples/wavs/ngm_12484_01067234848.wav FILE_PATH = &quot;ngm_12484_01067234848.wav&quot; asr_df = nlp.load(&#39;en.speech2text.hubert&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df text PEOPLE WHO DIED WHILE LIVING IN OTHER PLACES Automatic Speech Recognition (ASR) with Wav2Vec2 ASR Tutorial Notebook Recognize speech in Audio files with HuBERT # Let&#39;s download an audio file !wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/audio/samples/wavs/ngm_12484_01067234848.wav FILE_PATH = &quot;ngm_12484_01067234848.wav&quot; asr_df = nlp.load(&#39;en.speech2text.wav2vec2.v2_base_960h&#39;).predict(&#39;ngm_12484_01067234848.wav&#39;) asr_df text PEOPLE WHO DIED WHILE LIVING IN OTHER PLACES Table Question Answering (TAPAS) TAPS Tutorial Notebook Table Question Answering on Pandas DataFrames powered by TAPAS: Weakly Supervised Table Parsing via Pre-training First we need a pandas dataframe on for which we want to ask questions. The so called “context” import pandas as pd context_df = pd.DataFrame({ &#39;name&#39;:[&#39;Donald Trump&#39;,&#39;Elon Musk&#39;], &#39;money&#39;: [&#39;$100,000,000&#39;,&#39;$20,000,000,000,000&#39;], &#39;married&#39;: [&#39;yes&#39;,&#39;no&#39;], &#39;age&#39; : [&#39;75&#39;,&#39;55&#39;] }) context_df Then we create an array of questions questions = [ &quot;Who earns less than 200,000,000?&quot;, &quot;Who earns more than 200,000,000?&quot;, &quot;Who earns 100,000,000?&quot;, &quot;How much money has Donald Trump?&quot;, &quot;Who is the youngest?&quot;, ] questions Now Combine the data, pass it to NLU and get answers for your questions import nlu # Now we combine both to a tuple and we are done! We can now pass this to the .predict() method tapas_data = (context_df, questions) # Lets load a TAPAS QA model and predict on (context,question). # It will give us an aswer for every question in the questions array, based on the context in context_df answers = nlu.load(&#39;en.answer_question.tapas.wtq.large_finetuned&#39;).predict(tapas_data) answers sentence tapas_qa_UNIQUE_aggregation tapas_qa_UNIQUE_answer tapas_qa_UNIQUE_cell_positions tapas_qa_UNIQUE_cell_scores tapas_qa_UNIQUE_origin_question Who earns less than 200,000,000? NONE Donald Trump [0, 0] 1 Who earns less than 200,000,000? Who earns more than 200,000,000? NONE Elon Musk [0, 1] 1 Who earns more than 200,000,000? Who earns 100,000,000? NONE Donald Trump [0, 0] 1 Who earns 100,000,000? How much money has Donald Trump? SUM SUM($100,000,000) [1, 0] 1 How much money has Donald Trump? Who is the youngest? NONE Elon Musk [0, 1] 1 Who is the youngest? Image Classification (VIT) Image Classification Tutorial Notebook Image Classifier Based on VIT Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.base_patch16_224&#39;).predict(&#39;/content/images/images&#39;) TODO SCREENSHOT Image Classification (SWIN) Image Classification Tutorial Notebook Image Classifier Based on SWIN Lets download a folder of images and predict on it !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip import shutil shutil.unpack_archive(&quot;images.zip&quot;, &quot;images&quot;, &quot;zip&quot;) ! ls /content/images/images/ Once we have image data its easy to label it, we just pass the folder with images to nlu.predict() and NLU will return a pandas DF with one row per image detected nlu.load(&#39;en.classify_image.swin.tiny&#39;).predict(&#39;/content/images/images&#39;) TODO SCREENSHOT T5 Example of every T5 task Overview of every task available with T5 The T5 model is trained on various datasets for 17 different tasks which fall into 8 categories. Text summarization Question answering Translation Sentiment analysis Natural Language inference Coreference resolution Sentence Completion Word sense disambiguation Every T5 Task with explanation: Task Name Explanation 1.CoLA Classify if a sentence is gramaticaly correct 2.RTE Classify whether if a statement can be deducted from a sentence 3.MNLI Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class). 4.MRPC Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent) 5.QNLI Classify whether the answer to a question can be deducted from an answer candidate. 6.QQP Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent) 7.SST2 Classify the sentiment of a sentence as positive or negative 8.STSB Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes) 9.CB Classify for a premise and a hypothesis whether they contradict each other or not (binary). 10.COPA Classify for a question, premise, and 2 choices which choice the correct choice is (binary). 11.MultiRc Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary), 12.WiC Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences. 13.WSC/DPR Predict for an ambiguous pronoun in a sentence what it is referring to. 14.Summarization Summarize text into a shorter representation. 15.SQuAD Answer a question for a given context. 16.WMT1. Translate English to German 17.WMT2. Translate English to French 18.WMT3. Translate English to Romanian Every T5 Task example notebook to see how to use every T5 Task. T5 Open and Closed Book question answering notebook Text Summarization Summarization example Summarizes a paragraph into a shorter version with the same semantic meaning, based on Text summarization # Set the task on T5 pipe = nlp.load(&#39;summarize&#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . &#39;&#39;&#39;, &#39;&#39;&#39; Calculus, originally called infinitesimal calculus or &quot;the calculus of infinitesimals&quot;, is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally &quot;small pebble&quot; (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.&#39;&#39;&#39; ] #Predict on text data with T5 pipe.predict(data) Predicted summary Text manchester united face newcastle in the premier league on wednesday . louis van gaal’s side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends . the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . Binary Sentence similarity/ Paraphrasing Binary sentence similarity example Classify whether one sentence is a re-phrasing or similar to another sentence This is a sub-task of GLUE and based on MRPC - Binary Paraphrasing/ sentence similarity classification t5 = nlp.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;mrpc &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11 &quot; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: I like to eat peanutbutter for breakfast sentence2: I like to play football. &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Sentence1 Sentence2 prediction We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , “ Rumsfeld said . Rather , the US acted because the administration saw “ existing evidence in a new light , through the prism of our experience on September 11 “ . equivalent I like to eat peanutbutter for breakfast I like to play football not_equivalent How to configure T5 task for MRPC and pre-process text .setTask(&#39;mrpc sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity mrpc sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11&quot;, Regressive Sentence similarity/ Paraphrasing Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label. This is a sub-task of GLUE and based onSTSB - Regressive semantic sentence similarity . t5 = nlp.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;stsb &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: What was it like in Ancient rome? sentence2: What was Ancient rome like? &#39;&#39;&#39;, &#39;&#39;&#39; sentence1: What was live like as a King in Ancient Rome?? sentence2: What was Ancient rome like? &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Sentence1 Sentence2 prediction What attributes would have made you highly desirable in ancient Rome? How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? 0 What was it like in Ancient rome? What was Ancient rome like? 5.0 What was live like as a King in Ancient Rome?? What is it like to live in Rome? 3.2 How to configure T5 task for stsb and pre-process text .setTask(&#39;stsb sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 STSB - Regressive semantic sentence similarity stsb sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39;, Grammar Checking Grammar checking with T5 example) Judges if a sentence is grammatically acceptable. Based on CoLA - Binary Grammatical Sentence acceptability classification pipe = nlp.load(&#39;grammar_correctness&#39;) # Set the task on T5 pipe[&#39;t5&#39;].setTask(&#39;cola sentence: &#39;) # define Data data = [&#39;Anna and Mike is going skiing and they is liked is&#39;,&#39;Anna and Mike like to dance&#39;] #Predict on text data with T5 pipe.predict(data) sentence prediction Anna and Mike is going skiing and they is liked is unacceptable Anna and Mike like to dance acceptable Open book question answering T5 Open and Closed Book question answering tutorial You can imagine an open book question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen. In T5&#39;s terms, this means the model is given a question and an additional piece of textual information or so called context. This enables the T5 model to answer questions on textual datasets like medical records,newsarticles , wiki-databases , stories and movie scripts , product descriptions, ‘legal documents’ and many more. You can answer open book question in 1 line of code, leveraging the latest NLU release and Google’s T5. All it takes is : nlp.load(&#39;answer_question&#39;).predict(&quot;&quot;&quot; Where did Jebe die? context: Ghenkis Khan recalled Subtai back to Mongolia soon afterwards, and Jebe died on the road back to Samarkand&quot;&quot;&quot;) &gt;&gt;&gt; Output: Samarkand Example for answering medical questions based on medical context question =&#39;&#39;&#39; What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. &#39;&#39;&#39; #Predict on text data with T5 nlp.load(&#39;answer_question&#39;).predict(question) &gt;&gt;&gt; Output: carbon monoxide Take a look at this example on a recent news article snippet : question1 = &#39;Who is Jack ma?&#39; question2 = &#39;Who is founder of Alibaba Group?&#39; question3 = &#39;When did Jack Ma re-appear?&#39; question4 = &#39;How did Alibaba stocks react?&#39; question5 = &#39;Whom did Jack Ma meet?&#39; question6 = &#39;Who did Jack Ma hide from?&#39; # from https://www.bbc.com/news/business-55728338 news_article_snippet = &quot;&quot;&quot; context: Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire. His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses. The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media. Alibaba shares surged 5% on Hong Kong&#39;s stock exchange on the news. &quot;&quot;&quot; # join question with context, works with Pandas DF aswell! questions = [ question1+ news_article_snippet, question2+ news_article_snippet, question3+ news_article_snippet, question4+ news_article_snippet, question5+ news_article_snippet, question6+ news_article_snippet,] nlp.load(&#39;answer_question&#39;).predict(questions) This will output a Pandas Dataframe similar to this : Answer Question Alibaba Group founder Who is Jack ma? Jack Ma Who is founder of Alibaba Group? Wednesday When did Jack Ma re-appear? surged 5% How did Alibaba stocks react? 100 rural teachers Whom did Jack Ma meet? Chinese regulators Who did Jack Ma hide from? Closed book question answering T5 Open and Closed Book question answering tutorial A closed book question is the exact opposite of a open book question. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else. In T5&#39;s terms this means that T5 can only use it’s stored weights to answer a question and is given no aditional context. T5 was pre-trained on the C4 dataset which contains petabytes of web crawling data collected over the last 8 years, including Wikipedia in every language. This gives T5 the broad knowledge of the internet stored in it’s weights to answer various closed book questions You can answer closed book question in 1 line of code, leveraging the latest NLU release and Google’s T5. You need to pass one string to NLU, which starts which a question and is followed by a context: tag and then the actual context contents. All it takes is : nlp.load(&#39;en.t5&#39;).predict(&#39;Who is president of Nigeria?&#39;) &gt;&gt;&gt; Muhammadu Buhari nlp.load(&#39;en.t5&#39;).predict(&#39;What is the most spoken language in India?&#39;) &gt;&gt;&gt; Hindi nlp.load(&#39;en.t5&#39;).predict(&#39;What is the capital of Germany?&#39;) &gt;&gt;&gt; Berlin",
    "url": "/docs/en/jsl/examples",
    "relUrl": "/docs/en/jsl/examples"
  },
  "928": {
    "id": "928",
    "title": "Examples",
    "content": "Showcasing notebooks and codes of how to use Spark NLP in Python and Scala. Python Setup $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.7 -y $ conda activate sparknlp $ pip install spark-nlp==4.3.2 pyspark==3.3.1 Google Colab Notebook Google Colab is perhaps the easiest way to get started with spark-nlp. It requires no installation or setup other than having a Google account. Run the following code in Google Colab notebook and start using spark-nlp right away. # This is only to setup PySpark and Spark NLP on Colab !wget http://setup.johnsnowlabs.com/colab.sh -O - | bash This script comes with the two options to define pyspark and spark-nlp versions via options: # -p is for pyspark # -s is for spark-nlp # by default they are set to the latest !bash colab.sh -p 3.2.3 -s 4.3.2 Spark NLP quick start on Google Colab is a live demo on Google Colab that performs named entity recognitions and sentiment analysis by using Spark NLP pretrained pipelines. Kaggle Kernel Run the following code in Kaggle Kernel and start using spark-nlp right away. # Let&#39;s setup Kaggle for Spark NLP and PySpark !wget http://setup.johnsnowlabs.com/kaggle.sh -O - | bash Notebooks Tutorials and articles Jupyter Notebooks",
    "url": "/docs/en/examples",
    "relUrl": "/docs/en/examples"
  },
  "929": {
    "id": "929",
    "title": "Examples",
    "content": "Usage examples of nlp.load() The following examples demonstrate how to use nlu’s load api accompanied by the outputs generated by it. It enables loading any model or pipeline in one line You need to pass one NLU reference to the load method. You can also pass multiple whitespace separated references. You can find all NLU references here Medical Named Entity Recognition (NER) Medical NER tutorial notebook NLU provided a separate and highly tuned medical NER models for various Healthcare domains. These medical NER models are trained to extract various medical named entities. data =&quot;&quot;&quot;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days.&quot;&quot;&quot; df = nlp.load(&#39;med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical&#39;).predict(data) entities@clinical_results meta_entities@clinical_entity meta_entities@clinical_confidence chunk_resolution_results meta_chunk_resolution_all_k_aux_labels meta_chunk_resolution_target_text meta_chunk_resolution_distance meta_chunk_resolution_confidence meta_chunk_resolution_all_k_results meta_chunk_resolution_all_k_distances meta_chunk_resolution_all_k_cosine_distances 5-month-old Age 0.9982 49496   5-month-old 15.0536 1 49496 15.0536 0.5153 infant Age 0.9999 49492   infant 6.7093 1 49492 6.7093 0.3702 Monday RelativeDate 0.9983 59857   Monday 12.6501 1 59857 12.6501 0.5324 cold Symptom 0.7517 50547   cold 2.6313 1 50547 2.6313 0.4492 cough Symptom 0.9969 32215   cough 3.5559 1 32215 3.5559 0.4847 runny nose Symptom 0.7796 60281   runny nose 3.3286 1 60281 3.3286 0.3959 for 2 days Duration 0.5479 35390   for 2 days 2.3929 1 35390 2.3929 0.22 See the Models Hub for all avaiable Entity Resolution Models Zero-Shot NER Zero-Shot NER Tutorial Notebook Based on John Snow Labs Enterprise-NLP ZeroShotNerModel Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain. Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in various domains. Usage: We just need to load the zero-shot NER model and configure a set of entity definitions. # load zero-shot ner model enterprise_zero_shot_ner = nlp.load(&#39;en.zero_shot.ner_roberta&#39;) # Configure entity definitions enterprise_zero_shot_ner[&#39;zero_shot_ner&#39;].setEntityDefinitions( { &quot;PROBLEM&quot;: [ &quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot;, &quot;What does a patient suffer&quot;, &quot;What was the reason that the patient is admitted to the clinic?&quot;, ], &quot;DRUG&quot;: [ &quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;, ], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [ &quot;How old is the patient?&quot;, &quot;What is the gae of the patient?&quot;, ], } ) Then we can already use this pipeline to predict labels # Predict entities df = enterprise_zero_shot_ner.predict( [ &quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr.&quot;+ &quot;X for a right-sided pleural effusion for thoracentesis.&quot;, ] ) df document entities_zero_shot entities_zero_shot_class entities_zero_shot_confidence entities_zero_shot_origin_chunk entities_zero_shot_origin_sentence The doctor pescribed Majezik for my severe headache. Majezik DRUG 0.646716 0 0 The doctor pescribed Majezik for my severe headache. severe headache PROBLEM 0.552635 1 0 The patient was admitted to the hospital for his colon cancer. colon cancer PROBLEM 0.88985 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. 27 years old PATIENT_AGE 0.694308 0 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. Sep 1st ADMISSION_DATE 0.956461 1 0 27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis. a right-sided pleural effusion for thoracentesis PROBLEM 0.500266 2 0 Entity Resolution (for sentences) Entity Resolution tutorial notebook Classify each sentence extracted by a sentence detector into one of C resolvable classes. These classes usually are international disease , medicine , or procedure codes based on ICD standards. data = [&quot;&quot;&quot;He has a starvation ketosis but nothing found for significant for dry oral mucosa&quot;&quot;&quot;] nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10pcs&#39;).predict(data) sentence_results sentence_resolution_results entities@clinical_results meta_entities@clinical_entity meta_entities@clinical_confidence The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. DU12BBZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] Mom states she had no fever. F00ZNQZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] Her appetite was good but she was spitting up a lot. F08Z3YZ [‘5-month-old’, ‘infant’, ‘Monday’, ‘cold’, ‘cough’, ‘runny nose’, ‘for 2 days’, ‘Mom’, ‘she’, ‘fever’, ‘Her’, ‘she’, ‘spitting up a lot’] [‘Age’, ‘Age’, ‘RelativeDate’, ‘Symptom’, ‘Symptom’, ‘Symptom’, ‘Duration’, ‘Gender’, ‘Gender’, ‘VS_Finding’, ‘Gender’, ‘Gender’, ‘Symptom’] [‘0.9982’, ‘0.9999’, ‘0.9983’, ‘0.7517’, ‘0.9969’, ‘0.7796’, ‘0.5479’, ‘0.9427’, ‘0.9994’, ‘0.9975’, ‘0.9996’, ‘0.9985’, ‘0.30217502’] See the Models Hub for all avaiable Entity Resolution Models Relation Extraction Relation Extraction tutorial notebook Classify for pairs of entities what kind of relation exists between them. It classifies for every named entity , which type of relationship exists to the other entities. More precisely, internally the relation extractor classifies every pair of entities into one out of C potential relation classes. There could be no relation between a pair of entities or there could a relation, which is specified by ` the predicted relation label` . You can specify predict(data,output_level=&#39;relation to have one row per classified relation in your resulting dataframe. Depending on what models are loaded in your pipe, NLU infers output_level=relation automatically and configures to that, unless specified otherwise. See the Models Hub for all avaiable Relation Extractor Models data = &#39;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&#39; df = nlp.load(&#39;en.med_ner.jsl.wip.clinical.greedy en.relation&#39;).predict(data) document_results relation_results meta_relation_entity1 meta_relation_entity2 meta_relation_chunk1 meta_relation_chunk2 meta_relation_confidence entities@greedy_results meta_entities@greedy_entity meta_entities@greedy_confidence MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Disease_Syndrome_Disorder MRI infarction 0.900999 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI upper 0.947945 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI brain stem 0.654686 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI left 0.944728 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI cerebellum 0.683124 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Direction MRI right 0.96001 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Test Internal_organ_or_component MRI basil ganglia 0.958023 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction upper 0.986427 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction brain stem 0.872217 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction left 0.983788 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction cerebellum 0.974557 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Direction infarction right 0.981092 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Disease_Syndrome_Disorder Internal_organ_or_component infarction basil ganglia 0.968148 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component upper brain stem 0.999582 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction upper left 0.98803 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component upper cerebellum 0.990115 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction upper right 0.989708 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component upper basil ganglia 0.971543 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction brain stem left 0.768312 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Internal_organ_or_component Internal_organ_or_component brain stem cerebellum 0.504254 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction brain stem right 0.939806 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Internal_organ_or_component brain stem basil ganglia 0.944104 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component left cerebellum 0.999842 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Direction left right 0.99164 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Direction Internal_organ_or_component left basil ganglia 0.985331 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Direction cerebellum right 0.986705 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 0 Internal_organ_or_component Internal_organ_or_component cerebellum basil ganglia 0.975779 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” 1 Direction Internal_organ_or_component right basil ganglia 0.999613 [‘MRI’, ‘infarction’, ‘upper’, ‘brain stem’, ‘left’, ‘cerebellum’, ‘right’, ‘basil ganglia’] [‘Test’, ‘Disease_Syndrome_Disorder’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’, ‘Direction’, ‘Internal_organ_or_component’] [‘0.9979’, ‘0.5062’, ‘0.2152’, ‘0.2636’, ‘0.4775’, ‘0.8135’, ‘0.5086’, ‘0.3236’] Assertion Assertion tutorial notebook Assert for each entity the status into one out of C classes. These classes usually are : hypothetical, present, absent, possible, conditional, associated_with_someone_else. data = &quot;He has a starvation ketosis but nothing found for significant for dry oral mucosa&quot; assert_df = nlp.load(&#39;en.med_ner.clinical en.assert &#39;).predict(data) | entities@clinical_results | meta_entities@clinical_entity | meta_entities@clinical_confidence | assertion_results | meta_assertion_confidence | |:—————————-|:——————————–|————————————:|:——————–|—————————-:| | a starvation ketosis | PROBLEM | 0.932233 | present | 0.9938 | | dry oral mucosa | PROBLEM | 0.797567 | present | 0.9997 | See the Models Hub for all avaiable Assertion Models De-Identification De-Identification tutorial notebook Detect sensitive information in a string and replace the sensitive data with anonymized labels data= &#39;DR Johnson administerd to the patient Peter Parker last week 30 MG of penicilin on Friday 25. March 1999&#39; df = nlp.load(&#39;de_identify&#39;).predict(data) deidentified_results entities@ner_results meta_entities@ner_entity [‘DR administerd to the patient last week 30 MG of penicilin on Friday 25.&#39;, &#39; March &#39;] Johnson PER [‘DR administerd to the patient last week 30 MG of penicilin on Friday 25.&#39;, &#39; March &#39;] Peter Parker PER See the Models Hub for all avaiable De-Identification Models Drug Normalizer Drug Normalizer tutorial notebook Normalize raw text from clinical documents, e.g. scraped web pages or xml document. Removes all dirty characters from text following one or more input regex patterns. Can apply non wanted character removal which a specific policy. Can apply lower case normalization. Parameters are lowercase: whether to convert strings to lowercase. Default is False. policy: rule to remove patterns from text. Valid policy values are: all abbreviations, dosages Defaults is all. abbreviation policy used to expend common drugs abbreviations, dosages policy used to convert drugs dosages and values to the standard form (see examples bellow). data = [&quot;Agnogenic one half cup&quot;,&quot;adalimumab 54.5 + 43.2 gm&quot;,&quot;aspirin 10 meq/ 5 ml oral sol&quot;,&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;,&quot;Sodium Chloride/Potassium Chloride 13bag&quot;] nlp.load(&#39;norm_drugs&#39;).predict(data) drug_norm text Agnogenic 0.5 oral solution Agnogenic one half cup adalimumab 97700 mg adalimumab 54.5 + 43.2 gm aspirin 2 meq/ml oral solution aspirin 10 meq/ 5 ml oral sol interferon alfa - 2b 10000000 unt ( 1 ml ) injection interferon alfa-2b 10 million unit ( 1 ml ) injec Sodium Chloride / Potassium Chloride 13 bag Sodium Chloride/Potassium Chloride 13bag Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. import nlu import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlp.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Authorize access to licensed features and install healthcare dependencies You need a set of credentials to access the licensed healthcare features. You can grab one here Automatically Authorize Google Colab via JSON file By default, nlu checks /content/spark_nlp_for_healthcare.json on google colabe enviroments for a spark_nlp_for_healthcare.json file that you recieve via E-mail from us. If you upload the spark_nlp_for_healthcare.json file to the standard colab directory, nlp.load() will automatically find it and authorize your enviroment. Authorize anywhere via providing via JSON file You can specify the location of your spark_nlp_for_healthcare.json like this : path = &#39;/path/to/spark_nlp_for_healthcare.json&#39; nlp.auth(path).load(&#39;licensed_model&#39;).predict(data) Authorize via providing String parameters import nlu SPARK_NLP_LICENSE = &#39;YOUR_SECRETS&#39; AWS_ACCESS_KEY_ID = &#39;YOUR_SECRETS&#39; AWS_SECRET_ACCESS_KEY = &#39;YOUR_SECRETS&#39; JSL_SECRET = &#39;YOUR_SECRETS&#39; nlp.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET)",
    "url": "/docs/en/jsl/examples_hc",
    "relUrl": "/docs/en/jsl/examples_hc"
  },
  "930": {
    "id": "930",
    "title": "Annotations Export",
    "content": "Annotations can be exported in various format for storage and later use. You can export the annotations applied to the tasks of any project by going to the Tasks page and clicking on the Export button on the top-right corner of this page. You will be navigated to the Export page and from there you can select the format and configure the export options to export the annotations to a file/s. Supported Formats for Text Projects The completions and predictions are stored in a database for fast search and access. Completions and predictions can be exported into the formats described below. JSON You can export the manual annotations (completions) and automatic annotations (predictions) to JSON format using the JSON option on the Export page. An example of JSON export file is shown below: [ { &quot;completions&quot;: [ { &quot;created_username&quot;: &quot;eric&quot;, &quot;created_ago&quot;: &quot;2022-10-29T14:42:50.867Z&quot;, &quot;lead_time&quot;: 82, &quot;result&quot;: [ { &quot;value&quot;: { &quot;start&quot;: 175, &quot;end&quot;: 187, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9524 }, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 213, &quot;end&quot;: 239, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.904775 }, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 385, &quot;end&quot;: 394, &quot;text&quot;: &quot;pneumonia&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 436, &quot;end&quot;: 449, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9157500000000001 }, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 454, &quot;end&quot;: 465, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91495 }, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 532, &quot;end&quot;: 540, &quot;text&quot;: &quot;Shigella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 542, &quot;end&quot;: 555, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9163 }, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 561, &quot;end&quot;: 571, &quot;text&quot;: &quot;Salmonella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9164000000000001 }, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 623, &quot;end&quot;: 630, &quot;text&quot;: &quot;tetanus&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97 }, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 632, &quot;end&quot;: 645, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.976675 }, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 647, &quot;end&quot;: 657, &quot;text&quot;: &quot;diphtheria&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9737 }, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 659, &quot;end&quot;: 667, &quot;text&quot;: &quot;syphilis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97355 }, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 673, &quot;end&quot;: 689, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.899025 }, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 30, &quot;end&quot;: 38, &quot;text&quot;: &quot;bacteria&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;lq7qtJj1yX&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 98, &quot;end&quot;: 106, &quot;text&quot;: &quot;bacteria&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;kxaB_gMstN&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } ], &quot;honeypot&quot;: true, &quot;copied_from&quot;: &quot;prediction: 11001&quot;, &quot;id&quot;: 11001, &quot;confidence_range&quot;: [ 0, 1 ], &quot;copy&quot;: true, &quot;cid&quot;: &quot;11001&quot;, &quot;data_type&quot;: &quot;prediction&quot;, &quot;updated_at&quot;: &quot;2022-10-29T15:13:03.445569Z&quot;, &quot;updated_by&quot;: &quot;eric&quot;, &quot;submitted_at&quot;: &quot;2022-10-30T20:57:54.303&quot; }, { &quot;created_username&quot;: &quot;jenny&quot;, &quot;created_ago&quot;: &quot;2022-10-29T15:03:51.669Z&quot;, &quot;lead_time&quot;: 0, &quot;result&quot;: [ { &quot;value&quot;: { &quot;start&quot;: 175, &quot;end&quot;: 187, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9524 }, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 213, &quot;end&quot;: 239, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.904775 }, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 385, &quot;end&quot;: 394, &quot;text&quot;: &quot;pneumonia&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 436, &quot;end&quot;: 449, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9157500000000001 }, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 454, &quot;end&quot;: 465, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91495 }, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 532, &quot;end&quot;: 540, &quot;text&quot;: &quot;Shigella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.91655 }, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 542, &quot;end&quot;: 555, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9163 }, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 561, &quot;end&quot;: 571, &quot;text&quot;: &quot;Salmonella&quot;, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;confidence&quot;: 0.9164000000000001 }, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 623, &quot;end&quot;: 630, &quot;text&quot;: &quot;tetanus&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97 }, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 632, &quot;end&quot;: 645, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.976675 }, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 647, &quot;end&quot;: 657, &quot;text&quot;: &quot;diphtheria&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.9737 }, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 659, &quot;end&quot;: 667, &quot;text&quot;: &quot;syphilis&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.97355 }, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; }, { &quot;value&quot;: { &quot;start&quot;: 673, &quot;end&quot;: 689, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;confidence&quot;: 0.899025 }, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } ], &quot;honeypot&quot;: true, &quot;confidence_range&quot;: [ 0, 1 ], &quot;submitted_at&quot;: &quot;2022-10-29T20:48:51.669&quot;, &quot;id&quot;: 11002 } ], &quot;predictions&quot;: [ { &quot;created_username&quot;: &quot;SparkNLP Pre-annotation&quot;, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;zgam2AbdmY&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 187, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 175, &quot;text&quot;: &quot;tuberculosis&quot;, &quot;confidence&quot;: &quot;0.9524&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;1v76SqlWtj&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 239, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 213, &quot;text&quot;: &quot;Mycobacterium tuberculosis&quot;, &quot;confidence&quot;: &quot;0.904775&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;CURKae4Eca&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 394, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 385, &quot;text&quot;: &quot;pneumonia&quot;, &quot;confidence&quot;: &quot;0.91655&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;cM5BvAsZL4&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 449, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 436, &quot;text&quot;: &quot;Streptococcus&quot;, &quot;confidence&quot;: &quot;0.9157500000000001&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;KGOLhb8OPV&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 465, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 454, &quot;text&quot;: &quot;Pseudomonas&quot;, &quot;confidence&quot;: &quot;0.91495&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;JCIhVQTDZl&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 540, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 532, &quot;text&quot;: &quot;Shigella&quot;, &quot;confidence&quot;: &quot;0.91655&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;CkxrbwvFzb&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 555, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 542, &quot;text&quot;: &quot;Campylobacter&quot;, &quot;confidence&quot;: &quot;0.9163&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;c6ev6McH4Z&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 571, &quot;labels&quot;: [ &quot;Pathogen&quot; ], &quot;start&quot;: 561, &quot;text&quot;: &quot;Salmonella&quot;, &quot;confidence&quot;: &quot;0.9164000000000001&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;9ZmEaJnqKG&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 630, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 623, &quot;text&quot;: &quot;tetanus&quot;, &quot;confidence&quot;: &quot;0.97&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;Uo5CWzdd1S&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 645, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 632, &quot;text&quot;: &quot;typhoid fever&quot;, &quot;confidence&quot;: &quot;0.976675&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;7nc71jXT3P&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 657, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 647, &quot;text&quot;: &quot;diphtheria&quot;, &quot;confidence&quot;: &quot;0.9737&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;nIKfsOWNyE&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 667, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 659, &quot;text&quot;: &quot;syphilis&quot;, &quot;confidence&quot;: &quot;0.97355&quot; } }, { &quot;from_name&quot;: &quot;label&quot;, &quot;id&quot;: &quot;SyuVYMn7ax&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 689, &quot;labels&quot;: [ &quot;MedicalCondition&quot; ], &quot;start&quot;: 673, &quot;text&quot;: &quot;Hansen&#39;s disease&quot;, &quot;confidence&quot;: &quot;0.899025&quot; } } ], &quot;created_ago&quot;: &quot;2022-10-29T14:07:58.553246Z&quot;, &quot;id&quot;: 11001 } ], &quot;created_at&quot;: &quot;2022-10-29 14:07:12&quot;, &quot;created_by&quot;: &quot;admin&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;Although the vast majority of bacteria are harmless or beneficial to one&#39;s body, a few pathogenic bacteria can cause infectious diseases. The most common bacterial disease is tuberculosis, caused by the bacterium Mycobacterium tuberculosis, which affects about 2 million people mostly in sub-Saharan Africa. Pathogenic bacteria contribute to other globally important diseases, such as pneumonia, which can be caused by bacteria such as Streptococcus and Pseudomonas, and foodborne illnesses, which can be caused by bacteria such as Shigella, Campylobacter, and Salmonella. Pathogenic bacteria also cause infections such as tetanus, typhoid fever, diphtheria, syphilis, and Hansen&#39;s disease. They typically range between 1 and 5 micrometers in length.&quot;, &quot;title&quot;: &quot;cord19-11.txt&quot; }, &quot;id&quot;: 11 } ] Below are some explanations related to the structure of the JSON export file. The export represents a list/array of task, containing completions and/or predictions. Each task in the list has the following main elements: TASK: A task can have 0 or several completions and 0 or several predictions. { &quot;completions&quot;: [COMPLETION1, COMPLETION2, ...], &quot;predictions&quot;: [PREDICTION1, PREDICTION2, ...], &quot;created_at&quot;: &quot;2022-07-04 06:17:26&quot;, &quot;created_by&quot;: &quot;admin&quot;, &quot;data&quot;: { &quot;text&quot;: &lt;sample_text&gt;&quot; }, &quot;id&quot;: 1 } completions: list of completions (manual annotations) predictions: list of predictions (annotations generated by spark-nlp model(s)) created_by: time stamp representing the creation time for a task created_by: the user who created the task data: input data on which the annotations/preannotation are defined (text/image/audio etc) id: task ID COMPLETION/PREDICTION: Completions and predictions have the following structure: { &quot;created_username&quot;: &quot;collaborate&quot;, &quot;created_ago&quot;: &quot;2022-07-04T06:18:39.720155Z&quot;, &quot;lead_time&quot;: 11, &quot;result&quot;: [RESULT1, RESULT2, RESULT3, ....], &quot;honeypot&quot;: true, &quot;id&quot;: 1001, &quot;updated_at&quot;: &quot;2022-07-04T06:18:49.037150Z&quot;, &quot;updated_by&quot;: &quot;collaborate&quot;, } created_username: user who created the annotation created_ago: timestamp of when the annotation was created lead_time: time taken (in seconds) to create this annotation (valid for manual completion only) result: list of annotated labels honeypot: boolean value to set/unset ground truth id: completion/prediction ID updated_at: timestamp of when the annotation was last updated updated_by: user who updated the annotation Each completion/prediction contains one or several results which can be seen as individual annotations. RESULT: The structure of the RESULT dictionary differs according to the project configuration: 1. NER: { &quot;value&quot;: { &quot;start&quot;: 17, &quot;end&quot;: 25, &quot;text&quot;: &quot;pleasant&quot;, &quot;labels&quot;: [ &quot;FAC&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;iJOo_XgIao&quot;, &quot;from_name&quot;: &quot;label&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot; } value: start: start index of the annotated chunk end: end index of the annotated chunk text: annotated chunk labels: associated label confidence: confidence score (1 for manual annotation and a value between 0 and 1 for predicted annotations) id: id of annotation (used while creating relations between entities) from_name/to_name: this attribute is set according to the project config: from_name -&gt; name attribute of the Labels tag to_name -&gt; toName attribute of the Labels tag &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; type: type of the annotation (labels, choices, relations etc.) 2. Classification: { &quot;value&quot;: { &quot;choices&quot;: [ &quot;sadness&quot; ], &quot;confidence&quot;: 1 }, &quot;id&quot;: &quot;VyY-OHe_lf&quot;, &quot;from_name&quot;: &quot;surprise&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;choices&quot; } value: choices: the options/choises selected by users confidence: confidence score (1 for manual annotation and between 0 and 1 for predicted annotation) id: id of annotation from_name/to_name: this field is set according to the project config: `from_name` -&gt; name attribute of the Choice tag `to_name` -&gt; toName attribute of the Choice tag &lt;Choices name=&quot;surprise&quot; toName=&quot;text&quot; choice=&quot;single&quot;&gt; type: type of the annotation (labels, choices, relations etc) 3. Relations: The information below is added in the RESULT section: { &quot;from_id&quot;: &quot;ucfP3c4xWg&quot;, &quot;to_id&quot;: &quot;IlWac4TdFx&quot;, &quot;type&quot;: &quot;relation&quot;, &quot;direction&quot;: &quot;right&quot;, &quot;confidence&quot;: 1 } from_id/to_id: IDs of the related annotations type: type of the annotation (labels, choices, relations etc) direction: direction for the relation. The accepted values are right and left. Submitted annotation: When a completion is submitted, it has a submitted timestamp on the COMPLETION dictionary (refer to the above json example): &quot;submitted_at&quot;: &quot;2022-07-04T12:03:48.824&quot; Reviewed annotation: When a completion is reviewed, the following information is added to the COMPLETION dictionary: &quot;review_status&quot;: { &quot;approved&quot;: true, &quot;comment&quot;: &quot;Looks good!&quot;, &quot;reviewer&quot;: &quot;Mauro&quot;, &quot;reviewed_at&quot;: &quot;2022-07-04T06:19:31.897Z&quot; } approved: boolean value (true -&gt; approved and false -&gt; rejected) comment: text comment manually defined by the reviewer reviewer: user who reviewed the completion reviewed_at: review timestamp Copied Annotation: When an annotation is copied/cloned from a specific completion/prediction, the COMPLETION dictionary contains the copied_from filed: &quot;copied_from&quot;: &quot;prediction: 4001&quot; CSV Results are stored in a comma-separated tabular file with column names specified by “from_name” and “to_name” values. TSV Results are stored in a tab-separated tabular file with column names specified by “from_name” and “to_name” values. CoNLL2003 The CoNLL export feature generates a single output file, containing all available completions for all the tasks in the project. The resulting file has the following format: -DOCSTART- -X- O Sample -X- _ O Type -X- _ O Medical -X- _ O Specialty: -X- _ O Endocrinology -X- _ O Sample -X- _ O Name: -X- _ O Diabetes -X- _ B-Diagnosis Mellitus -X- _ I-Diagnosis Followup -X- _ O Description: -X- _ O Return -X- _ O visit -X- _ O to -X- _ O the -X- _ O endocrine -X- _ O clinic -X- _ O for -X- _ O followup -X- _ O management -X- _ O of -X- _ O type -X- _ O 1 -X- _ O diabetes -X- _ O mellitus -X- _ O Plan -X- _ O today -X- _ O is -X- _ O to -X- _ O make -X- _ O adjustments -X- _ O to -X- _ O her -X- _ O pump -X- _ O based -X- _ O on -X- _ O a -X- _ O total -X- _ O daily -X- _ B-FREQUENCY dose -X- _ O of -X- _ O 90 -X- _ O units -X- _ O of -X- _ O insulin -X- _ O … Users can specify if only starred completions should be included in the output file by checking the Only ground truth option before generating the export. Supported Formats for Visual NER Projects The process of annotations export from Visual NER projects is similar to that of text projects. When exporting the Visual NER annotations users have two additional formats available: COCO and VOC. For Visual NER projects, the image documents annotated as part of each task are included in the project export archive under the images folder. COCO The COCO format is a specific JSON structure dictating how labels and metadata are saved for an image dataset. It is a large-scale object detection, segmentation, and captioning dataset. Exporting in COCO format is available for Visual NER projects only. Below is a sample format: { &quot;images&quot;: [ { &quot;width&quot;: 6.588235294117647, &quot;height&quot;: 0.9396786905122766, &quot;id&quot;: 0, &quot;file_name&quot;: [ &quot;/images/19/0160023239a-1655481445_0.png&quot;, &quot;/images/19/0160023239a-1655481445_1.png&quot; ] } ], &quot;categories&quot;: [ { &quot;id&quot;: 0, &quot;name&quot;: &quot;OGSContractNumber&quot;, &quot;supercategory&quot;: &quot;OGSContractNumber&quot; }, { &quot;id&quot;: 1, &quot;name&quot;: &quot;Contractor&quot;, &quot;supercategory&quot;: &quot;Contractor&quot; }, { &quot;id&quot;: 2, &quot;name&quot;: &quot;FederalID&quot;, &quot;supercategory&quot;: &quot;FederalID&quot; }, { &quot;id&quot;: 3, &quot;name&quot;: &quot;VendorID&quot;, &quot;supercategory&quot;: &quot;VendorID&quot; }, { &quot;id&quot;: 4, &quot;name&quot;: &quot;Title&quot;, &quot;supercategory&quot;: &quot;Title&quot; }, { &quot;id&quot;: 5, &quot;name&quot;: &quot;AwardNumber&quot;, &quot;supercategory&quot;: &quot;AwardNumber&quot; }, { &quot;id&quot;: 6, &quot;name&quot;: &quot;ContractPeriod&quot;, &quot;supercategory&quot;: &quot;ContractPeriod&quot; }, { &quot;id&quot;: 7, &quot;name&quot;: &quot;BidOpeningDate&quot;, &quot;supercategory&quot;: &quot;BidOpeningDate&quot; }, { &quot;id&quot;: 8, &quot;name&quot;: &quot;DateOfIssue&quot;, &quot;supercategory&quot;: &quot;DateOfIssue&quot; }, { &quot;id&quot;: 9, &quot;name&quot;: &quot;SpecificationReference&quot;, &quot;supercategory&quot;: &quot;SpecificationReference&quot; }, { &quot;id&quot;: 10, &quot;name&quot;: &quot;GroupNumber&quot;, &quot;supercategory&quot;: &quot;GroupNumber&quot; } ], &quot;annotations&quot;: [ { &quot;id&quot;: 0, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 1, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 2, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 3, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land Dairies, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 4, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Hudson Valley Fresh Dairy, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 5, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Upstate Niagara Inc.&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 6, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;223629742&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 7, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;461053272&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 8, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;160845625&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 9, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100070111&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 10, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100212977&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 11, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1000014941&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 12, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land - LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 13, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 14, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Hudson Valley Fresh Dairy, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 15, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 16, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 17, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Upstate Niagara Cooperative, Inc.&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 18, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;; Upstate Niagara Cooperative,&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 19, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 20, &quot;image_id&quot;: 0, &quot;category_id&quot;: 4, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Milk, Fluid (Statewide)&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 21, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 22, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 2, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 21, 2021 Through September 20, 2026&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 23, &quot;image_id&quot;: 0, &quot;category_id&quot;: 7, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;June 10, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 24, &quot;image_id&quot;: 0, &quot;category_id&quot;: 8, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 14, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 27, &quot;image_id&quot;: 0, &quot;category_id&quot;: 10, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Group&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 29, &quot;image_id&quot;: 0, &quot;category_id&quot;: 4, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Milk, Fluid (Statewide)&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 30, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 31, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 2, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 21, 2021 Through September 20, 2026&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 32, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;June 10, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 33, &quot;image_id&quot;: 0, &quot;category_id&quot;: 6, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;September 14, 2021&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 34, &quot;image_id&quot;: 0, &quot;category_id&quot;: 5, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 2, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;23239&quot;, &quot;pageNumber&quot;: 1 }, { &quot;id&quot;: 35, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 36, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 1, 0, 1, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land Dairies, LLC&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 38, &quot;image_id&quot;: 0, &quot;category_id&quot;: 3, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;1100070111&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 39, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69435&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 41, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;461053272&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 43, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 0, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69436&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 45, &quot;image_id&quot;: 0, &quot;category_id&quot;: 2, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 3, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;160845625&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 47, &quot;image_id&quot;: 0, &quot;category_id&quot;: 1, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 4, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;Cream-O-Land&quot;, &quot;pageNumber&quot;: 2 }, { &quot;id&quot;: 49, &quot;image_id&quot;: 0, &quot;category_id&quot;: 0, &quot;segmentation&quot;: [], &quot;bbox&quot;: [ 5, 0, 0, 0 ], &quot;ignore&quot;: 0, &quot;iscrowd&quot;: 0, &quot;area&quot;: 0, &quot;text&quot;: &quot;PC69434&quot;, &quot;pageNumber&quot;: 2 } ], &quot;info&quot;: { &quot;year&quot;: 2022, &quot;version&quot;: &quot;1.0&quot;, &quot;contributor&quot;: &quot;Annotation Lab Converter&quot; } } Pascal VOC XML Pascal Visual Object Classes(VOC) is an XML file that contains the image details, bounding box details, classes, pose, truncated, and other data. For each image of the task there will be an XML annotation file. Exporting in VOC format is available for Visual NER projects only. Below is a sample format: &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;annotation&gt; &lt;folder&gt;images&lt;/folder&gt; &lt;filename&gt;0160023239a-1655481445_0.png&lt;/filename&gt; &lt;source&gt; &lt;database&gt;ALABDB&lt;/database&gt; &lt;/source&gt; &lt;owner&gt; &lt;name&gt;AnnotationLab&lt;/name&gt; &lt;/owner&gt; &lt;size&gt; &lt;width&gt;2550&lt;/width&gt; &lt;height&gt;3299&lt;/height&gt; &lt;depth&gt;1&lt;/depth&gt; &lt;/size&gt; &lt;segmented&gt;0&lt;/segmented&gt; &lt;object&gt; &lt;name&gt;Title&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1305&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1780&lt;/xmax&gt; &lt;ymax&gt;703&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;973&lt;/xmin&gt; &lt;ymin&gt;791&lt;/ymin&gt; &lt;xmax&gt;1099&lt;/xmax&gt; &lt;ymax&gt;834&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;903&lt;/ymin&gt; &lt;xmax&gt;2038&lt;/xmax&gt; &lt;ymax&gt;946&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;BidOpeningDate&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1013&lt;/ymin&gt; &lt;xmax&gt;1263&lt;/xmax&gt; &lt;ymax&gt;1054&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;DateOfIssue&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1124&lt;/ymin&gt; &lt;xmax&gt;1393&lt;/xmax&gt; &lt;ymax&gt;1166&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;SpecificationReference&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;973&lt;/xmin&gt; &lt;ymin&gt;1235&lt;/ymin&gt; &lt;xmax&gt;1729&lt;/xmax&gt; &lt;ymax&gt;1277&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;GroupNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1248&lt;/xmax&gt; &lt;ymax&gt;702&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;GroupNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1108&lt;/xmax&gt; &lt;ymax&gt;702&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1125&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1248&lt;/xmax&gt; &lt;ymax&gt;694&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;Title&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;1304&lt;/xmin&gt; &lt;ymin&gt;660&lt;/ymin&gt; &lt;xmax&gt;1780&lt;/xmax&gt; &lt;ymax&gt;703&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;791&lt;/ymin&gt; &lt;xmax&gt;1097&lt;/xmax&gt; &lt;ymax&gt;825&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;902&lt;/ymin&gt; &lt;xmax&gt;2038&lt;/xmax&gt; &lt;ymax&gt;945&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1013&lt;/ymin&gt; &lt;xmax&gt;1264&lt;/xmax&gt; &lt;ymax&gt;1054&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;ContractPeriod&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;974&lt;/xmin&gt; &lt;ymin&gt;1124&lt;/ymin&gt; &lt;xmax&gt;1393&lt;/xmax&gt; &lt;ymax&gt;1166&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;object&gt; &lt;name&gt;AwardNumber&lt;/name&gt; &lt;pose&gt;Unspecified&lt;/pose&gt; &lt;truncated&gt;0&lt;/truncated&gt; &lt;difficult&gt;0&lt;/difficult&gt; &lt;bndbox&gt; &lt;xmin&gt;791&lt;/xmin&gt; &lt;ymin&gt;2246&lt;/ymin&gt; &lt;xmax&gt;903&lt;/xmax&gt; &lt;ymax&gt;2276&lt;/ymax&gt; &lt;/bndbox&gt; &lt;/object&gt; &lt;/annotation&gt; Export Options Tags Only allow export of tasks having the specified tags. Only Ground Truth If this option is enabled then only the tasks having ground truth in the completion will be exported. Exclude tasks without Completions Previous versions of the Annotation Lab only allowed the export of tasks that contained completions. From version 2.8.0 on, the tasks without any completions can be exported as this can be necessary for cloning projects. In the case where only tasks with completions are required in the export, users can enable the Exclude tasks without Completions option on the Export page.",
    "url": "/docs/en/alab/export",
    "relUrl": "/docs/en/alab/export"
  },
  "931": {
    "id": "931",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/extended_java_wrapper.html",
    "relUrl": "/api/python/modules/sparknlp/internal/extended_java_wrapper.html"
  },
  "932": {
    "id": "932",
    "title": "Extract handwritten texts - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_handwritten_texts",
    "relUrl": "/extract_handwritten_texts"
  },
  "933": {
    "id": "933",
    "title": "Extract Tables - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_tables",
    "relUrl": "/extract_tables"
  },
  "934": {
    "id": "934",
    "title": "Extract Text from Documents - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/extract_text_from_documents",
    "relUrl": "/extract_text_from_documents"
  },
  "935": {
    "id": "935",
    "title": "Normalization & Data Augmentation - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_company_normalization",
    "relUrl": "/financial_company_normalization"
  },
  "936": {
    "id": "936",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/financial_deidentification",
    "relUrl": "/financial_deidentification"
  },
  "937": {
    "id": "937",
    "title": "Financial Document Splitting - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_document_splitting",
    "relUrl": "/financial_document_splitting"
  },
  "938": {
    "id": "938",
    "title": "Financial Document Understanding - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_document_understanding",
    "relUrl": "/financial_document_understanding"
  },
  "939": {
    "id": "939",
    "title": "Recognize Financial Entities - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_entity_recognition",
    "relUrl": "/financial_entity_recognition"
  },
  "940": {
    "id": "940",
    "title": "Extract Financial Relationships - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_relation_extraction",
    "relUrl": "/financial_relation_extraction"
  },
  "941": {
    "id": "941",
    "title": "Finance NLP Release Notes",
    "content": "Releases log         1.0.0 1.1.0 1.2.0 1.3.0 1.4.0 1.5.0 1.6.0 1.7.0 1.8.0 1.9.0     Slack - Join #finance channel",
    "url": "/docs/en/financial_release_notes",
    "relUrl": "/docs/en/financial_release_notes"
  },
  "942": {
    "id": "942",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/financial_table_extraction",
    "relUrl": "/financial_table_extraction"
  },
  "943": {
    "id": "943",
    "title": "Version Compatibility",
    "content": "Legal NLP runs on top of johnsnowlabs library (former nlu). Please find technical documentation about how to install it here. All our models are backwards compatible, which means it will be safe for you to always use the last version of johnsnowlabs. If you are curious about which version of Spark NLP, Visual NLP or Clinical NLP are included in the last johnsnowlabs versions, please check here Finance NLP is also supported in Annotation Lab from Alab 4.2.3 version on!",
    "url": "/docs/en/financial_version_compatibility",
    "relUrl": "/docs/en/financial_version_compatibility"
  },
  "944": {
    "id": "944",
    "title": "Financial Visual Document Classification - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/financial_visual_document_classification",
    "relUrl": "/financial_visual_document_classification"
  },
  "945": {
    "id": "945",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/finisher.html"
  },
  "946": {
    "id": "946",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$EachAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$EachAnnotations.html"
  },
  "947": {
    "id": "947",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$ExplodeAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$ExplodeAnnotations.html"
  },
  "948": {
    "id": "948",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$FilterAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$FilterAnnotations.html"
  },
  "949": {
    "id": "949",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$$MapAnnotations.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$$MapAnnotations.html"
  },
  "950": {
    "id": "950",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/functions$.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/functions$.html"
  },
  "951": {
    "id": "951",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/functions.html",
    "relUrl": "/api/python/modules/sparknlp/functions.html"
  },
  "952": {
    "id": "952",
    "title": "Genes, Variants, Phenotypes - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/genes_variants_phenotypes",
    "relUrl": "/genes_variants_phenotypes"
  },
  "953": {
    "id": "953",
    "title": "",
    "content": "",
    "url": "/api/python/genindex.html",
    "relUrl": "/api/python/genindex.html"
  },
  "954": {
    "id": "954",
    "title": "German - Medical NLP Demos & Notebooks",
    "content": "",
    "url": "/german",
    "relUrl": "/german"
  },
  "955": {
    "id": "955",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/gpt2_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/gpt2_transformer.html"
  },
  "956": {
    "id": "956",
    "title": "Tensorflow Graph",
    "content": "NER DL uses Char CNNs - BiLSTM - CRF Neural Network architecture. Spark NLP defines this architecture through a Tensorflow graph, which requires the following parameters: Tags Embeddings Dimension Number of Chars Spark NLP infers these values from the training dataset used in NerDLApproach annotator and tries to load the graph embedded on spark-nlp package. Currently, Spark NLP has graphs for the most common combination of tags, embeddings, and number of chars values: Tags Embeddings Dimension 10 100 10 200 10 300 10 768 10 1024 25 300 All of these graphs use an LSTM of size 128 and number of chars 100 In case, your train dataset has a different number of tags, embeddings dimension, number of chars and LSTM size combinations shown in the table above, NerDLApproach will raise an IllegalArgumentException exception during runtime with the message below: Graph [parameter] should be [value]: Could not find a suitable tensorflow graph for embeddings dim: [value] tags: [value] nChars: [value]. Check https://nlp.johnsnowlabs.com/docs/en/graph for instructions to generate the required graph. To overcome this exception message we have to follow these steps: Clone spark-nlp github repo Run python file create_models with number of tags, embeddings dimension and number of char values mentioned on your exception message error. cd spark-nlp/python/tensorflow export PYTHONPATH=lib/ner python ner/create_models.py [number_of_tags] [embeddings_dimension] [number_of_chars] [output_path] This will generate a graph on the directory defined on `output_path argument. Retry training with NerDLApproach annotator but this time use the parameter setGraphFolder with the path of your graph. Note: Make sure that you have Python 3 and Tensorflow 1.15.0 installed on your system since create_models requires those versions to generate the graph successfully. Note: We also have a notebook in the same directory if you prefer Jupyter notebook to cerate your custom graph (create_models.ipynb).",
    "url": "/docs/en/graph",
    "relUrl": "/docs/en/graph"
  },
  "957": {
    "id": "957",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/graph_extraction.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/graph_extraction.html"
  },
  "958": {
    "id": "958",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/graph_finisher.html",
    "relUrl": "/api/python/modules/sparknlp/base/graph_finisher.html"
  },
  "959": {
    "id": "959",
    "title": "Hardware Acceleration",
    "content": "",
    "url": "/docs/en/hardware_acceleration",
    "relUrl": "/docs/en/hardware_acceleration"
  },
  "960": {
    "id": "960",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/has_recursive_fit.html",
    "relUrl": "/api/python/modules/sparknlp/base/has_recursive_fit.html"
  },
  "961": {
    "id": "961",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/has_recursive_transform.html",
    "relUrl": "/api/python/modules/sparknlp/base/has_recursive_transform.html"
  },
  "962": {
    "id": "962",
    "title": "NLP Libraries Integration",
    "content": "Healthcare NLP provides an easy to use module for interacting with Annotation Lab with minimal code. In this section, you can find the instructions for performing specific operations using the annotation lab module of the Healthcare NLP library. You can execute these instructions in a python notebook (Jupyter, Colab, Kaggle, etc.). Before running the instructions described in the following sub-sections, some initial environment setup needs to be performed in order to configure the Healthcare NLP library and start a Spark session. NOTE: For using this integration a Healthcare, Finance and/or Legal NLP License key is requirend. If you do not have one, you can get it here. import json import os from google.colab import files license_keys = files.upload() with open(list(license_keys.keys())[0]) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) NOTE: The license upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving jsl_keys.json to jsl_keys (2).json # Installing pyspark and spark-nlp ! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION # Installing Spark NLP Healthcare ! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION --extra-index-url https://pypi.johnsnowlabs.com/$SECRET # Installing Spark NLP Display Library for visualization ! pip install -q spark-nlp-display |████████████████████████████████| 212.4 MB 51 kB/s |████████████████████████████████| 616 kB 56.5 MB/s |████████████████████████████████| 198 kB 52.8 MB/s Building wheel for pyspark (setup.py) ... done |████████████████████████████████| 206 kB 2.9 MB/s |████████████████████████████████| 95 kB 2.4 MB/s |████████████████████████████████| 66 kB 4.9 MB/s |████████████████████████████████| 1.6 MB 44.7 MB/s import pandas as pd import requests import json from zipfile import ZipFile from io import BytesIO import os from pyspark.ml import Pipeline,PipelineModel from pyspark.sql import SparkSession from pyspark.sql import functions as F from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.base import * import sparknlp_jsl import sparknlp import warnings warnings.filterwarnings(&#39;ignore&#39;) params = {&quot;spark.driver.memory&quot;:&quot;16G&quot;, &quot;spark.kryoserializer.buffer.max&quot;:&quot;2000M&quot;, &quot;spark.driver.maxResultSize&quot;:&quot;2000M&quot;} print(&quot;Spark NLP Version :&quot;, sparknlp.version()) print(&quot;Spark NLP_JSL Version :&quot;, sparknlp_jsl.version()) spark = sparknlp_jsl.start(license_keys[&#39;SECRET&#39;],params=params) spark Spark NLP Version : 4.1.0 Spark NLP_JSL Version : 4.1.0 SparkSession - in-memory SparkContext Spark UI Version v3.1.2 Master local[*] AppName Spark NLP Licensed Using already exported JSON to generate training data - No Annotation Lab Credentials Required # import the module from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() # downloading demo json !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Annotation_Lab/data/alab_demo.json --2022-09-29 18:47:21-- https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Annotation_Lab/data/alab_demo.json Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 66538 (65K) [text/plain] Saving to: ‘alab_demo.json’ alab_demo.json 100%[===================&gt;] 64.98K --.-KB/s in 0.01s 2022-09-29 18:47:21 (5.43 MB/s) - ‘alab_demo.json’ saved [66538/66538] Generating training data for different models No Annotation Lab Credentials Required. Only the exported JSON is used. Classification Model The following snippet shows how to generate data for training a classification model. alab.get_classification_data( # required: path to Annotation Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True ) Processing 14 annotation(s). Output:   task_id task_title text class 0 2 Note 2 The patient is a 5-month-old infant who presen… [Female] 1 3 Note 3 The patient is a 21-day-old male here for 2 da… [Male] 2 1 Note 1 On 18/08 patient declares she has a headache s… [Female] NER Model The JSON export must be converted into a CoNLL format suitable for training an NER model. alab.get_conll_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path=&quot;alab_demo.json&quot;, # required: name of the CoNLL file to save output_name=&quot;conll_demo&quot;, # optional: path for CoNLL file saving directory, defaults to &#39;exported_conll&#39; save_dir=&quot;exported_conll&quot;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: labels to exclude from CoNLL; these are all assertion labels and irrelevant NER labels, # defaults to empty list excluded_labels=[&#39;ABSENT&#39;], # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined regex_pattern=&quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot; # optional: list of Annotation Lab task IDs to exclude from CoNLL, defaults to empty list # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from CoNLL, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] pos_clinical download started this may take some time. Approximate size to download 1.5 MB [OK!] Spark NLP LightPipeline is created sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Spark NLP LightPipeline is created Attempting to process: Task ID# 1 Task ID# 1 is included Attempting to process: Task ID# 2 Task ID# 2 is included Attempting to process: Task ID# 3 Task ID# 3 is included Saved in location: exported_conll/conll_demo.conll Printing first 30 lines of CoNLL for inspection: [&#39;-DOCSTART- -X- -1- O n n&#39;, &#39;On II II O n&#39;, &#39;18/08 MC MC B-DATE n&#39;, &#39;patient NN NN O n&#39;, &#39;declares NNS NNS O n&#39;, &#39;she PN PN O n&#39;, &#39;has VHZ VHZ O n&#39;, &#39;a DD DD O n&#39;, &#39;headache NN NN B-PROBLEM n&#39;, &#39;since CS CS O n&#39;, &#39;06/08 MC MC B-DATE n&#39;, &#39;, NN NN O n&#39;, &#39;needs VVZ VVZ O n&#39;, &#39;to TO TO O n&#39;, &#39;get VVI VVI O n&#39;, &#39;a DD DD O n&#39;, &#39;head NN NN B-TEST n&#39;, &#39;CT NN NN I-TEST n&#39;, &#39;, NN NN O n&#39;, &#39;and CC CC O n&#39;, &#39;appears VVZ VVZ O n&#39;, &#39;anxious JJ JJ B-PROBLEM n&#39;, &#39;when CS CS O n&#39;, &#39;she PN PN O n&#39;, &#39;walks RR RR O n&#39;, &#39;fast JJ JJ O n&#39;, &#39;. NN NN O n&#39;, &#39;No NN NN O n&#39;, &#39;alopecia NN NN B-PROBLEM n&#39;, &#39;noted VVNJ VVNJ O n&#39;] Assertion Model The JSON export is converted into a dataframe, suitable for training an assertion model. alab.get_assertion_data( # required: SparkSession with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path = &#39;alab_demo.json&#39;, # required: annotated assertion labels to train on assertion_labels = [&#39;ABSENT&#39;], # required: relevant NER labels that are assigned assertion labels relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;], # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth = True, # optional: assertion label to assign to entities that have no assertion labels, defaults to None unannotated_label = &#39;PRESENT&#39;, # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined regex_pattern = &quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot;, # optional: set the strategy to control the number of occurrences of the unannotated assertion label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None unannotated_label_strategy = &#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY_LABEL&#39;: sample_weight_or_counts} to control the number of # occurrences of the unannotated assertion label in the output dataframe, where &#39;ENTITY_LABEL&#39; are the # NER labels that are assigned the unannotated assertion label, and sample_weight_or_counts should be # between 0 and 1 if `unannotated_label_strategy` is &#39;weighted&#39; or between 0 and the max number of # occurrences of that NER label if `unannotated_label_strategy` is &#39;counts&#39; unannotated_label_strategy_dict = {&#39;PROBLEM&#39;: 0.5, &#39;TREATMENT&#39;: 0.5}, # optional: list of Annotation Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Spark NLP LightPipeline is created Processing Task ID# 2 Processing Task ID# 3 Processing Task ID# 1 Output:   task_id title text target ner_label label start end 0 1 Note 1 On 18/08 patient declares she has a headache s… headache PROBLEM PRESENT 7 7 1 1 Note 1 On 18/08 patient declares she has a headache s… alopecia PROBLEM ABSENT 27 27 2 1 Note 1 On 18/08 patient declares she has a headache s… pain PROBLEM ABSENT 32 32 3 2 Note 2 Mom states she had no fever. fever PROBLEM ABSENT 5 5 4 2 Note 2 She had no difficulty breathing and her cough … difficulty breathing PROBLEM ABSENT 3 4 5 2 Note 2 She had no difficulty breathing and her cough … cough PROBLEM PRESENT 7 7 6 2 Note 2 She had no difficulty breathing and her cough … dry PROBLEM PRESENT 11 11 7 2 Note 2 She had no difficulty breathing and her cough … hacky PROBLEM PRESENT 13 13 8 2 Note 2 At that time, physical exam showed no signs of… flu PROBLEM ABSENT 10 10 9 3 Note 3 The patient is a 21-day-old male here for 2 da… congestion PROBLEM PRESENT 15 15 10 3 Note 3 The patient is a 21-day-old male here for 2 da… suctioning yellow discharge TREATMENT PRESENT 23 25 11 3 Note 3 The patient is a 21-day-old male here for 2 da… perioral cyanosis PROBLEM ABSENT 47 48 12 3 Note 3 One day ago, mom also noticed a tactile temper… tactile temperature PROBLEM PRESENT 8 9 Relation Extraction Model The JSON export is converted into a dataframe suitable for training a relation extraction model. alab.get_relation_extraction_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to Annotation Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: set to True to assign a relation label between entities where no relation was annotated, # defaults to False negative_relations=True, # optional: all assertion labels that were annotated in the Annotation Lab, defaults to None assertion_labels=[&#39;ABSENT&#39;], # optional: plausible pairs of entities for relations, separated by a &#39;-&#39;, use the same casing as the # annotations, include only one relation direction, defaults to all possible pairs of annotated entities relation_pairs=[&#39;DATE-PROBLEM&#39;,&#39;TREATMENT-PROBLEM&#39;,&#39;TEST-PROBLEM&#39;], # optional: set the strategy to control the number of occurrences of the negative relation label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None negative_relation_strategy=&#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY1-ENTITY2&#39;: sample_weight_or_counts} to control the number of # occurrences of negative relations in the output dataframe for each entity pair, where &#39;ENTITY1-ENTITY2&#39; # represent the pairs of entities for relations separated by a `-` (include only one relation direction), # and sample_weight_or_counts should be between 0 and 1 if `negative_relation_strategy` is &#39;weighted&#39; or # between 0 and the max number of occurrences of negative relations if `negative_relation_strategy` is # &#39;counts&#39;, defaults to None negative_relation_strategy_dict = {&#39;DATE-PROBLEM&#39;: 0.1, &#39;TREATMENT-PROBLEM&#39;: 0.5, &#39;TEST-PROBLEM&#39;: 0.2}, # optional: list of Annotation Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of Annotation Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;] ) Successfully processed relations for task: Task ID# 2 Successfully processed relations for task: Task ID# 3 Successfully processed relations for task: Task ID# 1 Total tasks processed: 3 Total annotated relations processed: 10 sentence_detector_dl_healthcare download started this may take some time. Approximate size to download 367.3 KB [OK!] Successfully processed NER labels for: Task ID# 2 Successfully processed NER labels for: Task ID# 3 Successfully processed NER labels for: Task ID# 1 Total tasks processed: 3 Total annotated NER labels processed: 28 Output:   task_id title sentence firstCharEnt1 firstCharEnt2 lastCharEnt1 lastCharEnt2 chunk1 chunk2 label1 label2 rel 0 1 Note 1 On 18/08 patient declares she has a headache s… 36 51 44 56 headache 06/08 PROBLEM DATE is_date_of 1 1 Note 1 On 18/08 patient declares she has a headache s… 36 73 44 80 headache head CT PROBLEM TEST is_test_of 2 1 Note 1 On 18/08 patient declares she has a headache s… 51 156 56 160 06/08 pain DATE PROBLEM O 3 1 Note 1 On 18/08 patient declares she has a headache s… 73 126 80 134 head CT alopecia TEST PROBLEM O 4 2 Note 2 At that time, physical exam showed no signs of… 14 47 27 50 physical exam flu TEST PROBLEM is_test_of 5 2 Note 2 The patient is a 5-month-old infant who presen… 63 76 68 80 Feb 8 cold DATE PROBLEM is_date_of 6 2 Note 2 The patient is a 5-month-old infant who presen… 63 82 68 87 Feb 8 cough DATE PROBLEM is_date_of 7 2 Note 2 The patient is a 5-month-old infant who presen… 63 93 68 103 Feb 8 runny nose DATE PROBLEM is_date_of 8 2 Note 2 The patient is a 5-month-old infant who presen… 82 110 87 115 cough Feb 2 PROBLEM DATE O 9 3 Note 3 One day ago, mom also noticed a tactile temper… 32 73 51 80 tactile temperature Tylenol PROBLEM TREATMENT is_treatment_of 10 3 Note 3 The patient is a 21-day-old male here for 2 da… 52 69 62 77 congestion Nov 8/15 PROBLEM DATE is_date_of 11 3 Note 3 The patient is a 21-day-old male here for 2 da… 52 93 62 120 congestion suctioning yellow discharge PROBLEM TREATMENT is_treatment_of 12 3 Note 3 The patient is a 21-day-old male here for 2 da… 93 244 120 261 suctioning yellow discharge perioral cyanosis TREATMENT PROBLEM O 13 3 Note 3 The patient is a 21-day-old male here for 2 da… 93 265 120 276 suctioning yellow discharge retractions TREATMENT PROBLEM O 14 3 Note 3 The patient is a 21-day-old male here for 2 da… 173 217 196 225 mild breathing problems Nov 9/15 PROBLEM DATE is_date_of Generate Pre-annotations using Spark NLP pipelines No Annotation Lab credentials are required. The first step is to define the Healthcare NLP pipeline. The same procedure can be followed for Legal and Finance NLP pipelines. document = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;sentence&#39;) .setCustomBounds([&#39; n&#39;]) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel().pretrained(&#39;embeddings_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &#39;token&#39;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&#39;ner_jsl&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) assertion_model = AssertionDLModel().pretrained(&#39;assertion_dl&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &#39;embeddings&#39;]) .setOutputCol(&quot;assertion_res&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;pos_tags&quot;, &quot;token&quot;]) .setOutputCol(&quot;dependencies&quot;) relation_clinical = RelationExtractionModel.pretrained(&#39;re_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_clinical&quot;) .setRelationPairs([&#39;procedure-disease_syndrome_disorder&#39;, &#39;test-oncological&#39;, &#39;test-disease_syndrome_disorder&#39;, &#39;external_body_part_or_region-procedure&#39;, &#39;oncological-external_body_part_or_region&#39;, &#39;oncological-procedure&#39;]) .setMaxSyntacticDistance(0) relation_pos = RelationExtractionModel.pretrained(&#39;posology_re&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_pos&quot;) .setRelationPairs([&#39;drug_ingredient-drug_brandname&#39;, &#39;drug_ingredient-dosage&#39;, &#39;drug_ingredient-strength&#39;, &#39;drug_ingredient-route&#39;]) .setMaxSyntacticDistance(0) ner_pipeline = Pipeline( stages = [ document, sentence, tokenizer, word_embeddings, ner_model, converter, assertion_model, pos_tagger, dependency_parser, relation_clinical, relation_pos ]) empty_data = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) pipeline_model = ner_pipeline.fit(empty_data) lmodel = LightPipeline(pipeline_model) embeddings_clinical download started this may take some time. Approximate size to download 1.6 GB [OK!] ner_jsl download started this may take some time. [OK!] assertion_dl download started this may take some time. [OK!] pos_clinical download started this may take some time. Approximate size to download 1.5 MB [OK!] dependency_conllu download started this may take some time. Approximate size to download 16.7 MB [OK!] re_clinical download started this may take some time. Approximate size to download 6 MB [OK!] Run on sample tasks txt1 = &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot; txt2 = &quot;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&quot; task_list = [txt1, txt2] results = lmodel.fullAnnotate(task_list) # full pipeline: # results = pipeline_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: task_list}))).collect() Generate pre-annotation JSON using pipeline results pre_annotations, summary = alab.generate_preannotations( # required: list of results. all_results = results, # requied: output column name of &#39;DocumentAssembler&#39; stage - to get original document string. document_column = &#39;document&#39;, # required: column name(s) of ner model(s). Note: multiple NER models can be used, but make sure their results don&#39;t overrlap. # Or use &#39;ChunkMergeApproach&#39; to combine results from multiple NER models. ner_columns = [&#39;ner_chunk&#39;], # optional: column name(s) of assertion model(s). Note: multiple assertion models can be used, but make sure their results don&#39;t overrlap. assertion_columns = [&#39;assertion_res&#39;], # optional: column name(s) of relation extraction model(s). Note: multiple relation extraction models can be used, but make sure their results don&#39;t overrlap. relations_columns = [&#39;relations_clinical&#39;, &#39;relations_pos&#39;], # optional: This can be defined to identify which pipeline/user/model was used to get predictions. # Default: &#39;model&#39; user_name = &#39;model&#39;, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; titles_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0 ) Processing 2 Annotations. The Generated JSON can be uploaded to Annotation Lab to particular project directly via UI or via API. pre_annotations [{&#39;predictions&#39;: [{&#39;created_username&#39;: &#39;model&#39;, &#39;result&#39;: [{&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;YCtU7EDvme&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 27, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;21-day-old&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xqbYIUPhhB&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 32, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 28, &#39;text&#39;: &#39;male&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;7GYr3DFbAs&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 48, &#39;labels&#39;: [&#39;Duration&#39;], &#39;start&#39;: 38, &#39;text&#39;: &#39;for 2 days&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;akBx3N0Gy2&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 62, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 52, &#39;text&#39;: &#39;congestion&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;TJKowx9hR2&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 77, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 69, &#39;text&#39;: &#39;Nov 8/15&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UuWHo6pGz8&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 83, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 80, &#39;text&#39;: &#39;mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;qIgnDgSJw6&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 110, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 104, &#39;text&#39;: &#39;yellow&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;DkE8rIoKVg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 111, &#39;text&#39;: &#39;discharge&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;RBjrHSa1sj&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 145, &#39;labels&#39;: [&#39;External_body_part_or_region&#39;], &#39;start&#39;: 140, &#39;text&#39;: &#39;nares&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;yHEPWvrk9s&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 155, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 152, &#39;text&#39;: &#39;she&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dbeel0WXqw&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 173, &#39;text&#39;: &#39;mild&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;cFJwsYMe2k&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 210, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 178, &#39;text&#39;: &#39;breathing problems while feeding&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;PhiSDTDXlV&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 225, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 217, &#39;text&#39;: &#39;Nov 9/15&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;lsGep4SLRn&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 261, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 244, &#39;text&#39;: &#39;perioral cyanosis&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;WiTJIGOZ9Z&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 276, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 265, &#39;text&#39;: &#39;retractions&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;omIdHl5z74&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 290, &#39;labels&#39;: [&#39;RelativeDate&#39;], &#39;start&#39;: 279, &#39;text&#39;: &#39;One day ago&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CqDclquhmD&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 295, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 292, &#39;text&#39;: &#39;mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;u8Q3GTVzZh&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 359, &#39;labels&#39;: [&#39;Drug_BrandName&#39;], &#39;start&#39;: 352, &#39;text&#39;: &#39;Tylenol&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;i2JLPQOUxv&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 27, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QShr4s6bpg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 32, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 28, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;800DYq0quS&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 48, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 38, &#39;text&#39;: &#39;Duration&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;ns3P70kktN&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 62, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 52, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;tQOdI1ANUO&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 77, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 69, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;oEwYVnyi2A&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 83, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 80, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;PkCkXQEIFN&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 110, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 104, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;m9Bz8CzaXd&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 111, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;GBIhXo8nks&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 145, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 140, &#39;text&#39;: &#39;External_body_part_or_region&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CDVDDIwVrl&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 155, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 152, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;CHPuFoT9iK&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 173, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;eS4vXGth7v&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 210, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 178, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;2nDgfsoGZ7&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 225, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 217, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dhYC0U4sKG&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 261, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 244, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;TKN6DIP2ua&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 276, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 265, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;7X9EwULTA1&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 290, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 279, &#39;text&#39;: &#39;RelativeDate&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UIFKYTDKcm&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 295, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 292, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;U6TqOYf3Ez&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 359, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 352, &#39;text&#39;: &#39;Drug_BrandName&#39;}}]}], &#39;data&#39;: {&#39;title&#39;: &#39;task_0&#39;, &#39;text&#39;: &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot;}, &#39;id&#39;: 0}, {&#39;predictions&#39;: [{&#39;created_username&#39;: &#39;model&#39;, &#39;result&#39;: [{&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;qd28OkdmDO&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 28, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;5-month-old&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;UIZm8wCy3c&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 35, &#39;labels&#39;: [&#39;Age&#39;], &#39;start&#39;: 29, &#39;text&#39;: &#39;infant&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;KpMv4PIy21&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 68, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 63, &#39;text&#39;: &#39;Feb 8&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;Uyj3awC8jp&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 80, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 76, &#39;text&#39;: &#39;cold&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;Dt3xtm1l5A&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 87, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 82, &#39;text&#39;: &#39;cough&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;bp9yUFAUaE&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 103, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 93, &#39;text&#39;: &#39;runny nose&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QhuFKxwFVk&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 113, &#39;labels&#39;: [&#39;Date&#39;], &#39;start&#39;: 110, &#39;text&#39;: &#39;Feb&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;m9ikgaeJMY&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 117, &#39;text&#39;: &#39;Mom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;QXhhDJ6CXn&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 131, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 128, &#39;text&#39;: &#39;she&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;YUCHE7GcHB&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 144, &#39;labels&#39;: [&#39;VS_Finding&#39;], &#39;start&#39;: 139, &#39;text&#39;: &#39;fever&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xbphfajGY1&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 149, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 146, &#39;text&#39;: &#39;She&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;xN5GuZpeUw&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 157, &#39;text&#39;: &#39;difficulty breathing&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;VK9lAjcVNy&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 185, &#39;labels&#39;: [&#39;Gender&#39;], &#39;start&#39;: 182, &#39;text&#39;: &#39;her&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;dqiohcfX4G&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 191, &#39;labels&#39;: [&#39;Symptom&#39;], &#39;start&#39;: 186, &#39;text&#39;: &#39;cough&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;18bjvjxuDL&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 212, &#39;labels&#39;: [&#39;Modifier&#39;], &#39;start&#39;: 209, &#39;text&#39;: &#39;dry&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;BB90sIXIYZ&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 274, &#39;labels&#39;: [&#39;Disease_Syndrome_Disorder&#39;], &#39;start&#39;: 271, &#39;text&#39;: &#39;flu&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;sAL9AHWvOa&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 28, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 17, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;vyio7vnpmS&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 35, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 29, &#39;text&#39;: &#39;Age&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;r6T6e8WmO9&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 68, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 63, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;3SdFeft6ya&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 80, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 76, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;0iyfhRx1nl&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 87, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 82, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;pqJFZRu8Zu&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 103, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 93, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;zRa9noedl5&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 113, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 110, &#39;text&#39;: &#39;Date&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;RJ8MHb5Css&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 120, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 117, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;sbtQpMnkxH&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 131, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 128, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;K0yEKeG7GR&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 144, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 139, &#39;text&#39;: &#39;VS_Finding&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;V4fTVAh4Ro&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 149, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 146, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;1K1NUt9mcU&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 177, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 157, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;kXl3bnMSqM&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 185, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 182, &#39;text&#39;: &#39;Gender&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;spqjsrISZg&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 191, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 186, &#39;text&#39;: &#39;Symptom&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;EcrKDs2yyH&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 212, &#39;labels&#39;: [&#39;present&#39;], &#39;start&#39;: 209, &#39;text&#39;: &#39;Modifier&#39;}}, {&#39;from_name&#39;: &#39;label&#39;, &#39;id&#39;: &#39;FHYcyz14aj&#39;, &#39;source&#39;: &#39;$text&#39;, &#39;to_name&#39;: &#39;text&#39;, &#39;type&#39;: &#39;labels&#39;, &#39;value&#39;: {&#39;end&#39;: 274, &#39;labels&#39;: [&#39;absent&#39;], &#39;start&#39;: 271, &#39;text&#39;: &#39;Disease_Syndrome_Disorder&#39;}}]}], &#39;data&#39;: {&#39;title&#39;: &#39;task_1&#39;, &#39;text&#39;: &#39;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&#39;}, &#39;id&#39;: 1}] An annotation summary is also generated that can be used to setup and configure a new project. { &#39;ner_labels&#39;: [ &#39;Age&#39;, &#39;VS_Finding&#39;, &#39;Gender&#39;, &#39;Modifier&#39;, &#39;Duration&#39;, &#39;RelativeDate&#39;, &#39;Symptom&#39;, &#39;Date&#39;, &#39;External_body_part_or_region&#39;, &#39;Disease_Syndrome_Disorder&#39;, &#39;Drug_BrandName&#39; ], &#39;assertion_labels&#39;: [&#39;present&#39;, &#39;absent&#39;], &#39;re_labels&#39;: [] } Interacting with Annotation Lab Credentials are required for the following actions. Set Credentials alab = AnnotationLab() username=&#39;&#39; password=&#39;&#39; client_secret=&quot;&quot; annotationlab_url=&quot;&quot; alab.set_credentials( # required: username username=username, # required: password password=password, # required: secret for you Annotation Lab instance (every Annotation Lab installation has a different secret) client_secret=client_secret, # required: http(s) url for you annotation lab annotationlab_url=annotationlab_url ) Get All visible projects alab.get_all_projects() Operation completed successfully. Response code: 200 {&#39;has_next&#39;: False, &#39;has_prev&#39;: False, &#39;items&#39;: [{&#39;creation_date&#39;: &#39;Thu, 29 Sep 2022 18:01:07 GMT&#39;, &#39;group_color&#39;: None, &#39;group_id&#39;: None, &#39;group_name&#39;: None, &#39;owner&#39;: &#39;hasham&#39;, &#39;owner_id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1129, &#39;project_members&#39;: [&#39;hasham&#39;], &#39;project_name&#39;: &#39;alab_demo&#39;, &#39;resource_id&#39;: &#39;1dabaac8-54a0-4c52-a876-8c01f42b44e7&#39;, &#39;total_tasks&#39;: 2}, {&#39;creation_date&#39;: &#39;Tue, 27 Sep 2022 03:12:18 GMT&#39;, &#39;group_color&#39;: None, &#39;group_id&#39;: None, &#39;group_name&#39;: None, &#39;owner&#39;: &#39;hasham&#39;, &#39;owner_id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1117, &#39;project_members&#39;: [&#39;hasham&#39;], &#39;project_name&#39;: &#39;testing101&#39;, &#39;resource_id&#39;: &#39;b1388775-9a3b-436e-b1cc-ea36bab44699&#39;, &#39;total_tasks&#39;: 9}, {&#39;creation_date&#39;: &#39;Fri, 06 Nov 2020 12:08:02 GMT&#39;, &#39;group_color&#39;: &#39;#dbdf2e&#39;, &#39;group_id&#39;: 10, &#39;group_name&#39;: &#39;MT_Samples&#39;, &#39;owner&#39;: &#39;mauro&#39;, &#39;owner_id&#39;: &#39;7b6048c8-f923-46e4-9011-2c749e3c2c93&#39;, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 126, &#39;project_members&#39;: [], &#39;project_name&#39;: &#39;PathologyReports&#39;, &#39;resource_id&#39;: &#39;7ed36c55-db19-48e0-bc56-4b2114f9a251&#39;, &#39;total_tasks&#39;: 97}], &#39;iter_pages&#39;: [1], &#39;next_num&#39;: None, &#39;prev_num&#39;: None, &#39;total_count&#39;: 3} Create a new project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39; ) Operation completed successfully. Response code: 201 {&#39;project_name&#39;: &#39;alab_demo&#39;} Delete a project alab.delete_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False ) Deleting Project. Press &quot;Y&quot; to confirm.y Operation completed successfully. Response code: 200 {&#39;message&#39;: &#39;Project successfully Deleted!&#39;} Set / Edit configuration of a project ## First, recreate a project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39; ) Operation completed successfully. Response code: 201 {&#39;project_name&#39;: &#39;alab_demo&#39;} Set Configuration - First Time ## set configuration - first time alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;], # optional: labels of classes for classification tasks ner_labels=[&#39;Age&#39;, &#39;Symptom&#39;, &#39;Procedure&#39;, &#39;BodyPart&#39;], # optional: labels of classes for classification tasks assertion_labels=[&#39;absent&#39;, &#39;family_history&#39;, &#39;someone_else&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Edit Configuration - add classes and labels ## Note: At least one type of labels should be provided. ## Note: to define relation labels, NER labels should be provided. alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;, &#39;Unknown&#39;], # optional: labels of classes for classification tasks ner_labels=[&#39;Age&#39;, &#39;Symptom&#39;, &#39;Procedure&#39;, &#39;BodyPart&#39;, &#39;Test&#39;, &#39;Drug&#39;], # optional: labels of classes for classification tasks assertion_labels=[&#39;absent&#39;, &#39;family_history&#39;, &#39;someone_else&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;, &#39;is_reactioni_of&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Set Configuration using summary generated at the pre-annotation step alab.set_project_config( # required: name of project project_name = &#39;alab_demo&#39;, # optional: labels of classes for classification tasks classification_labels=[&#39;Male&#39;, &#39;Female&#39;, &#39;Unknown&#39;], # optional: labels of classes for classification tasks ner_labels=summary[&#39;ner_labels&#39;], # optional: labels of classes for classification tasks assertion_labels=summary[&#39;assertion_labels&#39;], # optional: labels of classes for classification tasks relations_labels=[&#39;is_related&#39;, &#39;is_reactioni_of&#39;] ) Operation completed successfully. Response code: 201 {&#39;messages&#39;: [{&#39;message&#39;: &#39;Project config saved.&#39;, &#39;success&#39;: True}]} Get configuration of any project alab.get_project_config( # required: name of project project_name = &#39;alab_demo&#39; ) Operation completed successfully. Response code: 200 {&#39;analytics_permission&#39;: {}, &#39;annotators&#39;: [&#39;hasham&#39;], &#39;config&#39;: {&#39;allow_delete_completions&#39;: True, &#39;debug&#39;: False, &#39;editor&#39;: {&#39;debug&#39;: False}, &#39;enable_predictions_button&#39;: True, &#39;input_path&#39;: None, &#39;instruction&#39;: &#39;&#39;, &#39;ml_backends&#39;: [], &#39;output_dir&#39;: &#39;completions&#39;, &#39;port&#39;: 8200, &#39;sampling&#39;: &#39;uniform&#39;, &#39;templates_dir&#39;: &#39;examples&#39;, &#39;title&#39;: &#39;alab_demo&#39;}, &#39;created_version&#39;: &#39;4.0.1&#39;, &#39;creation_date&#39;: &#39;Thu, 29 Sep 2022 18:46:02 GMT&#39;, &#39;evaluation_info&#39;: None, &#39;group_id&#39;: None, &#39;isVisualNER&#39;: None, &#39;label_config&#39;: &#39;&#39;, &#39;labels&#39;: [&#39;Age&#39;, &#39;VS_Finding&#39;, &#39;Gender&#39;, &#39;Modifier&#39;, &#39;Duration&#39;, &#39;RelativeDate&#39;, &#39;Symptom&#39;, &#39;Date&#39;, &#39;External_body_part_or_region&#39;, &#39;Disease_Syndrome_Disorder&#39;, &#39;Drug_BrandName&#39;, &#39;present&#39;, &#39;absent&#39;], &#39;model_types&#39;: [{&#39;choices&#39;: [&#39;sentiment&#39;], &#39;name&#39;: &#39;classification&#39;}, {&#39;name&#39;: &#39;ner&#39;}, {&#39;name&#39;: &#39;assertion&#39;}], &#39;ocr_info&#39;: None, &#39;owner&#39;: {&#39;id&#39;: &#39;ba60df4b-7192-47ca-aa92-759fa577a617&#39;, &#39;username&#39;: &#39;hasham&#39;}, &#39;project_description&#39;: &#39;&#39;, &#39;project_id&#39;: 1130, &#39;project_name&#39;: &#39;alab_demo&#39;, &#39;resource_id&#39;: &#39;e8e17001-a25b-4a92-b419-88948d917647&#39;, &#39;tasks_count&#39;: 0, &#39;team_members_order&#39;: [&#39;hasham&#39;]} Upload tasks to a project # Define a list of tasks/string to upload txt1 = &quot;The patient is a 21-day-old male here for 2 days of congestion since Nov 8/15 - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild breathing problems while feeding since Nov 9/15 (without signs of perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol.&quot; txt2 = &quot;The patient is a 5-month-old infant who presented initially on Feb 8 with a cold, cough, and runny nose since Feb 2. Mom states she had no fever. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed no signs of flu.&quot; task_list = [txt1, txt2] alab.upload_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of examples / tasks as string (One string is one task). task_list=task_list, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; title_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0 ) Uploading 2 task(s). Operation completed successfully. Response code: 201 {&#39;completion_count&#39;: 0, &#39;duration&#39;: 0.11868953704833984, &#39;failed_count&#39;: 0, &#39;ignored_count&#39;: 0, &#39;prediction_count&#39;: 0, &#39;task_count&#39;: 2, &#39;task_ids&#39;: [1, 2], &#39;task_title_warning&#39;: 0, &#39;updated_count&#39;: 0} Delete tasks of a project alab.delete_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of ids of tasks. # note: you can get task ids from the above step. Look for &#39;task_ids&#39; key. task_ids=[1, 2], # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False ) Deleting 2 task(s). Press &quot;Y&quot; to confirm.y Operation completed successfully. Response code: 200 {&#39;message&#39;: &#39;Task(s) successfully deleted!&#39;} Upload pre-annotations to Annotation Lab You can get the data for pre_annotations from this section. alab.upload_preannotations( # required: name of project to upload annotations to project_name = &#39;alab_demo&#39;, # required: preannotation JSON preannotations = pre_annotations ) Uploading 2 preannotation(s). Operation completed successfully. Response code: 201 {&#39;completion_count&#39;: 0, &#39;duration&#39;: 0.14992427825927734, &#39;failed_count&#39;: 0, &#39;ignored_count&#39;: 0, &#39;prediction_count&#39;: 2, &#39;task_count&#39;: 2, &#39;task_ids&#39;: [1, 2], &#39;task_title_warning&#39;: 0, &#39;updated_count&#39;: 0}",
    "url": "/docs/en/alab/healthcare",
    "relUrl": "/docs/en/alab/healthcare"
  },
  "963": {
    "id": "963",
    "title": "Risk Adjustments Score Calculation",
    "content": "Our Risk Adjustment Score implementation uses the Hierarchical Condition Category (HCC) Risk Adjustment model from the Centers for Medicare &amp; Medicaid Service (CMS). HCC groups similar conditions in terms of healthcare costs and similarities in the diagnosis, and the model uses any ICD code that has a corresponging HCC category in the computation, discarding other ICD codes. This module supports versions 22, 23, and 24 of the CMS-HCC risk adjustment model and needs the following parameters in order to calculate the risk score: ICD Codes (Obtained by, e.g., our pretrained model sbiobertresolve_icd10cm_augmented_billable_hcc from theSentenceEntityResolverModel annotator) Age (Obtained by, e.g., our pretrained model ner_jsl from theNerModel annotator) Gender (Obtained by, e.g., our pretrained model classifierdl_gender_biobert from theClassifierDLModel annotator) The eligibility segment of the patient (information from the health plan provider) The original reason for entitlement (information from the health plan provider) If the patient is in Medicaid or not (information from the health plan provider) Available softwares and profiles As mentioned, we implemented versions 22, 23, and 24 of the CMS-HCC software, and have the following profiles: Version 22 Year 2017 Year 2018 Year 2019 Year 2020 Year 2021 Year 2022 Version 23 Year 2018 Year 2019 Version 24 Year 2017 Year 2018 Year 2019 Year 2020 Year 2021 Year 2022 Usage The module can perform the computations given a data frame containing the required information (Age, Gender, ICD codes, eligibility segment, the original reason for entitlement, and if the patient is in Medicaid or not). For example, given the dataset df: +--++--+-++--+-+--+-+ | filename|Age| icd10_code|Extracted_Entities_vs_ICD_Codes|Gender|eligibility|orec|medicaid| DOB| +--++--+-++--+-+--+-+ |mt_note_03.txt| 66|[C499, C499, D618...| [{leiomyosarcoma,...| F| CND| 1| false|1956-05-30| |mt_note_01.txt| 59| [C801]| [{cancer, C801}]| F| CFA| 0| true|1961-10-12| |mt_note_10.txt| 16| [C6960, C6960]| [{Rhabdomyosarcom...| M| CFA| 2| false|2006-02-14| |mt_note_08.txt| 66| [C459, C800]| [{malignant mesot...| F| CND| 1| true|1956-03-17| |mt_note_09.txt| 19| [D5702, K5505]| [{Sickle cell cri...| M| CPA| 3| true|2003-06-11| |mt_note_05.txt| 57|[C5092, C5091, C5...| [{Breast Cancer, ...| F| CPA| 3| true|1963-08-12| |mt_note_06.txt| 63| [F319, F319]| [{type 1 bipolar ...| F| CFA| 0| false|1959-07-24| +--++--+-++--+-+--+-+ Where column orec means original reason for entitlement and DOB means date of birth (can also be used to compute age). You can use any of the available profiles to compute the scores (in the example, we use version 24, year 2020): from johnsnowlabs import medical # Creates the risk profile df = df.withColumn( &quot;hcc_profile&quot;, medical.profileV24Y20( df.icd10_code, df.Age, df.Gender, df.eligibility, df.orec, df.medicaid ), ) # Extract relevant information df = ( df.withColumn(&quot;risk_score&quot;, df.hcc_profile.getItem(&quot;risk_score&quot;)) .withColumn(&quot;hcc_lst&quot;, df.hcc_profile.getItem(&quot;hcc_lst&quot;)) .withColumn(&quot;parameters&quot;, df.hcc_profile.getItem(&quot;parameters&quot;)) .withColumn(&quot;details&quot;, df.hcc_profile.getItem(&quot;details&quot;)) ) df.select( &quot;filename&quot;, &quot;risk_score&quot;, &quot;icd10_code&quot;, &quot;Age&quot;, &quot;Gender&quot;, &quot;eligibility&quot;, &quot;orec&quot;, &quot;medicaid&quot;, ).show(truncate=False) +--+-++++--+-+--+ filename |risk_score|icd10_code |Age|Gender|eligibility|orec|medicaid| +--+-++++--+-+--+ mt_note_01.txt|0.158 |[C801] |59 |F |CFA |0 |true | mt_note_03.txt|1.03 |[C499, C499, D6181, M069, C801] |66 |F |CND |1 |false | mt_note_05.txt|2.991 |[C5092, C5091, C779, C5092, C800, G20, C5092]|57 |F |CPA |3 |true | mt_note_06.txt|0.299 |[F319] |63 |F |CFA |0 |true | mt_note_08.txt|2.714 |[C459, C800] |66 |F |CND |1 |false | mt_note_09.txt|1.234 |[D5702, K5505] |19 |F |CPA |3 |true | +--+-++++--+-+--+ For more details and usage examples, check the notebook Medicare Risk Adjustment notebook from our Spark NLP Workshop repository.",
    "url": "/docs/en/healthcare_risk_adjustments_score_calculation",
    "relUrl": "/docs/en/healthcare_risk_adjustments_score_calculation"
  },
  "964": {
    "id": "964",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/helpers.html",
    "relUrl": "/api/python/user_guide/helpers.html"
  },
  "965": {
    "id": "965",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/audio/hubert_for_ctc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/audio/hubert_for_ctc.html"
  },
  "966": {
    "id": "966",
    "title": "Identify & Translate Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/identify_translate_languages",
    "relUrl": "/identify_translate_languages"
  },
  "967": {
    "id": "967",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/image_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/image_assembler.html"
  },
  "968": {
    "id": "968",
    "title": "Import Documents",
    "content": "Once a new project is created and its configuration is saved, the user is redirected to the Import page. Here the user has multiple options for importing tasks. Users can import the accepted file formats in multiple ways. They can drag and drop the file(s) to the upload box, select the file from the file explorer, provide the URL of the file in JSON format, or import it directly from the S3 bucket. To import from Amazon S3 bucket the user needs to provide the necessary connection details (credentials, access keys, and S3 bucket path). All documents present in the specified path, are then imported as tasks in the current project. Plain text file When you upload a plain text file, only one task will be created which will contain the entire data in the input file. This is an update from earlier versions of Annotation Lab when the input text file was split by the new line character and one task was created for each line. Json file For bulk importing a list of documents you can use the json import option. The expected format is illustrated in the image below. It consists of a list of dictionaries, each with 2 keys-values pairs (“text” and “title”). [{&quot;text&quot;: &quot;Task text content.&quot;, &quot;title&quot;:&quot;Task title&quot;}] CSV, TSV file When CSV / TSV formatted text file is used, column names are interpreted as task data keys: Task text content, Task title this is a first task, Colon Cancer.txt this is a second task, Breast radiation therapy.txt Import annotated tasks When importing tasks that already contain annotations (e.g. exported from another project, with predictions generated by pre-trained models) the user has the option to overwrite completions/predictions or to skip the tasks that are already imported into the project. NOTE: When importing tasks from different projects with the purpose of combining them in one project, users should take care of the overlaps existing between tasks IDs. Annotation Lab will simply overwrite tasks with the same ID. Dynamic Task Pagination The support for pagination offered by earlier versions of the Annotation Lab involved the use of the &lt;pagebreak&gt; tag. A document pre-processing step was necessary for adding/changing the page breaks and those involved extra effort from the part of the users. Annotation Lab 2.8.0 introduces a paradigm change for pagination. Going forward, pagination is dynamic and can be configured according to the user’s needs and preferences from the Labeling page. Annotators or reviewers can now choose the number of words to include on a single page from a predefined list of values or can add the desired counts. A new settings option has been added to prevent splitting a sentence into two different pages.",
    "url": "/docs/en/alab/import",
    "relUrl": "/docs/en/alab/import"
  },
  "969": {
    "id": "969",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/",
    "relUrl": "/api/python/user_guide/"
  },
  "970": {
    "id": "970",
    "title": "",
    "content": "",
    "url": "/api/python/getting_started/",
    "relUrl": "/api/python/getting_started/"
  },
  "971": {
    "id": "971",
    "title": "",
    "content": "",
    "url": "/api/python/third_party/",
    "relUrl": "/api/python/third_party/"
  },
  "972": {
    "id": "972",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/"
  },
  "973": {
    "id": "973",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/"
  },
  "974": {
    "id": "974",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/cv/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/cv/"
  },
  "975": {
    "id": "975",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/"
  },
  "976": {
    "id": "976",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/pos/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/pos/"
  },
  "977": {
    "id": "977",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/"
  },
  "978": {
    "id": "978",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/graph_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/graph_extraction/"
  },
  "979": {
    "id": "979",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/"
  },
  "980": {
    "id": "980",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/"
  },
  "981": {
    "id": "981",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentiment/"
  },
  "982": {
    "id": "982",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/"
  },
  "983": {
    "id": "983",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/classifier_encoder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/classifier_encoder/"
  },
  "984": {
    "id": "984",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/param/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/param/"
  },
  "985": {
    "id": "985",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/"
  },
  "986": {
    "id": "986",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/"
  },
  "987": {
    "id": "987",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/"
  },
  "988": {
    "id": "988",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/"
  },
  "989": {
    "id": "989",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/date_matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/date_matcher/"
  },
  "990": {
    "id": "990",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/matcher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/matcher/"
  },
  "991": {
    "id": "991",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/chunker/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/chunker/"
  },
  "992": {
    "id": "992",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/normalizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/normalizer/"
  },
  "993": {
    "id": "993",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/"
  },
  "994": {
    "id": "994",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/er/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/er/"
  },
  "995": {
    "id": "995",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/date2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/date2_chunk/"
  },
  "996": {
    "id": "996",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/"
  },
  "997": {
    "id": "997",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/"
  },
  "998": {
    "id": "998",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ld_dl/"
  },
  "999": {
    "id": "999",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/"
  },
  "1000": {
    "id": "1000",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/"
  },
  "1001": {
    "id": "1001",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/"
  },
  "1002": {
    "id": "1002",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/"
  },
  "1003": {
    "id": "1003",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/"
  },
  "1004": {
    "id": "1004",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/"
  },
  "1005": {
    "id": "1005",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/"
  },
  "1006": {
    "id": "1006",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/"
  },
  "1007": {
    "id": "1007",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/"
  },
  "1008": {
    "id": "1008",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/"
  },
  "1009": {
    "id": "1009",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/"
  },
  "1010": {
    "id": "1010",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/"
  },
  "1011": {
    "id": "1011",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/"
  },
  "1012": {
    "id": "1012",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/"
  },
  "1013": {
    "id": "1013",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/"
  },
  "1014": {
    "id": "1014",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/"
  },
  "1015": {
    "id": "1015",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/"
  },
  "1016": {
    "id": "1016",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/"
  },
  "1017": {
    "id": "1017",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/"
  },
  "1018": {
    "id": "1018",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/"
  },
  "1019": {
    "id": "1019",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/"
  },
  "1020": {
    "id": "1020",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/"
  },
  "1021": {
    "id": "1021",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/"
  },
  "1022": {
    "id": "1022",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/"
  },
  "1023": {
    "id": "1023",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/"
  },
  "1024": {
    "id": "1024",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/"
  },
  "1025": {
    "id": "1025",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/"
  },
  "1026": {
    "id": "1026",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/"
  },
  "1027": {
    "id": "1027",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/"
  },
  "1028": {
    "id": "1028",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/"
  },
  "1029": {
    "id": "1029",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/"
  },
  "1030": {
    "id": "1030",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/document_normalizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/document_normalizer/"
  },
  "1031": {
    "id": "1031",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/"
  },
  "1032": {
    "id": "1032",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/"
  },
  "1033": {
    "id": "1033",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/"
  },
  "1034": {
    "id": "1034",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/seq2seq/"
  },
  "1035": {
    "id": "1035",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/"
  },
  "1036": {
    "id": "1036",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/"
  },
  "1037": {
    "id": "1037",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/audio/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/audio/"
  },
  "1038": {
    "id": "1038",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/"
  },
  "1039": {
    "id": "1039",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/"
  },
  "1040": {
    "id": "1040",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/dependency/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/dependency/"
  },
  "1041": {
    "id": "1041",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/"
  },
  "1042": {
    "id": "1042",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/"
  },
  "1043": {
    "id": "1043",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/"
  },
  "1044": {
    "id": "1044",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_approach/"
  },
  "1045": {
    "id": "1045",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/"
  },
  "1046": {
    "id": "1046",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/"
  },
  "1047": {
    "id": "1047",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/"
  },
  "1048": {
    "id": "1048",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ner/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ner/"
  },
  "1049": {
    "id": "1049",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/"
  },
  "1050": {
    "id": "1050",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/"
  },
  "1051": {
    "id": "1051",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/"
  },
  "1052": {
    "id": "1052",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/spell_check/"
  },
  "1053": {
    "id": "1053",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/stemmer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/stemmer/"
  },
  "1054": {
    "id": "1054",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/chunk2_doc/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/chunk2_doc/"
  },
  "1055": {
    "id": "1055",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/"
  },
  "1056": {
    "id": "1056",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/"
  },
  "1057": {
    "id": "1057",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/sentence/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/sentence/"
  },
  "1058": {
    "id": "1058",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/"
  },
  "1059": {
    "id": "1059",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/"
  },
  "1060": {
    "id": "1060",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/"
  },
  "1061": {
    "id": "1061",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/"
  },
  "1062": {
    "id": "1062",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/"
  },
  "1063": {
    "id": "1063",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/"
  },
  "1064": {
    "id": "1064",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/"
  },
  "1065": {
    "id": "1065",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/"
  },
  "1066": {
    "id": "1066",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/"
  },
  "1067": {
    "id": "1067",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/"
  },
  "1068": {
    "id": "1068",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/"
  },
  "1069": {
    "id": "1069",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/"
  },
  "1070": {
    "id": "1070",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/"
  },
  "1071": {
    "id": "1071",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/"
  },
  "1072": {
    "id": "1072",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/"
  },
  "1073": {
    "id": "1073",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/"
  },
  "1074": {
    "id": "1074",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/"
  },
  "1075": {
    "id": "1075",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/"
  },
  "1076": {
    "id": "1076",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/"
  },
  "1077": {
    "id": "1077",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/embeddings/"
  },
  "1078": {
    "id": "1078",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/"
  },
  "1079": {
    "id": "1079",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/"
  },
  "1080": {
    "id": "1080",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/"
  },
  "1081": {
    "id": "1081",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/coref/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/coref/"
  },
  "1082": {
    "id": "1082",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/"
  },
  "1083": {
    "id": "1083",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/ws/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/ws/"
  },
  "1084": {
    "id": "1084",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/"
  },
  "1085": {
    "id": "1085",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/"
  },
  "1086": {
    "id": "1086",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/"
  },
  "1087": {
    "id": "1087",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/"
  },
  "1088": {
    "id": "1088",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/token/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/token/"
  },
  "1089": {
    "id": "1089",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/"
  },
  "1090": {
    "id": "1090",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotator/"
  },
  "1091": {
    "id": "1091",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/logging/comet/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/logging/comet/"
  },
  "1092": {
    "id": "1092",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/logging/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/logging/"
  },
  "1093": {
    "id": "1093",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/pretrained_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/pretrained_pipeline/"
  },
  "1094": {
    "id": "1094",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/utils/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/utils/"
  },
  "1095": {
    "id": "1095",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/resource_downloader/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/resource_downloader/"
  },
  "1096": {
    "id": "1096",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/pretrained/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/pretrained/"
  },
  "1097": {
    "id": "1097",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation/"
  },
  "1098": {
    "id": "1098",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/upload_to_hub/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/upload_to_hub/"
  },
  "1099": {
    "id": "1099",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_properties/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_properties/"
  },
  "1100": {
    "id": "1100",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_approach/"
  },
  "1101": {
    "id": "1101",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/recursive_annotator_approach/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/recursive_annotator_approach/"
  },
  "1102": {
    "id": "1102",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/read_as/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/read_as/"
  },
  "1103": {
    "id": "1103",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/coverage_result/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/coverage_result/"
  },
  "1104": {
    "id": "1104",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/utils/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/utils/"
  },
  "1105": {
    "id": "1105",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_type/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_type/"
  },
  "1106": {
    "id": "1106",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/storage/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/storage/"
  },
  "1107": {
    "id": "1107",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/annotator_model/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/annotator_model/"
  },
  "1108": {
    "id": "1108",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/properties/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/properties/"
  },
  "1109": {
    "id": "1109",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/common/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/common/"
  },
  "1110": {
    "id": "1110",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/spacy_to_annotation/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/spacy_to_annotation/"
  },
  "1111": {
    "id": "1111",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/pos/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/pos/"
  },
  "1112": {
    "id": "1112",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/conll/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/conll/"
  },
  "1113": {
    "id": "1113",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/pub_tator/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/pub_tator/"
  },
  "1114": {
    "id": "1114",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/conllu/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/conllu/"
  },
  "1115": {
    "id": "1115",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/tfgraphs/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/tfgraphs/"
  },
  "1116": {
    "id": "1116",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/training/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/training/"
  },
  "1117": {
    "id": "1117",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/has_recursive_transform/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/has_recursive_transform/"
  },
  "1118": {
    "id": "1118",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/"
  },
  "1119": {
    "id": "1119",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/recursive_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/recursive_pipeline/"
  },
  "1120": {
    "id": "1120",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/token2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/token2_chunk/"
  },
  "1121": {
    "id": "1121",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/token_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/token_assembler/"
  },
  "1122": {
    "id": "1122",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/table_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/table_assembler/"
  },
  "1123": {
    "id": "1123",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/doc2_chunk/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/doc2_chunk/"
  },
  "1124": {
    "id": "1124",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/light_pipeline/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/light_pipeline/"
  },
  "1125": {
    "id": "1125",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/graph_finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/graph_finisher/"
  },
  "1126": {
    "id": "1126",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/embeddings_finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/embeddings_finisher/"
  },
  "1127": {
    "id": "1127",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/image_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/image_assembler/"
  },
  "1128": {
    "id": "1128",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/document_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/document_assembler/"
  },
  "1129": {
    "id": "1129",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/finisher/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/finisher/"
  },
  "1130": {
    "id": "1130",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/audio_assembler/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/audio_assembler/"
  },
  "1131": {
    "id": "1131",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/has_recursive_fit/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/has_recursive_fit/"
  },
  "1132": {
    "id": "1132",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/base/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/base/"
  },
  "1133": {
    "id": "1133",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation_audio/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation_audio/"
  },
  "1134": {
    "id": "1134",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/util/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/util/"
  },
  "1135": {
    "id": "1135",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/annotation_image/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/annotation_image/"
  },
  "1136": {
    "id": "1136",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/functions/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/functions/"
  },
  "1137": {
    "id": "1137",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/annotator_java_ml/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/annotator_java_ml/"
  },
  "1138": {
    "id": "1138",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/extended_java_wrapper/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/extended_java_wrapper/"
  },
  "1139": {
    "id": "1139",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/params_getters_setters/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/params_getters_setters/"
  },
  "1140": {
    "id": "1140",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/recursive/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/recursive/"
  },
  "1141": {
    "id": "1141",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/annotator_transformer/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/annotator_transformer/"
  },
  "1142": {
    "id": "1142",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/internal/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/internal/"
  },
  "1143": {
    "id": "1143",
    "title": "",
    "content": "",
    "url": "/api/python/reference/autosummary/sparknlp/",
    "relUrl": "/api/python/reference/autosummary/sparknlp/"
  },
  "1144": {
    "id": "1144",
    "title": "",
    "content": "",
    "url": "/api/python/reference/",
    "relUrl": "/api/python/reference/"
  },
  "1145": {
    "id": "1145",
    "title": "",
    "content": "",
    "url": "/api/python/modules/",
    "relUrl": "/api/python/modules/"
  },
  "1146": {
    "id": "1146",
    "title": "",
    "content": "",
    "url": "/api/python/",
    "relUrl": "/api/python/"
  },
  "1147": {
    "id": "1147",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/aws/",
    "relUrl": "/api/com/johnsnowlabs/client/aws/"
  },
  "1148": {
    "id": "1148",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/gcp/",
    "relUrl": "/api/com/johnsnowlabs/client/gcp/"
  },
  "1149": {
    "id": "1149",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/client/",
    "relUrl": "/api/com/johnsnowlabs/client/"
  },
  "1150": {
    "id": "1150",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sentencepiece/"
  },
  "1151": {
    "id": "1151",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/sign/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/sign/"
  },
  "1152": {
    "id": "1152",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/tensorflow/",
    "relUrl": "/api/com/johnsnowlabs/ml/tensorflow/"
  },
  "1153": {
    "id": "1153",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/ai/",
    "relUrl": "/api/com/johnsnowlabs/ml/ai/"
  },
  "1154": {
    "id": "1154",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/crf/",
    "relUrl": "/api/com/johnsnowlabs/ml/crf/"
  },
  "1155": {
    "id": "1155",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/util/",
    "relUrl": "/api/com/johnsnowlabs/ml/util/"
  },
  "1156": {
    "id": "1156",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/ml/",
    "relUrl": "/api/com/johnsnowlabs/ml/"
  },
  "1157": {
    "id": "1157",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/collections/",
    "relUrl": "/api/com/johnsnowlabs/collections/"
  },
  "1158": {
    "id": "1158",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/spark/",
    "relUrl": "/api/com/johnsnowlabs/util/spark/"
  },
  "1159": {
    "id": "1159",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/util/",
    "relUrl": "/api/com/johnsnowlabs/util/"
  },
  "1160": {
    "id": "1160",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/pretrained/",
    "relUrl": "/api/com/johnsnowlabs/nlp/pretrained/"
  },
  "1161": {
    "id": "1161",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/"
  },
  "1162": {
    "id": "1162",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/btm/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/btm/"
  },
  "1163": {
    "id": "1163",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/cv/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/cv/"
  },
  "1164": {
    "id": "1164",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/util/"
  },
  "1165": {
    "id": "1165",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/yake/"
  },
  "1166": {
    "id": "1166",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/keyword/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/keyword/"
  },
  "1167": {
    "id": "1167",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/"
  },
  "1168": {
    "id": "1168",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sbd/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sbd/"
  },
  "1169": {
    "id": "1169",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/"
  },
  "1170": {
    "id": "1170",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/pos/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/pos/"
  },
  "1171": {
    "id": "1171",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/"
  },
  "1172": {
    "id": "1172",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/"
  },
  "1173": {
    "id": "1173",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/io/"
  },
  "1174": {
    "id": "1174",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/feature/"
  },
  "1175": {
    "id": "1175",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/util/"
  },
  "1176": {
    "id": "1176",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/typdep/"
  },
  "1177": {
    "id": "1177",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/"
  },
  "1178": {
    "id": "1178",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/param/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/param/"
  },
  "1179": {
    "id": "1179",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/"
  },
  "1180": {
    "id": "1180",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/common/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/common/"
  },
  "1181": {
    "id": "1181",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/er/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/er/"
  },
  "1182": {
    "id": "1182",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/parser/"
  },
  "1183": {
    "id": "1183",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/context/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/context/"
  },
  "1184": {
    "id": "1184",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/norvig/"
  },
  "1185": {
    "id": "1185",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/"
  },
  "1186": {
    "id": "1186",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/util/"
  },
  "1187": {
    "id": "1187",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/spell/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/spell/"
  },
  "1188": {
    "id": "1188",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/"
  },
  "1189": {
    "id": "1189",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/"
  },
  "1190": {
    "id": "1190",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/sda/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/sda/"
  },
  "1191": {
    "id": "1191",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/seq2seq/"
  },
  "1192": {
    "id": "1192",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/audio/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/audio/"
  },
  "1193": {
    "id": "1193",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tapas/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tapas/"
  },
  "1194": {
    "id": "1194",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/dl/"
  },
  "1195": {
    "id": "1195",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/classifier/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/classifier/"
  },
  "1196": {
    "id": "1196",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/dl/"
  },
  "1197": {
    "id": "1197",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/crf/"
  },
  "1198": {
    "id": "1198",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ner/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ner/"
  },
  "1199": {
    "id": "1199",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/dl/"
  },
  "1200": {
    "id": "1200",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ld/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ld/"
  },
  "1201": {
    "id": "1201",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/bpe/"
  },
  "1202": {
    "id": "1202",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/tokenizer/"
  },
  "1203": {
    "id": "1203",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/coref/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/coref/"
  },
  "1204": {
    "id": "1204",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/ws/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/ws/"
  },
  "1205": {
    "id": "1205",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/"
  },
  "1206": {
    "id": "1206",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/training/",
    "relUrl": "/api/com/johnsnowlabs/nlp/training/"
  },
  "1207": {
    "id": "1207",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/serialization/",
    "relUrl": "/api/com/johnsnowlabs/nlp/serialization/"
  },
  "1208": {
    "id": "1208",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/io/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/io/"
  },
  "1209": {
    "id": "1209",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/regex/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/regex/"
  },
  "1210": {
    "id": "1210",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/util/",
    "relUrl": "/api/com/johnsnowlabs/nlp/util/"
  },
  "1211": {
    "id": "1211",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/embeddings/",
    "relUrl": "/api/com/johnsnowlabs/nlp/embeddings/"
  },
  "1212": {
    "id": "1212",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/",
    "relUrl": "/api/com/johnsnowlabs/nlp/"
  },
  "1213": {
    "id": "1213",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/storage/",
    "relUrl": "/api/com/johnsnowlabs/storage/"
  },
  "1214": {
    "id": "1214",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/",
    "relUrl": "/api/com/johnsnowlabs/"
  },
  "1215": {
    "id": "1215",
    "title": "",
    "content": "",
    "url": "/api/com/",
    "relUrl": "/api/com/"
  },
  "1216": {
    "id": "1216",
    "title": "",
    "content": "",
    "url": "/api/",
    "relUrl": "/api/"
  },
  "1217": {
    "id": "1217",
    "title": "John Snow Labs <span>State of the Art Natural Language Processing in Python</span>",
    "content": "",
    "url": "/",
    "relUrl": "/"
  },
  "1218": {
    "id": "1218",
    "title": "Infer Meaning & Intent - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/infer_meaning_intent",
    "relUrl": "/infer_meaning_intent"
  },
  "1219": {
    "id": "1219",
    "title": "Infrastructure Configuration",
    "content": "The admin user can now define the infrastructure configurations for the prediction and training tasks. Resource allocation for Training and Preannotation Annotation Lab gives users the ability to change the configuration for the training and pre-annotation processes. This is done from the Settings &gt; Infrastructure page. The settings can be edited by admin user and they are read-only for the other users. The Infrastructure page consists of three sections namely Resource For Training, Resource For Preannotation Server, Resources for Prenotation Pipeline. Resources Inclusion: Memory Limit – Represents the maximum memory size to allocate for the training/pre-annotation processes. CPU Limit – Specifies this maximum number of CPUs to use by the training/pre-annotation server. Note: If the specified configurations exceed the available resources, the server will not start.",
    "url": "/docs/en/alab/infrastructure",
    "relUrl": "/docs/en/alab/infrastructure"
  },
  "1220": {
    "id": "1220",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs open source libraries, just run pip install johnsnowlabs To quickly test the installation, you can run in your Shell: python -c &quot;from johnsnowlabs import nlp;print(nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import nlp nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) when using Annotator based pipelines, use nlp.start() to start up your session from johnsnowlabs import nlp nlp.start() pipe = nlp.Pipeline(stages= [ nlp.DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;doc&#39;), nlp.Tokenizer().setInputCols(&#39;doc&#39;).setOutputCol(&#39;tok&#39;) ]) nlp.to_nlu_pipe(pipe).predict(&#39;That was easy&#39;) for alternative installation options see Custom Installation",
    "url": "/docs/en/jsl/install",
    "relUrl": "/docs/en/jsl/install"
  },
  "1221": {
    "id": "1221",
    "title": "Installation",
    "content": "Type of installation Dedicated Server AWS Marketplace Azure Marketplace EKS deployment AKS deployment AirGap Environment OpenShift Dedicated Server Install NLP Lab (Annotation Lab) on a dedicated server to reduce the likelihood of conflicts or unexpected behavior. Fresh install To install NLP Lab run the following command: wget https://setup.johnsnowlabs.com/annotationlab/install.sh -O - | sudo bash -s $VERSION Replace $VERSION in the above one liners with the version you want to install. For installing the latest available version of the NLP Lab use: wget https://setup.johnsnowlabs.com/annotationlab/install.sh -O - | sudo bash -s -- Upgrade To upgrade your NLP Lab installation to a newer version, run the following command on a terminal: wget https://setup.johnsnowlabs.com/annotationlab/upgrade.sh -O - | sudo bash -s $VERSION Replace $VERSION in the above one liners with the version you want to upgrade to. For upgrading to the latest version of the NLP Lab, use: wget https://setup.johnsnowlabs.com/annotationlab/upgrade.sh -O - | sudo bash -s -- NOTE: The install/upgrade script displays the login credentials for the admin user on the terminal. After running the install/upgrade script, the NLP Lab is available at http://INSTANCE_IP or https://INSTANCE_IP We have an aesthetically pleasing Sign-In Page with a section highlighting the key features of NLP Lab using animated GIFs. AWS Marketplace Visit the product page on AWS Marketplace and follow the instructions on the video below to subscribe and deploy. Deploy NLP Lab via AWS Marketplace Azure Marketplace Visit the product page on Azure Marketplace and follow the instructions on the video below to subscribe and deploy. Deploy NLP Lab via Azure Marketplace EKS deployment Create NodeGroup for a given cluster eksctl create nodegroup --config-file eks-nodegroup.yaml kind: ClusterConfig apiVersion: eksctl.io/v1alpha5 metadata: name: &lt;cluster-name&gt; region: &lt;region&gt; version: &quot;1.21&quot; availabilityZones: - &lt;zone-1&gt; - &lt;zone-2&gt; vpc: id: &quot;&lt;vpc-id&gt;&quot; subnets: private: us-east-1d: id: &quot;&lt;subnet-id&quot; us-east-1f: id: &quot;&lt;subent-id&gt;&quot; securityGroup: &quot;&lt;security-group&gt;&quot; iam: withOIDC: true managedNodeGroups: - name: alab-workers instanceType: m5.large desiredCapacity: 3 VolumeSize: 50 VolumeType: gp2 privateNetworking: true ssh: publicKeyPath: &lt;path/to/id_rsa_pub&gt; eksctl utils associate-iam-oidc-provider --region=us-east-1 --cluster=&lt;cluster-name&gt; --approve Create an EFS as shared storage. EFS stands for Elastic File System and is a scalable storage solution that can be used for general purpose workloads. curl -S https://raw.githubusercontent.com/kubernetes-sigs/aws-efs-csi-driver/v1.2.0/docs/iam-policy-example.json -o iam-policy.json aws iam create-policy --policy-name EFSCSIControllerIAMPolicy --policy-document file://iam-policy.json eksctl create iamserviceaccount --cluster=&lt;cluster&gt; --region &lt;AWS Region&gt; --namespace=kube-system --name=efs-csi-controller-sa --override-existing-serviceaccounts --attach-policy-arn=arn:aws:iam::&lt;AWS account ID&gt;:policy/EFSCSIControllerIAMPolicy --approve helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-efs-csi-driver helm repo update helm upgrade -i aws-efs-csi-driver aws-efs-csi-driver/aws-efs-csi-driver --namespace kube-system --set image.repository=602401143452.dkr.ecr.us-east-1.amazonaws.com/eks/aws-efs-csi-driver --set controller.serviceAccount.create=false --set controller.serviceAccount.name=efs-csi-controller-sa Create storageClass.yaml cat &lt;&lt;EOF &gt; storageClass.yaml kind: StorageClass apiVersion: storage.k8s.io/v1 metadata: name: efs-sc provisioner: efs.csi.aws.com parameters: provisioningMode: efs-ap fileSystemId: &lt;EFS file system ID&gt; directoryPerms: &quot;700&quot; EOF kubectl apply -f storageClass.yaml Edit annotationlab-installer.sh inside artifact folder as follows: helm install annotationlab annotationlab-${ANNOTATIONLAB_VERSION}.tgz --set image.tag=${ANNOTATIONLAB_VERSION} --set model_server.count=1 --set ingress.enabled=true --set networkPolicy.enabled=true --set networkPolicy.enabled=true --set extraNetworkPolicies=&#39;- namespaceSelector: matchLabels: kubernetes.io/metadata.name: kube-system podSelector: matchLabels: app.kubernetes.io/name: traefik app.kubernetes.io/instance: traefik&#39; --set keycloak.postgresql.networkPolicy.enabled=true --set sharedData.storageClass=efs-sc --set airflow.postgresql.networkPolicy.enabled=true --set postgresql.networkPolicy.enabled=true --set airflow.networkPolicies.enabled=true --set ingress.defaultBackend=true --set ingress.uploadLimitInMegabytes=16 --set &#39;ingress.hosts[0].host=domain.tld&#39; --set airflow.model_server.count=1 --set airflow.redis.password=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.FLASK_SECRET_KEY=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.KEYCLOAK_CLIENT_SECRET_KEY=$(bash -c &quot;echo ${uuid_gen_string}&quot;) --set postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.secrets.admincreds.stringData.user=admin --set keycloak.secrets.admincreds.stringData.password=$(bash -c &quot;echo ${password_gen_string}&quot;) Run annotationlab-installer.sh script ./artifacts/annotationlab-installer.sh Install ingress Controller helm repo add nginx-stable https://helm.nginx.com/stable helm repo update helm install my-release nginx-stable/nginx-ingress Apply ingress.yaml cat &lt;&lt;EOF &gt; ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: annotationlab meta.helm.sh/release-namespace: default name: annotationlab spec: defaultBackend: service: name: annotationlab port: name: http rules: - host: domain.tld http: paths: - backend: service: name: annotationlab port: name: http path: / pathType: ImplementationSpecific - backend: service: name: annotationlab-keyclo-http port: name: http path: /auth pathType: ImplementationSpecific EOF kubectl apply -f ingress.yaml AKS deployment To deploy NLP Lab on Azure Kubernetes Service (AKS) a Kubernetes cluster needs to be created in Microsoft Azure. Login to your Azure Portal and search for Kubernetes services. On the Kubernetes services page click on the Create dropdown and select Create a Kubernetes cluster. On the Create Kubernetes cluster page, select the resource group and provide the name you want to give to the cluster. You can keep the rest of the fields to default values and click on Review + create. Click on Create button to start the deployment process. Once the deployment is completed, click on Go to resource button. On the newly created resource page, click on Connect button. You will be shown a list of commands to run on the Cloud Shell or Azure CLI to connect to this resource. We will execute them successively in the following steps. Run the following commands to connect to Azure Kubernetes Service. az account set --subscription &lt;subscription-id&gt; NOTE: Replace with your account&#39;s subscription id. az aks get-credentials --resource-group &lt;resource-group-name&gt; --name &lt;cluster-name&gt; NOTE: Replace and with what you selected in Step 3. Check to see if azurefile or azuredisk storage class is present by running the following command: kubectl get storageclass Later in the helm script we need to update the value of sharedData.storageClass with the respective storage class. Go to the artifact directory and from there edit the annotationlab-installer.sh script. helm install annotationlab annotationlab-${ANNOTATIONLAB_VERSION}.tgz --set image.tag=${ANNOTATIONLAB_VERSION} --set model_server.count=1 --set ingress.enabled=true --set networkPolicy.enabled=true --set networkPolicy.enabled=true --set extraNetworkPolicies=&#39;- namespaceSelector: matchLabels: kubernetes.io/metadata.name: kube-system podSelector: matchLabels: app.kubernetes.io/name: traefik app.kubernetes.io/instance: traefik&#39; --set keycloak.postgresql.networkPolicy.enabled=true --set sharedData.storageClass=azurefile --set airflow.postgresql.networkPolicy.enabled=true --set postgresql.networkPolicy.enabled=true --set airflow.networkPolicies.enabled=true --set ingress.defaultBackend=true --set ingress.uploadLimitInMegabytes=16 --set &#39;ingress.hosts[0].host=domain.tld&#39; --set airflow.model_server.count=1 --set airflow.redis.password=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.FLASK_SECRET_KEY=$(bash -c &quot;echo ${password_gen_string}&quot;) --set configuration.KEYCLOAK_CLIENT_SECRET_KEY=$(bash -c &quot;echo ${uuid_gen_string}&quot;) --set postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.postgresql.postgresqlPassword=$(bash -c &quot;echo ${password_gen_string}&quot;) --set keycloak.secrets.admincreds.stringData.user=admin --set keycloak.secrets.admincreds.stringData.password=$(bash -c &quot;echo ${password_gen_string}&quot;) Execute the annotationlab-installer.sh script to run the NLP Lab installation. ./annotationlab-installer.sh Verify if the installation was successful. kubectl get pods Install ingress controller. This will be required for load-balancing purpose. helm repo add nginx-stable https://helm.nginx.com/stable helm repo update helm install my-release nginx-stable/nginx-ingress Create a YAML configuration file named ingress.yaml with the following configuration apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx meta.helm.sh/release-name: annotationlab meta.helm.sh/release-namespace: default name: annotationlab spec: defaultBackend: service: name: annotationlab port: name: http rules: - host: domain.tld http: paths: - backend: service: name: annotationlab port: name: http path: / pathType: ImplementationSpecific - backend: service: name: annotationlab-keyclo-http port: name: http path: /auth pathType: ImplementationSpecific Apply the ingress.yaml by running the following command kubectl apply -f ingress.yaml AirGap Environment Get Artifact Run the following command on a terminal to fetch the compressed artifact (tarball) of the NLP Lab. wget https://s3.amazonaws.com/auxdata.johnsnowlabs.com/annotationlab/annotationlab-$VERSION.tar.gz Extract the tarball and the change directory to the extracted folder (artifacts): tar -xzf annotationlab-$VERSION.tar.gz cd artifacts Replace $VERSION with the version you want to download and install. Fresh Install Run the installer script annotationlab-installer.sh with sudo privileges. $ sudo su $ ./annotationlab-installer.sh Upgrade Run the upgrade script annotationlab-updater.sh with sudo privileges. $ sudo su $ ./annotationlab-updater.sh OpenShift Annotation Lab can also be installed using the operator framework on an OpenShift cluster. The Annotation Lab operator can be found under the OperatorHub. Find and select The OperatorHub has a large list of operators that can be installed into your cluster. Search for Annotation Lab operator under AI/Machine Learning category and select it. Install Some basic information about this operator is provided on the navigation panel that opens after selecting Annotation Lab on the previous step. NOTE: Make sure you have defined shared storage such as efs/nfs/cephfs prior to installing the Annotation Lab Operator. Click on the Install button located on the top-left corner of this panel to start the installation process. After successful installation of the Annotation Lab operator, you can access it by navigating to the Installed Operators page. Create Instance Next step is to create a cluster instance of the Annotation Lab. For this, select the Annotation Lab operator under the Installed Operators page and then switch to Annotationlab tab. On this section, click on Create Annotationlab button to spawn a new instance of Annotation Lab. Define shared Storage Class Update the storageClass property in the YAML configuration to define the storage class to one of efs, nfs, or cephfs depending upon what storage you set up before Annotation Lab operator installation. Define domain name Update the host property in the YAML configuration to define the required domain name to use instead of the default hostname annotationlab as shown in the image below. Click on Create button once you have made all the necessary changes. This will also set up all the necessary resources to run the instance in addition to standing up the services themselves. View Resources After the instance is successfully created we can visit its page to view all the resources as well as supporting resources like the secrets, configuration maps, etc that were created. Now, we can access the Annotation Lab from the provided domain name or also from the location defined for this service under the Networking &gt; Routes page Work over proxy Custom CA certificate You can provide a custom CA certificate chain to be included into the deployment. To do it add --set-file custom_cacert=./cachain.pem options to helm install/upgrade command inside annotationlab-installer.sh and annotationlab-updater.sh files. cachain.pem must include a certificate in the following format: --BEGIN CERTIFICATE-- .... --END CERTIFICATE-- Proxy env variables You can provide a proxy to use for external communications. To do that add `--set proxy.http=[protocol://]&lt;host&gt;[:port]`, `--set proxy.https=[protocol://]&lt;host&gt;[:port]`, `--set proxy.no=&lt;comma-separated list of hosts/domains&gt;` commands inside annotationlab-installer.sh and annotationlab-updater.sh files. Recommended Configurations System requirements You can install Annotation Lab on a Ubuntu 20+ machine. Port requirements Annotation Lab expects ports 443 and 80 to be open by default. Server requirements The minimal required configuration is 32GB RAM, 8 Core CPU, 512 SSD. The ideal configuration in case model training and preannotations are required on a large number of tasks is 64 GiB, 16 Core CPU, 2TB HDD, 512 SSD. Web browser support Annotation Lab is tested with the latest version of Google Chrome and is expected to work in the latest versions of: Google Chrome Apple Safari Mozilla Firefox",
    "url": "/docs/en/alab/install",
    "relUrl": "/docs/en/alab/install"
  },
  "1222": {
    "id": "1222",
    "title": "Installation",
    "content": "",
    "url": "/docs/en/install",
    "relUrl": "/docs/en/install"
  },
  "1223": {
    "id": "1223",
    "title": "Install NLP Libraries",
    "content": "Spark NLP For installing Spark NLP on your infrastructure please follow the instructions detailed here. Spark NLP for Healthcare For installing Spark NLP for Healthcare please follow the instructions detailed here. Spark OCR For installing Spark OCR please follow the instructions detailed here.",
    "url": "/docs/en/install_NLP_libraries",
    "relUrl": "/docs/en/install_NLP_libraries"
  },
  "1224": {
    "id": "1224",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs open source libraries, just run pip install johnsnowlabs This installs Spark-NLP, NLU , Spark-NLP-Display , Pyspark and other open source sub-dependencies. To quickly test the installation, you can run in your Shell: python -c &quot;from johnsnowlabs import *;print(nlu.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import * nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) The quickest way to get access to licensed libraries like Finance NLP, Legal NLP, Healthcare NLP or Visual NLP is to run the following in python: from johnsnowlabs import * nlp.install() This will display a Browser Window Pop Up or show a Clickable Button with Pop Up. Click on the Authorize button to allow the library to connect to your account on my.JohnSnowLabs.com and access you licenses. This will enable the installation and use of all licensed products for which you have a valid license. Make sure to Restart your Notebook after installation. Colab Button Where the Pop-Up leads you to: After clicking Authorize: Additional Requirements Make sure you have Java 8 installed, for setup instructions see How to install Java 8 for Windows/Linux/Mac? Windows Users must additionally follow every step precisely defined in How to correctly install Spark NLP for Windows? Install Licensed Libraries The following is a more detailed overview of the alternative installation methods and parameters you can use. The parameters of nlp.install()parameters fall into 3 categories: Authorization Flow Choice &amp; Auth Flow Tweaks Installation Targets such as Airgap Offline, Databricks, new Pytho Venv, Currently running Python Enviroment, or target Python Environment Installation process tweaks List all of your accessible Licenses You can use nlp.list_remote_licenses() to list all available licenses in your my.johnsnowlabs.com/ account and nlp.list_local_licenses() to list all locally cached licenses. Authorization Flows overview The johnsnowlabs library gives you multiple methods to authorize and provide your license when installing licensed libraries. Once access to your license is provided, it is cached locally ~/.johnsnowlabs/licenses and re-used when calling nlp.start() and nlp.install(), so you don’t need to authorize again. Only 1 licenses can be provided and will be cached during authorization flows. If you have multiple licenses you can re-run an authorization method and use the local_license_number and remote_license_number parameter choose between licenses you have access to. Licenses are locally numbered in order they have been provided, for more info see License Caching. Auth Flow Method Description Python nlp.install() usage Browser Based Login (OAuth) Localhost Browser window will pop up, where you can give access to your license. Use remote_license_number parameter to choose between licenses. Use remote_license_number parameter to choose between licenses nlp.install() Browser Based Login (OAuth) on Google Colab A button is displayed in your notebook, click it and visit new page to give access to your license. Use remote_license_number parameter to choose between licenses nlp.install() Access Token Vist my.johnsnowlabs.com to extract a token which you can provide to enable license access. See Access Token Example for more details nlp.install(access_token=my_token) License JSON file path Define JSON license file with keys defined by License Variable Overview and provide file path nlp.install(json_license_path=path) Auto-Detect License JSON file from os.getcwd() os.getcwd() directory is scanned for a .json file containing license keys defined by License Variable Overview nlp.install() Auto-Detect OS Environment Variables Environment Variables are scanned for license variables defined by License Variable Overview nlp.install() Auto-Detect Cached License in ~/.johnsnowlabs/licenses If you already have provided a license previously, it is cached in ~/.johnsnowlabs/licenses and automatically loaded. Use local_license_number parameter to choose between licenses if you have multiple nlp.install() Manually specify license data Set each license value as python parameter, defined by License Variable Overview nlp.install(hc_license=hc_license enterprise_nlp_secret=enterprise_nlp_secret ocr_secret=ocr_secret ocr_license=ocr_license aws_access_key=aws_access_key aws_key_id=aws_key_id) Optional Auth Flow Parameters Use these parameters to configure the preferred authorization flow. Parameter description browser_login Enable or disable browser based login and pop up if no license is provided or automatically detected. Defaults to True. force_browser_login If a cached license if found, no browser pop up occurs. Set True to force the browser pop up, so that you can download different license, if you have several ones. local_license_number Specify the license number when loading a cached license from jsl home and multiple licenses have been cached. Defaults to 0 which will use the very first license every provided to the johnsnowlabs library. remote_license_number Specify the license number to use with OAuth based approaches. Defaults to 0 which will use your first license from my.johnsnowlabs.com. store_in_jsl_home By default license data and Jars/Wheels are stored in JSL home directory. This enables nlp.start() and nlp.install() to re-use your information and you don’t have to specify on every run. Set to False to disable this caching behaviour. only_refresh_credentials Set to True if you don’t want to install anything and just need to refresh or index a new license. Defaults to False. Optional Installation Target Parameters Use these parameters to configure where to install the libraries. Parameter description python_exec_path Specify path to a python executable into whose environment the libraries will be installed. Defaults to the current executing Python process, i.e. sys.executable and it’s pip module is used for setup. venv_creation_path Specify path to a folder, in which a fresh venv will be created with all libraries. Using this parameter ignores the python_exec_path parameter, since the newly created venv’s python executable is used for setup. offline_zip_dir Specify path to a folder in which 3 sub-folders are created, py_installs, java_installs with corrosponding Wheels/Jars/Tars and licenses. It will additionallly be zipped. Install to Databricks with access Token See Databricks Documentation for extracting a token which you can provide to databricks access, see Databricks Install Section for more details. Optional Installation Process Parameters Use the following parameters to configure what should be installed. Parameter description install_optional By default install all open source libraries if missing. Set the False to disable. install_licensed By default installs all licensed libraries you have access to if they are missing. Set to False to disable. include_dependencies Defaults to True which installs all depeendencies. If set to False pip will be executed with the --no-deps argument under the hood. product Specify product to install. By default installs everything you have access to. only_download_jars By default all libraries are installed to the current environment via pip. Set to False to disable installing Python dependencies and only download jars to the John Snow Labs home directory. jvm_install_type Specify hardware install type, either cpu, gpu, m1, or aarch . Defaults to cpu. If you have a GPU and want to leverage CUDA, set gpu. If you are an Apple M1 or Arch user choose the corresponding types. py_install_type Specify Python installation type to use, either tar.gz or whl, defaults to whl. refresh_install Delete any cached files before installing by removing John Snow Labs home folder. This will delete your locally cached licenses. Automatic Databricks Installation Use any of the databricks auth flows to enable the johnsnowlabs library to automatically install all open source and licensed features into a Databricks cluster. You additionally must use one of the John Snow Labs License Authorization Flows to give access to your John Snow Labs license,which will be installed to your Databricks cluster. A John Snow Labs Home directory is constructed in the distributed Databricks File System/dbfs/johnsnowlabs which has all Jars, Wheels and License Information to run all features in a Databricks cluster. Databricks Auth Flow Method Description Python nlp.install() usage Access Token See Databricks Documentation for extracting a token which you can provide to databricks access, see Databricks Install Section for details nlp.install(databricks_cluster_id=my_cluster_id, databricks_host=my_databricks_host, databricks_token=my_access_databricks_token) Where to find your Databricks Access Token: Databricks Cluster Creation Parameters You can set the following parameters on the nlp.install() function to define properties of the cluster which will be created. See Databricks Cluster Creation for a detailed description of all parameters. Cluster creation Parameter Default Value block_till_cluster_ready True num_workers 1 cluster_name John-Snow-Labs-Databricks-Auto-Cluster🚀 node_type_id i3.xlarge driver_node_type_id i3.xlarge spark_env_vars None autotermination_minutes 60 spark_version 10.5.x-scala2.12 spark_conf None auto_scale None aws_attributes None ssh_public_keys None custom_tags None cluster_log_conf None enable_elastic_disk None cluster_source None instance_pool_id None headers None The created cluster License Variables Names for JSON and OS variables The following variable names are checked when using a JSON or environment variables based approach for installing licensed features or when using nlp.start() . You can find all of your license information on https://my.johnsnowlabs.com/subscriptions AWS_ACCESS_KEY_ID : Assigned to you by John Snow Labs. Must be defined. AWS_SECRET_ACCESS_KEY : Assigned to you by John Snow Labs. Must be defined. HC_SECRET : The secret for a version of the enterprise NLP engine library. Changes between releases. Can be omitted if you don’t have access to enterprise nlp. HC_LICENSE : Your license for the medical features. Can be omitted if you don’t have a medical license. OCR_SECRET : The secret for a version of the Visual NLP (Spark OCR) library. Changes between releases. Can be omitted if you don’t have a Visual NLP (Spark OCR) license. OCR_LICENSE : Your license for the Visual NLP (Spark OCR) features. Can be omitted if you don’t have a Visual NLP (Spark OCR) license. JSL_LEGAL_LICENSE: Your license for Legal NLP Features JSL_FINANCE_LICENSE Your license for Finance NLP Features NOTE: Instead of JSL_LEGAL_LICENSE, HC_LICENSE and JSL_FINANCE_LICENSE you may have 1 generic SPARK_NLP_LICENSE. Installation Examples Via Auto Detection &amp; Browser Login All default search locations are searched, if any credentials are found they will be used. If no credentials are auto-detected, a Browser Window will pop up, asking to authorize access to https://my.johnsnowlabs.com/ In Google Colab, a clickable button will appear, which will make a window pop up where you can authorize access to https://my.johnsnowlabs.com/. nlp.install() Via Access Token Get your License Token from My John Snow Labs nlp.install(access_token=&#39;secret&#39;) Where you find the license Via Json Secrets file Path to a JSON containing secrets, see License Variable Names for more details. nlp.install(json_file_path=&#39;my/secret.json&#39;) Via Manually defining Secrets Manually specify all secrets. Some of these can be omitted, see License Variable Names for more details. nlp.install( hc_license=&#39;Your HC License&#39;, fin_license=&#39;Your FIN License&#39;, leg_license=&#39;Your LEG License&#39;, enterprise_nlp_secret=&#39;Your NLP Secret&#39;, ocr_secret=&#39;Your OCR Secret&#39;, ocr_license=&#39;Your OCR License&#39;, aws_access_key=&#39;Your Access Key&#39;, aws_key_id=&#39;Your Key ID&#39;, ) Into Current Python Process Uses sys.executable by default, i.e. the Python that is currently running the program. nlp.install() Into Custom Python Env Using specific python executable, which is not the currently running python. Will use the provided python’s executable pip module to install libraries. nlp.install(python_exec_path=&#39;my/python.exe&#39;) Into freshly created venv Create a new Venv using the currently executing Pythons Venv Module. nlp.install(venv_creation_path=&#39;path/to/where/my/new/venv/will/be&#39;) Into Airgap/Offline Installation (Automatic) Create a Zip with all Jars/Wheels/Licenses you need to run all libraries in an offline environment. Step1: nlp.install(offline_zip_dir=&#39;path/to/where/my/zip/will/be&#39;) Step2: Transfer the zip file securely to your offline environment and unzip it. One option is the unix scp command. scp /to/where/my/zip/will/be/john_snow_labs.zip 123.145.231.001:443/remote/directroy Step3: Then from the remote machine shell unzip with: # Unzip all files to ~/johnsowlabs unzip remote/directory/jsl.zip -d ~/johnsowlabs Step4 (option1): Install the wheels via jsl: # If you unzipped to ~/johnsowlabs, then just update this setting before running and nlp.install() handles the rest for you! from johnsnowlabs import * nlp.settings.jsl_root = &#39;~/johnsowlabs&#39; # Make sure you have Java 8 installed! nlp.install() Step4 (option2): Install the wheels via pip: # Assuming you unzipped to ~/johnsnowlabs, you can install all wheels like this pip install ~/johnsnowlabs/py_installs/*.whl Step5: Test your installation Via shell: python -c &quot;from johnsnowlabs import *;print(nlu.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;))&quot; or in Python: from johnsnowlabs import * nlp.load(&#39;emotion&#39;).predict(&#39;Wow that easy!&#39;) Into Airgap/Offline Manual Download all files yourself from the URLs printed by nlp.install(). You will have to folly the Automatic Instructions starting from step (2) of the automatic installation. I.e. provide the files somehow on your offline machine. # Print all URLs to files you need to provide on your host machine nlp.install(offline=True) Into a freshly created Databricks cluster automatically To install in databricks you must provide your accessToken and hostUrl. You can provide the secrets to the install function with any of the methods listed above, i.e. using access_token , browser, json_file, or manually defining secrets Your can get it from: # Create a new Cluster with Spark NLP and all licensed libraries ready to go: nlp.install(databricks_host=&#39;https://your_host.cloud.databricks.com&#39;, databricks_token = &#39;dbapi_token123&#39;,) Into Existing Databricks cluster Manual If you do not wish to use the recommended automatic installation but instead want to install manually you must install the johnsnowlabs_for_databricks pypi package instead of johnsnowlabs via the UI or any method of your choice. License Management &amp; Caching Storage of License Data and License Search behaviour The John Snow Labs library caches license data in ~/.johnsnowlabs/licenses whenever a new one is provided . After having provided license data once, you don’t need to specify it again since the cached licensed will be used. Use the local_license_number and remote_license_number parameters to switch between multiple licenses. Note: Locally cached licenses are numbered in the order they have been provided, starting at 0. remote_license_number=0 might not be the same as local_license_number=0. Use the following functions to see all your avaiable licenses. List all available licenses This shows you all licenses for your account in https://my.johnsnowlabs.com/. Use this to decide which license number to install when installing via browser or access token. nlp.list_remote_licenses() List all locally cached licenses Use this to decide which license number to use when using nlp.start() or nlp.install() to specify which local license you want to load. nlp.list_local_licenses() License Search precedence If there are multiples possible sources for licenses, the following order takes precedence: Manually provided license data by defining all license parameters. Browser/ Access Token. Os environment Variables for any var names that match up with secret names. /content/*.json for any json file smaller than 1 MB. current_working_dir/*.json for any json smaller than 1 MB. ~/.johnsnowlabs/licenses for any licenses. JSON files are scanned if they have any keys that match up with names of secrets. Name of the json file does not matter, file just needs to end with .json. Upgrade Flow Step 1: Upgrade the johnsnowlabs library. pip install johnsnowlabs --upgrade Step 2: Run install again, while using one Authorization Flows. nlp.install() The John Snow Labs Teams are working early to push out new Releases and Features each week! Simply run pip install johnsnowlabs --upgrade to get the latest open source libraries updated. Once the johnsnowlabs library is upgraded, it will detect any out-dated libraries any inform you that you can upgrade them by running nlp.install() again. You must run one of the Authorization Flows again, to gian access to the latest enterprise libraries. Next Steps &amp; Frequently Asked Questions How to setup Java 8 Setup Java 8 on Windows Setup Java 8 on Linux Setup Java 8 on Mac Join our Slack channel Join our channel, to ask for help and share your feedback. Developers and users can help each other get started here. NLU Slack Where to go next If you want to get your hands dirty with any of the features check out the NLU examples page, or Licensed Annotators Overview Detailed information about Johnsnowlabs Libraries APIs, concepts, components and more can be found on the following pages : Starting a Spark Session John Snow Labs Library usage and import Overview The NLU load function The NLU predict function The NLU components spellbook NLU Notebooks",
    "url": "/docs/en/jsl/install_advanced",
    "relUrl": "/docs/en/jsl/install_advanced"
  },
  "1225": {
    "id": "1225",
    "title": "Installation",
    "content": "To install the johnsnowlabs Python library and all of John Snow Labs licensed libraries, just run run in your shell pip install johnsnowlabs run in a Python Shell from johnsnowlabs import * jsl.install() This will display a Browser Window Pop Up or show a Clickable Button with Pop Up. Click on the Authorize button to allow the library to connect to your account on my.JohnSnowLabs.com and access you licenses. This will enable the installation and use of all licensed products for which you have a valid license. Colab Button: Where the Pop-Up leads you to: After clicking Authorize: To quickly test your installation, run in a Python shell for alternative installation options see Custom Installation",
    "url": "/docs/en/jsl/install_licensed_quick",
    "relUrl": "/docs/en/jsl/install_licensed_quick"
  },
  "1226": {
    "id": "1226",
    "title": "Installation",
    "content": "Deploy using Docker For deploying NLP Server on your instance run the following command. docker run --pull=always -p 5000:5000 johnsnowlabs/nlp-server:latest This will check if the latest docker image is available on your local machine and if not it will automatically download and run it. If you want to keep downloaded models between restarts of the docker image, you can mount a volume. mkdir /var/cache_pretrained chown 1000:1000 /var/cache_pretrained docker run --pull=always -v /var/cache_pretrained:/home/johnsnowlabs/cache_pretrained -p 5000:5000 johnsnowlabs/nlp-server:latest Deploy using AWS Marketplace NLP Server on AWS Marketplace provides one of the fastest and easiest ways to get up and running on Amazon Web Services (AWS). NLP Server is available through AWS Marketplace free of charge. However, to use licensed spells in NLP Server, you need to buy our license from here. You can get NLP Server on AWS Marketplace from this URL. Follow the seven steps instructions or the video tutorial given below to learn how to deploy NLP Server using AWS Marketplace. Make sure you have a valid AWS account and log in to the AWS Marketplace using your credentials. Deploy NLP Server via AWS Marketplace 1.Click on Continue to subscribe button for creating a subscription to the NLP Server product. The software is free of charge. 2.Read the subscription EULA and click on Accept terms button if you want to continue. 3.In a couple of seconds the subscription becomes active. Once it is active you see this screen. 4.Go to AWS Marketplace &gt; Manage subscriptions and click on the Launch new instance button corresponding to the NLP Server subscription. This will redirect you to the following screen. Click on Continue to launch through EC2 button. 5.From the available options select the instance type you want to use for the deployment. Then click on Review and Lauch button. 6.Select an existing key pair or create a new one. This ensures a secured connection to the instance. If you create a new key make sure that you download and safely store it for future usage. Click on the Launch button. 7.While the instance is starting you will see this screen. Then the instance will appear on your EC2 Instances list. The NLP Server can now be accessed via a web browser at http://PUBLIC_EC2_IP . API documentation is also available at http://PUBLIC_EC2_IP/docs Deploy using Azure Marketplace NLP Server on Azure Marketplace provides one of the fastest and easiest ways to get up and running on Microsoft Azure. NLP Server is available through Azure Marketplace free of charge. However, to use licensed spells in NLP Server, you need to buy our license from here. You can get NLP Server on Azure Marketplace from this URL. Follow the video tutorial given below to learn how to deploy NLP Server using Azure Marketplace. Deploy NLP Server using Azure Marketplace",
    "url": "/docs/en/nlp_server/installation",
    "relUrl": "/docs/en/nlp_server/installation"
  },
  "1227": {
    "id": "1227",
    "title": "John Snow Labs Configurations",
    "content": "Installed Library Version Settings Each version of the John Snow Labs library comes with a hardcoded set of versions for very of product of the John Snow Labs company. It will not accept library secrets which correspond to versions do not match the settings. This essentially prevents you from installing outdated or new but not deeply tested libraries, or from shooting yourself in the foot you might say. You can work around this protection mechanism, by configuring jsl.settings.enforce_versions=False. This will ignore bad secret versions. from johnsnowlabs import * jsl.settings.enforce_versions=False jsl.install(secret=&#39;1.2.3-My.Custom.or.Outdated.Secret&#39;) John Snow Labs Home Cache Folder The John Snow Labs library maintains a home folder in ~/.johnsnowlabs which contains all your Licenses, Jars for Java and Wheels for Python to install and run any feature. Additionally, each directory has an info.json file, telling you more about Spark compatibility, Hardware Targets and versions of the files. ~/.johnsnowlabs/ ├─ licenses/ │ ├─ info.json │ ├─ license1.json │ ├─ license2.json ├─ java_installs/ │ ├─ info.json │ ├─ app1.jar │ ├─ app2.jar ├─ py_installs/ │ ├─ info.json │ ├─ app1.tar.gz │ ├─ app2.tar.gz ├─ info.json",
    "url": "/docs/en/jsl/john-snow-labs-home",
    "relUrl": "/docs/en/jsl/john-snow-labs-home"
  },
  "1228": {
    "id": "1228",
    "title": "John Snow labs Usage & Overview",
    "content": "The John Snow Labs Python library gives you a clean and easy way to structure your Python projects. The very first line of a project should be: from johnsnowlabs import * This imports all licensed and open source Python modules installed from other John Snow Labs Products, as well as many handy utility imports. The following Functions, Classes and Modules will available in the global namespace The nlp Module nlp module with classes and methods from Spark NLP like nlp.BertForSequenceClassification and nlp.map_annotations() nlp.AnnotatorName via Spark NLP Annotators and Transformers i.e. nlp.BertForSequenceClassification Spark NLP Helper Functions i.e. nlp.map_annotations() nlp.F via import pyspark.sql.functions as F under the hood nlp.T via import pyspark.sql.types as T under the hood nlp.SQL via import pyspark.sql as SQL under the hood nlp.ML via from pyspark import ml as ML under the hood To see all the imports see the source The jsl Module jsl module with the following methods jsl.install() for installing John Snow Labs libraries and managing your licenses, more info here jsl.load() for predicting with any the 10k+ pretrained models in 1 line of code or training new ones, using the nlu.load() method under the hood jsl.start() for starting a Spark Session with access to features, more info here jsl.viz() for visualizing predictions with any of the 10k+ pretrained models using nlu.viz() under the hood jsl.viz_streamlit() and other `jsl.viz_streamlit_xyz for using any of the 10k+ pretrained models in 0 lines of code with an interactive Streamlit GUI and re-usable and stackable Streamlit Components jsl.to_pretty_df() for predicting on raw strings getting a nicely structures Pandas DF from a Spark Pipeline using nlu.to_pretty_df() under the hood The viz Module viz module with classes from Spark NLP Display viz.NerVisualizer for visualizing prediction outputs of Ner based Spark Pipelines viz.DependencyParserVisualizer for visualizing prediction outputs of DependencyParser based Spark Pipelines viz.RelationExtractionVisualizer for visualizing prediction outputs of RelationExtraction based Spark Pipelines viz.EntityResolverVisualizer for visualizing prediction outputs of EntityResolver based Spark Pipelines viz.AssertionVisualizer for visualizing prediction outputs of Assertion based Spark Pipelines The ocr Module ocr module with annotator classes and methods from Spark OCR like ocr.VisualDocumentClassifier and `ocr.helpful_method() Pipeline Components i.e. ocr.ImageToPdf Table Recognizers i.e. ocr.ImageTableDetector Visual Document Understanding i.e. ocr.VisualDocumentClassifier Object detectors i.e. ocr.ImageHandwrittenDetector Enums, Structures and helpers i.e. ocr.Color To see all the imports see the source The medical Module medical module with annotator classes and methods from Spark NLP for Medicine like medical.RelationExtractionDL and medical.profile() Medical Annotators , i.e. medical.DeIdentification Training Methods i.e. medical.AnnotationToolJsonReader Evaluation Methods, i.e. medical.NerDLEvaluation NOTE: Any class which has Medical in its name is available, but the Medical prefix has been omitted. I.e. medical.NerModel maps to sparknlp_jsl.annotator.MedicalNerModel This is achieved via from sparknlp_jsl.annotator import MedicalNerModel as NerModel under the hood. To see all the imports see the source The legal Module legal module with annotator classes and methods from Spark NLP for Legal like legal.RelationExtractionDL and legal.profile() Legal Annotators , i.e. legal.DeIdentification Training Methods i.e. legal.AnnotationToolJsonReader Evaluation Methods, i.e. legal.NerDLEvaluation NOTE: Any class which has Legal in its name is available, but the Legal prefix has been omitted. I.e. legal.NerModel maps to sparknlp_jsl.annotator.LegalNerModel This is achieved via from sparknlp_jsl.annotator import LegalNerModel as NerModel under the hood. To see all the imports see the source The finance Module finance module with annotator classes and methods from Spark NLP for Finance like finance.RelationExtractionDL and finance.profile() Finance Annotators , i.e. finance.DeIdentification Training Methods i.e. finance.AnnotationToolJsonReader Evaluation Methods, i.e. finance.NerDLEvaluation NOTE: Any class which has Finance in its name is available, but the Finance prefix has been omitted. I.e. finance.NerModel maps to sparknlp_jsl.annotator.FinanceNerModel This is achieved via from sparknlp_jsl.annotator import FinanceNerModel as NerModel under the hood. To see all the imports see the source",
    "url": "/docs/en/jsl/import-structure",
    "relUrl": "/docs/en/jsl/import-structure"
  },
  "1229": {
    "id": "1229",
    "title": "John Snow Labs Release Notes",
    "content": "See Github Releases for detailed information on Release History and Features. 4.3.3 Release date: 23-02-2023 The John Snow Labs 4.3.3 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.1 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc6 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.2 Release date: 21-02-2023 The John Snow Labs 4.3.2 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc6 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.1 Release date: 14-02-2023 The John Snow Labs 4.3.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc5 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.3.0 Release date: 14-02-2023 The John Snow Labs 4.3.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.3.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.3.0 Pyspark 3.1.2 4.2.9 Release date: 01-02-2023 The John Snow Labs 4.2.9 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.2.8 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.8 Pyspark 3.1.2 4.2.8 Release date: 29-01-2023 The John Snow Labs 4.2.8 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.3.0 Enterprise NLP 4.2.8 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.8 Pyspark 3.1.2 4.2.5 Release date: 27-12-2022 The John Snow Labs 4.2.5 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.4 Enterprise NLP 4.2.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.4 Release date: 21-12-2022 The John Snow Labs 4.2.4 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.1 Enterprise NLP 4.2.4 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.3 Release date: 02-12-2022 The John Snow Labs 4.2.3 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.1 Enterprise NLP 4.2.3 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.4 Pyspark 3.1.2 4.2.2 Release date: 17-10-2022 The John Snow Labs 4.2.2 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.2.0 Enterprise NLP 4.2.2 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.2 Pyspark 3.1.2 4.2.1 Release date: 10-10-2022 The John Snow Labs 4.2.1 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.1.0 Enterprise NLP 4.2.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.1 Pyspark 3.1.2 4.2.0 Release date: 06-10-2022 The John Snow Labs 4.2.0 Library released with the following pre-installed and recommended dependencies Library Version Visual NLP 4.0.0 Enterprise NLP 4.2.0 Finance NLP 1.X.X Legal NLP 1.X.X NLU 4.0.1rc4 Spark-NLP-Display 4.1 Spark-NLP 4.2.0 Pyspark 3.1.2",
    "url": "/docs/en/jsl/jsl-release-notes",
    "relUrl": "/docs/en/jsl/jsl-release-notes"
  },
  "1230": {
    "id": "1230",
    "title": "Labs, Tests, and Vitals - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/labs_tests_and_vitals",
    "relUrl": "/labs_tests_and_vitals"
  },
  "1231": {
    "id": "1231",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ld_dl/language_detector_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ld_dl/language_detector_dl.html"
  },
  "1232": {
    "id": "1232",
    "title": "African Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/languages_africa",
    "relUrl": "/languages_africa"
  },
  "1233": {
    "id": "1233",
    "title": "Languages of India - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/languages_india",
    "relUrl": "/languages_india"
  },
  "1234": {
    "id": "1234",
    "title": "",
    "content": "",
    "url": "/latest.html",
    "relUrl": "/latest.html"
  },
  "1235": {
    "id": "1235",
    "title": "Learn",
    "content": "Introductions to Spark NLP Videos State of the Art Natural Language Processing at Scale. David Talby - April 13, 2020 Spark NLP: State of the art natural language processing at scale. David Talby - 4 Jun 2020 What is Spark NLP. John Snow Labs - 30 Jul 2019 Apache Spark NLP Extending Spark ML to Deliver Fast, Scalable, and Unified Natural Language Process. David Talby - 6 May 2019 Natural Language Understanding at Scale with Spark Native NLP, Spark ML &amp;TensorFlow with Alex Thomas. Alex Thomas - 26 Oct 2017 Articles Introducing the Natural Language Processing Library for Apache SparkDavid Talby - October 19, 2017 Improving Clinical Document Understanding on COVID-19 Research with Spark NLPVeysel Kocaman, David Talby - 7 December, 2020 Topic Modelling with PySpark and Spark NLPMaria Obedkova - May 29, 2020 Installing Spark NLP and Spark OCR in air-gapped networks (offline mode)Veysel Kocaman - May 04, 2020 Cleaning and extracting text from HTML/XML documents by using Spark NLPStefano Lori - Jan 13, 2020 A Google Colab Notebook Introducing Spark NLPVeysel Kocaman - September, 2020 State-of-the-art Natural Language Processing at ScaleDavid Talby - April 13, 2020 How to Wrap Your Head Around Spark NLPMustafa Aytuğ Kaya - August 25, 2020 5 Reasons Why Spark NLP Is The Most Widely Used Library In EnterprisesAmbika Choudhury - May 28, 2019 My Experience with SparkNLP Workshop &amp; CertificationAngelina Maria Leigh - August 17, 2020 Out of the box Spark NLP models in actionDia Trambitas - August 14, 2020 Get started with Machine Learning in Java using Spark NLPWill Price - August 27, 2020 SPARK NLP 3: MASSIVE SPEEDUPS &amp; THE LATEST COMPUTE PLATFORMSMaziyar Panahi - March 25, 2021 SPARK NLP 2.7: 720+ NEW MODELS &amp; PIPELINES FOR 192 LANGUAGES!David Talby - January 05, 2021 Python’s NLU Library Videos &quot;Python&#39;s NLU library: 1,000+ Models, 200+ Languages, 1 Line of Code&quot; by: Christian Kasim Loan - 18 June 2021 John Snow Labs NLU: Become a Data Science Superhero with One Line of Python code. Christian Kasim Loan - November, 2020 Articles 1 line to GLOVE Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to XLNET Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to ALBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to COVIDBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to ELECTRA Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 line to BioBERT Word Embeddings with NLU in PythonChristian Kasim Loan - January 17, 2021 1 Line of Code, 350 + NLP Models with John Snow Labs’ NLU in PythonChristian Kasim Loan - September 21, 2020 Easy sentence similarity with BERT Sentence Embeddings using John Snow Labs NLUChristian Kasim Loan - November 20, 2020 Training Deep Learning NLP Classifier TutorialChristian Kasim Loan - November 20, 2020 1 Python Line for ELMo Word Embeddings and t-SNE plots with John Snow Labs’ NLUChristian Kasim Loan - October 24, 2020 1 line of Python code for BERT, ALBERT, ELMO, ELECTRA, XLNET, GLOVE, Part of Speech with NLU and t-SNEChristian Kasim Loan - September 21, 2020 1 line to BERT Word Embeddings with NLU in PythonChristian Kasim Loan - September 21, 2020 Question answering, intent classification, aspect based ner, and new multilingual models in python’s NLU libraryChristian Kasim Loan - February 12, 2021 Intent and action classification, analyze chinese news and crypto market, 200+ languages &amp; answer questions with NLU 1.1.3Christian Kasim Loan - March 02, 2021 Hindi wordembeddings, bengali named entity recognition, 30+ new models, analyze crypto news with NLU 1.1.2Christian Kasim Loan - February 18, 2021 Named Entity Recognition Videos State-of-the-art Clinical Named Entity Recognition in Spark NLP Workshop - Veysel Kocaman Train your own NerDL. John Snow Labs - 7 Oct 2019 Articles State-of-the-art named entity recognition with BERTVeysel Kocaman - February 26th, 2020 State-of-the-art Named Entity Recognition in Spark NLPVeysel Kocaman Spark NLP in action: intelligent, high-accuracy fact extraction from long financial documentsSaif Addin Ellafi - May 5, 2020 Named Entity Recognition (NER) with BERT in Spark NLPVeysel Kocaman - Mar 4, 2020 Document Classification Videos Spark NLP in Action: Learning to read Life Science research - Saif Addin Ellafi. Saif Addin Ellafi - 1 Aug 2018 State of the art emotion and sentiment analysis with Spark NLP (Data science Salon). Dia Trambitas - December 1, 2020 Articles GloVe, ELMo &amp; BERT. A guide to state-of-the-art text classification using Spark NLP Ryan Burke - March 16, 2021 Distributed Topic Modelling using Spark NLP and Spark MLLib(LDA)Satish Silveri - June 11, 2020 Text Classification in Spark NLP with Bert and Universal Sentence EncodersVeysel Kocaman - April 12, 2020 Classification of Unstructured Documents into the Environmental, Social &amp; Governance (ESG) TaxonomyAlina Petukhova - May, 2020 Using Spark NLP to build a drug discovery knowledge graph for COVID-19Vishnu Vettrivel, Alexander Thomas - October 8, 2020 Build Text Categorization Model with Spark NLPSatish Silveri - Jul 8 2020 Topic Modelling with PySpark and Spark NLPMaria Obedkova - May 29 2020 Spark NLP Tasks &amp; Pipelines Videos Spark NLP Annotators, Annotations and Pipelines. John Snow Labs - 23 Oct 2019 Your first Spark NLP Pipeline. John Snow Labs - 23 Oct 2019 Natural Language Understanding at Scale with Spark NLP | DSS 2020. Veysel Kocaman - December 12, 2020 Articles Cleaning and extracting text from HTML/XML documents by using Spark NLPStefano Lori - January 13 2021 NER model with ELMo Embeddings in 5 minutes in Spark-NLPChristian Kasim Loan - Jule 2020 Applying Context Aware Spell Checking in Spark NLPAlberto Andreotti - May 2020 Spark nlp 2.5 delivers state-of-the-art accuracy for spell checking and sentiment analysisIda Lucente - May 12, 2020 Spark NLP 2.4: More Accurate NER, OCR, and Entity ResolutionIda Lucente - February 14, 2020 Introduction to Spark NLP: Foundations and Basic Components (Part-I)Veysel Kocaman - Sep 29, 2019 Introducing Spark NLP: Why would we need another NLP library (Part-I)Veysel Kocaman - October 22, 2019 Introducing Spark NLP: basic components and underlying technologies (Part-III)Veysel Kocaman - December 2, 2019 Explain document DL – Spark NLP pretrained pipelineVeysel Kocaman - January 15, 2020 Spark NLP Walkthrough, powered by TensorFlowSaif Addin Ellafi - Nov 19, 2018 Natural Language Processing with PySpark and Spark-NLPAllison Honold - Feb 5, 2020 Spark NLP for Healthcare Videos Advancing the State of the Art in Applied Natural Language Processing | Healthcare NLP Summit 2021. David Talby - 21 Apr 2021 How to Apply State-of-the-Art Natural Language Processing in Healthcare. David Talby - 15 Sep 2020 Advanced Natural Language Processing with Apache Spark NLP. David Talby - 20 Aug 2020 Applying State-of-the-art Natural Language Processing for Personalized Healthcare. David Talby - April 13, 2020 State-of-the-art Natural Language Processing at Scale. David Talby - April 13, 2020 Apache SPARK NLP: Extending SPARK ML to Deliver Fast, Scalable &amp; Unified Natural Language Processing. David Talby - June 04, 2018 State of the Art Natural Language Processing at Scale. David Talby - June 04, 2018 Spark NLP in Action: Learning to read Life Science research. Saif Addin Ellafi - May 28, 2018 Natural Language Understanding at Scale with Spark-Native NLP, Spark ML, and TensorFlow. Alexander Thomas - October 14, 2018 Apache Spark NLP for Healthcare: Lessons Learned Building Real-World Healthcare AI Systems. Veysel Kocaman - 9 Jul 2020 SNOMED entity resolver. John Snow Labs - 31 Jul 2020 NLP and its applications in Healthcare. Veysel Kocaman - 17 May 2020 Lessons Learned Building Real-World Healthcare AI Systems. Veysel Kocaman - April 13, 2020 Application of Spark NLP for Development of Multi-Modal Prediction Model from EHR | Healthcare NLP. Sutanay Choudhury - 14 Apr 2021 Best Practices in Improving NLP Accuracy for Clinical Use Cases I Healthcare NLP Summit 2021. Rajesh Chamarthi, Veysel Kocaman - 15 Apr 2021 Articles Contextual Parser: Increased Flexibility Extracting Entities in Spark NLPLuca Martial - Feb 09 2022 Named Entity Recognition for Healthcare with SparkNLP NerDL and NerCRFMaggie Yilmaz - Jul 20 2020 Roche automates knowledge extraction from pathology reports with Spark NLPCase Study Spark NLP in action: Improving patient flow forecastingCase Study Using Spark NLP to Enable Real-World Evidence (RWE) and Clinical Decision Support in OncologyVeysel Kocaman - April 13, 2020 Applying State-of-the-art Natural Language Processing for Personalized HealthcareDavid Talby - April 13, 2020 Automated Mapping of Clinical Entities from Natural Language Text to Medical TerminologiesAndrés Fernández - April 29 2020 Contextual Parser in Spark NLP: Extracting Medical Entities ContextuallyAlina Petukhova - May 28 2020 Deep6 accelerates clinical trial recruitment with Spark NLPCase Study SelectData uses AI to better understand home health patientsCase Study Explain Clinical Document Spark NLP Pretrained PipelineVeysel Kocaman - January 20, 2020 Introducing Spark NLP: State of the art NLP Package (Part-II)Veysel Kocaman - January 20, 2020 Automated Adverse Drug Event (ADE) Detection from Text in Spark NLP with BioBertVeysel Kocaman - Octover 4, 2020 Normalize drug names and dosage units with spark NLPDavid Cecchini - February 23, 2021 Spark NLP for healthcare 2.7.3 with biobert extraction models, higher accuracy, de-identification, new radiology ner model &amp; moreVeysel Kocaman - February 09, 2021 Spark OCR &amp; De-Identification Videos Maximizing Text Recognition Accuracy with Image Transformers in Spark OCR. Mykola Melnyk - June 24, 2020 Accurate de-identification, obfuscation, and editing of scanned medical documents and images. Alina Petukhova - August 19, 2020 Accurate De-Identification of Structured &amp; Unstructured Medical Data at Scale. Julio Bonis - March 18, 2020 Articles A Unified CV, OCR &amp; NLP Model Pipeline for Document Understanding at DocuSignPatrick Beukema, Michael Chertushkin - October 6, 2020 Scaling High-Accuracy Text Extraction from Images using Spark OCR on DatabricksMikola Melnyk - July 2, 2020 Spark NLP at Scale Videos Turbocharging State-of-the-art Natural Language Processing on Ray. David Talby - October 3, 2020 Articles Big Data Analysis of Meetup Events using Spark NLP, Kafka and Vegas VisualizationAndrei Deuşteanu - August 25, 2020 Setup Spark NLP on Databricks in 2 Minutes and get the taste of scalable NLPChristian Kasim Loan - May 25, 2020 Real-time trending topic detection using Spark NLP, Kafka and Vegas VisualizationValentina Crisan - Oct 15, 2020 Mueller Report for Nerds! Spark meets NLP with TensorFlow and BERTMaziyar Panahi - May 1, 2019 Spark in Docker in Kubernetes: A Practical Approach for Scalable NLPJürgen Schmidl - Jan 18 2020 Running Spark NLP in Docker Container for Named Entity Recognition and Other NLP FeaturesYuefeng Zhang - Jun 5 2020 Annotation Lab Videos Accelerating Clinical Data Abstraction and Real-World Data Curation with Active Learning, Dia Trambitas - Apr 15, 2021 MLOPS Veysel &amp; Dia. Dia Trambitas, Veysel Kocaman - July 16, 2020 Best Practices &amp; Tools for Accurate Document Annotation and Data Abstraction. Dia Trambitas - May 27, 2020 Articles John Snow Labs’ data annotator &amp; active learning for human-in-the-loop AI is now included with all subscriptionsIda Lucente - May 26, 2020 Auto NLP: Pretrain, Tune &amp; Deploy State-of-the-art Models Without CodingDia Trambitas - October 6, 2020 Lesson Learned annotating training data for healthcare NLP projectsRebecca Leung, Marianne Mak - October 8, 2020 Task review workflows in the annotation labDia Trambitas - March 08, 2021 The annotation lab 1.1 is here with improvements to speed, accuracy, and productivityIda Lucente - January 20, 2021 Tips and tricks on how to annotate assertion in clinical textsMauro Nievas Offidani - November 24, 2020 Spark NLP Benchmarks Articles Biomedical Named Entity Recognition at ScaleVeysel Kocaman, David Talby - November 12, 2020 NLP Industry Survey Analysis: the industry landscape of natural language use cases in 2020Paco Nathan - October 6, 2020 Comparing the Functionality of Open Source Natural Language Processing LibrariesMaziyar Panahi and David Talby - April 7, 2019 SpaCy or Spark NLP — A Benchmarking ComparisonMustafa Aytuğ Kaya - Aug 27, 2020 Comparing production-grade NLP libraries: Training Spark-NLP and spaCy pipelinesSaif Addin Ellafi - February 28, 2018 Comparing production-grade NLP libraries: Running Spark-NLP and spaCy pipelinesSaif Addin Ellafi - February 28, 2018 Comparing production-grade NLP libraries: Accuracy, performance, and scalabilitySaif Addin Ellafi - February 28, 2018 Spark NLP Awards Articles John Snow Labs is healthcare tech outlook’s 2020 healthcare analytics provider of the yearIda Lucente - July 14, 2020 John Snow Labs wins the 2020 artificial intelligence excellence awardIda Lucente - April 27, 2020 John Snow Labs is named ‘2019 ai platform of the yearIda Lucente - August 14, 2019 Spark NLP is the world’s most widely used nlp library by enterprise practitionersIda Lucente - May 6, 2019 John Snow Labs’ spark nlp wins “most significant open source project” at the strata data awardsIda Lucente April 1 - 2019 John Snow Labs named “artificial intelligence solution provider of the year” by cio reviewIda Lucente - February 7, 2019",
    "url": "/learnold",
    "relUrl": "/learnold"
  },
  "1236": {
    "id": "1236",
    "title": "The NLP Learning Hub",
    "content": "The Technology Spark NLP Healthcare NLP Spark OCR NLP Lab Auto NLP Multimodal AI The Technology in Action Medical AI Applications Finance AI Applications De-Identification Multilingual NLP NLP on Databricks Industry Trends AI in Healthcare No-Code AI Responsible NLP Data Philanthropy Announcements Awards",
    "url": "/learn",
    "relUrl": "/learn"
  },
  "1237": {
    "id": "1237",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_assertion_status",
    "relUrl": "/legal_assertion_status"
  },
  "1238": {
    "id": "1238",
    "title": "Normalization & Data Augmentation - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_company_normalization",
    "relUrl": "/legal_company_normalization"
  },
  "1239": {
    "id": "1239",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_deidentification",
    "relUrl": "/legal_deidentification"
  },
  "1240": {
    "id": "1240",
    "title": "Recognize Legal Entities - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_entity_recognition",
    "relUrl": "/legal_entity_recognition"
  },
  "1241": {
    "id": "1241",
    "title": "Extract Legal Relationships - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_relation_extraction",
    "relUrl": "/legal_relation_extraction"
  },
  "1242": {
    "id": "1242",
    "title": "Legal NLP Release Notes",
    "content": "Releases log         1.0.0 1.1.0 1.2.0 1.3.0 1.4.0 1.5.0 1.6.0 1.7.0 1.8.0 1.9.0     Slack - Join #legal channel",
    "url": "/docs/en/legal_release_notes",
    "relUrl": "/docs/en/legal_release_notes"
  },
  "1243": {
    "id": "1243",
    "title": "Spark NLP in Action",
    "content": "",
    "url": "/legal_table_extraction",
    "relUrl": "/legal_table_extraction"
  },
  "1244": {
    "id": "1244",
    "title": "Classify Legal Texts - Legal NLP Demos & Notebooks",
    "content": "",
    "url": "/legal_text_classification",
    "relUrl": "/legal_text_classification"
  },
  "1245": {
    "id": "1245",
    "title": "Version Compatibility",
    "content": "Legal NLP runs on top of johnsnowlabs library (former nlu). Please find technical documentation about how to install it here. All our models are backwards compatible, which means it will be safe for you to always use the last version of johnsnowlabs. If you are curious about which version of Spark NLP, Visual NLP or Clinical NLP are included in the last johnsnowlabs versions, please check here Legal NLP is also supported in Annotation Lab from Alab 4.2.3 version on!",
    "url": "/docs/en/legal_version_compatibility",
    "relUrl": "/docs/en/legal_version_compatibility"
  },
  "1246": {
    "id": "1246",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/lemmatizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/lemmatizer.html"
  },
  "1247": {
    "id": "1247",
    "title": "Enterprise Spark NLP",
    "content": "PythonScalaNLU spark-nlp-jsljohnsnowlabs ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) val pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;token&quot;,&quot;sentence&quot;) .setOutputCol(&quot;pos&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, pos)) val data = Seq(&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) import nlu nlu.load(&quot;en.pos.clinical&quot;).predict(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) Getting started We call Enterprise Spark NLP libraries to all the commercial NLP libraries, including Healthcare NLP (former Spark NLP for Healthcare), Finance, Legal NLP, among others. This excludes Visual NLP (former Spark OCR), which has its own documentation page, available here. If you don’t have an Enterprise Spark NLP subscription yet, you can ask for a free trial by clicking on the Try Free button and following the instructions provides in the video below. Try Free 30-day free trials for the John Snow Labs NLP libraries can be obtained via AWS and Azure markeplaces. To get a free trial please subscribe to one of the pay-as-you-go products: John Snow Labs NLP Libraries - AWS Marketplace John Snow Labs NLP Libraries - Azure Marketplace Note: It is important to note that every AWS/Azure account is limited to one 30-day free trial period for John Snow Labs NLP Libraries, and users are responsible for verifying the status of any past trials before subscribing and being charged for usage. Enterprise Spark NLP libraries provides healthcare-specific annotators, pipelines, models, and embeddings for: Entity recognition Entity Linking Entity normalization Assertion Status Detection De-identification Relation Extraction Spell checking &amp; correction and much more!",
    "url": "/docs/en/license_getting_started",
    "relUrl": "/docs/en/license_getting_started"
  },
  "1248": {
    "id": "1248",
    "title": "License Management & Caching",
    "content": "Storage of License Data and License Search behaviour The John Snow Labs library caches license data in ~/.johnsnowlabs/licenses whenever a new one is provided . After having provided license data once, you don’t need to specify it again since the cached licensed will be used. Use the local_license_number and remote_license_number parameters to switch between multiple licenses. Note: Locally cached licenses are numbered in the order they have been provided, starting at 0. remote_license_number=0 might not be the same as local_license_number=0. Use the following functions to see all your avaiable licenses. List all available licenses This shows you all licenses for your account in https://my.johnsnowlabs.com/. Use this to decide which license number to install when installing via browser or access token. nlp..list_remote_licenses() List all locally cached licenses Use this to decide which license number to use when using nlp..start() or nlp..install() to specify which local license you want to load. nlp..list_local_licenses() License Search precedence If there are multiples possible sources for licenses, the following order takes precedence: Manually provided license data by defining all license parameters. Browser/ Access Token. Os environment Variables for any var names that match up with secret names. /content/*.json for any json file smaller than 1 MB. current_working_dir/*.json for any json smaller than 1 MB. ~/.johnsnowlabs/licenses for any licenses. JSON files are scanned if they have any keys that match up with names of secrets. Name of the json file does not matter, file just needs to end with .json.",
    "url": "/docs/en/nlplicense_management",
    "relUrl": "/docs/en/nlplicense_management"
  },
  "1249": {
    "id": "1249",
    "title": "Enterprise NLP Annotators",
    "content": "A Spark NLP Enterprise license includes access to unique annotators. At the Spark NLP Workshop you can see different types of annotators in action. By clicking on any annotator, you will see different sections: The Approach, or class to train models. The Model, to infer using pretrained models. Also, for most of the annotators, you will find examples for the different enterprise libraries: Healthcare NLP Finance NLP Legal NLP Check out the Spark NLP Annotators page for more information on how to read this page. Available Annotators Annotators Description AssertionDL AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionFilterer Filters entities coming from ASSERTION type annotations and returns the CHUNKS. AssertionLogReg Logistic Regression is used to extract Assertion Status from extracted entities and text. Chunk2Token A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN). ChunkEntityResolver Returns a normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database, etc). ChunkFilterer Filters entities coming from CHUNK annotations. ChunkKeyPhraseExtraction Uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. ChunkMerge Merges entities coming from different CHUNK annotations. ContextualParser Extracts entity from a document based on user defined rules. DeIdentification Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS. DocumentLogRegClassifier Classifies documents with a Logarithmic Regression algorithm. DrugNormalizer Annotator which normalizes raw text from documents, e.g. scraped web pages or xml documents FeaturesAssembler Collects features from different columns. GenericClassifier Creates a generic single-label classifier which uses pre-generated Tensorflow graphs. IOBTagger Merges token tags and NER labels from chunks in the specified format. NerChunker Extracts phrases that fits into a known pattern using the NER tags. NerConverterInternal Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. NerDisambiguator Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). MedicalNer This Named Entity recognition annotator is a generic NER model based on Neural Networks.. RENerChunksFilter Filters and outputs combinations of relations between extracted entities, for further processing. ReIdentification Reidentifies obfuscated entities by DeIdentification. RelationExtraction Extracts and classifies instances of relations between named entities. RelationExtractionDL Extracts and classifies instances of relations between named entities. SentenceEntityResolver Returns the normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database, etc) based on sentence embeddings. AnnotationMerger Merge annotations from different pipeline steps that have the same annotation type into a unified annotation. Possible annotations that can be merged include: document (e.g., output of DocumentAssembler annotator) token (e.g., output of Tokenizer annotator) word_embeddings (e.g., output of WordEmbeddingsModel annotator) sentence_embeddings (e.g., output of BertSentenceEmbeddings annotator) category (e.g., output of RelationExtractionModel annotator) date (e.g., output of DateMatcher annotator) sentiment (e.g., output of SentimentDLModel annotator) pos (e.g., output of PerceptronModel annotator) chunk (e.g., output of NerConverter annotator) named_entity (e.g., output of NerDLModel annotator) regex (e.g., output of RegexTokenizer annotator) dependency (e.g., output of DependencyParserModel annotator) language (e.g., output of LanguageDetectorDL annotator) keyword (e.g., output of YakeModel annotator) Input Annotator Types: ANY Output Annotator Type: ANY Python API: AnnotationMerger Scala API: AnnotationMerger Show Example PythonScala Medical # Create the pipeline with two RE models documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) pos_ner_tagger = MedicalNerModel() .pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner_pos&quot;) pos_ner_chunker = NerConverterInternal() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_pos&quot;]) .setOutputCol(&quot;pos_ner_chunks&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) pos_reModel = RelationExtractionModel() .pretrained(&quot;posology_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;pos_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;pos_relations&quot;) .setMaxSyntacticDistance(4) ade_ner_tagger = MedicalNerModel.pretrained(&quot;ner_ade_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ade_ner_tags&quot;) ade_ner_chunker = NerConverterInternal() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ade_ner_tags&quot;]) .setOutputCol(&quot;ade_ner_chunks&quot;) ade_reModel = RelationExtractionModel() .pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ade_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;ade_relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) annotation_merger = AnnotationMerger() .setInputCols(&quot;ade_relations&quot;, &quot;pos_relations&quot;) .setInputType(&quot;category&quot;) .setOutputCol(&quot;all_relations&quot;) merger_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, pos_ner_tagger, pos_ner_chunker, dependency_parser, pos_reModel, ade_ner_tagger, ade_ner_chunker, ade_reModel, annotation_merger ]) empty_df= spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) merger_model= merger_pipeline.fit(empty_df) # Show example result text = &quot;&quot;&quot; The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = merger_model.transform(data) result.show() +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ text| document| sentences| tokens| embeddings| pos_tags| ner_pos| pos_ner_chunks| dependencies| pos_relations| ade_ner_tags| ade_ner_chunks| ade_relations| all_relations| +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ The patient was ...|[{document, 0, 26...|[{document, 1, 95...|[{token, 1, 3, Th...|[{word_embeddings...|[{pos, 1, 3, DD, ...|[{named_entity, 1...|[{chunk, 28, 33, ...|[{dependency, 1, ...|[{category, 28, 4...|[{named_entity, 1...|[{chunk, 38, 45, ...|[{category, 134, ...|[{category, 134, ...| +--+--+--+--+--+--+--+--+--+--+--+--+--+--+ AssertionChunkConverter This annotator creates a CHUNK column with metadata useful for training an Assertion Status Detection model (see AssertionDL). In some cases, there may be issues while creating the chunk column when using token indices that can lead to loss of data to train assertion status models. The AssertionChunkConverter annotator uses both begin and end indices of the tokens as input to add a more robust metadata to the chunk column in a way that improves the reliability of the indices and avoid loss of data. NOTE: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of ALAB module. Input Annotator Types: TOKEN Output Annotator Type: CHUNK Python API: AssertionChunkConverter Scala API: AssertionChunkConverter Show Example PythonScala Medical data = spark.createDataFrame( [ [ &quot;An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.&quot;, &quot;Minnie&quot;, 57, 64, ], [ &quot;After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation &quot;, &quot;PCP&quot;, 31, 34, ], ] ).toDF(&quot;text&quot;, &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;) document_assembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;tokens&quot;) converter = ( AssertionChunkConverter() .setInputCols(&quot;tokens&quot;) .setChunkTextCol(&quot;target&quot;) .setChunkBeginCol(&quot;char_begin&quot;) .setChunkEndCol(&quot;char_end&quot;) .setOutputTokenBeginCol(&quot;token_begin&quot;) .setOutputTokenEndCol(&quot;token_end&quot;) .setOutputCol(&quot;chunk&quot;) ) pipeline = Pipeline().setStages( [document_assembler, sentenceDetector, tokenizer, converter] ) results = pipeline.fit(data).transform(data) results.selectExpr( &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;, &quot;token_begin&quot;, &quot;token_end&quot;, &quot;tokens[token_begin].result&quot;, &quot;tokens[token_end].result&quot;, &quot;target&quot;, &quot;chunk&quot;, ).show(truncate=False) ++-+--+--++--+++-+ |target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk | ++-+--+--++--+++-+ |Minnie|57 |64 |10 |10 |Minnie |Minnie |Minnie|[{chunk, 57, 62, Minnie, {sentence -&gt; 0}, []}]| |PCP |31 |34 |5 |5 |PCP |PCP |PCP |[{chunk, 31, 33, PCP, {sentence -&gt; 0}, []}] | ++-+--+--++--+++-+ AssertionDL ApproachModel Trains AssertionDL, a deep Learning based approach used to extract Assertion Status from extracted entities and text. Contains all the methods for training an AssertionDLModel. For pretrained models please use AssertionDLModel and see the Models Hub for available models. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLApproach Scala API: AssertionDLApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Define AssertionDLApproach with parameters and start training assertionStatus = medical.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012) .setLearningRate(0.015) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) trainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Define AssertionDLApproach with parameters and start training assertionStatus = finance.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012) .setLearningRate(0.015) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) trainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * # First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. document = nlp.DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;doc_chunk&quot;) token = nlp.Tokenizer() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;token&#39;) roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) # Define AssertionDLApproach with parameters and start training assertionStatus = legal.AssertionDLApproach() .setLabelCol(&quot;assertion_label&quot;) .setInputCols(&quot;document&quot;, &quot;doc_chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setLearningRate(0.001) .setEpochs(2) .setStartCol(&quot;tkn_start&quot;) .setEndCol(&quot;tkn_end&quot;) .setMaxSentLen(1200) .setEnableOutputLogs(True) .setOutputLogsPath(&#39;training_logs/&#39;) .setGraphFolder(graph_folder) .setGraphFile(f&quot;{graph_folder}/assertion_graph.pb&quot;) .setTestDataset(path=&quot;test_data.parquet&quot;, read_as=&#39;SPARK&#39;, options={&#39;format&#39;: &#39;parquet&#39;}) .setScopeWindow(scope_window) #.setValidationSplit(0.2) #.setDropout(0.1) trainingPipeline = Pipeline().setStages([ document, chunk, token, roberta_embeddings, assertionStatus ]) assertionModel = trainingPipeline.fit(data) assertionResults = assertionModel.transform(data).cache() MedicalFinanceLegal from johnsnowlabs import * // First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. val document = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Define AssertionDLApproach with parameters and start training val assertionStatus = new medical.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012f) .setLearningRate(0.015f) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * // First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined. val document = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Define AssertionDLApproach with parameters and start training val assertionStatus = new finance.AssertionDLApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setDropout(0.012f) .setLearningRate(0.015f) .setEpochs(1) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setMaxSentLen(250) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() from johnsnowlabs import * val document = new nlp.DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;doc_chunk&quot;) .setChunkCol(&quot;chunk&quot;) .setStartCol(&quot;tkn_start&quot;) .setStartColByTokenIndex(True) .setFailOnMissing(False) .setLowerCase(False) val token = new nlp.Tokenizer() .setInputCols([&#39;document&#39;]) .setOutputCol(&#39;token&#39;) val roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) # Define AssertionDLApproach with parameters and start training val assertionStatus = new legal.AssertionDLApproach() .setLabelCol(&quot;assertion_label&quot;) .setInputCols(&quot;document&quot;, &quot;doc_chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setBatchSize(128) .setLearningRate(0.001) .setEpochs(2) .setStartCol(&quot;tkn_start&quot;) .setEndCol(&quot;tkn_end&quot;) .setMaxSentLen(1200) .setEnableOutputLogs(True) .setOutputLogsPath(&#39;training_logs/&#39;) .setGraphFolder(graph_folder) .setGraphFile(f&quot;{graph_folder}/assertion_graph.pb&quot;) .setTestDataset(path=&quot;test_data.parquet&quot;, read_as=&#39;SPARK&#39;, options={&#39;format&#39;: &#39;parquet&#39;}) .setScopeWindow(scope_window) #.setValidationSplit(0.2) #.setDropout(0.1) val trainingPipeline = new Pipeline().setStages(Array( document, chunk, token, roberta_embeddings, assertionStatus )) val assertionModel = trainingPipeline.fit(data) val assertionResults = assertionModel.transform(data).cache() AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionDLModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type annotator inputs, which can be obtained by e.g a DocumentAssembler, NerConverter and WordEmbeddingsModel. The result is an assertion status annotation for each recognized entity. Possible values include “present”, “absent”, “hypothetical”, “conditional”, “associated_with_other_person” etc. For pretrained models please see the Models Hub for available models. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLModel Scala API: AssertionDLModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to extract NER chunks first data = spark.createDataFrame([ [&quot;Patient with severe fever and sore throat&quot;], [&quot;Patient shows no stomach pain&quot;], [&quot;She was maintained on an epidural and PCA for pain control.&quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setOutputCol(&quot;embeddings&quot;) nerModel = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Then a pretrained AssertionDLModel is used to extract the assertion status clinicalAssertion = medical.AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion ]) assertionModel = assertionPipeline.fit(data) # Show results result = assertionModel.transform(data) result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=False) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ from johnsnowlabs import * data = spark.createDataFrame([[&quot;Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc.&quot;]]).toDF(&quot;text&quot;) document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) assertion = finance.AssertionDLModel.pretrained(&quot;finassertion_competitors&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, assertion ]) assertionModel = pipeline.fit(data) # Show results result = assertionModel.transform(data) result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata, result.assertion.result)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;1&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sent_id&quot;), F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;2&#39;]&quot;).alias(&quot;assertion&quot;)).show(truncate=False) +-+++-+ |sent_id|chunk |ner_label|assertion | +-+++-+ |0 |McAfee LLC |ORG |COMPETITOR| |0 |Broadcom Inc|ORG |COMPETITOR| +-+++-+ from johnsnowlabs import * data = spark.createDataFrame([[&quot;This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc.&quot;]]).toDF(&quot;text&quot;) document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings_ner = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings_ner&quot;) ner_model = legal.NerModel.pretrained(&#39;legner_contract_doc_parties&#39;, &#39;en&#39;, &#39;legal/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings_ner&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;DOC&quot;, &quot;EFFDATE&quot;, &quot;PARTY&quot;]) embeddings_ass = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings_ass&quot;) assertion = legal.AssertionDLModel.pretrained(&quot;legassertion_time&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings_ass&quot;]) .setOutputCol(&quot;assertion&quot;) nlpPipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings_ner, ner_model, ner_converter, embeddings_ass, assertion ]) assertionModel = nlpPipeline.fit(data) # Show results result = assertionModel.transform(data) result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.begin, result.ner_chunk.end, result.ner_chunk.metadata, result.assertion.result)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols[&#39;2&#39;]&quot;).alias(&quot;end&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;4&#39;]&quot;).alias(&quot;assertion&quot;)).show(truncate=False) +-+--++++ |chunk |begin|end|ner_label|assertion| +-+--++++ |Intellectual Property Agreement|11 |41 |DOC |PRESENT | |Amazon Inc |51 |60 |PARTY |PRESENT | |Atlantic Inc |67 |78 |PARTY |PRESENT | +-+--++++ MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to extract NER chunks first val data = Seq( &quot;Patient with severe fever and sore throat&quot;, &quot;Patient shows no stomach pain&quot;, &quot;She was maintained on an epidural and PCA for pain control.&quot;).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embeddings&quot;) val nerModel = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Then a pretrained AssertionDLModel is used to extract the assertion status val clinicalAssertion = medical.AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion )) val assertionModel = assertionPipeline.fit(data) // Show results val result = assertionModel.transform(data) result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=false) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ from johnsnowlabs import * val data = Seq(&quot;Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc.&quot;).toDF(&quot;text&quot;) val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val assertion = finance.AssertionDLModel.pretrained(&quot;finassertion_competitors&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, assertion ) val assertionModel = pipeline.fit(data) from johnsnowlabs import * val data = Seq(&quot;This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc.&quot;).toDF(&quot;text&quot;) val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings_ner = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings_ner&quot;) val ner_model = legal.NerModel.pretrained(&#39;legner_contract_doc_parties&#39;, &#39;en&#39;, &#39;legal/models&#39;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings_ner&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(Array(&quot;DOC&quot;, &quot;EFFDATE&quot;, &quot;PARTY&quot;)) val embeddings_ass = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings_ass&quot;) val assertion = legal.AssertionDLModel.pretrained(&quot;legassertion_time&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings_ass&quot;)) .setOutputCol(&quot;assertion&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, embeddings_ner, ner_model, ner_converter, embeddings_ass, assertion ) val assertionModel = pipeline.fit(data) AssertionFilterer Filters entities coming from ASSERTION type annotations and returns the CHUNKS. Filters can be set via a white list on the extracted chunk, the assertion or a regular expression. White list for assertion is enabled by default. To use chunk white list, criteria has to be set to &quot;isin&quot;. For regex, criteria has to be set to &quot;regex&quot;. Input Annotator Types: DOCUMENT, CHUNK, ASSERTION Output Annotator Type: CHUNK Python API: AssertionFilterer Scala API: AssertionFilterer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = medical.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) # Show results: result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=False) +--+--+ |result |result | +--+--+ |[severe fever, sore throat] |[present, present] | |[stomach pain] |[absent] | |[an epidural, PCA, pain control]|[present, present, hypothetical]| +--+--+ result.select(&quot;filtered.result&quot;).show(3, truncate=False) ++ |result | ++ |[severe fever, sore throat]| |[] | |[an epidural, PCA] | ++ from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = finance.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) from johnsnowlabs import * # To see how the assertions are extracted, see the example for AssertionDLModel. # Define an extra step where the assertions are filtered assertionFilterer = legal.AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;present&quot;]) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer ]) assertionModel = assertionPipeline.fit(data) result = assertionModel.transform(data) MedicalFinanceLegal from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new medical.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) // Show results: // // result.selectExpr(&quot;ner_chunk.result&quot;, &quot;assertion.result&quot;).show(3, truncate=false) // +--+--+ // |result |result | // +--+--+ // |[severe fever, sore throat] |[present, present] | // |[stomach pain] |[absent] | // |[an epidural, PCA, pain control]|[present, present, hypothetical]| // +--+--+ // result.select(&quot;filtered.result&quot;).show(3, truncate=false) // ++ // |result | // ++ // |[severe fever, sore throat]| // |[] | // |[an epidural, PCA] | // ++ // from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new legal.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) from johnsnowlabs import * // To see how the assertions are extracted, see the example for // [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]]. // Define an extra step where the assertions are filtered val assertionFilterer = new legal.AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList(&quot;present&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, clinicalAssertion, assertionFilterer )) val assertionModel = assertionPipeline.fit(data) val result = assertionModel.transform(data) AssertionLogReg ApproachModel Trains a classification method, which uses the Logarithmic Regression Algorithm. It is used to extract Assertion Status from extracted entities and text. Contains all the methods for training a AssertionLogRegModel, together with trainWithChunk, trainWithStartEnd. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegApproach Scala API: AssertionLogRegApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = medical.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = finance.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * # Training with Glove Embeddings # First define pipeline stages to extract embeddings and text chunks documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(False) chunkAssembler = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) # Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. assertion = legal.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols([&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) assertionPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion ]) assertionModel = assertionPipeline.fit(dataset) MedicalFinanceLegal from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new medical.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new finance.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) from johnsnowlabs import * // Training with Glove Embeddings // First define pipeline stages to extract embeddings and text chunks val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val glove = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) .setCaseSensitive(false) val chunkAssembler = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) // Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training. val assertion = new legal.AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(Array(&quot;document&quot;, &quot;chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val assertionPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, assertion )) val assertionModel = assertionPipeline.fit(dataset) This is a main class in AssertionLogReg family. Logarithmic Regression is used to extract Assertion Status from extracted entities and text. AssertionLogRegModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type annotator inputs, which can be obtained by e.g a DocumentAssembler, NerConverter and WordEmbeddingsModel. The result is an assertion status annotation for each recognized entity. Possible values are &quot;Negated&quot;, &quot;Affirmed&quot; and &quot;Historical&quot;. Unlike the DL Model, this class does not extend AnnotatorModel. Instead it extends the RawAnnotator, that’s why the main point of interest is method transform(). At the moment there are no pretrained models available for this class. Please refer to AssertionLogRegApproach to train your own model. Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegModel Scala API: AssertionLogRegModel BertSentenceChunkEmbeddings This annotator allows aggregating sentence embeddings with ner chunk embeddings to get specific and more accurate resolution codes. It works by averaging sentence and chunk embeddings add contextual information in the embedding value. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. For more information and examples of BertSentenceChunkEmbeddings annotator, you can check the Spark NLP Workshop, and in special, the notebook 24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: SENTENCE_EMBEDDINGS Python API: BertSentenceChunkEmbeddings Scala API: BertSentenceChunkEmbeddings Show Example PythonScala Medical # Define the pipeline document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = medical.NerModel.pretrained(&quot;ner_abbreviation_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = medical.NerConverterInternal() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;ABBR&#39;]) sentence_chunk_embeddings = medical.BertSentenceChunkEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setChunkWeight(0.5) .setCaseSensitive(True) abbr_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_clinical_abbreviation_acronym&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;abbr_meaning&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver_pipeline = Pipeline( stages = [ document_assembler, tokenizer, word_embeddings, clinical_ner, ner_converter, sentence_chunk_embeddings, abbr_resolver ]) # Example results sample_text = [ &quot;&quot;&quot;The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSES: 1. A 58-year-old female with a history of stage 2 squamous cell carcinoma of the cervix status post total pelvic exenteration in 1991.&quot;&quot;&quot;, &quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] from pyspark.sql.types import StringType, IntegerType df = spark.createDataFrame(sample_text, StringType()).toDF(&#39;text&#39;) df.show(truncate = 100) +-+ | text| +-+ |The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSE...| |Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA...| +-+ Medical val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;tokens&quot;) val wordEmbeddings = BertEmbeddings .pretrained(&quot;biobert_pubmed_base_cased&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val nerModel = MedicalNerModel .pretrained(&quot;ner_clinical_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new NerConverter() .setInputCols(&quot;sentence&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) val sentenceChunkEmbeddings = BertSentenceChunkEmbeddings .pretrained(&quot;sbluebert_base_uncased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;sentence_chunk_embeddings&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, wordEmbeddings, nerModel, nerConverter, sentenceChunkEmbeddings)) val sampleText = &quot;Her Diabetes has become type 2 in the last year with her Diabetes.&quot; + &quot; He complains of swelling in his right forearm.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(sentence_chunk_embeddings) AS s&quot;) .selectExpr(&quot;s.result&quot;, &quot;slice(s.embeddings, 1, 5) AS averageEmbedding&quot;) .show(truncate=false) +--+--+ | result| averageEmbedding| +--+--+ |Her Diabetes |[-0.31995273, -0.04710883, -0.28973156, -0.1294758, 0.12481072] | |type 2 |[-0.027161136, -0.24613449, -0.0949309, 0.1825444, -0.2252143] | |her Diabetes |[-0.31995273, -0.04710883, -0.28973156, -0.1294758, 0.12481072] | |swelling in his right forearm|[-0.45139068, 0.12400375, -0.0075617577, -0.90806055, 0.12871636]| +--+--+ Chunk2Token A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN). When the input is empty, an empty array is returned. This Annotator is specially convenient when using NGramGenerator annotations as inputs to WordEmbeddingsModels Input Annotator Types: CHUNK Output Annotator Type: TOKEN Scala API: Chunk2Token Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define a pipeline for generating n-grams data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = medical.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]).fit(data) result = trainingPipeline.transform(data).cache() result.selectExpr(&quot;explode(ngram_tokens)&quot;).show(5, False) +-+ |col | +-+ |{token, 3, 15, A_63-year-old, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{token, 5, 19, 63-year-old_man, {sentence -&gt; 0, chunk -&gt; 1}, []}| |{token, 17, 28, man_presents, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{token, 21, 31, presents_to, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{token, 30, 35, to_the, {sentence -&gt; 0, chunk -&gt; 4}, []} | +-+ from johnsnowlabs import * # Define a pipeline for generating n-grams document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = finance.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]) from johnsnowlabs import * # Define a pipeline for generating n-grams document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) token = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) ngrammer = nlp.NGramGenerator() .setN(2) .setEnableCumulative(False) .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) # Stage to convert n-gram CHUNKS to TOKEN type chunk2Token = legal.Chunk2Token().setInputCols([&quot;ngrams&quot;]).setOutputCol(&quot;ngram_tokens&quot;) trainingPipeline = Pipeline(stages=[document, sentenceDetector, token, ngrammer, chunk2Token]) MedicalFinanceLegal from johnsnowlabs import * // Define a pipeline for generating n-grams val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new medical.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)).fit(data) val result = trainingPipeline.transform(data).cache() result.selectExpr(&quot;explode(ngram_tokens)&quot;).show(5, false) +-+ |col | +-+ |{token, 3, 15, A_63-year-old, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{token, 5, 19, 63-year-old_man, {sentence -&gt; 0, chunk -&gt; 1}, []}| |{token, 17, 28, man_presents, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{token, 21, 31, presents_to, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{token, 30, 35, to_the, {sentence -&gt; 0, chunk -&gt; 4}, []} | +-+ from johnsnowlabs import * // Define a pipeline for generating n-grams val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new finance.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)) from johnsnowlabs import * // Define a pipeline for generating n-grams val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val token = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val ngrammer = new nlp.NGramGenerator() .setN(2) .setEnableCumulative(false) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;ngrams&quot;) .setDelimiter(&quot;_&quot;) // Stage to convert n-gram CHUNKS to TOKEN type val chunk2Token = new legal.Chunk2Token().setInputCols(&quot;ngrams&quot;).setOutputCol(&quot;ngram_tokens&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, sentenceDetector, token, ngrammer, chunk2Token)) ChunkConverter Convert chunks from RegexMatcher to chunks with a entity in the metadata. This annotator is important when the user wants to merge entities identified by NER models together with rules-based matching used by the RegexMathcer annotator. In the following steps of the pipeline, all the identified entities can be treated in a unified field. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: CHUNK Python API: ChunkConverter Scala API: ChunkConverter Show Example PythonScala Medical # Creating the pipeline documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_clinical_large&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter= NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) regex_matcher = RegexMatcher() .setInputCols(&#39;document&#39;) .setStrategy(&quot;MATCH_ALL&quot;) .setOutputCol(&quot;regex_matches&quot;) .setExternalRules(path=&#39;file:/dbfs/regex_rules.txt&#39;, delimiter=&#39;,&#39;) chunkConverter = ChunkConverter() .setInputCols(&quot;regex_matches&quot;) .setOutputCol(&quot;regex_chunk&quot;) merger= ChunkMergeApproach() .setInputCols([&quot;regex_chunk&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;merged_chunks&quot;) .setMergeOverlapping(True) .setChunkPrecedence(&quot;field&quot;) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, ner_model, ner_converter, regex_matcher, chunkConverter, merger ]) empty_df= spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model= pipeline.fit(empty_df) lp_model = LightPipeline(model) results = lp_model.fullAnnotate(sample_text)[0] # Displaying the results chunk= [] merge= [] for result in list(results[&quot;merged_chunks&quot;]): merge.append(result.metadata[&quot;entity&quot;]) chunk.append(result.result) df_merge = pd.DataFrame({&quot;chunk&quot;: chunk, &quot;merged_entity&quot;: merge}) df_merge | chunk | merged_entity | |--:|:| | POSTOPERATIVE DIAGNOSIS: | SECTION_HEADER | | Cervical lymphadenopathy | PROBLEM | | PROCEDURE: | SECTION_HEADER | | Excisional biopsy of right cervical lymph node | TEST | | ANESTHESIA: | SECTION_HEADER | | General endotracheal anesthesia | TREATMENT | | Right cervical lymph node | PROBLEM | | EBL: | SECTION_HEADER | | COMPLICATIONS: | SECTION_HEADER | | FINDINGS: | SECTION_HEADER | | Enlarged level 2 lymph node | PROBLEM | | ... | | Medical val sampleDataset = ResourceHelper.spark.createDataFrame(Seq( (1, &quot;My first sentence with the first rule. This is my second sentence with ceremonies rule.&quot;) )).toDF(&quot;id&quot;, &quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val regexMatcher = new RegexMatcher() .setExternalRules(ExternalResource(&quot;src/test/resources/regex-matcher/rules.txt&quot;, ReadAs.TEXT, Map(&quot;delimiter&quot; -&gt; &quot;,&quot;))) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;regex&quot;) .setStrategy(strategy) val chunkConverter = new ChunkConverter().setInputCols(&quot;regex&quot;).setOutputCol(&quot;chunk&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, sentence, regexMatcher,chunkConverter)) val results = pipeline.fit(sampleDataset).transform(sampleDataset) results.select(&quot;chunk&quot;).show(truncate = false) ++ |col | ++ |[chunk, 23, 31, the first, [identifier -&gt; NAME, sentence -&gt; 0, chunk -&gt; 0, entity -&gt; NAME], []] | |[chunk, 71, 80, ceremonies, [identifier -&gt; NAME, sentence -&gt; 1, chunk -&gt; 0, entity -&gt; NAME], []]| ++ ChunkEntityResolver ApproachModel Contains all the parameters and methods to train a ChunkEntityResolverModel. It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use ChunkEntityResolverModel and see the Models Hub for available models. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Scala API: ChunkEntityResolverApproach Show Example PythonScala Medical from johnsnowlabs import * # Training a SNOMED model # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data # and their labels. document = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) chunk = nlp.Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) chunkEmb = nlp.ChunkEmbeddings() .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) snomedTrainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, chunkEmb ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with snomedExtractor = medical.ChunkEntityResolverApproach() .setInputCols([&quot;token&quot;, &quot;chunk_embeddings&quot;]) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(True).setEnableTfidf(True).setEnableJaccard(True) .setEnableSorensenDice(True).setEnableJaroWinkler(True).setEnableLevenshtein(True) .setDistanceWeights([1, 2, 2, 1, 1, 1]) .setAllDistancesMetadata(True) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) model = snomedExtractor.fit(snomedData) Medical from johnsnowlabs import * // Training a SNOMED model // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data // and their labels. val document = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val chunk = new nlp.Doc2Chunk() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;chunk&quot;) val token = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val chunkEmb = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;chunk&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;chunk_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( document, chunk, token, embeddings, chunkEmb )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val snomedExtractor = new medical.ChunkEntityResolverApproach() .setInputCols(Array(&quot;token&quot;, &quot;chunk_embeddings&quot;)) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(true).setEnableTfidf(true).setEnableJaccard(true) .setEnableSorensenDice(true).setEnableJaroWinkler(true).setEnableLevenshtein(true) .setDistanceWeights(Array(1, 2, 2, 1, 1, 1)) .setAllDistancesMetadata(true) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) val model = snomedExtractor.fit(snomedData) Returns a normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc). For available pretrained models please see the Models Hub. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Scala API: ChunkEntityResolverModel Show Example PythonScala Medical from johnsnowlabs import * # Using pretrained models for SNOMED # First the prior steps of the pipeline are defined. # Output of types TOKEN and WORD_EMBEDDINGS are needed. data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) icdo_ner = medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;icdo_ner&quot;) icdo_chunk = nlp.NerConverter().setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;icdo_ner&quot;]).setOutputCol(&quot;icdo_chunk&quot;).setWhiteList([&quot;Cancer&quot;]) icdo_chunk_embeddings = nlp.ChunkEmbeddings() .setInputCols([&quot;icdo_chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;icdo_chunk_embeddings&quot;) icdo_chunk_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_icdo_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;icdo_chunk_embeddings&quot;]) .setOutputCol(&quot;tm_icdo_code&quot;) clinical_ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ner_chunk_tokenizer = nlp.ChunkTokenizer() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_token&quot;) ner_chunk_embeddings = nlp.ChunkEmbeddings() .setInputCols([&quot;ner_chunk&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner_chunk_embeddings&quot;) # Definition of the SNOMED Resolution ner_snomed_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_snomed_findings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_token&quot;,&quot;ner_chunk_embeddings&quot;]).setOutputCol(&quot;snomed_result&quot;) pipelineFull = Pipeline().setStages([ docAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, ner_chunk_embeddings, ner_chunk_tokenizer, ner_snomed_resolver, icdo_ner, icdo_chunk, icdo_chunk_embeddings, icdo_chunk_resolver ]) pipelineModelFull = pipelineFull.fit(data) result = pipelineModelFull.transform(data).cache() # Show results result.selectExpr(&quot;explode(snomed_result)&quot;) .selectExpr( &quot;col.metadata.target_text&quot;, &quot;col.metadata.resolved_text&quot;, &quot;col.metadata.confidence&quot;, &quot;col.metadata.all_k_results&quot;, &quot;col.metadata.all_k_resolutions&quot;) .filter($&quot;confidence&quot; &gt; 0.2).show(5) +--+--+-+--+--+ | target_text| resolved_text|confidence| all_k_results| all_k_resolutions| +--+--+-+--+--+ |hypercholesterolemia|Hypercholesterolemia| 0.2524|13644009:::267432...|Hypercholesterole...| | CBC| Neocyte| 0.4980|259680000:::11573...|Neocyte:::Blood g...| | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| | platelets| Increased platelets| 0.5267|6631009:::2596800...|Increased platele...| | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| +--+--+-+--+--+ Medical from johnsnowlabs import * // Using pretrained models for SNOMED // First the prior steps of the pipeline are defined. // Output of types TOKEN and WORD_EMBEDDINGS are needed. val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val icdo_ner = medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;icdo_ner&quot;) val icdo_chunk = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;icdo_ner&quot;)).setOutputCol(&quot;icdo_chunk&quot;).setWhiteList(&quot;Cancer&quot;) val icdo_chunk_embeddings = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;icdo_chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;icdo_chunk_embeddings&quot;) val icdo_chunk_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_icdo_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;token&quot;,&quot;icdo_chunk_embeddings&quot;)) .setOutputCol(&quot;tm_icdo_code&quot;) val clinical_ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val ner_chunk_tokenizer = new nlp.ChunkTokenizer() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_token&quot;) val ner_chunk_embeddings = new nlp.ChunkEmbeddings() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner_chunk_embeddings&quot;) // Definition of the SNOMED Resolution val ner_snomed_resolver = medical.ChunkEntityResolverModel.pretrained(&quot;chunkresolve_snomed_findings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_token&quot;,&quot;ner_chunk_embeddings&quot;)).setOutputCol(&quot;snomed_result&quot;) val pipelineFull = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, ner_chunk_embeddings, ner_chunk_tokenizer, ner_snomed_resolver, icdo_ner, icdo_chunk, icdo_chunk_embeddings, icdo_chunk_resolver )) val pipelineModelFull = pipelineFull.fit(data) val result = pipelineModelFull.transform(data).cache() // Show results // // result.selectExpr(&quot;explode(snomed_result)&quot;) // .selectExpr( // &quot;col.metadata.target_text&quot;, // &quot;col.metadata.resolved_text&quot;, // &quot;col.metadata.confidence&quot;, // &quot;col.metadata.all_k_results&quot;, // &quot;col.metadata.all_k_resolutions&quot;) // .filter($&quot;confidence&quot; &gt; 0.2).show(5) // +--+--+-+--+--+ // | target_text| resolved_text|confidence| all_k_results| all_k_resolutions| // +--+--+-+--+--+ // |hypercholesterolemia|Hypercholesterolemia| 0.2524|13644009:::267432...|Hypercholesterole...| // | CBC| Neocyte| 0.4980|259680000:::11573...|Neocyte:::Blood g...| // | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| // | platelets| Increased platelets| 0.5267|6631009:::2596800...|Increased platele...| // | CD38| Hypoviscosity| 0.2560|47872005:::370970...|Hypoviscosity:::E...| // +--+--+-+--+--+ // ChunkFilterer Filters entities coming from CHUNK annotations. Filters can be set via a white list of terms or a regular expression. White list criteria is enabled by default. To use regex, criteria has to be set to regex. Input Annotator Types: DOCUMENT,CHUNK Output Annotator Type: CHUNK Python API: ChunkFilterer Scala API: ChunkFilterer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined data = spark.createDataFrame([[&quot;Has a past history of gastroenteritis and stomach pain, however patient ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = medical.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(chunk)&quot;).show(truncate=False) ++ |col | ++ |{chunk, 11, 17, history, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 42, 53, stomach pain, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{chunk, 64, 70, patient, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{chunk, 81, 110, stomach pain now.We don&#39;t care, {sentence -&gt; 0, chunk -&gt; 4}, []}| |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []} | ++ result.selectExpr(&quot;explode(filtered)&quot;).show(truncate=False) +-+ |col | +-+ |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}| +-+ from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = finance.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * # Filtering POS tags # First pipeline stages to extract the POS tags are defined docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) posTagger = nlp.PerceptronModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;pos&quot;) chunker = nlp.Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) # Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. chunkerFilter = legal.ChunkFilterer() .setInputCols([&quot;sentence&quot;,&quot;chunk&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&quot;gastroenteritis&quot;]) pipeline = Pipeline(stages=[ docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Filtering POS tags // First pipeline stages to extract the POS tags are defined val data = Seq(&quot;Has a past history of gastroenteritis and stomach pain, however patient ...&quot;).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new medical.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) result.selectExpr(&quot;explode(chunk)&quot;).show(truncate=false) ++ |col | ++ |{chunk, 11, 17, history, {sentence -&gt; 0, chunk -&gt; 0}, []} | |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 42, 53, stomach pain, {sentence -&gt; 0, chunk -&gt; 2}, []} | |{chunk, 64, 70, patient, {sentence -&gt; 0, chunk -&gt; 3}, []} | |{chunk, 81, 110, stomach pain now.We don&#39;t care, {sentence -&gt; 0, chunk -&gt; 4}, []}| |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []} | ++ result.selectExpr(&quot;explode(filtered)&quot;).show(truncate=false) +-+ |col | +-+ |{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []} | |{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}| +-+ from johnsnowlabs import * val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new finance.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) from johnsnowlabs import * val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val posTagger = nlp.PerceptronModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;pos&quot;) val chunker = new nlp.Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) // Then the chunks can be filtered via a white list. Here only terms with &quot;gastroenteritis&quot; remain. val chunkerFilter = new legal.ChunkFilterer() .setInputCols(Array(&quot;sentence&quot;,&quot;chunk&quot;)) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList(&quot;gastroenteritis&quot;) val pipeline = new Pipeline().setStages(Array( docAssembler, sentenceDetector, tokenizer, posTagger, chunker, chunkerFilter)) ChunkKeyPhraseExtraction Chunk KeyPhrase Extraction uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. The input to the model consists of chunk annotations and sentence or document annotation. The model compares the chunks against the corresponding sentences/documents and selects the chunks which are most representative of the broader text context (i.e. the document or the sentence they belong to). The key phrases candidates (i.e. the input chunks) can be generated in various ways, e.g. by NGramGenerator, TextMatcher or NerConverter. The model operates either at sentence (selecting the most descriptive chunks from the sentence they belong to) or at document level. In the latter case, the key phrases are selected to represent all the input document annotations. This model is a subclass of [[BertSentenceEmbeddings]] and shares all parameters with it. It can load any pretrained BertSentenceEmbeddings model. Available models can be found at the Models Hub. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: CHUNK Python API: ChunkKeyPhraseExtraction Scala API: ChunkKeyPhraseExtraction Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_tagger = medical.NerModel() .pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = medical.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_tagger, ner_converter, key_phrase_extractor]) data = spark.createDataFrame([[&quot;Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm.&quot;]]).toDF(&quot;text&quot;) results = pipeline.fit(data).transform(data) results .selectExpr(&quot;explode(ner_chunk_key_phrases) AS key_phrase&quot;) .selectExpr( &quot;key_phrase.result&quot;, &quot;key_phrase.metadata.entity&quot;, &quot;key_phrase.metadata.DocumentSimilarity&quot;, &quot;key_phrase.metadata.MMRScore&quot;) .show(truncate=False) +--++-+ |result |DocumentSimilarity|MMRScore | +--++-+ |gestational diabetes mellitus|0.7391447825527298|0.44348688715422274| |28-year-old |0.4366776288430703|0.13577881610104517| |type two diabetes mellitus |0.7323921930094919|0.085800103824974 | +--++-+ from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = finance.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_model, ner_converter, key_phrase_extractor]) from johnsnowlabs import * documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embeddings = nlp.WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) key_phrase_extractor = legal.ChunkKeyPhraseExtraction .pretrained() .setTopN(1) .setDocumentLevelProcessing(False) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;ner_chunks&quot;]) .setOutputCol(&quot;ner_chunk_key_phrases&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, sentencer, tokenizer, embeddings, ner_model, ner_converter, key_phrase_extractor]) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = medical.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) val sampleText = &quot;Her Diabetes has become type 2 in the last year with her Diabetes.&quot; + &quot; He complains of swelling in his right forearm.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(key_phrases) AS key_phrase&quot;) .selectExpr( &quot;key_phrase.result&quot;, &quot;key_phrase.metadata.DocumentSimilarity&quot;, &quot;key_phrase.metadata.MMRScore&quot;) .show(truncate=false) +--+-++ |result |DocumentSimilarity |MMRScore | +--+-++ |complains swelling forearm|0.6325718954229369 |0.1897715761677257| |type 2 year |0.40181028931546364|-0.189501077108947| +--+-++ from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = finance.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val stopWordsCleaner = nlp.StopWordsCleaner.pretrained() .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;clean_tokens&quot;) .setCaseSensitive(false) val nGrams = new nlp.NGramGenerator() .setInputCols(Array(&quot;clean_tokens&quot;)) .setOutputCol(&quot;ngrams&quot;) .setN(3) val chunkKeyPhraseExtractor = legal.ChunkKeyPhraseExtraction .pretrained() .setTopN(2) .setDivergence(0.7f) .setInputCols(Array(&quot;document&quot;, &quot;ngrams&quot;)) .setOutputCol(&quot;key_phrases&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner, nGrams, chunkKeyPhraseExtractor)) ChunkMapper ApproachModel We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries. This is the AnnotatorApproach of the ChunkMapper, which can be used to train ChunkMapper models by giving a custom mapping dictionary. To use pretriained models, check the documentation of the ChunkMapperModel annotator. The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.). Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK Output Annotator Type: LABEL_DEPENDENCY Python API: ChunkMapperApproach Scala API: ChunkMapperApproach Show Example PythonScala Medical # First, create a dictionay in JSON format following this schema: import json data_set= { &quot;mappings&quot;: [ { &quot;key&quot;: &quot;metformin&quot;, &quot;relations&quot;: [ { &quot;key&quot;: &quot;action&quot;, &quot;values&quot; : [&quot;hypoglycemic&quot;, &quot;Drugs Used In Diabetes&quot;] }, { &quot;key&quot;: &quot;treatment&quot;, &quot;values&quot; : [&quot;diabetes&quot;, &quot;t2dm&quot;] }] }] } with open(&#39;sample_drug.json&#39;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: json.dump(data_set, f, ensure_ascii=False, indent=4) # Create a pipeline document_assembler = DocumentAssembler() .setInputCol(&#39;text&#39;) .setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) #NER model to detect drug in the text clinical_ner = MedicalNerModel.pretrained(&quot;ner_posology_small&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setLabelCasing(&quot;upper&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;DRUG&quot;]) chunkerMapper = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;sample_drug.json&quot;) .setRels([&quot;action&quot;]) #or treatment pipeline = Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunkerMapper, ] ) # Train the model text = [&quot;The patient was given 1 unit of metformin daily.&quot;] test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;) model = pipeline.fit(test_data) We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries. This is the AnnotatorModel of the ChunkMapper, which can be used to access pretrained models with the .pretrained() or .load() methods. To train a new model, check the documentation of the ChunkMapperApproach annotator. The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.). Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK Output Annotator Type: LABEL_DEPENDENCY Python API: ChunkMapperModel Scala API: ChunkMapperModel Show Example PythonScala Medical # Use `rxnorm_mapper` pretrained model to map entities with their corresponding RxNorm codes. document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;rxnorm&quot;) .setRels([&quot;rxnorm_code&quot;]) mapper_pipeline = Pipeline().setStages([document_assembler, chunkerMapper]) empty_df = spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;) mapper_model = mapper_pipeline.fit(empty_df) mapper_lp = LightPipeline(mapper_model) mapper_lp.fullAnnotate(&quot;metformin&quot;) [{&#39;ner_chunk&#39;: [Annotation(document, 0, 8, metformin, {})], &#39;rxnorm&#39;: [Annotation(labeled_dependency, 0, 8, 6809, {&#39;entity&#39;: &#39;metformin&#39;, &#39;relation&#39;: &#39;rxnorm_code&#39;, &#39;all_relations&#39;: &#39;&#39;})]}] Medical val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) val chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;rxnorm&quot;) .setRels([&quot;rxnorm_code&quot;]) mapper_pipeline = Pipeline().setStages([document_assembler, chunkerMapper]) empty_df = spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;) mapper_model = mapper_pipeline.fit(empty_df) mapper_lp = LightPipeline(mapper_model) mapper_lp.fullAnnotate(&quot;metformin&quot;) [{&#39;ner_chunk&#39;: [Annotation(document, 0, 8, metformin, {})], &#39;rxnorm&#39;: [Annotation(labeled_dependency, 0, 8, 6809, {&#39;entity&#39;: &#39;metformin&#39;, &#39;relation&#39;: &#39;rxnorm_code&#39;, &#39;all_relations&#39;: &#39;&#39;})]}] ChunkMapperFilterer ApproachModel Input Annotator Types: `` Output Annotator Type: `` ChunkMapperFilterer is an annotator to be used after ChunkMapper that allows to filter chunks based on the results of the mapping, whether it was successful or failed. Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook Healthcare Chunk Mapping. Input Annotator Types: CHUNK, LABEL_DEPENDENCY Output Annotator Type: CHUNK Python API: ChunkMapperFilterer Scala API: ChunkMapperFilterer Show Example PythonScala Medical document_assembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentence_detector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) word_embeddings = ( WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_model = ( MedicalNerModel.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ) ner_converter = ( NerConverter().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;).setOutputCol(&quot;chunk&quot;) ) chunkerMapper = ( ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;RxNorm_Mapper&quot;) .setRel(&quot;rxnorm_code&quot;) ) cfModel = ( ChunkMapperFilterer() .setInputCols([&quot;chunk&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;chunks_fail&quot;) .setReturnCriteria(&quot;fail&quot;) ) chunk2doc = Chunk2Doc().setInputCols(&quot;chunks_fail&quot;).setOutputCol(&quot;doc_chunk&quot;) sbert_embedder = ( BertSentenceEmbeddings.pretrained( &quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;doc_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setCaseSensitive(False) ) resolver = ( SentenceEntityResolverModel.pretrained( &quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;chunks_fail&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolver_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ) resolverMerger = ( ResolverMerger() .setInputCols([&quot;resolver_code&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;RxNorm&quot;) ) mapper_pipeline = Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, word_embeddings, ner_model, ner_converter, chunkerMapper, chunkerMapper, cfModel, chunk2doc, sbert_embedder, resolver, resolverMerger, ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = mapper_pipeline.fit(empty_data) samples = [ [&quot;The patient was given Adapin 10 MG, coumadn 5 mg&quot;], [&quot;The patient was given Avandia 4 mg, Tegretol, zitiga&quot;], ] result = model.transform(spark.createDataFrame(samples).toDF(&quot;text&quot;)) result.selectExpr( &quot;chunk.result as chunk&quot;, &quot;RxNorm_Mapper.result as RxNorm_Mapper&quot;, &quot;chunks_fail.result as chunks_fail&quot;, &quot;resolver_code.result as resolver_code&quot;, &quot;RxNorm.result as RxNorm&quot;, ).show(truncate=False) +--+-+--+-++ chunk |RxNorm_Mapper |chunks_fail |resolver_code|RxNorm | +--+-+--+-++ [Adapin 10 MG, coumadn 5 mg] |[1000049, NONE] |[coumadn 5 mg]|[200883] |[1000049, 200883] | [Avandia 4 mg, Tegretol, zitiga]|[261242, 203029, NONE]|[zitiga] |[220989] |[261242, 203029, 220989]| +--+-+--+-++ ChunkMerge ApproachModel Merges two chunk columns coming from two annotators(NER, ContextualParser or any other annotator producing chunks). The merger of the two chunk columns is made by selecting one chunk from one of the columns according to certain criteria. The decision on which chunk to select is made according to the chunk indices in the source document. (chunks with longer lengths and highest information will be kept from each source) Labels can be changed by setReplaceDictResource. Input Annotator Types: CHUNK, CHUNK Output Annotator Type: CHUNK Python API: ChunkMergeApproach Scala API: ChunkMergeApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) pipeline = Pipeline(stages=[ nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;), nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;), nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;), nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setOutputCol(&quot;embs&quot;), medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;jsl_ner&quot;), nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]).setOutputCol(&quot;jsl_ner_chunk&quot;), medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;bionlp_ner&quot;), nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bionlp_ner&quot;]) .setOutputCol(&quot;bionlp_ner_chunk&quot;), medical.ChunkMergeApproach().setInputCols([&quot;jsl_ner_chunk&quot;, &quot;bionlp_ner_chunk&quot;]).setOutputCol(&quot;merged_chunk&quot;) ]) # Show results result = pipeline.fit(data).transform(data).cache() result.selectExpr(&quot;explode(merged_chunk) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.entity as entity&quot;) .show(5, False) +--++--++ |begin|end|chunk |entity | +--++--++ |5 |15 |63-year-old|Age | |17 |19 |man |Gender | |64 |72 |recurrent |Modifier | |98 |107|cellulitis |Diagnosis| |110 |119|pneumonias |Diagnosis| +--++--++ from johnsnowlabs import * data = spark.createDataFrame([[&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_finner = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;]) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER chunk_merge = finance.ChunkMergeApproach() .setInputCols(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge]) # Show results result = nlpPipeline.fit(data).transform(data).cache() result.select(F.explode(F.arrays_zip(result.deid_merged_chunk.result, result.deid_merged_chunk.metadata)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)).show(truncate=False) +++ |chunk |ner_label| +++ |Jeffrey Preston Bezos|PERSON | |founder |ROLE | |CEO |ROLE | |Amazon |PARTY | +++ from johnsnowlabs import * data = spark.createDataFrame([[&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;]]).toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_signers = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;]) .setOutputCol(&quot;ner_signer_chunk&quot;) chunk_merge = legal.ChunkMergeApproach() .setInputCols(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge]) # Show results result = nlpPipeline.fit(data).transform(data).cache() result.select(F.explode(F.arrays_zip(result.deid_merged_chunk.result, result.deid_merged_chunk.metadata)).alias(&quot;cols&quot;)) .select(F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;1&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)).show(truncate=False) +--+--+ |chunk |ner_label | +--+--+ |ENTIRE AGREEMENT |DOC | |INC |PARTY | |J. Magliarditi |SIGNING_PERSON| |Bajaj |SIGNING_PERSON| |Dominic J. Magliarditi |SIGNING_PERSON| |Sanjay Bajaj |SIGNING_PERSON| |President |SIGNING_TITLE | |VP Business Development|SIGNING_TITLE | +--+--+ MedicalFinanceLegal from johnsnowlabs import * // Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;), new nlp.SentenceDetector().setInputCol(&quot;document&quot;).setOutputCol(&quot;sentence&quot;), new nlp.Tokenizer().setInputCol(&quot;sentence&quot;).setOutputCol(&quot;token&quot;), nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)).setOutputCol(&quot;embs&quot;), medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;jsl_ner&quot;), new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)).setOutputCol(&quot;jsl_ner_chunk&quot;), medical.NerModel.pretrained(&quot;ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;bionlp_ner&quot;), new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bionlp_ner&quot;)) .setOutputCol(&quot;bionlp_ner_chunk&quot;), new medical.ChunkMergeApproach().setInputCols(Array(&quot;jsl_ner_chunk&quot;, &quot;bionlp_ner_chunk&quot;)).setOutputCol(&quot;merged_chunk&quot;) )) // Show results val result = pipeline.fit(data).transform(data).cache() result.selectExpr(&quot;explode(merged_chunk) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.entity as entity&quot;) .show(5, false) +--++--++ |begin|end|chunk |entity | +--++--++ |5 |15 |63-year-old|Age | |17 |19 |man |Gender | |64 |72 |recurrent |Modifier | |98 |107|cellulitis |Diagnosis| |110 |119|pneumonias |Diagnosis| +--++--++ from johnsnowlabs import * val data = Seq((&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;)).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCol(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;bert_embeddings&quot;) val fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; val ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;)) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_finner = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;)) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER val chunk_merge = new finance.ChunkMergeApproach() .setInputCols(Array(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge)) val model = nlpPipeline.fit(data) from johnsnowlabs import * val data = Seq((&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;)).toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCol(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_signers = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;)) .setOutputCol(&quot;ner_signer_chunk&quot;) val chunk_merge = new legal.ChunkMergeApproach() .setInputCols(Array(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge)) val model = nlpPipeline.fit(data) Merges entities coming from different CHUNK annotations Input Annotator Types: CHUNK, CHUNK Output Annotator Type: CHUNK Python API: ChunkMergeModel Scala API: ChunkMergeModel ChunkSentenceSplitter ApproachModel Input Annotator Types: `` Output Annotator Type: `` ChunkSentenceSplitter annotator can split the documents into chunks according to separators given as CHUNK columns. It is useful when you need to perform different models or analysis in different sections of your document (for example, for different headers, clauses, items, etc.). The given separator chunk can be the output from, for example, RegexMatcher or NerModel. For detailed usage of this annotator, visit this notebook from our Spark NLP Workshop. Input Annotator Types: DOCUMENT, CHUNK Output Annotator Type: DOCUMENT Python API: ChunkSentenceSplitter Scala API: ChunkSentenceSplitter Show Example PythonScala Medical # Defining the pipeline documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) tokenizer = Tokenizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;token&quot;) tokenClassifier = ( MedicalBertForTokenClassifier.pretrained( &quot;bert_token_classifier_ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ) ner_converter = ( NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Header&quot;]) ) chunkSentenceSplitter = ( ChunkSentenceSplitter() .setInputCols(&quot;document&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(False) ) pipeline = Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, ner_converter, chunkSentenceSplitter, ] ) empty_df = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) pipeline_model = pipeline.fit(empty_df) sentences = [ [ &quot;&quot;&quot;ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma. PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma. REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface. &quot;&quot;&quot; ] ] df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) paragraphs = pipeline_model.transform(df) paragraphs.selectExpr(&quot;explode(paragraphs) as result&quot;).selectExpr(&quot;result.result&quot;,&quot;result.metadata.entity&quot;, &quot;result.metadata.splitter_chunk&quot;).show(truncate=80) +--++-+ | result|entity| splitter_chunk| +--++-+ |ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelio...|Header|ADMISSION DIAGNOSIS| |PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma....|Header|PRINCIPAL DIAGNOSIS| |REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered thr...|Header| REVIEW OF SYSTEMS| +--++-+ Medical val data = Seq(text,text).toDS.toDF(&quot;text&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;doc&quot;) val regexMatcher = new RegexMatcher().setInputCols(&quot;doc&quot;).setOutputCol(&quot;chunks&quot;).setExternalRules(&quot;src/test/resources/chunker/title_regex.txt&quot;,&quot;,&quot;) val chunkSentenceSplitter = new ChunkSentenceSplitter().setInputCols(&quot;chunks&quot;,&quot;doc&quot;).setOutputCol(&quot;paragraphs&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler,regexMatcher,chunkSentenceSplitter)) val result = pipeline.fit(data).transform(data).select(&quot;paragraphs&quot;) result.show(truncate = false) ContextualParser ApproachModel Creates a model, that extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a JSON file. It is set through the parameter setJsonPath() In this JSON file, regex is defined that you want to match along with the information that will output on metadata field. Additionally, a dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: ContextualParserApproach Scala API: ContextualParserApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) data = spark.createDataFrame([[&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;]]).toDF(&quot;text&quot;) contextualParser = medical.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) result = pipeline.fit(data).transform(data) # Show Results result.selectExpr(&quot;explode(entity)&quot;).show(5, truncate=False) +-+ |col | +-+ |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}| |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []} | |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} | +-+ from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) contextualParser = finance.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) from johnsnowlabs import * # An example JSON file `regex_token.json` can look like this: # # { # &quot;entity&quot;: &quot;Stage&quot;, # &quot;ruleScope&quot;: &quot;sentence&quot;, # &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, # &quot;matchScope&quot;: &quot;token&quot; # } # # Which means to extract the stage code on a sentence level. # An example pipeline could then be defined like this # Pipeline could then be defined like this documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Define the parser (json file needs to be provided) contextualParser = legal.ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(True) .setContextMatch(False) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, contextualParser ]) MedicalFinanceLegal from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new medical.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) val result = pipeline.fit(data).transform(data) // Show Results // // result.selectExpr(&quot;explode(entity)&quot;).show(5, truncate=false) // +-+ // |col | // +-+ // |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | // |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []} | // |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}| // |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []} | // |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} | // +-+ // from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new finance.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) from johnsnowlabs import * // An example JSON file `regex_token.json` can look like this: // // { // &quot;entity&quot;: &quot;Stage&quot;, // &quot;ruleScope&quot;: &quot;sentence&quot;, // &quot;regex&quot;: &quot;[cpyrau]?[T][0-9X?][a-z^cpyrau]&quot;, // &quot;matchScope&quot;: &quot;token&quot; // } // // Which means to extract the stage code on a sentence level. // An example pipeline could then be defined like this val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) // Define the parser (json file needs to be provided) val data = Seq(&quot;A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... &quot;).toDF(&quot;text&quot;) val contextualParser = new legal.ContextualParserApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;/path/to/regex_token.json&quot;) .setCaseSensitive(true) .setContextMatch(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, contextualParser )) Extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a JSON file. In this file, regex is defined that you want to match along with the information that will output on metadata field. To instantiate a model, see ContextualParserApproach and its accompanied example. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: ContextualParserModel Scala API: ContextualParserModel DateNormalizer This annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, some times from different countries that has different formats to represent dates. For the relative dates (next year, past month, etc.), you can define an achor date to create the normalized date by setting the parameters anchorDateYear, anchorDateMonth, and anchorDateDay. The resultant chunk date will contain a metada indicating whether the normalization was successful or not (True / False). Input Annotator Types: CHUNK Output Annotator Type: CHUNK Python API: DateNormalizer Scala API: DateNormalizer Show Example PythonScala Medical from pyspark.sql.types import StringType dates = [ &quot;08/02/2018&quot;, &quot;11/2018&quot;, &quot;11/01/2018&quot;, &quot;12Mar2021&quot;, &quot;Jan 30, 2018&quot;, &quot;13.04.1999&quot;, &quot;3April 2020&quot;, &quot;next monday&quot;, &quot;today&quot;, &quot;next week&quot;, ] df = spark.createDataFrame(dates, StringType()).toDF(&quot;original_date&quot;) document_assembler = ( DocumentAssembler().setInputCol(&quot;original_date&quot;).setOutputCol(&quot;document&quot;) ) doc2chunk = Doc2Chunk().setInputCols(&quot;document&quot;).setOutputCol(&quot;date_chunk&quot;) date_normalizer = ( DateNormalizer() .setInputCols(&quot;date_chunk&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateYear(2000) .setAnchorDateMonth(3) .setAnchorDateDay(15) ) pipeline = Pipeline(stages=[document_assembler, doc2chunk, date_normalizer]) result = pipeline.fit(df).transform(df) result.selectExpr( &quot;date.result as normalized_date&quot;, &quot;original_date&quot;, &quot;date.metadata[0].normalized as metadata&quot;, ).show() ++-+--+ |normalized_date|original_date|metadata| ++-+--+ | [2018/08/02]| 08/02/2018| true| | [2018/11/DD]| 11/2018| true| | [2018/11/01]| 11/01/2018| true| | [2021/03/12]| 12Mar2021| true| | [2018/01/30]| Jan 30, 2018| true| | [1999/04/13]| 13.04.1999| true| | [2020/04/03]| 3April 2020| true| | [2000/03/20]| next monday| true| | [2000/03/15]| today| true| | [2000/03/22]| next week| true| ++-+--+ Medical val df = Seq((&quot;08/02/2018&quot;),(&quot;11/2018&quot;),(&quot;11/01/2018&quot;),(&quot;next monday&quot;),(&quot;today&quot;),(&quot;next week&quot;)).toDF(&quot;original_date&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;original_date&quot;).setOutputCol(&quot;document&quot;) val chunksDF = documentAssembler .transform(df) .mapAnnotationsCol[Seq[Annotation]](&quot;document&quot;, &quot;chunk_date&quot;, CHUNK, (aa:Seq[Annotation]) =&gt; aa.map( ann =&gt; ann.copy(annotatorType = CHUNK))) val dateNormalizerModel = new DateNormalizer() .setInputCols(&quot;chunk_date&quot;) .setOutputCol(&quot;date&quot;) .setAnchorDateDay(15) .setAnchorDateMonth(3) .setAnchorDateYear(2000) val dateDf = dateNormalizerModel.transform(chunksDF) dateDf.select(&quot;chunk_date.result&quot;,&quot;text&quot;).show() +-+-+ | result|original_date| +-+-+ | [08/02/2018]| 08/02/2018| | [11/2018]| 11/2018| | [11/01/2018]| 11/01/2018| |[next monday]| next monday| | [today]| today| | [next week]| next week| +-+-+ DeIdentification ApproachModel Contains all the methods for training a DeIdentificationModel model. This module can obfuscate or mask the entities that contains personal information. These can be set with a file of regex patterns with setRegexPatternsDictionary, where each line is a mapping of entity to regex. DATE d{4} AID d{6,7} Additionally, obfuscation strings can be defined with setObfuscateRefFile, where each line is a mapping of string to entity. The format and seperator can be speficied with setRefFileFormat and setRefSep. Dr. Gregory House#DOCTOR 01010101#MEDICALRECORD Ideally this annotator works in conjunction with Demographic Named EntityRecognizers that can be trained either using TextMatchers, RegexMatchers, DateMatchers, NerCRFs or NerDLs Input Annotator Types: DOCUMENT, TOKEN, CHUNK Output Annotator Type: DOCUMENT Python API: DeIdentification Scala API: DeIdentification Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities clinical_sensitive_entities = medical.NerModel .pretrained(&quot;ner_deid_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) # Deidentification deIdentification = medical.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline data = spark.createDataFrame([ [&quot;# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.&quot;] ]).toDF(&quot;text&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_sensitive_entities, nerConverter, deIdentification ]) result = pipeline.fit(data).transform(data) # Show Results result.select(&quot;dei.result&quot;).show(truncate = False) +--+ |result | +--+ |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| +--+ from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_con&quot;) # Deidentification deIdentification = finance.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification ]) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(True) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Ner entities ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_con&quot;) # Deidentification deIdentification = legal.DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) # file with custom regex pattern for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) # file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) # Pipeline pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification ]) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val clinical_sensitive_entities = medical.NerModel.pretrained(&quot;ner_deid_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new medical.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val data = Seq( &quot;# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.&quot; ).toDF(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_sensitive_entities, nerConverter, deIdentification )) val result = pipeline.fit(data).transform(data) result.select(&quot;dei.result&quot;).show(truncate = false) // Show Results // // result.select(&quot;dei.result&quot;).show(truncate = false) // +--+ // |result | // +--+ // |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| // +--+ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new finance.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification )) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(true) val tokenizer = new nlp.Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Ner entities val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_con&quot;) // Deidentification val deIdentification = new legal.DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) // file with custom regex patterns for custom entities .setRegexPatternsDictionary(&quot;path/to/dic_regex_patterns_main_categories.txt&quot;) // file with custom obfuscator names for the entities .setObfuscateRefFile(&quot;path/to/obfuscate_fixed_entities.txt&quot;) .setRefFileFormat(&quot;csv&quot;) .setRefSep(&quot;#&quot;) .setMode(&quot;obfuscate&quot;) .setDateFormats(Array(&quot;MM/dd/yy&quot;,&quot;yyyy-MM-dd&quot;)) .setObfuscateDate(true) .setDateTag(&quot;DATE&quot;) .setDays(5) .setObfuscateRefSource(&quot;file&quot;) // Pipeline val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, deIdentification )) Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS. To create a configured DeIdentificationModel, please see the example of DeIdentification. Input Annotator Types: DOCUMENT, TOKEN, CHUNK Output Annotator Type: DOCUMENT Python API: DeIdentificationModel Scala API: DeIdentificationModel Show Example PythonScala FinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_finner = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;]) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER chunk_merge = finance.ChunkMergeApproach() .setInputCols(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) deidentification = finance.DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline data = spark.createDataFrame([ [&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;] ]).toDF(&quot;text&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge, deidentification]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter_signers = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;]) .setOutputCol(&quot;ner_signer_chunk&quot;) chunk_merge = legal.ChunkMergeApproach() .setInputCols(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) deidentification = legal.DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline data = spark.createDataFrame([ [&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;] ]).toDF(&quot;text&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge, deidentification]) result = nlpPipeline.fit(data).transform(data) FinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;bert_embeddings&quot;) val fin_ner = finance.NerModel.pretrained(&#39;finner_deid&#39;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; val ner_finner = finance.NerModel.pretrained(&quot;finner_org_per_role_date&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;bert_embeddings&quot;)) .setOutputCol(&quot;ner_finner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_finner = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_finner&quot;)) .setOutputCol(&quot;ner_finner_chunk&quot;) .setWhiteList([&#39;ROLE&#39;]) # Just use &quot;ROLE&quot; entity from this NER val chunk_merge = new finance.ChunkMergeApproach() .setInputCols(Array(&quot;ner_finner_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val deidentification = new finance.DeIdentification() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;)) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline val data = Seq(&quot;Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon&quot;).toDF(&quot;text&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, bert_embeddings, fin_ner, ner_converter, ner_finner, ner_converter_finner, chunk_merge, deidentification)) val result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val ner_signers = legal.NerModel.pretrained(&quot;legner_signers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_signers&quot;) #.setLabelCasing(&quot;upper&quot;) val ner_converter_signers = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_signers&quot;)) .setOutputCol(&quot;ner_signer_chunk&quot;) val chunk_merge = new legal.ChunkMergeApproach() .setInputCols(Array(&quot;ner_signer_chunk&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;deid_merged_chunk&quot;) val deidentification = new legal.DeIdentification() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;deid_merged_chunk&quot;)) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;mask&quot;) .setIgnoreRegex(True) # Pipeline val data = Seq(&quot;ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. 2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 &quot;).toDF(&quot;text&quot;) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter, ner_signers, ner_converter_signers, chunk_merge, deidentification)) val result = nlpPipeline.fit(data).transform(data) Doc2ChunkInternal Converts DOCUMENT, TOKEN typed annotations into CHUNK type with the contents of a chunkCol. Chunk text must be contained within input DOCUMENT. May be either StringType or ArrayType[StringType] (using setIsArray). Useful for annotators that require a CHUNK type input. For more extended examples on document pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: CHUNK Python API: Doc2ChunkInternal Scala API: Doc2ChunkInternal Show Example PythonScala Medical import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) tokenizer = Tokenizer().setInputCol(&quot;document&quot;).setOutputCol(&quot;token&quot;) chunkAssembler = ( Doc2ChunkInternal() .setInputCols(&quot;document&quot;, &quot;token&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;chunk&quot;) .setIsArray(True) ) data = spark.createDataFrame( [ [ &quot;Spark NLP is an open-source text processing library for advanced natural language processing.&quot;, [&quot;Spark NLP&quot;, &quot;text processing library&quot;, &quot;natural language processing&quot;], ] ] ).toDF(&quot;text&quot;, &quot;target&quot;) pipeline = ( Pipeline().setStages([documentAssembler, tokenizer, chunkAssembler]).fit(data) ) result = pipeline.transform(data) result.selectExpr(&quot;chunk.result&quot;, &quot;chunk.annotatorType&quot;).show(truncate=False) +--++ |result |annotatorType | +--++ |[Spark NLP, text processing library, natural language processing]|[chunk, chunk, chunk]| +--++ DocumentHashCoder This annotator can replace dates in a column of DOCUMENT type according with the hash code of any other column. It uses the hash of the specified column and creates a new document column containing the day shift information. In sequence, the DeIdentification annotator deidentifies the document with the shifted date information. If the specified column contains strings that can be parsed to integers, use those numbers to make the shift in the data accordingly. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: DocumentHashCoder Scala API: DocumentHashCoder Show Example PythonScala Medical import pandas as pd data = pd.DataFrame( {&#39;patientID&#39; : [&#39;A001&#39;, &#39;A001&#39;, &#39;A003&#39;, &#39;A003&#39;], &#39;text&#39; : [&#39;Chris Brown was discharged on 10/02/2022&#39;, &#39;Mark White was discharged on 10/04/2022&#39;, &#39;John was discharged on 15/03/2022&#39;, &#39;John Moore was discharged on 15/12/2022&#39; ], &#39;dateshift&#39; : [&#39;10&#39;, &#39;10&#39;, &#39;30&#39;, &#39;30&#39;] } ) my_input_df = spark.createDataFrame(data) documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setDateShiftColumn(&quot;dateshift&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document2&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document2&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel .pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document2&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;document2&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) pipeline_col = Pipeline().setStages([ documentAssembler, documentHasher, tokenizer, embeddings, clinical_ner, ner_converter, de_identification ]) empty_data = spark.createDataFrame([[&quot;&quot;, &quot;&quot;, &quot;&quot;]]).toDF(&quot;patientID&quot;,&quot;text&quot;, &quot;dateshift&quot;) pipeline_col_model = pipeline_col.fit(empty_data) output = pipeline_col_model.transform(my_input_df) output.select(&#39;text&#39;, &#39;dateshift&#39;, &#39;deid_text.result&#39;).show(truncate = False) +-++-+ text |dateshift|result | +-++-+ Chris Brown was discharged on 10/02/2022|10 |[Ellender Manual was discharged on 20/02/2022]| Mark White was discharged on 10/04/2022 |10 |[Errol Bang was discharged on 20/04/2022] | John was discharged on 15/03/2022 |30 |[Ariel Null was discharged on 14/04/2022] | John Moore was discharged on 15/12/2022 |30 |[Jean Cotton was discharged on 14/01/2023] | +-++-+ DocumentLogRegClassifier ApproachModel Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for text and their label. The result is a trained DocumentLogRegClassifierModel. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierApproach Scala API: DocumentLogRegClassifierApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = medical.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = finance.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) from johnsnowlabs import * # Define pipeline stages to prepare the data document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) normalizer = nlp.Normalizer() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = nlp.StopWordsCleaner() .setInputCols([&quot;normalized&quot;]) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = nlp.Stemmer() .setInputCols([&quot;cleanTokens&quot;]) .setOutputCol(&quot;stem&quot;) # Define the document classifier and fit training data to it logreg = legal.DocumentLogRegClassifierApproach() .setInputCols([&quot;stem&quot;]) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline(stages=[ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) model = pipeline.fit(trainingData) MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new medical.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new finance.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) from johnsnowlabs import * // Define pipeline stages to prepare the data val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val normalizer = new nlp.Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) val stopwords_cleaner = new nlp.StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val stemmer = new nlp.Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) // Define the document classifier and fit training data to it val logreg = new legal.DocumentLogRegClassifierApproach() .setInputCols(&quot;stem&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg )) val model = pipeline.fit(trainingData) Classifies documents with a Logarithmic Regression algorithm. Currently there are no pretrained models available. Please see DocumentLogRegClassifierApproach to train your own model. Please check out the Models Hub for available models in the future. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierModel Scala API: DocumentLogRegClassifierModel DrugNormalizer Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents, from document type columns into Sentence. Removes all dirty characters from text following one or more input regex patterns. Can apply non wanted character removal which a specific policy. Can apply lower case normalization. See Spark NLP Workshop for more examples of usage. Input Annotator Types: DOCUMENT Output Annotator Type: DOCUMENT Python API: DrugNormalizer Scala API: DrugNormalizer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * data = spark.createDataFrame([ [&quot;Sodium Chloride/Potassium Chloride 13bag&quot;], [&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;], [&quot;aspirin 10 meq/ 5 ml oral sol&quot;] ]).toDF(&quot;text&quot;) document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = medical.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) result = trainingPipeline.fit(data).transform(data) result.selectExpr(&quot;explode(document_normalized.result) as normalized_text&quot;).show(truncate=False) +-+ |normalized_text | +-+ |Sodium Chloride / Potassium Chloride 13 bag | |interferon alfa - 2b 10000000 unt ( 1 ml ) injection| |aspirin 2 meq/ml oral solution | +-+ from johnsnowlabs import * document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = finance.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) from johnsnowlabs import * document = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) drugNormalizer = legal.DrugNormalizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;document_normalized&quot;) trainingPipeline = Pipeline(stages=[document, drugNormalizer]) MedicalFinanceLegal from johnsnowlabs import * val data = Seq( (&quot;Sodium Chloride/Potassium Chloride 13bag&quot;), (&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;), (&quot;aspirin 10 meq/ 5 ml oral sol&quot;) ).toDF(&quot;text&quot;) val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new medical.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) val result = trainingPipeline.fit(data).transform(data) result.selectExpr(&quot;explode(document_normalized.result) as normalized_text&quot;).show(false) +-+ |normalized_text | +-+ |Sodium Chloride / Potassium Chloride 13 bag | |interferon alfa - 2b 10000000 unt ( 1 ml ) injection| |aspirin 2 meq/ml oral solution | +-+ from johnsnowlabs import * val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new finance.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) from johnsnowlabs import * val document = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val drugNormalizer = new legal.DrugNormalizer().setInputCols(&quot;document&quot;).setOutputCol(&quot;document_normalized&quot;) val trainingPipeline = new Pipeline().setStages(Array(document, drugNormalizer)) EntityChunkEmbeddings Weighted average embeddings of multiple named entities chunk annotations. Entity Chunk Embeddings uses BERT Sentence embeddings to compute a weighted average vector represention of related entity chunks. The input the model consists of chunks of recognized named entities. One or more entities are selected as target entities and for each of them a list of related entities is specified (if empty, all other entities are assumed to be related). The model looks for chunks of the target entities and then tries to pair each target entity (e.g. DRUG) with other related entities (e.g. DOSAGE, STRENGTH, FORM, etc). The criterion for pairing a target entity with another related entity is that they appear in the same sentence and the maximal syntactic distance is below a predefined threshold. The relationship between target and related entities is one-to-many, meaning that if there multiple instances of the same target entity (e.g.) within a sentence, the model will map a related entity (e.g. DOSAGE) to at most one of the instances of the target entity. For example, if there is a sentence “The patient was given 125 mg of paracetamol and metformin”, the model will pair “125 mg” to “paracetamol”, but not to “metformin”. The output of the model is an average embeddings of the chunks of each of the target entities and their related entities. It is possible to specify a particular weight for each entity type. An entity can be defined both as target a entity and as a related entity for some other target entity. For example, we may want to compute the embeddings of SYMPTOMs and their related entities, as well as the embeddings of DRUGs and their related entities, one of each is also SYMPTOM. In such cases, it is possible to use the TARGET_ENTITY:RELATED_ENTITY notation to specify the weight of an related entity (e.g. “DRUG:SYMPTOM” to set the weight of SYMPTOM when it appears as an related entity to target entity DRUG). The relative weights of entities for particular entity chunk embeddings are available in the annotations metadata. This model is a subclass of BertSentenceEmbeddings and shares all parameters with it. It can load any pretrained BertSentenceEmbeddings model. The default model is &quot;sbiobert_base_cased_mli&quot; from clinical/models. Other available models can be found at Models Hub. Input Annotator Types: DEPENDENCY, CHUNK Output Annotator Type: SENTENCE_EMBEDDINGS Python API: EntityChunkEmbeddingsModel Scala API: EntityChunkEmbeddingsModel Show Example PythonScala Medical import sparknlp from sparknlp.base import * from sparknlp_jsl.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) sentence_detector = SentenceDetector() .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) embeddings = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel() .pretrained(&quot;ner_posology_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal() .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunks&quot;) pos_tager = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) drug_chunk_embeddings = EntityChunkEmbeddings() .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities({&quot;DRUG&quot;: []}) .setEntityWeights({&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;DOSAGE&quot;: 0.2, &quot;FORM&quot;: 0.5}) sampleData = &quot;The parient was given metformin 125 mg, 250 mg of coumadin and then one pill paracetamol&quot; data = SparkContextForTest.spark.createDataFrame([[sampleData]]).toDF(&quot;text&quot;) pipeline = Pipeline().setStages([ documenter, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, pos_tager, dependency_parser, drug_chunk_embeddings]) results = pipeline.fit(data).transform(data) results = results .selectExpr(&quot;explode(drug_chunk_embeddings) AS drug_chunk&quot;) .selectExpr(&quot;drug_chunk.result&quot;, &quot;slice(drug_chunk.embeddings, 1, 5) AS drug_embedding&quot;) .cache() results.show(truncate=False) +--+--+ | result| drug_embedding&quot;| +--+--+ |metformin 125 mg |[-0.267413, 0.07614058, -0.5620966, 0.83838946, 0.8911504] | |250 mg coumadin |[0.22319649, -0.07094894, -0.6885556, 0.79176235, 0.82672405] | |one pill paracetamol |[-0.10939768, -0.29242, -0.3574444, 0.3981813, 0.79609615] | +--+--+ Medical import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotator.SentenceDetector import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel import com.johnsnowlabs.nlp.annotators.ner.{MedicalNerModel, NerConverterInternal} import com.johnsnowlabs.nlp.annotators.embeddings.EntityChunkEmbeddings import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;tokens&quot;) val wordEmbeddings = WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;word_embeddings&quot;) val nerModel = MedicalNerModel .pretrained(&quot;ner_posology_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;tokens&quot;, &quot;word_embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val nerConverter = new NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;tokens&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) val posTager = PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;) .setOutputCol(&quot;pos_tags&quot;) val dependencyParser = DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val drugChunkEmbeddings = EntityChunkEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities(Map(&quot;DRUG&quot; -&gt; List())) .setEntityWeights(Map[String, Float](&quot;DRUG&quot; -&gt; 0.8f, &quot;STRENGTH&quot; -&gt; 0.2f, &quot;DOSAGE&quot; -&gt; 0.2f, &quot;FORM&quot; -&gt; 0.5f)) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, tokenizer, wordEmbeddings, nerModel, nerConverter, posTager, dependencyParser, drugChunkEmbeddings)) val sampleText = &quot;The patient was given metformin 125 mg, 250 mg of coumadin and then one pill paracetamol.&quot; val testDataset = Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(emptyDataset).transform(testDataset) result .selectExpr(&quot;explode(drug_chunk_embeddings) AS drug_chunk&quot;) .selectExpr(&quot;drug_chunk.result&quot;, &quot;slice(drug_chunk.embeddings, 1, 5) AS drugEmbedding&quot;) .show(truncate=false) +--+--+ | result| drugEmbedding| +--+--+ |metformin 125 mg |[-0.267413, 0.07614058, -0.5620966, 0.83838946, 0.8911504] | |250 mg coumadin |[0.22319649, -0.07094894, -0.6885556, 0.79176235, 0.82672405] | |one pill paracetamol |[-0.10939768, -0.29242, -0.3574444, 0.3981813, 0.79609615] | +--+-+ FeaturesAssembler The FeaturesAssembler is used to collect features from different columns. It can collect features from single value columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the result field). The output of the transformer is a FEATURE_VECTOR annotation (the numeric vector is in the embeddings field). Input Annotator Types: NONE Output Annotator Type: &quot;feature_vector&quot; Python API: FeaturesAssembler Scala API: FeaturesAssembler Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * features_asm = medical.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = finance.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = legal.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setLearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline(stages=[ features_asm, gen_clf ]) clf_model = pipeline.fit(data) MedicalFinanceLegal from johnsnowlabs import * val features_asm = new medical.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new finance.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new legal.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) GenericClassifier ApproachModel Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from FeaturesAssembler as input, classifies them and outputs CATEGORY annotations. Please see the Parameters section for required training parameters. For a more extensive example please see the Spark NLP Workshop. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierApproach Scala API: GenericClassifierApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * features_asm = medical.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = finance.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) from johnsnowlabs import * features_asm = legal.FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) MedicalFinanceLegal from johnsnowlabs import * val features_asm = new medical.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new medical.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new finance.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new finance.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) from johnsnowlabs import * val features_asm = new legal.FeaturesAssembler() .setInputCols(Array(&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;)) .setOutputCol(&quot;features&quot;) val gen_clf = new legal.GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols(&quot;features&quot;) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001f) .setFixImbalance(true) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2f) // keep 20% of the data for validation purposes val pipeline = new Pipeline().setStages(Array( features_asm, gen_clf )) val clf_model = pipeline.fit(data) Creates a generic single-label classifier which uses pre-generated Tensorflow graphs. The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler. Requires the FeaturesAssembler to create the input. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierModel Scala API: GenericClassifierModel IOBTagger Merges token tags and NER labels from chunks in the specified format. For example output columns as inputs from NerConverter and Tokenizer can be used to merge. Input Annotator Types: TOKEN, CHUNK Output Annotator Type: NAMED_ENTITY Python API: IOBTagger Scala API: IOBTagger Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. data = spark.createDataFrame([[&quot;A 63-year-old man presents to the hospital ...&quot;]]).toDF(&quot;text&quot;) docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) nerModel = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = medical.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, iobTagger]) result.selectExpr(&quot;explode(ner_label) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.word as word&quot;) .where(&quot;chunk!=&#39;O&#39;&quot;).show(5, False) +--++--+--+ |begin|end|chunk |word | +--++--+--+ |5 |15 |B-Age |63-year-old| |17 |19 |B-Gender |man | |64 |72 |B-Modifier |recurrent | |98 |107|B-Diagnosis|cellulitis | |110 |119|B-Diagnosis|pneumonias | +--++--+--+ from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = finance.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger]) from johnsnowlabs import * # Pipeline stages are defined where NER is done. NER is converted to chunks. docAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;embs&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;]).setOutputCol(&quot;ner&quot;) nerConverter = nlp.NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) # Define the IOB tagger, which needs tokens and chunks as input. Show results. iobTagger = legal.IOBTagger().setInputCols([&quot;token&quot;, &quot;ner_chunk&quot;]).setOutputCol(&quot;ner_label&quot;) pipeline = Pipeline(stages=[docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger]) MedicalFinanceLegal from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val data = Seq((&quot;A 63-year-old man presents to the hospital ...&quot;)).toDF(&quot;text&quot;) val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val nerModel = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new medical.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, nerModel, nerConverter, iobTagger)) result.selectExpr(&quot;explode(ner_label) as a&quot;) .selectExpr(&quot;a.begin&quot;,&quot;a.end&quot;,&quot;a.result as chunk&quot;,&quot;a.metadata.word as word&quot;) .where(&quot;chunk!=&#39;O&#39;&quot;).show(5, false) +--++--+--+ |begin|end|chunk |word | +--++--+--+ |5 |15 |B-Age |63-year-old| |17 |19 |B-Gender |man | |64 |72 |B-Modifier |recurrent | |98 |107|B-Diagnosis|cellulitis | |110 |119|B-Diagnosis|pneumonias | +--++--+--+ from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new legal.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger)) from johnsnowlabs import * // Pipeline stages are defined where NER is done. NER is converted to chunks. val docAssembler = new nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)).setOutputCol(&quot;embs&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;).setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;)).setOutputCol(&quot;ner&quot;) val nerConverter = new nlp.NerConverter().setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)).setOutputCol(&quot;ner_chunk&quot;) // Define the IOB tagger, which needs tokens and chunks as input. Show results. val iobTagger = new legal.IOBTagger().setInputCols(Array(&quot;token&quot;, &quot;ner_chunk&quot;)).setOutputCol(&quot;ner_label&quot;) val pipeline = new Pipeline().setStages(Array(docAssembler, sentenceDetector, tokenizer, embeddings, ner_model, nerConverter, iobTagger)) NerChunker Extracts phrases that fits into a known pattern using the NER tags. Useful for entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. A Regex needs to be provided to extract the tokens between entities. Input Annotator Types: DOCUMENT, NAMED_ENTITY Output Annotator Type: CHUNK Python API: NerChunker Scala API: NerChunker Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Defining pipeline stages for NER data= spark.createDataFrame([[&quot;She has cystic cyst on her kidney.&quot;]]).toDF(&quot;text&quot;) documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner = medical.NerModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setIncludeConfidence(True) # Define the NerChunker to combine to chunks chunker = medical.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner, chunker ]) result = pipeline.fit(data).transform(data) # Show results: result.selectExpr(&quot;explode(arrays_zip(ner.metadata , ner.result))&quot;) .selectExpr(&quot;col[&#39;0&#39;].word as word&quot; , &quot;col[&#39;1&#39;] as ner&quot;).show(truncate=False) ++--+ |word |ner | ++--+ |She |O | |has |O | |cystic|B-ImagingFindings| |cyst |I-ImagingFindings| |on |O | |her |O | |kidney|B-BodyPart | |. |O | ++--+ result.select(&quot;ner_chunk.result&quot;).show(truncate=False) ++ |result | ++ |[cystic cyst on her kidney]| ++ from johnsnowlabs import * # Defining pipeline stages for NER documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) # Define the NerChunker to combine to chunks chunker = finance.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker ]) from johnsnowlabs import * # Defining pipeline stages for NER documentAssembler= nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector= nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) tokenizer= nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) # Define the NerChunker to combine to chunks chunker = legal.NerChunker() .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;&quot;]) pipeline= Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker ]) MedicalFinanceLegal from johnsnowlabs import * // Defining pipeline stages for NER val data= Seq(&quot;She has cystic cyst on her kidney.&quot;).toDF(&quot;text&quot;) val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner = medical.NerModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) .setIncludeConfidence(True) // Define the NerChunker to combine to chunks val chunker = new medical.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner, chunker )) val result = pipeline.fit(data).transform(data) // Show results: // // result.selectExpr(&quot;explode(arrays_zip(ner.metadata , ner.result))&quot;) // .selectExpr(&quot;col[&#39;0&#39;].word as word&quot; , &quot;col[&#39;1&#39;] as ner&quot;).show(truncate=false) // ++--+ // |word |ner | // ++--+ // |She |O | // |has |O | // |cystic|B-ImagingFindings| // |cyst |I-ImagingFindings| // |on |O | // |her |O | // |kidney|B-BodyPart | // |. |O | // ++--+ // result.select(&quot;ner_chunk.result&quot;).show(truncate=false) // ++ // |result | // ++ // |[cystic cyst on her kidney]| // ++ // from johnsnowlabs import * // Defining pipeline stages for NER val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) // Define the NerChunker to combine to chunks val chunker = new finance.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker )) from johnsnowlabs import * // Defining pipeline stages for NER val documentAssembler=new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector=new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) .setUseAbbreviations(False) val tokenizer=new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;,&quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) // Define the NerChunker to combine to chunks val chunker = new legal.NerChunker() .setInputCols(Array(&quot;sentence&quot;,&quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers(Array(&quot;&lt;ImagingFindings&gt;.&lt;BodyPart&gt;&quot;)) val pipeline=new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, chunker )) NerConverterInternal Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label. Chunks with no associated entity (tagged “O”) are filtered out. This licensed annotator adds extra functionality to the open-source version by adding the following parameters: blackList, greedyMode, threshold, and ignoreStopWords that are not available in the NerConverter annotator. See also Inside–outside–beginning (tagging) for more information. Input Annotator Types: DOCUMENT, TOKEN, NAMED_ENTITY Output Annotator Type: CHUNK Python API: NerConverterInternal Scala API: NerConverterInternal Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) jsl_ner = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) jsl_ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]) .setOutputCol(&quot;jsl_ner_chunk&quot;) jsl_ner_converter_internal = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;jsl_ner&quot;]) .setOutputCol(&quot;replaced_ner_chunk&quot;) .setReplaceDictResource(&quot;replace_dict.csv&quot;,&quot;text&quot;, {&quot;delimiter&quot;:&quot;,&quot;}) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter, jsl_ner_converter_internal ]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) #.setCustomBounds([&quot; n n&quot;]) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) fin_ner = finance.NerModel.pretrained(&quot;finner_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = finance.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) # Replace &quot;ORG&quot; entity as &quot;PARTY&quot; nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, fin_ner, ner_converter]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) #.setCustomBounds([&quot; n n&quot;]) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) legal_ner = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) #.setLabelCasing(&quot;upper&quot;) ner_converter = legal.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) # &quot;ALIAS&quot; are secondary names of companies, so let&#39;s extract them also as PARTY nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter]) result = nlpPipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val jsl_ner = medical.NerModel .pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;jsl_ner&quot;) val jsl_ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;jsl_ner_chunk&quot;) val jsl_ner_converter_internal = new medical.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;replaced_ner_chunk&quot;) .setReplaceDictResource(&quot;replace_dict.csv&quot;,&quot;text&quot;, {&quot;delimiter&quot;:&quot;,&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter, jsl_ner_converter_internal )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val fin_ner = finance.NerModel .pretrained(&quot;finner_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new finance.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ORG&quot;: &quot;PARTY&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, fin_ner, ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val legal_ner = legal.NerModel .pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new legal.NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setReplaceLabels({&quot;ALIAS&quot;: &quot;PARTY&quot;}) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, legal_ner, ner_converter )) val result = pipeline.fit(data).transform(data) NerDisambiguator ApproachModel Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. The model needs extracted CHUNKS and SENTENCE_EMBEDDINGS type input from e.g. SentenceEmbeddings and NerConverter. Input Annotator Types: CHUNK, SENTENCE_EMBEDDINGS Output Annotator Type: DISAMBIGUATION Python API: NerDisambiguator Scala API: NerDisambiguator Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. data = spark.createDataFrame([[&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;]]) .toDF(&quot;text&quot;) documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = nlp.NerDLModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = medical.NerDisambiguator() .setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) model = nlpPipeline.fit(data) result = model.transform(data) # Show results result.selectExpr(&quot;explode(disambiguation)&quot;) .selectExpr(&quot;col.metadata.chunk as chunk&quot;, &quot;col.result as result&quot;).show(5, False) +++ |chunk |result | +++ |Donald Trump |http:#en.wikipedia.org/?curid=4848272, http:#en.wikipedia.org/?curid=31698421, http:#en.wikipedia.org/?curid=55907961 | |Christina Aguilera|http:#en.wikipedia.org/?curid=144171, http:#en.wikipedia.org/?curid=6636454 | +++ from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = finance.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) from johnsnowlabs import * # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. # Extracting Person identities # First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) sentence_embeddings = nlp.SentenceEmbeddings() .setInputCols([&quot;sentence&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;PER&quot;]) # Then the extracted entities can be disambiguated. disambiguator = legal.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator]) MedicalFinanceLegal from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = nlp.NerDLModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new medical.NerDisambiguator() .setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) val model = nlpPipeline.fit(data) val result = model.transform(data) // Show results // // result.selectExpr(&quot;explode(disambiguation)&quot;) // .selectExpr(&quot;col.metadata.chunk as chunk&quot;, &quot;col.result as result&quot;).show(5, false) // +++ // |chunk |result | // +++ // |Donald Trump |http://en.wikipedia.org/?curid=4848272, http://en.wikipedia.org/?curid=31698421, http://en.wikipedia.org/?curid=55907961| // |Christina Aguilera|http://en.wikipedia.org/?curid=144171, http://en.wikipedia.org/?curid=6636454 | // +++ // from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new finance.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) from johnsnowlabs import * // Extracting Person identities // First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities. val data = Seq(&quot;The show also had a contestant named Donald Trump who later defeated Christina Aguilera ...&quot;) .toDF(&quot;text&quot;) val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val sentence_embeddings = new nlp.SentenceEmbeddings() .setInputCols(Array(&quot;sentence&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;sentence_embeddings&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;PER&quot;) // Then the extracted entities can be disambiguated. val disambiguator = new legal.NerDisambiguator() #.setS3KnowledgeBaseName(&quot;i-per&quot;) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;disambiguation&quot;) .setNumFirstChars(5) val nlpPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, sentence_embeddings, ner_model, ner_converter, disambiguator)) Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. Instantiated / pretrained model of the NerDisambiguator. Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs), mentions, or surface forms. Input Annotator Types: CHUNK, SENTENCE_EMBEDDINGS Output Annotator Type: DISAMBIGUATION Python API: NerDisambiguatorModel Scala API: NerDisambiguatorModel NerModel ApproachModel This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. For instantiated/pretrained models, see NerDLModel. The training data should be a labeled Spark Dataset, in the format of CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel with clinical embeddings (any clinical word embeddings can be chosen). For extended examples of usage, see the Spark NLP Workshop (sections starting with Training a Clinical NER) Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerApproach Scala API: MedicalNerApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = medical.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) # We use the text and labels from the CoNLL dataset conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = finance.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) from johnsnowlabs import * # First extract the prerequisites for the NerDLApproach documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = nlp.WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = legal.NerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) MedicalFinanceLegal from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new medical.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new finance.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) from johnsnowlabs import * // First extract the prerequisites for the NerDLApproach val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.WordEmbeddingsModel .pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new legal.NerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) This Named Entity recognition annotator is a generic NER model based on Neural Networks. Pretrained models can be loaded with pretrained of the companion object: val nerModel = nlp.NerDLModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) The default model is &quot;ner_clinical&quot;, if no name is provided. For available pretrained models please see the Models Hub. Additionally, pretrained pipelines are available for this module, see Pipelines. Note that some pretrained models require specific types of embeddings, depending on which they were trained on. For example, the default model &quot;ner_dl&quot; requires the WordEmbeddings &quot;ner_clinical&quot;. For extended examples of usage, see the Spark NLP Workshop (sections starting with Training a Clinical NER) Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerModel Scala API: MedicalNerModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) jsl_ner = medical.NerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) jsl_ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;]) .setOutputCol(&quot;jsl_ner_chunk&quot;) jsl_ner_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter]) result = jsl_ner_pipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_headers&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) result = nlpPipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_headers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) result = nlpPipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val jsl_ner = medical.NerModel .pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;jsl_ner&quot;) val jsl_ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;jsl_ner&quot;)) .setOutputCol(&quot;jsl_ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, jsl_ner, jsl_ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_headers&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = legal.NerModel .pretrained(&quot;legner_headers&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter )) val result = pipeline.fit(data).transform(data) QuestionAnswering QuestionAnswering is a GPT-based model for answering questions given a context. Unlike span-based models, it generates the answers to the questions, rather than selecting phrases from the given context. The model is capable of answering various types of questions, including yes-no or full-text ones. Types of questions are supported: &quot;short&quot; (producing yes/no/maybe) answers and &quot;long&quot; (full answers). Available models can be found at the Models Hub. For more extended examples on the document, pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT, DOCUMENT Output Annotator Type: CHUNK Python API: MedicalQuestionAnswering Scala API: MedicalQuestionAnswering Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = medical.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = finance.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) from johnsnowlabs import * document_assembler = nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = legal.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = nlp.Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;long&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == &#39;short&#39;&quot;)) .select(&quot;answer.result&quot;) .show(truncate=False) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = medical.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = finance.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = legal.QuestionAnswering .pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract, &quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) RENerChunksFilter Filters entities’ dependency relations. The annotator filters desired relation pairs (defined by the parameter realtionPairs), and store those on the output column. Filtering the possible relations can be useful to perform additional analysis for a specific use case (e.g., checking adverse drug reactions and drug realations), which can be the input for further analysis using a pretrained RelationExtractionDLModel. For example, the ner_clinical NER model can identify PROBLEM, TEST, and TREATMENT entities. By using the RENerChunksFilter, one can filter only the relations between PROBLEM and TREATMENT entities only, removing any relation between the other entities, to further analyze the associations between clinical problems and treatments. Input Annotator Types: CHUNK, DEPENDENCY Output Annotator Type: CHUNK Python API: RENerChunksFilter Scala API: RENerChunksFilter Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = medical.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = trained_pipeline.fit(data).transform(data) # Show results result.selectExpr(&quot;explode(re_ner_chunks) as re_chunks&quot;) .selectExpr(&quot;re_chunks.begin&quot;, &quot;re_chunks.result&quot;, &quot;re_chunks.metadata.entity&quot;, &quot;re_chunks.metadata.paired_to&quot;) .show(6, truncate=False) +--+-+++ |begin|result |entity |paired_to| +--+-+++ |35 |upper |Direction |41 | |41 |brain stem |Internal_organ_or_component|35 | |35 |upper |Direction |59 | |59 |cerebellum |Internal_organ_or_component|35 | |35 |upper |Direction |81 | |81 |basil ganglia|Internal_organ_or_component|35 | +--+-+++ from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = finance.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter ]) from johnsnowlabs import * # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embedding&quot;]) .setOutputCol(&quot;ner&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relation pairs and the filter relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_ner_chunk_filter = legal.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter ]) MedicalFinanceLegal from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new medical.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = trained_pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(re_ner_chunks) as re_chunks&quot;) // .selectExpr(&quot;re_chunks.begin&quot;, &quot;re_chunks.result&quot;, &quot;re_chunks.metadata.entity&quot;, &quot;re_chunks.metadata.paired_to&quot;) // .show(6, truncate=false) // +--+-+++ // |begin|result |entity |paired_to| // +--+-+++ // |35 |upper |Direction |41 | // |41 |brain stem |Internal_organ_or_component|35 | // |35 |upper |Direction |59 | // |59 |cerebellum |Internal_organ_or_component|35 | // |35 |upper |Direction |81 | // |81 |basil ganglia|Internal_organ_or_component|35 | // +--+-+++ // from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new finance.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter )) from johnsnowlabs import * // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embedding&quot;)) .setOutputCol(&quot;ner&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relation pairs and the filter val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_ner_chunk_filter = new legal.RENerChunksFilter() .setInputCols(Array(&quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, dependency_parser, ner_model, ner_chunker, re_ner_chunk_filter )) ReIdentification Reidentifies obfuscated entities by DeIdentification. This annotator requires the outputs from the deidentification as input. Input columns need to be the deidentified document and the deidentification mappings set with DeIdentification.setMappingsColumn. To see how the entities are deidentified, please refer to the example of that class. Input Annotator Types: DOCUMENT,CHUNK Output Annotator Type: DOCUMENT Python API: ReIdentification Scala API: ReIdentification Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = medical.ReIdentification() .setInputCols([&quot;dei&quot;, &quot;protectedEntities&quot;]) .setOutputCol(&quot;reid&quot;) .transform(result) # Show results result.select(&quot;dei.result&quot;).show(truncate = False) +--+ |result | +--+ |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| +--+ reideintification.selectExpr(&quot;explode(reid.result)&quot;).show(truncate=False) +--+ |col | +--+ |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.| +--+ from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = finance.ReIdentification() .setInputCols([&quot;aux&quot;, &quot;deidentified&quot;]) .setOutputCol(&quot;original&quot;) .transform(result) from johnsnowlabs import * # Define the reidentification stage and transform the deidentified documents reideintification = legal.ReIdentification() .setInputCols([&quot;aux&quot;, &quot;deidentified&quot;]) .setOutputCol(&quot;original&quot;) .transform(result) MedicalFinanceLegal from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new medical.ReIdentification() .setInputCols(Array(&quot;dei&quot;, &quot;protectedEntities&quot;)) .setOutputCol(&quot;reid&quot;) .transform(result) // Show results // // result.select(&quot;dei.result&quot;).show(truncate = false) // +--+ // |result | // +--+ // |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]| // +--+ // reideintification.selectExpr(&quot;explode(reid.result)&quot;).show(false) // +--+ // |col | // +--+ // |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.| // +--+ // from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new finance.ReIdentification() .setInputCols(Array(&quot;aux&quot;, &quot;deidentified&quot;)) .setOutputCol(&quot;original&quot;) .transform(result) from johnsnowlabs import * // Define the reidentification stage and transform the deidentified documents val reideintification = new legal.ReIdentification() .setInputCols(Array(&quot;aux&quot;, &quot;deidentified&quot;)) .setOutputCol(&quot;original&quot;) .transform(result) RelationExtraction ApproachModel Trains a TensorFlow model for relation extraction. To train a custom relation extraction model, you need to first creat a Tensorflow graph using either the TfGraphBuilder annotator or the tf_graph module. Then, set the path to the Tensorflow graph using the method .setModelFile(&quot;path/to/tensorflow_graph.pb&quot;). If the parameter relationDirectionCol is set, the model will be trained using the direction information (see the parameter decription for details). Otherwise, the model won’t have direction between the relation of the entities. After training a model (using the .fit() method), the resulting object is of class RelationExtractionModel. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: NONE Python API: RelationExtractionApproach Scala API: RelationExtractionApproach Show Example PythonScala Medical from johnsnowlabs import * # Defining pipeline stages to extract entities first documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;tokens&quot;) embedder = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) posTagger = nlp.PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;posTags&quot;) nerTagger = nlp.MedicalNerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) nerConverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;nerChunks&quot;) depencyParser = nlp.DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) # Then define `RelationExtractionApproach` and training parameters re = medical.RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations_t&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(300) .setBatchSize(200) .setLearningRate(0.001) .setModelFile(&quot;path/to/graph_file.pb&quot;) .setFixImbalance(True) .setValidationSplit(0.05) .setFromEntity(&quot;from_begin&quot;, &quot;from_end&quot;, &quot;from_label&quot;) .setToEntity(&quot;to_begin&quot;, &quot;to_end&quot;, &quot;to_label&quot;) finisher = nlp.Finisher() .setInputCols([&quot;relations_t&quot;]) .setOutputCols([&quot;relations&quot;]) .setCleanAnnotations(False) .setValueSplitSymbol(&quot;,&quot;) .setAnnotationSplitSymbol(&quot;,&quot;) .setOutputAsArray(False) # Define complete pipeline and start training pipeline = Pipeline(stages=[ documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re, finisher]) model = pipeline.fit(trainData) Medical from johnsnowlabs import * // Defining pipeline stages to extract entities first val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val embedder = nlp.WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val posTagger = nlp.PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;) val nerTagger = medical.NerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val nerConverter = new nlp.NerConverter() .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val depencyParser = nlp.DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) // Then define `RelationExtractionApproach` and training parameters val re = new medical.RelationExtractionApproach() .setInputCols(Array(&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;relations_t&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(300) .setBatchSize(200) .setlearningRate(0.001f) .setModelFile(&quot;path/to/graph_file.pb&quot;) .setFixImbalance(true) .setValidationSplit(0.05f) .setFromEntity(&quot;from_begin&quot;, &quot;from_end&quot;, &quot;from_label&quot;) .setToEntity(&quot;to_begin&quot;, &quot;to_end&quot;, &quot;to_label&quot;) val finisher = new nlp.Finisher() .setInputCols(Array(&quot;relations_t&quot;)) .setOutputCols(Array(&quot;relations&quot;)) .setCleanAnnotations(false) .setValueSplitSymbol(&quot;,&quot;) .setAnnotationSplitSymbol(&quot;,&quot;) .setOutputAsArray(false) // Define complete pipeline and start training val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re, finisher)) val model = pipeline.fit(trainData) Extracts and classifies instances of relations between named entities. For pretrained models please see the Models Hub for available models. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: CATEGORY Python API: RelationExtractionModel Scala API: RelationExtractionModel Show Example PythonScala Medical from johnsnowlabs import * # Relation Extraction between body parts # Define pipeline stages to extract entities documenter = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencer = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentences&quot;]) .setOutputCol(&quot;tokens&quot;) words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ner_chunker = nlp.NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;]) .setOutputCol(&quot;ner_chunks&quot;) # Define the relations that are to be extracted relationPairs = [ &quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot; ] re_model = medical.RelationExtractionModel.pretrained(&quot;re_bodypart_directions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs(relationPairs) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9) pipeline = Pipeline().setStages([ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_model ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # Show results # result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ) .where(&quot;result != 0&quot;) .show(truncate=False) # Show results result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ).where(&quot;result != 0&quot;) .show(truncate=False) +++-+++ |chunk1|entity1 |chunk2 |entity2 |result| +++-+++ |upper |Direction|brain stem |Internal_organ_or_component|1 | |left |Direction|cerebellum |Internal_organ_or_component|1 | |right |Direction|basil ganglia|Internal_organ_or_component|1 | +++-+++ Medical from johnsnowlabs import * // Relation Extraction between body parts // Define pipeline stages to extract entities val documenter = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentencer = new nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;tokens&quot;) val words_embedder = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val pos_tagger = nlp.PerceptronModel.pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;pos_tags&quot;) val dependency_parser = nlp.DependencyParserModel.pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val clinical_ner_tagger = medical.NerModel.pretrained(&quot;jsl_ner_wip_greedy_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;) val ner_chunker = new nlp.NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;ner_chunks&quot;) // Define the relations that are to be extracted val relationPairs = Array(&quot;direction-external_body_part_or_region&quot;, &quot;external_body_part_or_region-direction&quot;, &quot;direction-internal_organ_or_component&quot;, &quot;internal_organ_or_component-direction&quot;) val re_model = medical.RelationExtractionModel.pretrained(&quot;re_bodypart_directions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;relations&quot;) .setRelationPairs(relationPairs) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9f) val pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_model )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(relations) as relations&quot;) // .select( // &quot;relations.metadata.chunk1&quot;, // &quot;relations.metadata.entity1&quot;, // &quot;relations.metadata.chunk2&quot;, // &quot;relations.metadata.entity2&quot;, // &quot;relations.result&quot; // ) // .where(&quot;result != 0&quot;) // .show(truncate=false) // +++-+++ // |chunk1|entity1 |chunk2 |entity2 |result| // +++-+++ // |upper |Direction|brain stem |Internal_organ_or_component|1 | // |left |Direction|cerebellum |Internal_organ_or_component|1 | // |right |Direction|basil ganglia|Internal_organ_or_component|1 | // +++-+++ // RelationExtractionDL Extracts and classifies instances of relations between named entities. In contrast with RelationExtractionModel, RelationExtractionDLModel is based on BERT. For pretrained models please see the Models Hub for available models. Input Annotator Types: CHUNK, DOCUMENT Output Annotator Type: CATEGORY Python API: RelationExtractionDLModel Scala API: RelationExtractionDLModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Relation Extraction between body parts # This is a continuation of the RENerChunksFilter example. See that class on how to extract the relation chunks. # Define the extraction model re_ner_chunk_filter = medical.RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;internal_organ_or_component-direction&quot;]) re_model = medical.RelationExtractionDLModel.pretrained(&quot;redl_bodypart_direction_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) trained_pipeline = Pipeline(stages=[ documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter, re_model ]) data = spark.createDataFrame([[&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;]]).toDF(&quot;text&quot;) result = trained_pipeline.fit(data).transform(data) # Show results result.selectExpr(&quot;explode(relations) as relations&quot;) .select( &quot;relations.metadata.chunk1&quot;, &quot;relations.metadata.entity1&quot;, &quot;relations.metadata.chunk2&quot;, &quot;relations.metadata.entity2&quot;, &quot;relations.result&quot; ) .where(&quot;result != 0&quot;) .show(truncate=False) +++-+++ |chunk1|entity1 |chunk2 |entity2 |result| +++-+++ |upper |Direction|brain stem |Internal_organ_or_component|1 | |left |Direction|cerebellum |Internal_organ_or_component|1 | |right |Direction|basil ganglia|Internal_organ_or_component|1 | +++-+++ from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;,&quot;en&quot;,&quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_org&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_org&quot;]) .setOutputCol(&quot;ner_chunk_org&quot;) token_classifier = nlp.DeBertaForTokenClassification.pretrained(&quot;deberta_v3_base_token_classifier_ontonotes&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;ner_date&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) ner_converter_date = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_date&quot;]) .setOutputCol(&quot;ner_chunk_date&quot;) .setWhiteList([&quot;DATE&quot;]) chunk_merger = finance.ChunkMergeApproach() .setInputCols(&quot;ner_chunk_org&quot;, &quot;ner_chunk_date&quot;) .setOutputCol(&#39;ner_chunk&#39;) re_model = finance.RelationExtractionDLModel.pretrained(&quot;finre_acquisitions_subsidiaries&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setPredictionThreshold(0.3) .setInputCols([&quot;ner_chunk&quot;, &quot;document&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, token_classifier, ner_converter_date, chunk_merger, re_model ]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) ner_model = legal.NerModel.pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) re_model = legal.RelationExtractionDLModel.pretrained(&quot;legre_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, re_model ]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Relation Extraction between body parts // This is a continuation of the [[RENerChunksFilter]] example. See that class on how to extract the relation chunks. // Define the extraction model val re_ner_chunk_filter = new medical.RENerChunksFilter() .setInputCols(&quot;ner_chunks&quot;, &quot;dependencies&quot;) .setOutputCol(&quot;re_ner_chunks&quot;) .setMaxSyntacticDistance(4) .setRelationPairs(Array(&quot;internal_organ_or_component-direction&quot;)) val re_model = medical.RelationExtractionDLModel.pretrained(&quot;redl_bodypart_direction_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5f) .setInputCols(&quot;re_ner_chunks&quot;, &quot;sentences&quot;) .setOutputCol(&quot;relations&quot;) val trained_pipeline = new Pipeline().setStages(Array( documenter, sentencer, tokenizer, words_embedder, pos_tagger, clinical_ner_tagger, ner_chunker, dependency_parser, re_ner_chunk_filter, re_model )) val data = Seq(&quot;MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia&quot;).toDF(&quot;text&quot;) val result = trained_pipeline.fit(data).transform(data) // Show results // // result.selectExpr(&quot;explode(relations) as relations&quot;) // .select( // &quot;relations.metadata.chunk1&quot;, // &quot;relations.metadata.entity1&quot;, // &quot;relations.metadata.chunk2&quot;, // &quot;relations.metadata.entity2&quot;, // &quot;relations.result&quot; // ) // .where(&quot;result != 0&quot;) // .show(truncate=false) // +++-+++ // |chunk1|entity1 |chunk2 |entity2 |result| // +++-+++ // |upper |Direction|brain stem |Internal_organ_or_component|1 | // |left |Direction|cerebellum |Internal_organ_or_component|1 | // |right |Direction|basil ganglia|Internal_organ_or_component|1 | // +++-+++ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner_org&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_org&quot;)) .setOutputCol(&quot;ner_chunk_org&quot;) val token_classifier = nlp.DeBertaForTokenClassification .pretrained(&quot;deberta_v3_base_token_classifier_ontonotes&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;ner_date&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) val ner_converter_date = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner_date&quot;)) .setOutputCol(&quot;ner_chunk_date&quot;) .setWhiteList(Array(&quot;DATE&quot;)) val chunk_merger = new finance.ChunkMergeApproach() .setInputCols(&quot;ner_chunk_org&quot;, &quot;ner_chunk_date&quot;) .setOutputCol(&#39;ner_chunk&#39;) val re_model = finance.RelationExtractionDLModel .pretrained(&quot;finre_acquisitions_subsidiaries&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setPredictionThreshold(0.3) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;document&quot;)) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, token_classifier, ner_converter_date, chunk_merger, re_model )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.RoBertaEmbeddings .pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setMaxSentenceLength(512) val ner_model = legal.NerModel .pretrained(&quot;legner_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val re_model = legal.RelationExtractionDLModel .pretrained(&quot;legre_contract_doc_parties&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setPredictionThreshold(0.5) .setInputCols(Array(&quot;ner_chunk&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, re_model )) val result = pipeline.fit(data).transform(data) SentenceEntityResolver ApproachModel Trains a SentenceEntityResolverModel that maps sentence embeddings to entities in a knowledge base. To train a custom model, you need to provide a dataset with the following columns: label: Entity name chunk: Occurrence of the entity in the text, without standartization sentence_embeddings: Sentence embeddings from, e.g., the BertSentenceEmbeddings annotator. Optionally, you can also provide the following columns: aux_label: Auxiliary label which maps resolved entities to additional labels. If you have ground truth of the knowledge base entities, setting this column will help the model to learn better. You can find pretrained Sentence Embeddings (using BERT or other architecgture) in the NLP Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;_. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverApproach Scala API: SentenceEntityResolverApproach Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import nlp, medical # Training a SNOMED resolution model using BERT sentence embeddings # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) snomedTrainingPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with bertExtractor = medical.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import nlp, finance # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_large_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) preprocessing_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) preprocessing_model = preprocessing_pipeline.fit(data) processed_data = preprocessing_model.transform(data).cache() # Then the Resolver can be trained with bertExtractor = finance.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) model = bertExtractor.fit(processed_data) from johnsnowlabs import nlp, legal # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_uncased_legal&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) preprocessing_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) data_preprocessing_model = preprocessing_pipeline.fit(data) processed_data = data_preprocessing_model.transform(data).cache() # Then the Resolver can be trained with bertExtractor = legal.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) model = bertExtractor.fit(processed_data) MedicalFinanceLegal from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new medical.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new finance.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) from johnsnowlabs import * // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new legal.SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g. BertSentenceEmbeddings and returns the normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc.). For a list of pretrained models, please see the Models Hub. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverModel Scala API: SentenceEntityResolverModel Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * # Resolving CPT # First define pipeline stages to extract entities documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = medical.NerModel.pretrained(&quot;jsl_ner_wip_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Test&quot;,&quot;Procedure&quot;]) c2doc = nlp.Chunk2Doc() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = nlp.BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) # Then the resolver is defined on the extracted entities and sentence embeddings cpt_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cpt_procedures_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;cpt_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) sbert_pipeline_cpt = Pipeline().setStages([ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, c2doc, sbert_embedder, cpt_resolver]) sbert_outputs = sbert_pipeline_cpt.fit(data_ner).transform(data) # Show results # # sbert_outputs # .select(&quot;explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code&quot;) # .selectExpr( # &quot;cpt_code[&#39;0&#39;] as chunk&quot;, # &quot;cpt_code[&#39;1&#39;].entity as entity&quot;, # &quot;cpt_code[&#39;2&#39;] as code&quot;, # &quot;cpt_code[&#39;3&#39;].confidence as confidence&quot;, # &quot;cpt_code[&#39;3&#39;].all_k_resolutions as all_k_resolutions&quot;, # &quot;cpt_code[&#39;3&#39;].all_k_results as all_k_results&quot; # ).show(5) # +--++--+-+--+--+ # | chunk| entity| code|confidence| all_k_resolutions| all_k_codes| # +--++--+-+--+--+ # | heart cath|Procedure|93566| 0.1180|CCA - Cardiac cat...|93566:::62319:::9...| # |selective coronar...| Test|93460| 0.1000|Coronary angiogra...|93460:::93458:::9...| # |common femoral an...| Test|35884| 0.1808|Femoral artery by...|35884:::35883:::3...| # | StarClose closure|Procedure|33305| 0.1197|Heart closure:::H...|33305:::33300:::3...| # | stress test| Test|93351| 0.2795|Cardiovascular st...|93351:::94621:::9...| # +--++--+-+--+--+ # from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk2doc = nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sentence_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_edgar_company_name&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;text&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver ]) result = pipeline.fit(data).transform(data) from johnsnowlabs import * documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel.pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk2doc = nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sentence_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) resolver = legal.SentenceEntityResolverModel.pretrained(&quot;legel_edgar_company_name&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;text&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver ]) result = pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * // Resolving CPT // First define pipeline stages to extract entities val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val word_embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val clinical_ner = medical.NerModel.pretrained(&quot;jsl_ner_wip_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(&quot;Test&quot;,&quot;Procedure&quot;) val c2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sbert_embedder = nlp.BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sbert_embeddings&quot;) // Then the resolver is defined on the extracted entities and sentence embeddings val cpt_resolver = medical.SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cpt_procedures_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sbert_embeddings&quot;)) .setOutputCol(&quot;cpt_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val sbert_pipeline_cpt = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, c2doc, sbert_embedder, cpt_resolver)) // Show results // // sbert_outputs // .select(&quot;explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code&quot;) // .selectExpr( // &quot;cpt_code[&#39;0&#39;] as chunk&quot;, // &quot;cpt_code[&#39;1&#39;].entity as entity&quot;, // &quot;cpt_code[&#39;2&#39;] as code&quot;, // &quot;cpt_code[&#39;3&#39;].confidence as confidence&quot;, // &quot;cpt_code[&#39;3&#39;].all_k_resolutions as all_k_resolutions&quot;, // &quot;cpt_code[&#39;3&#39;].all_k_results as all_k_results&quot; // ).show(5) // +--++--+-+--+--+ // | chunk| entity| code|confidence| all_k_resolutions| all_k_codes| // +--++--+-+--+--+ // | heart cath|Procedure|93566| 0.1180|CCA - Cardiac cat...|93566:::62319:::9...| // |selective coronar...| Test|93460| 0.1000|Coronary angiogra...|93460:::93458:::9...| // |common femoral an...| Test|35884| 0.1808|Femoral artery by...|35884:::35883:::3...| // | StarClose closure|Procedure|33305| 0.1197|Heart closure:::H...|33305:::33300:::3...| // | stress test| Test|93351| 0.2795|Cardiovascular st...|93351:::94621:::9...| // +--++--+-+--+--+ // from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = finance.NerModel .pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val chunk2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sentence_embeddings = nlp.UniversalSentenceEncoder .pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val resolver = finance.SentenceEntityResolverModel .pretrained(&quot;finel_edgar_company_name&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols(Array(&quot;text&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver )) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val documentAssembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = nlp.SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new nlp.Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = nlp.BertEmbeddings .pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = legal.NerModel .pretrained(&quot;legner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new nlp.NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val chunk2doc = new nlp.Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) val sentence_embeddings = nlp.UniversalSentenceEncoder .pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) .setInputCols(&quot;ner_chunk_doc&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) val resolver = legal.SentenceEntityResolverModel .pretrained(&quot;legel_edgar_company_name&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols(Array(&quot;text&quot;, &quot;sentence_embeddings&quot;)) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter, chunk2doc, sentence_embeddings, resolver )) val result = pipeline.fit(data).transform(data) Summarizer Summarizer annotator that uses a generative deep learning model to create summaries of medical texts given clinical contexts. This annotator helps to quickly summarize complex medical information. Available models can be found at the Models Hub. For more extended examples on document pre-processing see the Spark NLP Workshop Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: MedicalSummarizer Scala API: MedicalSummarizer Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = medical.Summarizer .pretrained(&quot;summarizer-generic-jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) .setMaxTextLength(1024) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = finance.Summarizer .pretrained(&quot;summarizer-generic-jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) .setMaxTextLength(1024) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_summarizer = legal.Summarizer .pretrained(&quot;summarizer-generic-jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) .setMaxTextLength(1024) pipeline = nlp.Pipeline(stages=[document_assembler, med_summarizer]) text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = medical.Summarizer.pretrained(&quot;flat_t5_ft_caching&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = finance.Summarizer.pretrained(&quot;flat_t5_ft_caching&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_summarizer = legal.Summarizer.pretrained(&quot;flat_t5_ft_caching&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(100) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_summarizer)) val text = &quot;&quot;&quot;Patient with hypertension, syncope, and spinal stenosis - for recheck. (Medical Transcription Sample Report) SUBJECTIVE: The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema. PAST MEDICAL HISTORY / SURGERY / HOSPITALIZATIONS: Reviewed and unchanged from the dictation on 12/03/2003. MEDICATIONS: Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily. She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash. ALLERGIES:...&quot;&quot;&quot; val data = Seq(text).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) TextGenerator TextGenerator uses the basic BioGPT model to perform various tasks related to medical text abstraction. With this annotator, a user can provide a prompt and context and instruct the system to perform a specific task, such as explaining why a patient may have a particular disease or paraphrasing the context more directly. In addition, this annotator can create a clinical note for a cancer patient using the given keywords or write medical texts based on introductory sentences. The BioGPT model is trained on large volumes of medical data allowing it to identify and extract the most relevant information from the text provided. Available models can be found at the Models Hub. For more extended examples on document pre-processing see the Spark NLP Workshop. Input Annotator Types: DOCUMENT Output Annotator Type: CHUNK Python API: MedicalTextGenerator Scala API: MedicalTextGenerator Show Example PythonScala MedicalFinanceLegal from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = medical.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = finance.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) from johnsnowlabs import * document_assembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) med_text_generator = legal.TextGenerator .pretrained(&quot;medical_text_generator&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(True) .setTopK(3) .setRandomSeed(42) pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator ]) data = spark.createDataFrame([ [&quot;Covid 19 is&quot;], [&quot;The most common cause of stomach pain is&quot;] ]).toDF(&quot;text&quot;) pipeline.fit(data).transform(data) MedicalFinanceLegal from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = medical.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = finance.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) from johnsnowlabs import * val document_assembler = new nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val med_text_generator = legal.TextGenerator .pretrained(&quot;medical_text_generator&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summary&quot;) .setMaxNewTokens(20) .setDoSample(true) .setTopK(3) .setRandomSeed(42) val pipeline = new nlp.Pipeline().setStages(Array(document_assembler, med_text_generator )) val data = Seq(Array( &quot;Covid 19 is&quot;, &quot;The most common cause of stomach pain is&quot;)).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) ZeroShotNerModel This is a zero shot named entity recognition based on RoBertaForQuestionAnswering. Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain. Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in many different scenarions. Input Annotator Types: DOCUMENT, TOKEN Output Annotator Type: NAMED_ENTITY Python API: ZeroShotNerModel Scala API: ZeroShotNerModel Show Example PythonScala MedicalFinanceLegal documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentenceDetector = ( SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) zero_shot_ner = ( ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setEntityDefinitions( { &quot;PROBLEM&quot;: [ &quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot;, &quot;What does a patient suffer&quot;, &quot;What was the reason that the patient is admitted to the clinic?&quot;, ], &quot;DRUG&quot;: [ &quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;, ], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [ &quot;How old is the patient?&quot;, &quot;What is the gae of the patient?&quot;, ], } ) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setPredictionThreshold(0.1) ) # default 0.01 ner_converter = ( sparknlp.annotators.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter, ] ) zero_shot_ner_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text_list = [ &quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis.&quot;, ] data = spark.createDataFrame(text_list, StringType()).toDF(&quot;text&quot;) results = zero_shot_ner_model.transform(data) results.select( F.explode( F.arrays_zip( results.token.result, results.zero_shot_ner.result, results.zero_shot_ner.metadata, results.zero_shot_ner.begin, results.zero_shot_ner.end, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;token&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols[&#39;2&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sentence&quot;), F.expr(&quot;cols[&#39;3&#39;]&quot;).alias(&quot;begin&quot;), F.expr(&quot;cols[&#39;4&#39;]&quot;).alias(&quot;end&quot;), F.expr(&quot;cols[&#39;2&#39;][&#39;confidence&#39;]&quot;).alias(&quot;confidence&quot;), ).show( 50, truncate=100 ) +-+-+--+--++-+ token| ner_label|sentence|begin|end|confidence| +-+-+--+--++-+ The| O| 0| 0| 2| null| doctor| O| 0| 4| 9| null| pescribed| O| 0| 11| 19| null| Majezik| B-DRUG| 0| 21| 27| 0.6467137| for| O| 0| 29| 31| null| my| O| 0| 33| 34| null| severe| B-PROBLEM| 0| 36| 41|0.55263567| headache| I-PROBLEM| 0| 43| 50|0.55263567| .| O| 0| 51| 51| null| The| O| 0| 0| 2| null| patient| O| 0| 4| 10| null| was| O| 0| 12| 14| null| admitted| O| 0| 16| 23| null| to| O| 0| 25| 26| null| the| O| 0| 28| 30| null| hospital| O| 0| 32| 39| null| for| O| 0| 41| 43| null| his| O| 0| 45| 47| null| colon| B-PROBLEM| 0| 49| 53| 0.8898501| cancer| I-PROBLEM| 0| 55| 60| 0.8898501| .| O| 0| 61| 61| null| 27| B-PATIENT_AGE| 0| 0| 1| 0.6943086| years| I-PATIENT_AGE| 0| 3| 7| 0.6943086| old| I-PATIENT_AGE| 0| 9| 11| 0.6943086| patient| O| 0| 13| 19| null| was| O| 0| 21| 23| null| admitted| O| 0| 25| 32| null| to| O| 0| 34| 35| null| clinic| O| 0| 37| 42| null| on| O| 0| 44| 45| null| Sep|B-ADMISSION_DATE| 0| 47| 49|0.95646083| 1st|I-ADMISSION_DATE| 0| 51| 53|0.95646083| by| O| 0| 55| 56| null| Dr| O| 0| 58| 59| null| .| O| 0| 60| 60| null| X| O| 0| 62| 62| null| for| O| 0| 64| 66| null| a| B-PROBLEM| 0| 68| 68|0.50026655| right-sided| I-PROBLEM| 0| 70| 80|0.50026655| pleural| I-PROBLEM| 0| 82| 88|0.50026655| effusion| I-PROBLEM| 0| 90| 97|0.50026655| for| I-PROBLEM| 0| 99|101|0.50026655| thoracentesis| I-PROBLEM| 0| 103|115|0.50026655| .| O| 0| 116|116| null| +-+-+--+--++-+ document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) sentence_detector = ( nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) ) tokenizer = nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) zero_shot_ner = ( finance.ZeroShotNerModel.pretrained( &quot;finner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [ &quot;When was the company acquisition?&quot;, &quot;When was the company purchase agreement?&quot;, ], &quot;ORG&quot;: [&quot;Which company was acquired?&quot;], &quot;PRODUCT&quot;: [&quot;Which product?&quot;], &quot;PROFIT_INCREASE&quot;: [&quot;How much has the gross profit increased?&quot;], &quot;REVENUES_DECLINED&quot;: [&quot;How much has the revenues declined?&quot;], &quot;OPERATING_LOSS_2020&quot;: [&quot;Which was the operating loss in 2020&quot;], &quot;OPERATING_LOSS_2019&quot;: [&quot;Which was the operating loss in 2019&quot;], } ) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = nlp.Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, zero_shot_ner, ner_converter, ] ) from pyspark.sql.types import StringType sample_text = [ &quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.&quot;, &quot;We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019.&quot;, ] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select( F.explode( F.arrays_zip( res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;) ).filter( &quot;ner_label!=&#39;O&#39;&quot; ).show( truncate=False ) ++-+ |chunk |ner_label | ++-+ |March 2012 |DATE | |Vertro |ORG | |ALOT |PRODUCT | |February 2017 |DATE | |NetSeer |ORG | |81.4% |PROFIT_INCREASE | |27% |REVENUES_DECLINED | |$8,048,581 million|OPERATING_LOSS_2020| |$7,738,193 |OPERATING_LOSS_2019| |2019 |DATE | ++-+ documentAssembler = nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentence = nlp.SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) zero_shot_ner = ( legal.ZeroShotNerModel.pretrained(&quot;legner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [ &quot;When was the company acquisition?&quot;, &quot;When was the company purchase agreement?&quot;, &quot;When was the agreement?&quot;, ], &quot;ORG&quot;: [&quot;Which company?&quot;], &quot;STATE&quot;: [&quot;Which state?&quot;], &quot;AGREEMENT&quot;: [&quot;What kind of agreement?&quot;], &quot;LICENSE&quot;: [&quot;What kind of license?&quot;], &quot;LICENSE_RECIPIENT&quot;: [&quot;To whom the license is granted?&quot;], } ) ) nerconverter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) pipeline = nlp.Pipeline( stages=[ documentAssembler, sentence, tokenizer, zero_shot_ner, nerconverter, ] ) from pyspark.sql.types import StructType, StructField, StringType sample_text = [ &quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the &#39;Effective Date&#39;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&#39;Seller&#39;) and AFI Licensing LLC, a Delaware company (the &#39;Licensee&#39;)&quot;, &quot;The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license&quot;, ] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select( F.explode( F.arrays_zip( res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata, ) ).alias(&quot;cols&quot;) ).select( F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;) ).filter( &quot;ner_label!=&#39;O&#39;&quot; ).show( truncate=False ) +-+--+ |chunk |ner_label | +-+--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |LICENSE_RECIPIENT| |Delaware |STATE | |AFI Licensing LLC, a Delaware company|LICENSE_RECIPIENT| |Seller |LICENSE_RECIPIENT| |perpetual |LICENSE | |non- exclusive |LICENSE | |royalty-free |LICENSE | +-+--+ FinanceLegal val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val zeroShotNer = ZeroShotNerModel .pretrained() .setEntityDefinitions( Map( &quot;NAME&quot; -&gt; Array(&quot;What is his name?&quot;, &quot;What is her name?&quot;), &quot;CITY&quot; -&gt; Array(&quot;Which city?&quot;))) .setPredictionThreshold(0.01f) .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;zero_shot_ner&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, zeroShotNer)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Clara often travels between New York and Paris.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;document&quot;, &quot;explode(zero_shot_ner) AS entity&quot;) .select( col(&quot;entity.result&quot;), col(&quot;entity.metadata.word&quot;), col(&quot;entity.metadata.sentence&quot;), col(&quot;entity.begin&quot;), col(&quot;entity.end&quot;), col(&quot;entity.metadata.confidence&quot;), col(&quot;entity.metadata.question&quot;)) .show(truncate=false) ++--+--+--++-++ |result|word |sentence|begin|end|confidence|question | ++--+--+--++-++ |B-CITY|Paris|0 |41 |45 |0.78655756|Which is the city?| |B-CITY|New |0 |28 |30 |0.29346612|Which city? | |I-CITY|York |0 |32 |35 |0.29346612|Which city? | ++--+--+--++-++ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val zeroShotNer = ZeroShotNerModel .pretrained() .setEntityDefinitions( Map( &quot;NAME&quot; -&gt; Array(&quot;What is his name?&quot;, &quot;What is her name?&quot;), &quot;CITY&quot; -&gt; Array(&quot;Which city?&quot;))) .setPredictionThreshold(0.01f) .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;zero_shot_ner&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentenceDetector, zeroShotNer)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Clara often travels between New York and Paris.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;document&quot;, &quot;explode(zero_shot_ner) AS entity&quot;) .select( col(&quot;entity.result&quot;), col(&quot;entity.metadata.word&quot;), col(&quot;entity.metadata.sentence&quot;), col(&quot;entity.begin&quot;), col(&quot;entity.end&quot;), col(&quot;entity.metadata.confidence&quot;), col(&quot;entity.metadata.question&quot;)) .show(truncate=false) ++--+--+--++-++ |result|word |sentence|begin|end|confidence|question | ++--+--+--++-++ |B-CITY|Paris|0 |41 |45 |0.78655756|Which is the city?| |B-CITY|New |0 |28 |30 |0.29346612|Which city? | |I-CITY|York |0 |32 |35 |0.29346612|Which city? | ++--+--+--++-++ ZeroShotRelationExtractionModel ZeroShotRelationExtractionModel implements zero-shot binary relations extraction by utilizing BERT transformer models trained on the NLI (Natural Language Inference) task. The model inputs consists of documents/sentences and paired NER chunks, usually obtained by RENerChunksFilter. The definitions of relations which are extracted is given by a dictionary structures, specifying a set of statements regarding the relationship of named entities. These statements are automatically appended to each document in the dataset and the NLI model is used to determine whether a particular relationship between entities. For available pretrained models please see the NLP Models Hub. Input Annotator Types: CHUNK, DOCUMENT Output Annotator Type: CATEGORY Python API: ZeroShotRelationExtractionModel Scala API: ZeroShotRelationExtractionModel Show Example PythonScala MedicalFinanceLegal documenter = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sentencer = ( SentenceDetectorDLModel.pretrained( &quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) ) tokenizer = Tokenizer().setInputCols([&quot;sentences&quot;]).setOutputCol(&quot;tokens&quot;) words_embedder = ( WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_clinical = ( MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_clinical&quot;) ) ner_clinical_converter = ( NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_clinical&quot;]) .setOutputCol(&quot;ner_clinical_chunks&quot;) .setWhiteList([&quot;PROBLEM&quot;, &quot;TEST&quot;]) ) # PROBLEM-TEST-TREATMENT ner_posology = ( MedicalNerModel.pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_posology&quot;) ) ner_posology_converter = ( NerConverter() .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_posology&quot;]) .setOutputCol(&quot;ner_posology_chunks&quot;) .setWhiteList([&quot;DRUG&quot;]) ) # DRUG-FREQUENCY-DOSAGE-DURATION-FORM-ROUTE-STRENGTH chunk_merger = ( ChunkMergeApproach() .setInputCols(&quot;ner_clinical_chunks&quot;, &quot;ner_posology_chunks&quot;) .setOutputCol(&quot;merged_ner_chunks&quot;) ) ## ZERO-SHOT RE Starting... pos_tagger = ( PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) ) dependency_parser = ( DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;document&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) ) re_ner_chunk_filter = ( RENerChunksFilter() .setRelationPairs([&quot;problem-test&quot;, &quot;problem-drug&quot;]) .setMaxSyntacticDistance(4) .setDocLevelRelations(False) .setInputCols([&quot;merged_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) ) re_model = ( ZeroShotRelationExtractionModel.pretrained( &quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot; ) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationalCategories( { &quot;ADE&quot;: [&quot;{DRUG} causes {PROBLEM}.&quot;], &quot;IMPROVE&quot;: [&quot;{DRUG} improves {PROBLEM}.&quot;, &quot;{DRUG} cures {PROBLEM}.&quot;], &quot;REVEAL&quot;: [&quot;{TEST} reveals {PROBLEM}.&quot;], } ) .setMultiLabel(True) ) pipeline = sparknlp.base.Pipeline().setStages( [ documenter, sentencer, tokenizer, words_embedder, ner_clinical, ner_clinical_converter, ner_posology, ner_posology_converter, chunk_merger, pos_tagger, dependency_parser, re_ner_chunk_filter, re_model, ] ) sample_text = &quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot; data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;) model = pipeline.fit(data) results = model.transform(data) from pyspark.sql import functions as F results.select( F.explode(F.arrays_zip(results.relations.metadata, results.relations.result)).alias( &quot;cols&quot; ) ).select( F.expr(&quot;cols[&#39;0&#39;][&#39;sentence&#39;]&quot;).alias(&quot;sentence&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1_begin&#39;]&quot;).alias(&quot;entity1_begin&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1_end&#39;]&quot;).alias(&quot;entity1_end&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;chunk1&#39;]&quot;).alias(&quot;chunk1&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity1&#39;]&quot;).alias(&quot;entity1&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2_begin&#39;]&quot;).alias(&quot;entity2_begin&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2_end&#39;]&quot;).alias(&quot;entity2_end&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;chunk2&#39;]&quot;).alias(&quot;chunk2&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;entity2&#39;]&quot;).alias(&quot;entity2&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;hypothesis&#39;]&quot;).alias(&quot;hypothesis&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;nli_prediction&#39;]&quot;).alias(&quot;nli_prediction&quot;), F.expr(&quot;cols[&#39;1&#39;]&quot;).alias(&quot;relation&quot;), F.expr(&quot;cols[&#39;0&#39;][&#39;confidence&#39;]&quot;).alias(&quot;confidence&quot;), ).show( truncate=70 ) +--+-+--+--+-+-+--+--+-++--+--+-+ sentence|entity1_begin|entity1_end| chunk1|entity1|entity2_begin|entity2_end| chunk2|entity2| hypothesis|nli_prediction|relation|confidence| +--+-+--+--+-+-+--+--+-++--+--+-+ 0| 0| 10|Paracetamol| DRUG| 38| 45|sickness|PROBLEM|Paracetamol improves sickness.| entail| IMPROVE|0.98819494| 0| 0| 10|Paracetamol| DRUG| 26| 33|headache|PROBLEM|Paracetamol improves headache.| entail| IMPROVE| 0.9929625| 1| 48| 58|An MRI test| TEST| 80| 85| cancer|PROBLEM| An MRI test reveals cancer.| entail| REVEAL| 0.9760039| +--+-+--+--+-+-+--+--+-++--+--+-+ document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) sentence_detector = ( nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) ) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) embeddings = ( nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;, &quot;en&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ) ner_model = ( finance.NerModel.pretrained(&quot;finner_financial_small&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) re_model = ( finance.ZeroShotRelationExtractionModel.pretrained( &quot;finre_zero_shot&quot;, &quot;en&quot;, &quot;finance/models&quot; ) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;relations&quot;) .setMultiLabel(False) ) re_model.setRelationalCategories( { &quot;profit_decline_by&quot;: [ &quot;{PROFIT_DECLINE} decreased by {AMOUNT} from&quot;, &quot;{PROFIT_DECLINE} decreased by {AMOUNT} to&quot;, ], &quot;profit_decline_by_per&quot;: [ &quot;{PROFIT_DECLINE} decreased by a {PERCENTAGE} from&quot;, &quot;{PROFIT_DECLINE} decreased by a {PERCENTAGE} to&quot;, ], &quot;profit_decline_from&quot;: [ &quot;{PROFIT_DECLINE} decreased from {AMOUNT}&quot;, &quot;{PROFIT_DECLINE} decreased from {AMOUNT} for the year&quot;, ], &quot;profit_decline_from_per&quot;: [ &quot;{PROFIT_DECLINE} decreased from {PERCENTAGE} to&quot;, &quot;{PROFIT_DECLINE} decreased from {PERCENTAGE} to a total of&quot;, ], &quot;profit_decline_to&quot;: [&quot;{PROFIT_DECLINE} to {AMOUNT}&quot;], &quot;profit_increase_from&quot;: [&quot;{PROFIT_INCREASE} from {AMOUNT}&quot;], &quot;profit_increase_to&quot;: [&quot;{PROFIT_INCREASE} to {AMOUNT}&quot;], &quot;expense_decrease_by&quot;: [&quot;{EXPENSE_DECREASE} decreased by {AMOUNT}&quot;], &quot;expense_decrease_by_per&quot;: [&quot;{EXPENSE_DECREASE} decreased by a {PERCENTAGE}&quot;], &quot;expense_decrease_from&quot;: [&quot;{EXPENSE_DECREASE} decreased from {AMOUNT}&quot;], &quot;expense_decrease_to&quot;: [ &quot;{EXPENSE_DECREASE} for a total of {AMOUNT} for the fiscal year&quot; ], &quot;has_date&quot;: [ &quot;{AMOUNT} for the fiscal year ended {FISCAL_YEAR}&quot;, &quot;{PERCENTAGE} for the fiscal year ended {FISCAL_YEAR}&quot;, ], } ) pipeline = nlp.Pipeline( stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter, re_model, ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) sample_text = &quot;&quot;&quot;License fees revenue decreased 40 %, or $ 0.5 million to $ 0.7 million for the year ended December 31, 2020 compared to $ 1.2 million for the year ended December 31, 2019. Services revenue increased 4 %, or $ 1.1 million, to $ 25.6 million for the year ended December 31, 2020 from $ 24.5 million for the year ended December 31, 2019. Costs of revenue, excluding depreciation and amortization increased by $ 0.1 million, or 2 %, to $ 8.8 million for the year ended December 31, 2020 from $ 8.7 million for the year ended December 31, 2019. Also, a decrease in travel costs of $ 0.4 million due to travel restrictions caused by the global pandemic. As a percentage of revenue, cost of revenue, excluding depreciation and amortization was 34 % for each of the years ended December 31, 2020 and 2019. Sales and marketing expenses decreased 20 %, or $ 1.5 million, to $ 6.0 million for the year ended December 31, 2020 from $ 7.5 million for the year ended December 31, 2019&quot;&quot;&quot; data = spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;) result = model.transform(data) result.selectExpr(&quot;explode(relations) as relation&quot;).show(truncate=False) ++ |relation | ++ |{category, 8462, 8693, has_date, {entity1_begin -&gt; 227, relation -&gt; has_date, hypothesis -&gt; 25.6 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.8744761, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 332, entity1_end -&gt; 238, entity2_begin -&gt; 316, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 25.6 million, sentence -&gt; 1}, []} | |{category, 4643, 4873, has_date, {entity1_begin -&gt; 31, relation -&gt; has_date, hypothesis -&gt; 40 for the fiscal year ended December 31, 2019, confidence -&gt; 0.7889031, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 32, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 40, sentence -&gt; 0}, []} | |{category, 13507, 13748, expense_decrease_from, {entity1_begin -&gt; 799, relation -&gt; expense_decrease_from, hypothesis -&gt; Sales and marketing expenses decreased from 7.5 million, confidence -&gt; 0.9770538, nli_prediction -&gt; entail, entity1 -&gt; EXPENSE_DECREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 7.5 million, entity2_end -&gt; 933, entity1_end -&gt; 826, entity2_begin -&gt; 923, entity2 -&gt; AMOUNT, chunk1 -&gt; Sales and marketing expenses, sentence -&gt; 5}, []}| |{category, 5354, 5593, has_date, {entity1_begin -&gt; 59, relation -&gt; has_date, hypothesis -&gt; 0.7 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.6718765, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 69, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.7 million, sentence -&gt; 0}, []} | |{category, 6490, 6697, profit_increase_to, {entity1_begin -&gt; 172, relation -&gt; profit_increase_to, hypothesis -&gt; Services revenue to 25.6 million, confidence -&gt; 0.9674029, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 25.6 million, entity2_end -&gt; 238, entity1_end -&gt; 187, entity2_begin -&gt; 227, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 4412, 4642, has_date, {entity1_begin -&gt; 31, relation -&gt; has_date, hypothesis -&gt; 40 for the fiscal year ended December 31, 2020, confidence -&gt; 0.778003, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 32, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 40, sentence -&gt; 0}, []} | |{category, 13989, 14221, has_date, {entity1_begin -&gt; 838, relation -&gt; has_date, hypothesis -&gt; 20 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8545547, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 914, entity1_end -&gt; 839, entity2_begin -&gt; 898, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 20, sentence -&gt; 5}, []} | |{category, 11157, 11314, expense_decrease_by, {entity1_begin -&gt; 561, relation -&gt; expense_decrease_by, hypothesis -&gt; travel costs decreased by 0.4 million, confidence -&gt; 0.9946776, nli_prediction -&gt; entail, entity1 -&gt; EXPENSE_DECREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 0.4 million, entity2_end -&gt; 589, entity1_end -&gt; 572, entity2_begin -&gt; 579, entity2 -&gt; AMOUNT, chunk1 -&gt; travel costs, sentence -&gt; 3}, []} | |{category, 5114, 5353, has_date, {entity1_begin -&gt; 42, relation -&gt; has_date, hypothesis -&gt; 0.5 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.77566886, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 52, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.5 million, sentence -&gt; 0}, []} | |{category, 6281, 6489, profit_increase_from, {entity1_begin -&gt; 172, relation -&gt; profit_increase_from, hypothesis -&gt; Services revenue from 1.1 million, confidence -&gt; 0.96610945, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 1.1 million, entity2_end -&gt; 219, entity1_end -&gt; 187, entity2_begin -&gt; 209, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 9199, 9471, has_date, {entity1_begin -&gt; 408, relation -&gt; has_date, hypothesis -&gt; 0.1 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.9083246, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 537, entity1_end -&gt; 418, entity2_begin -&gt; 521, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.1 million, sentence -&gt; 2}, []} | |{category, 14455, 14696, has_date, {entity1_begin -&gt; 849, relation -&gt; has_date, hypothesis -&gt; 1.5 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.75281376, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 914, entity1_end -&gt; 859, entity2_begin -&gt; 898, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 1.5 million, sentence -&gt; 5}, []} | |{category, 14697, 14938, has_date, {entity1_begin -&gt; 849, relation -&gt; has_date, hypothesis -&gt; 1.5 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.8073463, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 970, entity1_end -&gt; 859, entity2_begin -&gt; 954, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 1.5 million, sentence -&gt; 5}, []} | |{category, 4874, 5113, has_date, {entity1_begin -&gt; 42, relation -&gt; has_date, hypothesis -&gt; 0.5 million for the fiscal year ended December 31, 2020, confidence -&gt; 0.71575713, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 106, entity1_end -&gt; 52, entity2_begin -&gt; 90, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.5 million, sentence -&gt; 0}, []} | |{category, 6908, 7115, profit_increase_to, {entity1_begin -&gt; 172, relation -&gt; profit_increase_to, hypothesis -&gt; Services revenue to 24.5 million, confidence -&gt; 0.85972106, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_INCREASE, syntactic_distance -&gt; undefined, chunk2 -&gt; 24.5 million, entity2_end -&gt; 295, entity1_end -&gt; 187, entity2_begin -&gt; 284, entity2 -&gt; AMOUNT, chunk1 -&gt; Services revenue, sentence -&gt; 1}, []} | |{category, 5594, 5833, has_date, {entity1_begin -&gt; 59, relation -&gt; has_date, hypothesis -&gt; 0.7 million for the fiscal year ended December 31, 2019, confidence -&gt; 0.7484568, nli_prediction -&gt; entail, entity1 -&gt; AMOUNT, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 169, entity1_end -&gt; 69, entity2_begin -&gt; 153, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 0.7 million, sentence -&gt; 0}, []} | |{category, 7326, 7546, has_date, {entity1_begin -&gt; 199, relation -&gt; has_date, hypothesis -&gt; 4 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8412763, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 275, entity1_end -&gt; 199, entity2_begin -&gt; 259, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 4, sentence -&gt; 1}, []} | |{category, 9472, 9734, has_date, {entity1_begin -&gt; 424, relation -&gt; has_date, hypothesis -&gt; 2 for the fiscal year ended December 31, 2020, confidence -&gt; 0.8046481, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2020, entity2_end -&gt; 481, entity1_end -&gt; 424, entity2_begin -&gt; 465, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 2, sentence -&gt; 2}, []} | |{category, 9735, 9997, has_date, {entity1_begin -&gt; 424, relation -&gt; has_date, hypothesis -&gt; 2 for the fiscal year ended December 31, 2019, confidence -&gt; 0.8485106, nli_prediction -&gt; entail, entity1 -&gt; PERCENTAGE, syntactic_distance -&gt; undefined, chunk2 -&gt; December 31, 2019, entity2_end -&gt; 537, entity1_end -&gt; 424, entity2_begin -&gt; 521, entity2 -&gt; FISCAL_YEAR, chunk1 -&gt; 2, sentence -&gt; 2}, []} | |{category, 691, 916, profit_decline_by_per, {entity1_begin -&gt; 0, relation -&gt; profit_decline_by_per, hypothesis -&gt; License fees revenue decreased by a 40 to, confidence -&gt; 0.9948003, nli_prediction -&gt; entail, entity1 -&gt; PROFIT_DECLINE, syntactic_distance -&gt; undefined, chunk2 -&gt; 40, entity2_end -&gt; 32, entity1_end -&gt; 19, entity2_begin -&gt; 31, entity2 -&gt; PERCENTAGE, chunk1 -&gt; License fees revenue, sentence -&gt; 0}, []} | ++ only showing top 20 rows document_assembler = ( nlp.DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) ) tokenizer = nlp.Tokenizer().setInputCols([&quot;sentence&quot;]).setOutputCol(&quot;token&quot;) tokenClassifier = ( legal.BertForTokenClassification.pretrained( &quot;legner_obligations&quot;, &quot;en&quot;, &quot;legal/models&quot; ) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ) ner_converter = ( nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) ) re_model = ( legal.ZeroShotRelationExtractionModel.pretrained( &quot;legre_zero_shot&quot;, &quot;en&quot;, &quot;legal/models&quot; ) .setInputCols([&quot;ner_chunk&quot;, &quot;document&quot;]) .setOutputCol(&quot;relations&quot;) ) re_model.setRelationalCategories( { &quot;should_provide&quot;: [ &quot;{OBLIGATION_SUBJECT} will provide {OBLIGATION}&quot;, &quot;{OBLIGATION_SUBJECT} should provide {OBLIGATION}&quot;, ], &quot;commits_with&quot;: [ &quot;{OBLIGATION_SUBJECT} to {OBLIGATION_INDIRECT_OBJECT}&quot;, &quot;{OBLIGATION_SUBJECT} with {OBLIGATION_INDIRECT_OBJECT}&quot;, ], &quot;commits_to&quot;: [&quot;{OBLIGATION_SUBJECT} commits to {OBLIGATION}&quot;], &quot;agree_to&quot;: [&quot;{OBLIGATION_SUBJECT} agrees to {OBLIGATION}&quot;], } ) pipeline = nlp.Pipeline( stages=[document_assembler, tokenizer, tokenClassifier, ner_converter, re_model] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) import pandas as pd def get_relations_df(results, col=&quot;relations&quot;): rel_pairs = [] for i in range(len(results)): for rel in results[i][col]: rel_pairs.append( ( rel.result, rel.metadata[&quot;entity1&quot;], rel.metadata[&quot;entity1_begin&quot;], rel.metadata[&quot;entity1_end&quot;], rel.metadata[&quot;chunk1&quot;], rel.metadata[&quot;entity2&quot;], rel.metadata[&quot;entity2_begin&quot;], rel.metadata[&quot;entity2_end&quot;], rel.metadata[&quot;chunk2&quot;], rel.metadata[&quot;confidence&quot;], ) ) rel_df = pd.DataFrame( rel_pairs, columns=[ &quot;relation&quot;, &quot;entity1&quot;, &quot;entity1_begin&quot;, &quot;entity1_end&quot;, &quot;chunk1&quot;, &quot;entity2&quot;, &quot;entity2_begin&quot;, &quot;entity2_end&quot;, &quot;chunk2&quot;, &quot;confidence&quot;, ], ) return rel_df sample_text = &quot;&quot;&quot;This INTELLECTUAL PROPERTY AGREEMENT (this &quot;Agreement&quot;), dated as of December 31, 2018 (the &quot;Effective Date&quot;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&quot;Seller&quot;) and AFI Licensing LLC, a Delaware limited liability company (&quot;Licensing&quot; and together with Seller, &quot;Arizona&quot;) and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (&quot;Buyer&quot;) and Armstrong Hardwood Flooring Company, a Tennessee corporation (the &quot;Company&quot; and together with Buyer the &quot;Buyer Entities&quot;) (each of Arizona on the one hand and the Buyer Entities on the other hand, a &quot;Party&quot; and collectively, the &quot;Parties&quot;).&quot;&quot;&quot; result = light_model.fullAnnotate(sample_text) rel_df = get_relations_df(result) rel_df[rel_df[&quot;relation&quot;] != &quot;no_rel&quot;] | relation | entity1 | entity1_begin | entity1_end | chunk1 | entity2 | entity2_begin | entity2_end | chunk2 | confidence | |:|--:|--:|:|:|--:|--:|:|:|--:| | dated_as | DOC | 5 | 35 | INTELLECTUAL PROPERTY AGREEMENT | EFFDATE | 69 | 85 | December 31, 2018 | 0.98433626 | | signed_by | DOC | 5 | 35 | INTELLECTUAL PROPERTY AGREEMENT | PARTY | 141 | 163 | Armstrong Flooring, Inc | 0.60404813 | | has_alias | PARTY | 141 | 163 | Armstrong Flooring, Inc | ALIAS | 192 | 197 | Seller | 0.96357507 | | has_alias | PARTY | 205 | 221 | AFI Licensing LLC | ALIAS | 263 | 271 | Licensing | 0.9546678 | | has_alias | PARTY | 315 | 330 | AHF Holding, Inc | ALIAS | 611 | 615 | Party | 0.5387175 | | has_alias | PARTY | 315 | 330 | AHF Holding, Inc | ALIAS | 641 | 647 | Parties | 0.5387175 | | has_collective_alias | ALIAS | 399 | 403 | Buyer | ALIAS | 611 | 615 | Party | 0.5539445 | | has_collective_alias | ALIAS | 399 | 403 | Buyer | ALIAS | 641 | 647 | Parties | 0.5539445 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 478 | 484 | Company | 0.92106056 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 611 | 615 | Party | 0.58123946 | | has_alias | PARTY | 411 | 445 | Armstrong Hardwood Flooring Company | ALIAS | 641 | 647 | Parties | 0.58123946 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 516 | 529 | Buyer Entities | 0.63492435 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 611 | 615 | Party | 0.6483803 | | has_collective_alias | ALIAS | 505 | 509 | Buyer | ALIAS | 641 | 647 | Parties | 0.6483803 | | has_collective_alias | ALIAS | 516 | 529 | Buyer Entities | ALIAS | 611 | 615 | Party | 0.6970743 | | has_collective_alias | ALIAS | 516 | 529 | Buyer Entities | ALIAS | 641 | 647 | Parties | 0.6970743 | Medical val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;tokens&quot;) val sentencer = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentences&quot;) val embeddings = WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;) val posTagger = PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;) val nerTagger = MedicalNerModel .pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;nerTags&quot;) val nerConverter = new NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;nerTags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val dependencyParser = DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;) val reNerFilter = new RENerChunksFilter() .setRelationPairs(Array(&quot;problem-test&quot;,&quot;problem-treatment&quot;)) .setMaxSyntacticDistance(4) .setDocLevelRelations(false) .setInputCols(Array(&quot;nerChunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;RENerChunks&quot;) val re = ZeroShotRelationExtractionModel .load(&quot;/tmp/spark_sbert_zero_shot&quot;) .setRelationalCategories( Map( &quot;CURE&quot; -&gt; Array(&quot;{TREATMENT} cures {PROBLEM}.&quot;), &quot;IMPROVE&quot; -&gt; Array(&quot;{TREATMENT} improves {PROBLEM}.&quot;, &quot;{TREATMENT} cures {PROBLEM}.&quot;), &quot;REVEAL&quot; -&gt; Array(&quot;{TEST} reveals {PROBLEM}.&quot;) )) .setPredictionThreshold(0.9f) .setMultiLabel(false) .setInputCols(Array(&quot;sentences&quot;, &quot;RENerChunks&quot;)) .setOutputCol(&quot;relations) val pipeline = new Pipeline() .setStages(Array( documentAssembler, sentencer, tokenizer, embeddings, posTagger, nerTagger, nerConverter, dependencyParser, reNerFilter, re)) val model = pipeline.fit(Seq(&quot;&quot;).toDS.toDF(&quot;text&quot;)) val results = model.transform( Seq(&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;).toDS.toDF(&quot;text&quot;)) results .selectExpr(&quot;EXPLODE(relations) as relation&quot;) .selectExpr(&quot;relation.result&quot;, &quot;relation.metadata.confidence&quot;) .show(truncate = false) +-+-+ |result |confidence| +-+-+ |REVEAL |0.9760039 | |IMPROVE|0.98819494| |IMPROVE|0.9929625 | +-+-+",
    "url": "/docs/en/licensed_annotators",
    "relUrl": "/docs/en/licensed_annotators"
  },
  "1250": {
    "id": "1250",
    "title": "Enterprise Spark NLP Installation",
    "content": "AWS Marketplace The entire suite of John Snow Labs NLP and Visual NLP libraries are offered as a pay-as-you-go product on AWS Marketplace, pre-installed and ready to use. 30+ Notebooks are included in the AWS product to allow you to start experimenting on your own data right away. To subscribe to the pay-as-you-go product on AWS Marketplace navigate to the product page and follow the instructions in the video below. Subscribe to John Snow Labs NLP Libraries via AWS Marketplace Note: 30-day free trial are available for AWS and Azure subscriptions. Installation with johnsnowlabs On Oct 4th, 2022 we released johnsnowlabs library, which eases the installation and session starting processes in an almost transparent way for the user. Finance NLP and Legal NLP are built on the top of a new John Snow Labs library, called johnsnowlabs. If you are a former user of Spark NLP or Spark NLP for Healthcare, you will find this new way of deploying your Spark NLP clusters much more user-friendly! Clinical NLP (former Spark NLP for Healthcare) still can be run without johnsnowlabs library, although we highly recommend to install it with this new method. For advanced installation options, please check johnsnowlabs webpage. 1. Installing johnsnowlabs The first step you need to carry out is installing johnsnowlabs library. This is as easy as doing: !pip install johnsnowlabs 2. Installing Enterprise NLP (Finance, Legal, Clinical) Import johnsnowlabs and use our one-liner nlp.install() to install all the dependencies, downloading the jars (yes, Spark NLP runs on top of the Java Virtual Machine!), preparing the cluster environment variables, licenses, etc! from johnsnowlabs import * nlp.install(force_browser=True) The force_browser=True command gets rid of you uploading a license. It will open a popup to connect to our license server at my.johnsnowlabs.com retrieve the license for you, and install everything your license allows you to use! If you are a user of Financial NLP, you will get that installed. If you are a Legal user, then Legal NLP will be installed, or Clinical! Everything will be taken care on your behalf! Optional: Uploading the license manually We still have the way of downloading manually the license, in case the connection with my.johnsnowlabs.com is not an option for you. Just put your license json in the same folder of the notebook, and run: nlp.install() In colab, you can use this fancy widget to upload a file to your environment: from google.colab import files print(&#39;Please Upload your John Snow Labs License using the button below&#39;) license_keys = files.upload() And then do: nlp.install() 3. Starting an Enterprise NLP cluster Another one-liner can be used to start your Enterprise Spark NLP cluster: spark = nlp.start() It will take into account the previous steps and your license and return a Spark Session. 4. Ready to go! And you are done! Simple, isn’t it? Find hundreds of notebooks using johnsnowlabs library here: Finance NLP notebooks Legal NLP notebooks Clinical NLP notebooks Finance, Legal, Clinical NLP on Databricks List of tested runtimes. Recommended instance type Standard_F8s_v2 (16 GB Memory, 8 Cores) or higher. The installation takes around 15 minutes. Connection via Databricks Partner connect Databricks has an integration of Spark NLP libraries via Partner Connect. If you are eligible, you can connect your Databricks workspace to John Snow Labs. The Partner Connect wizard will redirect you to John Snow Labs portal. After you fill-in/validate your information a 30-day trial license will be automatically generated for you. A new Databricks cluster will also be created, and all necessary resources to run the library on your account will be installed on your new cluster. Furthermore, a set of ready to use notebooks will be copied to your workspace, so you can start experimenting on your data right away. The trial license file will also be deployed to your environment and made available to your cluster. The trial period is 30 days. You can use the trial period only once. After the trial period, we will contact you with a licensing offer. Start exploring preloaded notebooks Workspace -&gt; Shared -&gt; John Snow Labs Automatic deployment of John Snow Labs NLP libraries from www.johnsnowlabs.com/databricks Alternatively, you can automatically deploy John Snow Labs libraries on Databricks by filling in the form available here. This will allow you to start a 30-day free trial with no limit on the amount of processed data. You just need to provide a Databricks Access Token that is used by our deployment script to connect to your Databricks instance and install John Snow Labs NLP libraries on a cluster of your choice. Start exploring preloaded notebooks Workspace -&gt; Shared -&gt; John Snow Labs Automatic deployment via my.JohnSnowLabs.com Login to your account on my.JohnSnowLabs.com, navigate to ‘My Subscriptions’ page, and identify your license for Databricks. Click on the three dots as illustrated in the image below, then select the Install On Cluster option. On the install form, provide an access token for this account and then select the cluster where you want to install the libraries. Once it is done, you will get an email with information on the status of your deployment and on how to get started with the libraries. Automatic deployment or upgrade from the Databricks workspace If you have already deployed the libraries in the past, you have a script Workspace -&gt; Shared -&gt; John Snow Labs -&gt; Install JohnSnowLabs NLP. If you attach it to any cluster and run it, it will reinstall the libraries on the respective cluster. This is also the recommended way to upgrade to the latest versions of the libraries. Manual deployment of Enterprise Spark NLP Automatic deployment is the preferred option. Create a cluster with one of the supported runtimes if you don’t have one already. On a new cluster or existing one you need to add the following to the Advanced Options -&gt; Spark tab, in Spark.Config box: spark.kryoserializer.buffer.max 1000M spark.serializer org.apache.spark.serializer.KryoSerializer Please add the following to the Advanced Options -&gt; Spark tab, in Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz Note: Enterprise Spark NLP also support reading the license from the Databricks DFS, on the fixed location, dbfs:/FileStore/johnsnowlabs/license.key. The precedence for that location is the highest, so make sure that file is not containing any outdated license key. (OPTIONAL) If the environment variables used to setup the AWS Access/Secret keys are conflicting with the credential provider chain in Databricks, you may not be able to access to other s3 buckets. To access both JSL repos with JSL AWS keys as well as your own s3 bucket with your own AWS keys), you need to use the following script, copy that to dbfs folder, then go to the Databricks console (init scripts menu) to add the init script for your cluster as follows: %scala val script = &quot;&quot;&quot; #!/bin/bash echo &quot;******** Inject Spark NLP AWS Profile Credentials ******** &quot; mkdir ~/.aws/ cat &lt;&lt; EOF &gt; ~/.aws/credentials [spark_nlp] aws_access_key_id=&lt;YOUR_AWS_ACCESS_KEY&gt; aws_secret_access_key=&lt;YOUR_AWS_SECRET_KEY&gt; EOF echo &quot;******** End Inject Spark NLP AWS Profile Credentials ******** &quot; &quot;&quot;&quot; In Libraries tab inside your cluster you need to follow these steps: Lookup the version of Healhcare NLP vs. Spark NLP you will install. Install Spark NLP (Public): New -&gt; PyPI -&gt; spark-nlp==${x.y.z_public_version} -&gt; Install Install: New -&gt; Maven -&gt; Coordinates -&gt; com.johnsnowlabs.nlp:spark-nlp_2.12:${x.y.z_public_version} -&gt; Install Please add following jars: Install: New -&gt; Python Whl -&gt; upload https://pypi.johnsnowlabs.com/${secret.code}/spark-nlp-jsl/spark_nlp_jsl-${x.y.z_healthcare_version}-py3-none-any.whl Install: New -&gt; Jar -&gt; upload https://pypi.johnsnowlabs.com/${secret.code}/spark-nlp-jsl-${x.y.z_healthcare_version}.jar (For Legal and Finance NLP) Install: New -&gt; PyPI -&gt; johnsnowlabs-for-databricks==${x.y.z_healthcare_version} -&gt; Install Now you can attach your notebook to the cluster and use Spark NLP! Windows Support In order to fully take advantage of Spark NLP on Windows (8 or 10), you need to setup/install Apache Spark, Apache Hadoop, Java and a Pyton environment correctly by following the following instructions: https://github.com/JohnSnowLabs/spark-nlp/discussions/1022 How to correctly install Spark NLP on Windows Follow the below steps to set up Spark NLP with Spark 3.1.2: Download Adopt OpenJDK 1.8 Make sure it is 64-bit Make sure you install it in the root of your main drive C: java. During installation after changing the path, select setting Path Download the pre-compiled Hadoop binaries winutils.exe, hadoop.dll and put it in a folder called C: hadoop bin from https://github.com/cdarlint/winutils/tree/master/hadoop-3.2.0/bin Note: The version above is for Spark 3.1.2, which was built for Hadoop 3.2.0. You might have to change the hadoop version in the link, depending on which Spark version you are using. Download Apache Spark 3.1.2 and extract it to C: spark. Set/add environment variables for HADOOP_HOME to C: hadoop and SPARK_HOME to C: spark. Add %HADOOP_HOME% bin and %SPARK_HOME% bin to the PATH environment variable. Install Microsoft Visual C++ 2010 Redistributed Package (x64). Create folders C: tmp and C: tmp hive If you encounter issues with permissions to these folders, you might need to change the permissions by running the following commands: %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/hive %HADOOP_HOME% bin winutils.exe chmod 777 /tmp/ Requisites for PySpark We recommend using conda to manage your python environment on Windows. Download Miniconda for python 3.8 See Quick Install on how to set up a conda environment with Spark NLP. The following environment variables need to be set: PYSPARK_python=python Optionally, if you want to use the Jupyter Notebook runtime of Spark: first install it in the environment with conda install notebook then set PYSPARK_DRIVER_python=jupyter, PYSPARK_DRIVER_python_OPTS=notebook The environment variables can either be directly set in windows, or if only the conda env will be used, with conda env config vars set PYSPARK_python=python. After setting the variable with conda, you need to deactivate and re-activate the environment. Now you can use the downloaded binary by navigating to %SPARK_HOME% bin and running Either create a conda env for python 3.6, install pyspark==3.1.2 spark-nlp numpy and use Jupyter/python console, or in the same conda env you can go to spark bin for pyspark –packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.4.4. Non-johnsnowlabs Clinical NLP on Ubuntu These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. For installing John Snow Labs NLP libraries on an Ubuntu machine/VM please run the following command: wget https://setup.johnsnowlabs.com/nlp/install.sh -O - | sudo bash -s -- -a PATH_TO_LICENSE_JSON_FILE -i -r This script will install Spark NLP, Enterprise Spark NLP, Spark OCR, NLU and Spark NLP Display on the specified virtual environment. It will also create a special folder, ./JohnSnowLabs, dedicated to all resources necessary for using the libraries. Under ./JohnSnowLabs/example_notebooks you will find some ready to use example notebooks that you can use to test the libraries on your data. For a complete step-by-step guide on how to install NLP Libraries check the video below: Install John Snow Labs NLP Libraries on Ubuntu The install script offers several options: -h show brief help -i install mode: create a virtual environment and install the library -r run mode: start jupyter after installation of the library -v path to virtual environment (default: ./sparknlp_env) -j path to license json file for Enterprise Spark NLP -o path to license json file for Spark OCR -a path to a single license json file for both Spark OCR and Spark NLP -s specify pyspark version -p specify port of jupyter notebook Use the -i flag for installing the libraries in a new virtual environment. You can provide the desired path for virtual env using -v flag, otherwise a default location of ./sparknlp_env will be selected. The PATH_TO_LICENSE_JSON_FILE parameter must be replaced with the path where the license file is available on the local machine. According to the libraries you want to use different flags are available: -j, -o or -a. The license files can be easily downloaded from My Subscription section in your my.JohnSnowLabs.com account. To start using Jupyter Notebook after the installation of the libraries use the -r flag. The install script downloads a couple of example notebooks that you can use to start experimenting with the libraries. Those will be availabe under ./JohnSnowLabs/example_notebooks folder. Non-johnsnowlabs Clinical NLP via Docker These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. A docker image that contains all the required libraries for installing and running Enterprise Spark NLP libraries is also available. However, it does not contain the library itself, as it is licensed, and requires installation credentials. Make sure you have a valid license for Enterprise Spark NLP libraries (in case you do not have one, you can ask for a trial here ), and follow the instructions below: Instructions Run the following commands to download the docker-compose.yml and the sparknlp_keys.txt files on your local machine: curl -o docker-compose.yaml https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/blob/513a4d682f11abc33b2e26ef8a9d72ad52a7b4f0/jupyter/docker_image_nlp_hc/docker-compose.yaml curl -o sparknlp_keys.txt https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/docker_image_nlp_hc/sparknlp_keys.txt Download your license key in json format from my.JohnSnowLabs.com Populate License keys in sparknlp_keys.txt file. Run the following command to run the container in detached mode: docker-compose up -d By default, the jupyter notebook runs on port 8888 - you can access it by typing localhost:8888 in your browser. Troubleshooting Make sure docker is installed on your system. If you face any error while importing the lib inside jupyter, make sure all the credentials are correct in the key files and restart the service again. If the default port 8888 is already occupied by another process, please change the mapping. You can change/adjust volume and port mapping in the docker-compose.yml file. You don’t have a license key? Ask for a trial license here. Non-johnsnowlabs Clinical NLP on python These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. You can install the Clinical NLP by using: pip install -q spark-nlp-jsl==${version} --extra-index-url https://pypi.johnsnowlabs.com/${secret.code} --upgrade {version} is the version part of the {secret.code} ({secret.code}.split(&#39;-&#39;)[0]) (i.e. 2.6.0) The {secret.code} is a secret code that is only available to users with valid/trial license. You can ask for a free trial for Enterprise Spark NLP libraries here. Then, you can obtain the secret code by visiting your account on my.JohnSnowLabs.com. Read more on how to get a license here. Setup AWS-CLI Credentials for licensed pretrained models You need to first set up your AWS credentials to be able to access the private repository for John Snow Labs Pretrained Models. You can do this setup via Amazon AWS Command Line Interface (AWSCLI). Instructions about how to install AWSCLI are available at: Installing the AWS CLI Make sure you configure your credentials with AWS configure following the instructions at: Configuring the AWS CLI Please substitute the ACCESS_KEY and SECRET_KEY with the credentials available on your license json file. This is available on your account from my.JohnSnowLabs.com. Read this for more information. Start Spark NLP Session from python The following will initialize the spark session in case you have run the Jupyter Notebook directly. If you have started the notebook using pyspark this cell is just ignored. Initializing the spark session takes some seconds (usually less than 1 minute) as the jar from the server needs to be loaded. The {secret.code} is a secret code that is only available to users with valid/trial license. You can ask for a free trial for Enterprise Spark NLP here. Then, you can obtain the secret code by visiting your account on my.JohnSnowLabs.com. Read more on how to get a license here. You can either use our convenience function to start your Spark Session that will use standard configuration arguments: import sparknlp_jsl spark = sparknlp_jsl.start(SECRET) Or use the SparkSession module for more flexibility: from pyspark.sql import SparkSession def start(SECRET): builder = SparkSession.builder .appName(&quot;Spark NLP Licensed&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;16G&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:&quot;+PUBLIC_VERSION) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/&quot;+SECRET+&quot;/spark-nlp-jsl-&quot;+JSL_VERSION+&quot;.jar&quot;) return builder.getOrCreate() spark = start(SECRET) If you want to download the source files (jar and whl files) locally, you can follow the instructions here. Cheatsheet # Install Spark NLP from PyPI pip install spark-nlp==3.2.3 #install Spark NLP helathcare pip install spark-nlp-jsl==${version} --extra-index-url https://pypi.johnsnowlabs.com/${secret.code} --upgrade # Load Spark NLP with Spark Shell spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar # Load Spark NLP with PySpark pyspark --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar # Load Spark NLP with Spark Submit spark-submit --packages com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3 --jars spark-nlp-jsl-${version}.jar Non-johnsnowlabs Clinical NLP for Scala These instructions use non-johnsnowlabs installation syntax, since johnsnowlabs is a Python library. Use Spark NLP in Spark shell 1.Download the fat jar for Enterprise Spark NLP aws s3 cp --region us-east-2 s3://pypi.johnsnowlabs.com/$jsl_secret/spark-nlp-jsl-$jsl_version.jar spark-nlp-jsl-$jsl_version.jar 2.Set up the Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz 3.The preferred way to use the library when running Spark programs is using the --packagesand --jar option as specified in the spark-packages section. spark-shell --packages com.johnsnowlabs.nlp:spark-nlp_2.12:${public-version} --jars /spark-nlp-jsl-${version}.jar Non-johnsnowlabs Clinical NLP in Sbt project These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. 1.Download the fat jar for Enterprise Spark NLP. aws s3 cp --region us-east-2 s3://pypi.johnsnowlabs.com/$jsl_secret/spark-nlp-jsl-$jsl_version.jar spark-nlp-jsl-$jsl_version.jar 2.Set up the Environment Variables box: AWS_ACCESS_KEY_ID=xxx AWS_SECRET_ACCESS_KEY=yyy SPARK_NLP_LICENSE=zzz 3.Add the spark-nlp jar in your build.sbt project libraryDependencies += &quot;com.johnsnowlabs.nlp&quot; %% &quot;spark-nlp&quot; % &quot;{public-version}&quot; 4.You need to create the /lib folder and paste the spark-nlp-jsl-${version}.jar file. 5.Add the fat spark-nlp-healthcare in your classpath. You can do it by adding this line in your build.sbt unmanagedJars in Compile += file(&quot;lib/sparknlp-jsl.jar&quot;) Non-johnsnowlabs Clinical NLP on Colab This is the way to run Clinical NLP in Google Colab if you don’t use johnsnowlabs library. Run the following code in Google Colab notebook and start using Spark NLP right away. The first thing that you need is to create the json file with the credentials and the configuration in your local system. { &quot;PUBLIC_VERSION&quot;: &quot;3.2.3&quot;, &quot;JSL_VERSION&quot;: &quot;{version}&quot;, &quot;SECRET&quot;: &quot;{version}-{secret.code}&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;xxxxx&quot;, &quot;AWS_ACCESS_KEY_ID&quot;: &quot;yyyy&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;zzzz&quot; } If you have a valid floating license, the license json file can be downloaded from your account on my.JohnSnowLabs.com on My Subscriptions section. To get a trial license please visit Then you need to write that piece of code to load the credentials that you created before. import json import os from google.colab import files license_keys = files.upload() with open(list(license_keys.keys())[0]) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) # This is only to setup PySpark and Spark NLP on Colab !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jsl_colab_setup.sh # -p is for pyspark (by default 3.1.1) !bash jsl_colab_setup.sh Spark NLP quick start on Google Colab is a live demo on Google Colab that performs named entity recognitions for HealthCare. Non-johnsnowlabs Clinical NLP on GCP Dataproc These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. You can follow the steps here for installation via IU Create a cluster if you don’t have one already as follows. At gcloud shell: gcloud services enable dataproc.googleapis.com compute.googleapis.com storage-component.googleapis.com bigquery.googleapis.com bigquerystorage.googleapis.com REGION=&lt;region&gt; BUCKET_NAME=&lt;bucket_name&gt; gsutil mb -c standard -l ${REGION} gs://${BUCKET_NAME} REGION=&lt;region&gt; ZONE=&lt;zone&gt; CLUSTER_NAME=&lt;cluster_name&gt; BUCKET_NAME=&lt;bucket_name&gt; You can set image-version, master-machine-type, worker-machine-type, master-boot-disk-size, worker-boot-disk-size, num-workers as your needs. If you use the previous image-version from 2.0, you should also add ANACONDA to optional-components. And, you should enable gateway. As noticed below, you should explicitly write JSL_SECRET and JSL_VERSION at metadata param inside the quotes. This will start the pip installation using the wheel file of Licensed SparkNLP! gcloud dataproc clusters create ${CLUSTER_NAME} --region=${REGION} --network=${NETWORK} --zone=${ZONE} --image-version=2.0 --master-machine-type=n1-standard-4 --worker-machine-type=n1-standard-2 --master-boot-disk-size=128GB --worker-boot-disk-size=128GB --num-workers=2 --bucket=${BUCKET_NAME} --optional-components=JUPYTER --enable-component-gateway --metadata &#39;PIP_PACKAGES=google-cloud-bigquery google-cloud-storage spark-nlp-display https://s3.eu-west-1.amazonaws.com/pypi.johnsnowlabs.com/JSL_SECRET/spark-nlp-jsl/spark_nlp_jsl-JSL_VERSION-py3-none-any.whl&#39; --initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh On an existing one, you need to install spark-nlp and spark-nlp-display packages from PyPI. Now, you can attach your notebook to the cluster and use Spark NLP via following the instructions. The key part of this usage is how to start SparkNLP sessions using Apache Hadoop YARN cluster manager. 3.1. Read license file from the notebook using GCS. 3.2. Set the right path of the Java Home Path. 3.3. Use the start function to start the SparkNLP JSL version such as follows: def start(secret): builder = SparkSession.builder .appName(&quot;Spark NLP Licensed&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.johnsnowlabs.nlp:spark-nlp_2.12:&quot;+PUBLIC_VERSION) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/&quot;+SECRET+&quot;/spark-nlp-jsl-&quot;+JSL_VERSION+&quot;.jar&quot;) return builder.getOrCreate() spark = start(SECRET) As you see, we did not set .master(&#39;local[*]&#39;) explicitly to let YARN manage the cluster. Or you can set .master(&#39;yarn&#39;). Non-johnsnowlabs Clinical NLP on AWS SageMaker These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. Access AWS Sagemaker in AWS. Go to Notebook -&gt; Notebook Instances. Create a new Notebook Instance, follow this Instructions Steps Minimum requirement 16G RAM and 50G Volume. This is the configuration we have used, although most of the interesting models will require a ml.t3.xlarge instance or more. Reserve at least 50GB of memory Once created, open JupyterLab and use Conda python 3 kernel. Upload license key and set Environment Variables. import json import os with open(&#39;spark_nlp_for_healthcare.json&#39;, &#39;r&#39;) as f: for k, v in json.load(f).items(): %set_env $k=$v %set_env PYSPARK=3.2.2 %set_env SPARK_HOME=/home/ec2-user/SageMaker/spark-3.2.2-bin-hadoop2.7 Download and install libraries !wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jsl_sagemaker_setup.sh !bash jsl_sagemaker_setup.sh Import libraries and start session import sparknlp import sparknlp_jsl from pyspark.sql import SparkSession spark = sparknlp_jsl.start(license_keys[&#39;SECRET&#39;]) Non-johnsnowlabs Clinical NLP with Poetry These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. This is a sample project.toml file which you can use with poetry install to setup spark NLP + the Healthcare python library spark-nlp-jsl You need to point it to either the tar.gz or .whl file which are hosted at https://pypi.johnsnowlabs.com/&lt;SECRET&gt;/spark-nlp-jsl/ NOTE You must update the url whenever you are upgrading your spark-nlp-jsl version [tool.poetry] name = &quot;poertry_demo&quot; version = &quot;0.1.0&quot; description = &quot;&quot; authors = [&quot;person &lt;person@gmail.com&gt;&quot;] [tool.poetry.dependencies] python = &quot;^3.7&quot; [tool.poetry.dev-dependencies] spark-nlp = &quot;3.4.4&quot; spark-nlp-jsl = { url = &quot;https://pypi.johnsnowlabs.com/SECRET/spark-nlp-jsl/spark_nlp_jsl-tar.gz_OR_.whl&quot; } [build-system] requires = [&quot;poetry-core&gt;=1.0.0&quot;] build-backend = &quot;poetry.core.masonry.api&quot; Non-johnsnowlabs Clinical NLP on AWS EMR These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. In this page we explain how to setup Spark-NLP + Spark-NLP Healthcare in AWS EMR, using the AWS console. Steps You must go to the blue button “Create Cluster” on the UI. By doing that you will get directed to the “Create Cluster - Quick Options” page. Don’t use the quick options, click on “Go to advanced options” instead. Now in Advanced Options, on Step 1, “Software and Steps”, please pick the following selection in the checkboxes, Also in the “Edit Software Settings” page, enter the following, [{ &quot;Classification&quot;: &quot;spark-env&quot;, &quot;Configurations&quot;: [{ &quot;Classification&quot;: &quot;export&quot;, &quot;Properties&quot;: { &quot;PYSPARK_python&quot;: &quot;/usr/bin/python3&quot;, &quot;AWS_ACCESS_KEY_ID&quot;: &quot;XYXYXYXYXYXYXYXYXYXY&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;XYXYXYXYXYXYXYXYXYXY&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;XYXYXYXYXYXYXYXYXYXYXYXYXYXY&quot; } }] }, { &quot;Classification&quot;: &quot;spark-defaults&quot;, &quot;Properties&quot;: { &quot;spark.yarn.stagingDir&quot;: &quot;hdfs:///tmp&quot;, &quot;spark.yarn.preserve.staging.files&quot;: &quot;true&quot;, &quot;spark.kryoserializer.buffer.max&quot;: &quot;2000M&quot;, &quot;spark.serializer&quot;: &quot;org.apache.spark.serializer.KryoSerializer&quot;, &quot;spark.driver.maxResultSize&quot;: &quot;0&quot;, &quot;spark.driver.memory&quot;: &quot;32G&quot; } }] Make sure that you replace all the secret information(marked here as XYXYXYXYXY) by the appropriate values that you received with your license. In “Step 2” choose the hardware and networking configuration you prefer, or just pick the defaults. Move to next step by clocking the “Next” blue button. Now you are in “Step 3”, in which you assign a name to your cluster, and you can change the location of the cluster logs. If the location of the logs is OK for you, take note of the path so you can debug potential problems by using the logs. Still on “Step 3”, go to the bottom of the page, and expand the “Bootstrap Actions” tab. We’re gonna add an action to execute during bootstrap of the cluster. Select “Custom Action”, then press on “Configure and add”. You need to provide a path to a script on S3. The path needs to be public. Keep this in mind, no secret information can be contained there. The script we’ll used for this setup is emr_bootstrap.sh . This script will install Spark-NLP 3.1.0, and Spark-NLP Healthcare 3.1.1. You’ll have to edit the script if you need different versions. After you entered the route to S3 in which you place the emr_bootstrap.sh file, and before clicking “add” in the dialog box, you must pass an additional parameter containing the SECRET value you received with your license. Just paste the secret on the “Optional arguments” field in that dialog box. There’s not much additional setup you need to perform. So just start a notebook server, connect it to the cluster you just created(be patient, it takes a while), and test with the NLP_EMR_Setup.ipynb test notebook. Non-johnsnowlabs Clinical NLP on Amazon Linux 2 These instructions use non-johnsnowlabs installation syntax. For simplified installation with johnsnowlabs library, check first section. # Update Package List &amp; Install Required Packages sudo yum update sudo yum install -y amazon-linux-extras sudo yum -y install python3-pip # Create python virtual environment and activate it: python3 -m venv .sparknlp-env source .sparknlp-env/bin/activate Check JAVA version: For Sparknlp versions above 3.x, please use JAVA-11 For Sparknlp versions below 3.x and SparkOCR, please use JAVA-8 Checking Java versions installed on your machine: sudo alternatives --config java You can pick the index number (I am using java-8 as default - index 2): If you dont have java-11 or java-8 in you system, you can easily install via: sudo yum install java-1.8.0-openjdk Now, we can start installing the required libraries: pip install jupyter We can start jupyter notebook via: jupyter notebook ### Now we are in the jupyter notebook cell: import json import os with open(&#39;sparknlp_for_healthcare.json) as f: license_keys = json.load(f) # Defining license key-value pairs as local variables locals().update(license_keys) # Adding license key-value pairs to environment variables os.environ.update(license_keys) # Installing pyspark and spark-nlp ! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION # Installing Spark NLP Healthcare ! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION --extra-index-url https://pypi.johnsnowlabs.com/$SECRET Fancy trying? You can ask for a free trial for Enterprise Spark NLP here. This will automatically create a new account for you on my.JohnSnowLabs.com. Login in to your new account and from My Subscriptions section, you can download your license key as a json file. The license json file contains: the secrets for installing the Enterprise Spark NLP and Spark OCR libraries, the license key as well as AWS credentials that you need to access the s3 bucket where the healthcare models and pipelines are published. If you have asked for a trial license, but you cannot access your account on my.JohnSnowLabs.com and you did not receive the license information via email, please contact us at support@johnsnowlabs.com.",
    "url": "/docs/en/licensed_install",
    "relUrl": "/docs/en/licensed_install"
  },
  "1251": {
    "id": "1251",
    "title": "Licensed Models",
    "content": "Pretrained Models We are currently in the process of moving the pretrained models and pipelines to a Model Hub that you can explore here: Models Hub",
    "url": "/docs/en/licensed_models",
    "relUrl": "/docs/en/licensed_models"
  },
  "1252": {
    "id": "1252",
    "title": "Spark NLP for Healthcare Release Notes",
    "content": "4.3.2 Highlights Welcoming BioGPT (Generative pre-trained transformer for biomedical text generation and mining) to Spark NLP, with a faster inference and better memory management. New MedicalQuestionAnswering annotator based on BioGPT to answer questions from PubMed abstracts Crossing 1000+ healthcare specific pretrained models &amp; pipelines in the Model hub Running obfuscation and deidentification at the same time, based on selected entities in one pass Core improvements and bug fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Added new sub-module to the ALAB module for reviewing annotations and spotting label errors easily Added ner_jsl model label definitions to the model cards More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and updated notebooks New and updated demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New blogposts 30+ new clinical models and pipelines added &amp; updated in total Welcoming BioGPT (Generative Pre-Trained Transformer For Biomedical Text Generation and Mining) to Spark NLP BioGPT is a domain-specific generative pre-trained Transformer language model for biomedical text generation and mining. BioGPT follows the Transformer language model backbone, and is pre-trained on 15M PubMed abstracts from scratch. Experiments demonstrate that BioGPT achieves better performance compared with baseline methods and other well-performing methods across all the tasks. Read more at the official paper. We ported BioGPT (BioGPT-QA-PubMedQA-BioGPT) into Spark NLP for Healthcare with better inference speed and memory optimization. New MedicalQuestionAnswering Annotator Based On BioGPT To Answer Questions From PubMed Abstracts New medical_qa_biogpt model is based on the original BioGPT-QA-PubMedQA-BioGPT model (trained with Pubmed abstracts) can generate two types of answers, short and long. The first type of question is &quot;short&quot; and is designed to elicit a simple, concise answer that is typically one of three options: yes, no, or maybe. The second type of question is &quot;long&quot; and intended to prompt a more detailed response. Unlike the short questions, which are generally answerable with a single word, long questions require a more thoughtful and comprehensive response. Overall, the distinction between short and long questions is based on the complexity of the answers they are meant to elicit. Short questions are used when a quick and simple answer is sufficient, while long questions are used when a more detailed and nuanced response is required. med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; Result for long answer: Question [&quot;What is the effect of directing attention on memory?&quot;] Answer [&quot;the results of the present study suggest that the visual indexing theory does not fully explain the effects of spatial attention on memory performance.&quot;] Result for short answer: Question [&quot;Does directing attention improve memory for items?&quot;] Answer [&quot;no&quot;] You can check the Medical Question Answering Notebook for more examples and see the Medical Question Answering demo. Crossing 1000+ Healthcare Specific Pretrained Models &amp; Pipelines In Models Hub We just crossed 1000+ healthcare specific pretrained models &amp; pipelines in the Models Hub Page! Running Obfuscation and Deidentification At The Same Time, Based On Selected Entities In One Pass The DeIdentification() annotator has been enhanced with the inclusion of multi-mode functionality. Users are required to define a dictionary that contains the policies which will be applied to the labels and save it as a JSON file. Then multi-mode functionality can be utilized in the de-identification process by providing the path of the JSON file to the setSelectiveObfuscationModes() parameter. If the entities are not provided in the JSON file, they will be deidentified according to the setMode() as default. Example JSON file : sample_deid = { &quot;obfuscate&quot;: [&quot;PHONE&quot;], &quot;mask_entity_labels&quot;: [&quot;ID&quot;], &quot;skip&quot;: [&quot;DATE&quot;], &quot;mask_same_length_chars&quot;: [&quot;NAME&quot;], &quot;mask_fixed_length_chars&quot;: [&quot;ZIP&quot;, &quot;LOCATION&quot;] } Description of possible modes to enable multi-mode deidentification: obfuscate: Replace the values with random values. mask_same_length_chars: Replace the name with the minus two same lengths asterisk, plus one bracket on both ends. mask_entity_labels: Replace the values with the entity labels. mask_fixed_length_chars: Replace the name with the asterisk with fixed length. You can also invoke setFixedMaskLength(). skip: Skip the entities (intact). Example: ... deid = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setSelectiveObfuscationModesPath(&quot;sample_deid.json&quot;) .setSameLengthFormattedEntities([&quot;PHONE&quot;]) text = &quot;Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora , M.R # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .&quot; Result: [Record date : 2093-01-13 , [********] , M.D . , Name : [*************] , M.R # &lt;ID&gt;, Date : 01/13/93 . PCP : [******] , &lt;AGE&gt; years-old , Record date : 2079-11-09 . ******* , ******* , Phone 98-496-9970 ] DATE entities were skipped: 2093-01-13 =&gt; 2093-01-13, 01/13/93=&gt; 01/13/93 PHONE entity was obfuscated with fake phone number: 55-555-5555 =&gt; 98-496-9970 ID entity was masked with ID tag: 7194334 =&gt; &lt;ID&gt; NAME entities were masked with same original lenght: David Hale = &gt; [********], Hendrickson Ora =&gt; [*************] LOCATION entities were masked with fixed lenght: Cocke County Baptist Hospital =&gt; ******* , 0295 Keats Street =&gt; ******* Core Improvements and Bug Fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Adding new sub-module to the ALAB module to review annotation and spot label errors easily Added ner_jsl model label definitions to the model card More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline, please see Spark OCR Utility Module Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and Updated Notebooks New Medical Question Answering Notebook for showing how medical question answering can be used with new MedicalQuestionAnswering annotator. Updated Clinical DeIdentification Notebook with latest updates. New and Updated Demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New Blogposts Extract Social Determinants of Health Entities From Clinical Text with Spark NLP Extract Clinical Entities From Patient Forums with Healthcare NLP Mapping Rxnorm and NDC Codes to the National Institute of Health (NIH) Drug Brand Names with Spark NLP Format Consistency For Entity Obfuscation In De-Identification with Spark NLP 30+ New Clinical Models and Pipelines Added &amp; Updated in Total biogpt_pubmed_qa 30+ new clinical ner pipelines For all Spark NLP for Healthcare models, please check: Models Hub Page Previous versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/licensed_release_notes",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/licensed_release_notes"
  },
  "1253": {
    "id": "1253",
    "title": "Serving Spark NLP&#58 MLFlow on Databricks",
    "content": "This is the first article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using Databricks Jobs and MLFlow Serve APIs. Don’t forget to check the other articles in this series, namely: How to serve Spark NLP using Microsoft Synapse ML, available here. How to server Spark NLP using FastAPI and LightPipelines, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Databricks Jobs API and MLFlow Serve as an example for that purpose. Databricks Jobs and MLFlow Serve APIs About Databricks Databricks is an enterprise software company founded by the creators of Apache Spark. The company has also created MLflow, the Serialization and Experiment tracking library you can use (inside or outside databricks), as described in the section “Experiment Tracking”. Databricks develops a web-based platform for working with Spark, that provides automated cluster management and IPython-style notebooks. Their infrastructured is provided for training and production purposes, and is integrated in cloud platforms as Azure and AWS. Spark NLP is a proud partner of Databricks and we offer a seamless integration with them — see Install on Databricks. All Spark NLP capabilities run in Databricks, including MLFlow serialization and Experiment tracking, what can be used for serving Spark NLP for production purposes. About MLFlow MLFlow is a serialization and Experiment Tracking platform, which also natively supports Spark NLP. We have a documentation entry about MLFlow in the “Experiment Tracking” section. It’s highly recommended that you take a look before moving forward in this document, since we will use some of the concepts explained there. We will use MLFlow serialization to serve our Spark NLP models. Strengths Easily configurable and scalable clusters in Databricks Seamless integration of SPark NLP and Databricks for automatically creating Spark NLP clusters (check Install on Databricks URL) Integration with MLFlow, experiment tracking, etc. Configure your training and serving environments separately. Use your serving environment for inference and scale it as you need. Weaknesses This approach does not allow you to customize your endpoints, it uses Databricks JOBS API ones Requires some time and expertise in Databricks to configure everything properly Creating a cluster in Databricks As mentioned before, Spark NLP offers a seamless integration with Databricks. To create a cluster, please follow the instructions in Install on Databricks. That cluster can be then replicated (cloned) for production purposes later on. Configuring Databricks for serving Spark NLP on MLFlow In Databricks Runtime Version, select any Standard runtime, not ML ones… These add their version of MLFlow, and some incompatibilities may arise. For this example, we have used 8.3 (includes Apache Spark 3.1.1, Scala 2.12) The cluster instantiated is prepared to use Spark NLP, but to make it production-ready using MLFlow, we need to add the MLFlow jar, in addition to the Spark NLP jar, as shown in the “Experiment Tracking” section. In that case, we did it adding both jars… (&quot;spark.jars.packages&quot;:&quot; com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&quot;) …into the SparkSession. However, in Databricks, you don’t instantiate programmatically a session, but you configure it in the Compute screen, selecting your Spark NLP cluster, and then going to Configuration -&gt; Advanced Options -&gt; Spark -&gt; Spark Config, as shown in the following image: In addition to Spark Config, we need to add the Spark NLP and MLFlow libraries to the Cluster. You can do that by going to Libraries inside your cluster. Make sure you have spark-nlp and mlflow. If not, you can install them either using PyPI or Maven artifacts. In the image below you can see the PyPI alternative: TIP: You can also use the Libraries section to add the jars (using Maven Coordinates) instead of setting them in the Spark Config, as showed before. Creating a notebook You are ready to create a notebook in Databricks and attach it to the recently created cluster. To do that, go to Create --&gt; Notebook, and select the cluster you want in the dropdown above your notebook. Make sure you have selected the cluster with the right Spark NLP + MLFlow configuration. To check everything is ok, run the following lines: To check the session is running: spark To check jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) You should see the following output from the last line (versions may differ depending on which ones you used to configure your cluster) Out[2]: &#39;com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&#39; Logging the experiment in Databricks using MLFlow As explained in the “Experiment Tracking” section, MLFlow can log Spark MLLib / NLP Pipelines as experiments, to carry out runs on them, track versions, etc. MLFlow is natively integrated in Databricks, so we can leverage the mlflow.spark.log_model() function of the Spark flavour of MLFlow, to start tracking our Spark NLP pipelines. Let’s first import our libraries: import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession Then, create a Lemmatization pipeline: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) lemmatizer = LemmatizerModel.pretrained() .setInputCols([&quot;token&quot;]) .setOutputCol(&quot;prediction&quot;) # It&#39;s mandatory to call it prediction pipeline = Pipeline(stages=[ documentAssembler, tokenizer, lemmatizer ]) IMPORTANT: Last output column of the last component in the pipeline should be called prediction. Finally, let’s log the experiment. In the Experiment Tracking section, we used the pip_requirements parameter in the log_model() function to set the required libraries: But we mentioned using conda is also available. Let’s use conda in this example: conda_env = { &#39;channels&#39;: [&#39;conda-forge&#39;], &#39;dependencies&#39;: [ &#39;python=3.8.8&#39;, { &quot;pip&quot;: [ &#39;pyspark==3.1.1&#39;, &#39;mlflow==1.21.0&#39;, &#39;spark-nlp==[YOUR_SPARKNLP_VERSION]&#39; ] } ], &#39;name&#39;: &#39;mlflow-env&#39; } With this conda environment, we are ready to log our pipeline: mlflow.spark.log_model(p_model, &quot;lemmatizer&quot;, conda_env=conda_env) You should see an output similar to this one: (6) Spark Jobs (1) MLflow run *Logged 1 run to an experiment in MLflow. Learn more* Experiment UI On the top right corner of your notebook, you will see the Experiment widget, and inside, as shown in the image below. You can also access Experiments UI if you switch your environment from “Data Science &amp; Engineering” to “Machine Learning”, on the left panel… Once in the experiment UI, you will see the following screen, where your experiments are tracked. If you click on the Start Time cell of your experiment, you will reach the registered MLFlow run. On the left panel you will see the MLFlow model and some other artifacts, as the conda.yml and pip_requirements.txt that manage the dependencies of your models. On the right panel, you will see two snippets, about how to call to the model for inference internally from Databricks. Snippet for calling with a Pandas Dataframe: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; Load model as a Spark UDF. loaded_model = mlflow.pyfunc.spark_udf(spark, model_uri=logged_model) Predict on a Spark DataFrame. columns = list(df.columns) df.withColumn(&#39;predictions&#39;, loaded_model(*columns)).collect() Snippet for calling with a Spark Dataframe. We won’t include it in this documentation because that snippet does not include SPark NLP specificities. To make it work, the correct snippet should be: import mlflow logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) ### Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) IMPORTANT: You will only get the last column (prediction) results, which is a list of Rows of Annotation Types. To convert the result list into a Spark Dataframe, use the following schema: import pyspark.sql.types as T import pyspark.sql.functions as f annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) And then, get the results (for example, in res_spark) and apply the schema: spark_res = spark.createDataFrame(res_pandas[0], schema=annotationType) Calling the experiment for production purposes using MLFlow Rest API Instead of choosing a Batch Inference, you can select REST API. This will lead you to another screen, when the model will be loaded for production purposes in an independent cluster. Once deployed, you will be able to: Check the endpoint URL to consume the model externally; Test the endpoint writing a json (in our example, ‘text’ is our first input col of the pipeline, so it shoud look similar to: {&quot;text&quot;: &quot;This is a test of how the lemmatizer works&quot;} You can see the response in the same screen. Check what is the Python code or cURL command to do that very same thing programatically. By just using that Python code, you can already consume it for production purposes from any external web app. IMPORTANT: As per 17/02/2022, there is an issue being studied by Databricks team, regarding the creation on the fly of job clusters to serve MLFlow models that require configuring the Spark Session with specific jars. This will be fixed in later versions of Databricks. In the meantime, the way to go is using Databricks Jobs API. Calling the experiment for production purposes using Databricks Asynchronous Jobs API Creating the notebook for the inference job And last, but not least, another approach to consume models for production purposes. the Jobs API. Databricks has its own API for managing jobs, that allows you to instantiate any notebook or script as a job, run it, stop it, and manage all the life cycle. And you can configure the cluster where this job will run before hand, what prevents having the issue described in point 3. To do that: Create a new production cluster, as described before, cloning you training environment but adapting it to your needs for production purposes. Make sure the Spark Config is right, as described at the beginning of this documentation. Create a new notebook. Always check that the jars are in the session: spark.sparkContext.getConf().get(&#39;spark.jars.packages&#39;) Out[2]: &#39;com.johnsnowlabs.nlp:spark-nlp_2.12:[YOUR_SPARKNLP_VERSION],org.mlflow:mlflow-spark:1.21.0&#39; Add the Spark NLP imports. import mlflow import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline import pandas as pd from sparknlp.training import CoNLL import pyspark from pyspark.sql import SparkSession import pyspark.sql.types as T import pyspark.sql.functions as f import json Let’s define that an input param called text will be sent in the request. Let’s get the text from that parameter using dbutils. input = &quot;&quot; try: input = dbutils.widgets.get(&quot;text&quot;) print(&#39;&quot;text&quot; input found: &#39; + input) except: print(&#39;Unable to run: dbutils.widgets.get(&quot;text&quot;). Setting it to NOT_SET&#39;) input = &quot;NOT_SET&quot; Right now, the input text will be in input var. You can trigger an exception or set the input to some default value if the parameter does not come in the request. Let’s create a Spark Dataframe with the input df = spark.createDataFrame([[input]]).toDF(&#39;text&#39;) And now, we just need to use the snippet for Spark Dataframe to consume MLFlow models, described above: import mlflow import pyspark.sql.types as T import pyspark.sql.functions as f logged_model = &#39;runs:/a8cf070528564792bbf66d82211db0a0/lemmatizer&#39; loaded_model = mlflow.pyfunc.load_model(model_uri=logged_model) Predict on a Spark DataFrame. res_spark = loaded_model.predict(df_1_spark.rdd) annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) spark_res = spark.createDataFrame(res_spark[0], schema=annotationType) Let’s transform our lemmatized tokens from the Dataframe into a list of strings: lemmas = spark_res.select(&quot;result&quot;).collect() txt_results = [x[&#39;result&#39;] for x in lemmas] And finally, let’s use again dbutils to tell Databricks to spin off the run and return an exit parameter: the list of token strings. dbutils.notebook.exit(json.dumps({ &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: txt_results })) Configuring the job Last, but not least. We need to precreate the job, so that we run it from the API. We could do that using the API as well, but we will show you how to do it using the UI. On the left panel, go to Jobs and then Create Job. In the jobs screen, you will see you job created. It’s not running, it’s prepared to be called on demand, programatically or in the interface, with a text input param. Let’s see how to do that: Running the job In the jobs screen, if you click on the job, you will enter the Job screen, and be able to set your text input parameter and run the job manually. You can use this for testing purposes, but the interesting part is calling it externally, using the Databricks Jobs API. Using the Databricks Jobs API, from for example, Postman. POST HTTP request URL: https://[your_databricks_instance]/api/2.1/jobs/run-now Authorization: [use Bearer Token. You can get it from Databricks, Settings, User Settings, Generate New Token.] Body: { &quot;job_id&quot;: [job_id, check it in the Jobs screen], &quot;notebook_params&quot;: {&quot;text&quot;: &quot;This is an example of how well the lemmatizer works&quot;} } As it’s an asynchronous call, it will return the number a number of run, but no results. You will need to query for results using the number of the run and the following url https://[your_databricks_instance]/2.1/jobs/runs/get-output You will get a big json, but the most relevant info, the output, will be up to the end: Results (list of lemmatized words) {&quot;notebook_output&quot;: { &quot;status&quot;: &quot;OK&quot;, &quot;results&quot;: [&quot;This&quot;, &quot;is&quot;, &quot;a&quot;, &quot;example&quot;, &quot;of&quot;, &quot;how&quot;, &quot;lemmatizer&quot;, &quot;work&quot;] }} The notebook will be prepared in the job, but idle, until you call it programmatically, what will instantiate a run. Check the Jobs API for more information about what you can do with it and how to adapt it to your solutions for production purposes. Do you want to know more? Check how to productionize Spark NLP in our official documentation here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_databricks_mlflow",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_databricks_mlflow"
  },
  "1254": {
    "id": "1254",
    "title": "Serving Spark NLP&#58 FastAPI",
    "content": "This is the second article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using FastAPI and LightPipelines for a quick inference. Don’t forget to check the other articles in this series, namely: How to serve Spark NLP using Microsoft Synapse ML, available here. How to serve Spark NLP using Databricks Jobs and MLFlow Rest APIs, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Microsoft’s Synapse ML as an example for that purpose. FastAPI and Spark NLP LightPipelines FastAPI is, as defined by the creators… …a modern, fast (high-performance), web framework for building APIs with Python 3.6+ based on standard Python type hints. FastAPI provides with a very good latency and response times that, all along with the good performance of Spark NLP LightPipelines, makes this option the quickest one of the four described in the article. Read more about the performance advantages of using LightPipelines in this article created by John Snow Labs Data Scientist Lead Veysel Kocaman. Strengths Quickest approach Adds flexibility to build and adapt a custom API for your models Weaknesses LightPipelines are executed sequentially and don’t leverage the distributed computation that Spark Clusters provide. As an alternative, you can use FastAPI with default pipelines and a custom LoadBalancer, to distribute the calls over your cluster nodes. You can serve SparkNLP + FastAPI on Docker. To do that, we will create a project with the following files: Dockerfile: Image for creating a SparkNLP + FastAPI Docker image requirements.txt: PIP Requirements entrypoint.sh: Dockerfile entrypoint content/: folder containing FastAPI webapp and SparkNLP keys content/main.py: FastAPI webapp, entrypoint content/sparknlp_keys.json: SparkNLP keys (for Healthcare or OCR) Dockerfile The aim of this file is to create a suitable Docker Image with all the OS and Python libraries required to run SparkNLP. Also, adds a entry endpoint for the FastAPI server (see below) and a main folder containing the actual code to run a pipeline on an input text and return the expected values. FROM ubuntu:18.04 RUN apt-get update &amp;&amp; apt-get -y update RUN apt-get -y update &amp;&amp; apt-get install -y wget &amp;&amp; apt-get install -y jq &amp;&amp; apt-get install -y lsb-release &amp;&amp; apt-get install -y openjdk-8-jdk-headless &amp;&amp; apt-get install -y build-essential python3-pip &amp;&amp; pip3 -q install pip --upgrade &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* /usr/share/man /usr/share/doc /usr/share/doc-base ENV PYSPARK_DRIVER_PYTHON=python3 ENV PYSPARK_PYTHON=python3 ENV LC_ALL=C.UTF-8 ENV LANG=C.UTF-8 # We expose the FastAPI default port 8515 EXPOSE 8515 # Install all Python required libraries COPY requirements.txt / RUN pip install -r /requirements.txt # Adds the entrypoint to the FastAPI server COPY entrypoint.sh / RUN chmod +x /entrypoint.sh # In /content folder we will have our main.py and the license files COPY ./content/ /content/ WORKDIR content/ # We tell Docker to run this file when a container is instantiated ENTRYPOINT [&quot;/entrypoint.sh&quot;] requirements.txt This file describes which Python libraries will be required when creating the Docker image to run Spark NLP on FastAPI. pyspark==3.1.2 fastapi==0.70.1 uvicorn==0.16 wget==3.2 pandas==1.4.1 entrypoint.sh This file is the entry point of our Docker container, which carries out the following actions: Takes the sparknlp_keys.json and exports its values as environment variables, as required by Spark NLP for Healthcare. Installs the proper version of Spark NLP for Healthcare, getting the values from the license keys we have just exported in the previous step. Runs the main.py file, that will load the pipelines and create and endpoint to serve them. #!/bin/bash # Load the license from sparknlp_keys.json and export the values as OS variables export_json () { for s in $(echo $values | jq -r &#39;to_entries|map(&quot; (.key)= (.value|tostring)&quot;)|.[]&#39; $1 ); do export $s done } export_json &quot;/content/sparknlp_keys.json&quot; # Installs the proper version of Spark NLP for Healthcare pip install --upgrade spark-nlp-jsl==$JSL_VERSION --user --extra-index-url [https://pypi.johnsnowlabs.com/$SECRET](https://pypi.johnsnowlabs.com/$SECRET) if [ $? != 0 ]; then exit 1 fi # Script to create FastAPI endpoints and preloading pipelines for inference python3 /content/main.py content/main.py: Serving 2 pipelines in a FastAPI endpoint To maximize the performance and minimize the latency, we are going to store two Spark NLP pipelines in memory, so that we load only once (at server start) and we just use them everytime we get an API request to infer. To do this, let’s create a content/main.py Python script to download the required resources, store them in memory and serve them in Rest API endpoints. First, the import section import uvicorn, json, os from fastapi import FastAPI from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.base import * import sparknlp, sparknlp_jsl from sparknlp.pretrained import PretrainedPipeline app = FastAPI() pipelines = {} Then, let’s define the endpoint to serve the pipeline: @app.get(&quot;/benchmark/pipeline&quot;) async def get_one_sequential_pipeline_result(modelname, text=&#39;&#39;): return pipelines[modelname].annotate(text) Then, the startup event to preload the pipelines and start a Spark NLP Session: @app.on_event(&quot;startup&quot;) async def startup_event(): with open(&#39;/content/sparknlp_keys.json&#39;, &#39;r&#39;) as f: license_keys = json.load(f) spark = sparknlp_jsl.start(secret=license_keys[&#39;SECRET&#39;]) pipelines[&#39;ner_profiling_clinical&#39;] = PretrainedPipeline(&#39;ner_profiling_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipelines[&#39;clinical_deidentification&#39;] = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) Finally, let’s run a uvicorn server, listening on port 8515 to the endpoints declared before: if __name__ == &quot;__main__&quot;: uvicorn.run(&#39;main:app&#39;, host=&#39;0.0.0.0&#39;, port=8515) content/sparknlp_keys.json For using Spark NLP for Healthcare, please add your Spark NLP for Healthcare license keys to content/sparknlp_keys.jsonDThe file is ready, you only need to fulfill with your own values taken from the json file John Snow Labs has provided you with. { &quot;AWS_ACCESS_KEY_ID&quot;: &quot;&quot;, &quot;AWS_SECRET_ACCESS_KEY&quot;: &quot;&quot;, &quot;SECRET&quot;: &quot;&quot;, &quot;SPARK_NLP_LICENSE&quot;: &quot;&quot;, &quot;JSL_VERSION&quot;: &quot;&quot;, &quot;PUBLIC_VERSION&quot;: &quot;&quot; } And now, let’s run the server! Creating the Docker image and running the container docker build -t johnsnowlabs/sparknlp:sparknlp_api . docker run -v jsl_keys.json:/content/sparknlp_keys.json -p 8515:8515 -it johnsnowlabs/sparknlp:sparknlp_api Consuming the API using a Python script Lets import some libraries import requests import time Then, let’s create a clinical note ner_text = &quot;&quot;&quot; A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day. &quot;&quot;&quot; We have preloaded and served two Pretrained Pipelines: clinical_deidentification and ner_profiling_clinical . In modelname, let’s set which one we want to check # Change this line to execute any of the two pipelines modelname = &#39;clinical_deidentification&#39; # modelname = &#39;ner_profiling_clinical&#39; And finally, let’s use the requestslibrary to send a test request to the endpoint and get the results. query = f&quot;?modelname={modelname}&amp;text={ner_text}&quot; url = f&quot;http://localhost:8515/benchmark/pipeline{query}&quot; print(requests.get(url)) Results (original and deidentified texts in json format) &gt;&gt; { &#39;masked&#39;: [&#39;A &lt;AGE&gt; female with a history of gestational diabetes mellitus diagnosed ...], &#39;obfuscated&#39;: [&#39;A 48 female with a history of gestational diabetes mellitus diagnosed ...&#39;], &#39;ner_chunk&#39;: [&#39;28-year-old&#39;], &#39;sentence&#39;: [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed ...&#39;] } You can also prettify the json using the following function with the result of the annotate() function: def explode_annotate(ann_result): &#39;&#39;&#39; Function to convert result object to json input: raw result output: processed result dictionary &#39;&#39;&#39; result = {} for column, ann in ann_result[0].items(): result[column] = [] for lines in ann: content = { &quot;result&quot;: lines.result, &quot;begin&quot;: lines.begin, &quot;end&quot;: lines.end, &quot;metadata&quot;: dict(lines.metadata), } result[column].append(content) return result Do you want to know more? Check the example notebooks in the Spark NLP Workshop repository, available here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_fastapi",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_fastapi"
  },
  "1255": {
    "id": "1255",
    "title": "Serving Spark NLP&#58 SynapseML",
    "content": "This is the first article of the “Serving Spark NLP via API” series, showcasing how to serve Spark NLP using Synapse ML Don’t forget to check the other articles in this series, namely: How to server Spark NLP using FastAPI and LightPipelines, available here. How to serve Spark NLP using Databricks Jobs and MLFlow Rest APIs, available here. Background Spark NLP is a Natural Language Understanding Library built on top of Apache Spark, leveranging Spark MLLib pipelines, that allows you to run NLP models at scale, including SOTA Transformers. Therefore, it’s the only production-ready NLP platform that allows you to go from a simple PoC on 1 driver node, to scale to multiple nodes in a cluster, to process big amounts of data, in a matter of minutes. Before starting, if you want to know more about all the advantages of using Spark NLP (as the ability to work at scale on air-gapped environments, for instance) we recommend you to take a look at the following resources: John Snow Labs webpage; The official technical documentation of Spark NLP; Spark NLP channel on Medium; Also, follow Veysel Kocaman, Data Scientist Lead and Head of Spark NLP for Healthcare, for the latests tips. Motivation Spark NLP is server-agnostic, what means it does not come with an integrated API server, but offers a lot of options to serve NLP models using Rest APIs. There is a wide range of possibilities to add a web server and serve Spark NLP pipelines using RestAPI, and in this series of articles we are only describing some of them. Let’s have an overview of how to use Microsoft’s Synapse ML as an example for that purpose. Microsoft’s Synapse ML Synapse ML (previously named SparkMML) is, as they state in their official webpage: … an ecosystem of tools aimed towards expanding the distributed computing framework Apache Spark in several new directions. They offer a seamless integratation with OpenCV, LightGBM, Microsoft Cognitive Tool and, the most relevant for our use case, Spark Serving, an extension of *Spark Streaming *with an integrated server and a Load Balancer, that can attend multiple requests via Rest API, balance and attend them leveraging the capabilities of a Spark Cluster. That means that you can sin up a server and attend requests that will be distributed transparently over a Spark NLP cluster, in a very effortless way. Strengths Ready-to-use server Includes a Load Balancer Distributes the work over a Spark Cluster Can be used for both Spark NLP and Spark OCR Weaknesses For small use cases that don’t require big cluster processing, other approaches may be faster (as FastAPI using LightPipelines) Requires using an external Framework This approach does not allow you to customize your endpoints, it uses Synapse ML ones How to set up Synapse ML to serve Spark NLP pipelines We will skip here how to install Spark NLP. If you need to do that, please follow this official webpage about how to install Spark NLP or, if Spark NLP for Healthcare if you are using the Healthcare library. Synapse ML recommends using at least Spark 3.2, so first of all, let’s configure the Spark Session with the required jars packages(both for Synapse ML and Spark) with the the proper Spark version (take a look at the suffix spark-nlp-spark32) and also, very important, add to jars.repository the Maven repository for SynapseML. sparknlpjsl_jar = &quot;spark-nlp-jsl.jar&quot; from pyspark.sql import SparkSession spark = SparkSession.builder .appName(&quot;Spark&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;16G&quot;) .config(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) .config(&quot;spark.kryoserializer.buffer.max&quot;, &quot;2000M&quot;) .config(&quot;spark.jars.packages&quot;, &quot;com.microsoft.azure:synapseml_2.12:0.9.5,com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:[YOUR_SPARKNLP_VERSION]) .config(&quot;spark.jars&quot;, sparknlpjsl_jar) .config(&quot;spark.jars.repositories&quot;, &quot;https://mmlspark.azureedge.net/maven&quot;) .getOrCreate() After the initialization, add your required imports (Spark NLP) and add to them the SynapseML-specific ones: import sparknlp import sparknlp_jsl ... import synapse.ml from synapse.ml.io import * Now, let’s create a Spark NLP for Healthcare pipeline to carry out Entity Resolution. document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetectorDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter_icd = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;PROBLEM&#39;]) .setPreservePosition(False) c2doc = Chunk2Doc() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setCaseSensitive(False) icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver_pipeline = Pipeline( stages = [ document_assembler, sentenceDetectorDL, tokenizer, word_embeddings, clinical_ner, ner_converter_icd, c2doc, sbert_embedder, icd_resolver ]) Let’s use a clinical note to test Synapse ML. clinical_note = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity.&quot;&quot;&quot; Since SynapseML serves a RestAPI, we will be sending JSON requests. Let’s define a simple json with the clinical note: data_json = {&quot;text&quot;: clinical_note } Now, let’s spin up a server using Synapse ML Spark Serving. It will consist of: a streaming server that will receive a json and transform it into a Spark Dataframe a call to Spark NLP transform on the dataframe, using the pipeline a write operation returning the output also in json format. #1: Creating the streaming server and transforming json to Spark Dataframe serving_input = spark.readStream.server() .address(&quot;localhost&quot;, 9999, &quot;benchmark_api&quot;) .option(&quot;name&quot;, &quot;benchmark_api&quot;) .load() .parseRequest(&quot;benchmark_api&quot;, data.schema) #2: Applying transform to the dataframe using our Spark NLP pipeline serving_output = resolver_p_model.transform(serving_input) .makeReply(&quot;icd10cm_code&quot;) #3: Returning the response in json format server = serving_output.writeStream .server() .replyTo(&quot;benchmark_api&quot;) .queryName(&quot;benchmark_query&quot;) .option(&quot;checkpointLocation&quot;, &quot;file:///tmp/checkpoints-{}&quot;.format(uuid.uuid1())) .start() And we are ready to test the endpoint using the requests library. import requests res = requests.post(&quot;http://localhost:9999/benchmark_api&quot;, data= json.dumps(data_json)) And last, but not least, let’s check the results: for i in range (0, len(response_list.json())): print(response_list.json()[i][&#39;result&#39;]) Results (list of ICD-10-CM codes from NER chunks) &gt;&gt; O2441 O2411 P702 K8520 B159 E669 Z6841 R35 R631 R630 R111... SynapseML on Databricks You can also run the above code in Databricks. To do that, you only need to remove the Creating a Spark Session, since Databricks manages that session for you. After we remove that part of the code from our notebook, we need to set the same configuration params in the Cluster Configuration, so that Databricks spins a cluster with the proper jars and config params (similarly to what we did programatically in Creating a Spark Session above, but using Databricks UI) To do so, go to Compute →Clusters in Databricks and create a new cluster (name it, for instance, Synapse). In your environment variables, as always, add the keys from your license in a key=value format Then, in Cluster → Libraries, you need to install: SynapseML jar (Maven → com.microsoft.azure:synapseml_2.12:0.9.5) Spark NLP jar ( Maven →com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:[YOUR_SPARKNLP_VERSION]) Spark NLP wheel (PyPi → spark-nlp==[YOUR_SPARKNLP_VERSION]) If you are using Spark NLP for Healthcare Spark NLP for Healthcare jar. Download the jar using the secret from your license, and then upload the jar to DBFS and add it in the Libraries section (DBFS/ADLS → dbfs:/FileStore/johnsnowlabs/libs/spark_nlp_jsl_[YOUR_SPARKNLP_VERSION].jar) Spark NLP for Healthcare wheel. Same that with the jar. Download the jar using the secret from your license, and then upload the jar to DBFS and add it in the Libraries section (DBFS/ADLS → dbfs:/FileStore/johnsnowlabs/libs/spark_nlp_jsl_[YOUR_SPARKNLP_VERSION].whl) And the rest of the code from the Importing all the libraries section and on remains exactly the same. Do you want to know more? Check the example notebooks in the Spark NLP Workshop repository, available here Visit John Snow Labs and Spark NLP Technical Documentation websites Follow us on Medium: Spark NLP and Veysel Kocaman Write to support@johnsnowlabs.com for any additional request you may have",
    "url": "/docs/en/licensed_serving_spark_nlp_via_api_synapseml",
    "relUrl": "/docs/en/licensed_serving_spark_nlp_via_api_synapseml"
  },
  "1256": {
    "id": "1256",
    "title": "Training",
    "content": "Training Datasets These are classes to load common datasets to train annotators for tasks such as Relation Model, Assertion models and more. Annotation tool json reader. All the annotations from Annotation Lab can be exported in a standard JSON format as shown below. The JSON holds multiple types of annotations like NER, Assertion, and Relations. To generate training datasets from the json, a utility class AnnotationToolJsonReader can be used, which can generate training datasets for training NER and Assertion models. AnnotationToolJsonReader Colab Notebook provides the code and details of processing the exported JSON to generate training datasets for NER and Assertion models in section 2. Users can distinguish between different label types by using constructor parameters described below. This notebook also explains how to connect to your Annotation Lab instance via API for uploading tasks, pre-annotations, and exporting entire projects. Input File Format: [ { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-18T20:48:18.117Z&quot;, &quot;created_username&quot;: &quot;admin&quot;, &quot;id&quot;: 3001, &quot;lead_time&quot;: 19.255, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;o752YyB2g9&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 3, &quot;text&quot;: &quot;have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;wf2U3o7I6T&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 24, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 16, &quot;text&quot;: &quot; to trust&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;Q3BkU5eZNx&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 40, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 35, &quot;text&quot;: &quot;to the&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-18 20:47:53&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 3 }, { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-17T17:52:41.563Z&quot;, &quot;created_username&quot;: &quot;andres.fernandez&quot;, &quot;id&quot;: 1, &quot;lead_time&quot;: 31.449, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;IQjoZJNKEv&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;Disease&quot; ], &quot;start&quot;: 3, &quot;text&quot;: &quot;have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;tHsbn4oYy5&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 46, &quot;labels&quot;: [ &quot;Treatment&quot; ], &quot;start&quot;: 42, &quot;text&quot;: &quot;water&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;IJHkc9bxJ-&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-17 17:52:02&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 0 }, { &quot;completions&quot;: [ { &quot;created_ago&quot;: &quot;2020-05-17T17:57:19.402Z&quot;, &quot;created_username&quot;: &quot;andres.fernandez&quot;, &quot;id&quot;: 1001, &quot;lead_time&quot;: 15.454, &quot;result&quot;: [ { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;j_lT0zwtrJ&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 46, &quot;labels&quot;: [ &quot;Disease&quot; ], &quot;start&quot;: 20, &quot;text&quot;: &quot;trust yourself to the water&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;e1FuGWu7EQ&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 33, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 19, &quot;text&quot;: &quot; trust yourself&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;q0MCSM9SXz&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;Treatment&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } }, { &quot;from_name&quot;: &quot;ner&quot;, &quot;id&quot;: &quot;9R7dvPphPX&quot;, &quot;source&quot;: &quot;$text&quot;, &quot;to_name&quot;: &quot;text&quot;, &quot;type&quot;: &quot;labels&quot;, &quot;value&quot;: { &quot;end&quot;: 12, &quot;labels&quot;: [ &quot;AsPresent&quot; ], &quot;start&quot;: 0, &quot;text&quot;: &quot;To have faith&quot; } } ] } ], &quot;created_at&quot;: &quot;2020-05-17 17:52:54&quot;, &quot;created_by&quot;: &quot;andres.fernandez&quot;, &quot;data&quot;: { &quot;text&quot;: &quot;To have faith is to trust yourself to the water&quot; }, &quot;id&quot;: 1, &quot;predictions&quot;: [] } ] Constructor Parameters: assertion_labels: The assertions labels are used for the training dataset creation. excluded_labels: The assertions labels that are excluded for the training dataset creation. split_chars: The split chars that are used in the default tokenizer. context_chars: The context chars that are used in the default tokenizer. SDDLPath: The context chars that are used in the default tokenizer. Parameters for readDataset: spark: Initiated Spark Session with Spark NLP path: Path to the resource Refer to the documentation for more details on the API: Python API: Scala API: AnnotationToolJsonReader Show Example PythonScala from sparknlp_jsl.training import AnnotationToolJsonReader assertion_labels = [&quot;AsPresent&quot;,&quot;Absent&quot;] excluded_labels = [&quot;Treatment&quot;] split_chars = [&quot; &quot;, &quot; -&quot;] context_chars = [&quot;.&quot;, &quot;,&quot;, &quot;;&quot;, &quot;:&quot;, &quot;!&quot;, &quot;?&quot;, &quot;*&quot;, &quot;-&quot;, &quot;(&quot;, &quot;)&quot;, &quot; &quot;&quot;, &quot;&#39;&quot;,&quot;+&quot;,&quot;%&quot;,&quot;&#39;&quot;] SDDLPath = &quot;&quot; rdr = AnnotationToolJsonReader(assertion_labels = assertion_labels, excluded_labels = excluded_labels, split_chars = split_chars, context_chars = context_chars,SDDLPath=SDDLPath) path = &quot;src/test/resources/anc-pos-corpus-small/test-training.txt&quot; df = rdr.readDataset(spark, json_path) assertion_df = rdr.generateAssertionTrainSet(df) assertion_df.show() +--+--++--++ | text| target| label|start|end| +--+--++--++ |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...| have faith|AsPresent| 1| 2| |To have faith is ...| to trust|AsPresent| 4| 5| |To have faith is ...| to the|AsPresent| 7| 8| |To have faith is ...| yourself|AsPresent| 6| 6| |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...|trust yourself|AsPresent| 5| 6| +--+--++--++ import com.johnsnowlabs.nlp.training.POS val filename = &quot;src/test/resources/json_import.json&quot; val reader = new AnnotationToolJsonReader(assertionLabels=List(&quot;AsPresent&quot;,&quot;Absent&quot;).asJava, splitChars=List(&quot; &quot;, &quot; -&quot;).asJava, excludedLabels = List(&quot;Treatment&quot;).asJava) val df = reader.readDataset(ResourceHelper.spark, filename) val assertionDf = reader.generateAssertionTrainSet(df) assertionDf.show() +--+--++--++ | text| target| label|start|end| +--+--++--++ |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...| have faith|AsPresent| 1| 2| |To have faith is ...| to trust|AsPresent| 4| 5| |To have faith is ...| to the|AsPresent| 7| 8| |To have faith is ...| yourself|AsPresent| 6| 6| |To have faith is ...| To have faith|AsPresent| 0| 2| |To have faith is ...|trust yourself|AsPresent| 5| 6| +--+--++--++ Assertion Trains AssertionDL, a deep Learning based approach used to extract Assertion Status from extracted entities and text. AssertionDLApproach Train a Assertion Model algorithm using deep learning. The training data should have annotations columns of type DOCUMENT, CHUNK, WORD_EMBEDDINGS, the labelcolumn (The assertion status that you want to predict), the start (the start index for the term that has the assertion status), the end column (the end index for the term that has the assertion status).This model use a deep learning to predict the entity. Excluding the label, this can be done with for example a SentenceDetector, a Chunk , a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionDLApproach Scala API: AssertionDLApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) POSTag = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) chunker = Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) assertion_status = AssertionDLApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setLearningRate(0.01) .setDropout(0.15) .setBatchSize(16) .setEpochs(3) .setValidationSplit(0.2) .setIncludeConfidence(True) pipeline = Pipeline().setStages([ document_assembler, sentence_detector, tokenizer, POSTag, chunker, pubmed, assertion_status ]) conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) // This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. // If a custom dataset is used, these need to be defined. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.{Chunker, Tokenizer} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotator.PerceptronModel import com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel import com.johnsnowlabs.nlp.annotator.NerCrfApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val POSTag = PerceptronModel .pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val chunker = new Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) val pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val assertionStatus = new AssertionDLApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setLearningRate(0.01f) .setDropout(0.15f) .setBatchSize(16) .setEpochs(3) .setValidationSplit(0.2f) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, POSTag, chunker, pubmed, assertionStatus )) datasetPath = &quot;/../src/test/resources/rsAnnotations-1-120-random.csv&quot; train_data = SparkContextForTest.spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(path=&quot;file:///&quot; + os.getcwd() + datasetPath) val pipelineModel = pipeline.fit(trainingData) AssertionLogRegApproach Train a Assertion Model algorithm using a regression log model. The training data should have annotations columns of type DOCUMENT, CHUNK, WORD_EMBEDDINGS, the labelcolumn (The assertion status that you want to predict), the start (the start index for the term that has the assertion status), the end column (the end index for the term that has the assertion status).This model use a deep learning to predict the entity. Excluding the label, this can be done with for example a SentenceDetector, a Chunk , a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). Input Annotator Types: DOCUMENT, CHUNK, WORD_EMBEDDINGS Output Annotator Type: ASSERTION Python API: AssertionLogRegApproach Scala API: AssertionLogRegApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) POSTag = PerceptronModel.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) chunker = Chunker() .setInputCols([&quot;pos&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;chunk&quot;) .setRegexParsers([&quot;(&lt;NN&gt;)+&quot;]) pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) assertion_status = AssertionLogRegApproach() .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) .setLabelCol(&quot;label&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setEpochs(3) pipeline = Pipeline().setStages([ document_assembler, sentence_detector, tokenizer, POSTag, chunker, pubmed, assertion_status ]) conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) // This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types. // If a custom dataset is used, these need to be defined. import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.{Chunker, Tokenizer} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotator.PerceptronModel import com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel import com.johnsnowlabs.nlp.annotator.NerCrfApproach import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val POSTag = PerceptronModel .pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;pos&quot;) val chunker = new Chunker() .setInputCols(Array(&quot;pos&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;chunk&quot;) .setRegexParsers(Array(&quot;(&lt;NN&gt;)+&quot;)) val pubmed = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(false) val assertion = new AssertionLogRegApproach() .setLabelCol(&quot;label&quot;) .setInputCols(&quot;document&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) .setReg(0.01) .setBefore(11) .setAfter(13) .setStartCol(&quot;start&quot;) .setEndCol(&quot;end&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, tokenizer, POSTag, chunker, pubmed, assertion )) datasetPath = &quot;/../src/test/resources/rsAnnotations-1-120-random.csv&quot; train_data = SparkContextForTest.spark.read.option(&quot;header&quot;, &quot;true&quot;).csv(path=&quot;file:///&quot; + os.getcwd() + datasetPath) val pipelineModel = pipeline.fit(trainingData) Token Classification These are annotators that can be trained to recognize named entities in text. MedicalNer This Named Entity recognition annotator allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets. For instantiated/pretrained models, see NerDLModel. The training data should be a labeled Spark Dataset, in the format of CoNLL 2003 IOB with Annotation type columns. The data should have columns of type DOCUMENT, TOKEN, WORD_EMBEDDINGS and an additional label column of annotator type NAMED_ENTITY. Excluding the label, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel with clinical embeddings (any clinical word embeddings can be chosen). Input Annotator Types: DOCUMENT, TOKEN, WORD_EMBEDDINGS Output Annotator Type: NAMED_ENTITY Python API: MedicalNerApproach Scala API: MedicalNerApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.annotator import * from sparknlp_jsl.annotator import * from sparknlp.training import * from pyspark.ml import Pipeline # First extract the prerequisites for the NerDLApproach documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&#39;embeddings_clinical&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # Then the training can start nerTagger = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(2) .setBatchSize(64) .setRandomSeed(0) .setVerbose(1) .setValidationSplit(0.2) .setEvaluationLogExtended(True) .setEnableOutputLogs(True) .setIncludeConfidence(True) .setOutputLogsPath(&#39;ner_logs&#39;) .setGraphFolder(&#39;medical_ner_graphs&#39;) .setEnableMemoryOptimizer(True) #&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch pipeline = Pipeline().setStages([ documentAssembler, sentence, tokenizer, clinical_embeddings, nerTagger ]) # We use the text and labels from the CoNLL dataset conll = CoNLL() trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) pipelineModel = pipeline.fit(trainingData) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) Text Classification These are annotators that can be trained to classify text into different classes, such as sentiment. DocumentLogRegClassifier Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for text and their label. The result is a trained GenericClassifierModel. Input Annotator Types: TOKEN Output Annotator Type: CATEGORY Python API: DocumentLogRegClassifierApproach Scala API: DocumentLogRegClassifierApproach Show Example PythonScala import sparknlp from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline document_assembler = DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) normalizer = Normalizer() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;normalized&quot;) stopwords_cleaner = StopWordsCleaner() .setInputCols(&quot;normalized&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(False) stemmer = Stemmer() .setInputCols(&quot;cleanTokens&quot;) .setOutputCol(&quot;stem&quot;) gen_clf = DocumentLogRegClassifierApproach() .setLabelColumn(&quot;category&quot;) .setInputCols(&quot;stem&quot;) .setOutputCol(&quot;prediction&quot;) pipeline = Pipeline().setStages([ document_assembler, tokenizer, normalizer, stopwords_cleaner, stemmer, logreg ]) clf_model = pipeline.fit(data) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) GenericClassifier Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from FeaturesAssembler as input, classifies them and outputs CATEGORY annotations. Please see the Parameters section for required training parameters. For a more extensive example please see the Spark NLP Workshop. Input Annotator Types: FEATURE_VECTOR Output Annotator Type: CATEGORY Python API: GenericClassifierApproach Scala API: GenericClassifierApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline features_asm = FeaturesAssembler() .setInputCols([&quot;feature_1&quot;, &quot;feature_2&quot;, &quot;...&quot;, &quot;feature_n&quot;]) .setOutputCol(&quot;features&quot;) gen_clf = GenericClassifierApproach() .setLabelColumn(&quot;target&quot;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(&quot;/path/to/graph_file.pb&quot;) .setEpochsNumber(50) .setBatchSize(100) .setFeatureScaling(&quot;zscore&quot;) .setlearningRate(0.001) .setFixImbalance(True) .setOutputLogsPath(&quot;logs&quot;) .setValidationSplit(0.2) # keep 20% of the data for validation purposes pipeline = Pipeline().setStages([ features_asm, gen_clf ]) clf_model = pipeline.fit(data) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach import com.johnsnowlabs.nlp.training.CoNLL import org.apache.spark.ml.Pipeline // First extract the prerequisites for the NerDLApproach val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setOutputCol(&quot;embeddings&quot;) // Then the training can start val nerTagger =new MedicalNerApproach() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) .setMaxEpochs(5) .setLr(0.003f) .setBatchSize(8) .setRandomSeed(0) .setVerbose(1) .setEvaluationLogExtended(false) .setEnableOutputLogs(false) .setIncludeConfidence(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, sentence, tokenizer, embeddings, nerTagger )) // We use the text and labels from the CoNLL dataset val conll = CoNLL() val trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;) val pipelineModel = pipeline.fit(trainingData) Relation Models RelationExtractionApproach Trains a Relation Extraction Model to predict attributes and relations for entities in a sentence. Relation Extraction is the key component for building relation knowledge graphs, and it is of crucial significance to natural language processing applications such as structured search, sentiment analysis, question answering, and summarization. The dataset will be a csv with the following that contains the following columns (sentence,chunk1,firstCharEnt1,lastCharEnt1,label1,chunk2,firstCharEnt2,lastCharEnt2,label2,rel), This annotator can be don with for example: Excluding the rel, this can be done with for example a SentenceDetector, a Tokenizer and a WordEmbeddingsModel (any word embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings). a Chunk can be created using the firstCharEnt1, lastCharEnt1,chunk1, label1 columns and firstCharEnt2, lastCharEnt2, chunk2, label2 columns An example of that dataset can be found in the following link i2b2_clinical_dataset sentence,chunk1,firstCharEnt1,lastCharEnt1,label1,chunk2,firstCharEnt2,lastCharEnt2,label2,rel Previous studies have reported the association of prodynorphin (PDYN) promoter polymorphism with temporal lobe epilepsy (TLE) susceptibility, but the results remain inconclusive.,PDYN,64,67,GENE,epilepsy,111,118,PHENOTYPE,0 The remaining cases, clinically similar to XLA, are autosomal recessive agammaglobulinemia (ARA).,XLA,43,45,GENE,autosomal recessive,52,70,PHENOTYPE,0 YAP/TAZ have been reported to be highly expressed in malignant tumors.,YAP,19,21,GENE,tumors,82,87,PHENOTYPE,0 Apart from that, no additional training data is needed. Input Annotator Types: WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY Output Annotator Type: CATEGORY Python API: RelationExtractionApproach Scala API: RelationExtractionApproach Show Example PythonScala import functools import numpy as np import pyspark.sql.functions as F import pyspark.sql.types as T from sparknlp.base import annotationType = T.StructType([ T.StructField(&#39;annotatorType&#39;, T.StringType(), False), T.StructField(&#39;begin&#39;, T.IntegerType(), False), T.StructField(&#39;end&#39;, T.IntegerType(), False), T.StructField(&#39;result&#39;, T.StringType(), False), T.StructField(&#39;metadata&#39;, T.MapType(T.StringType(), T.StringType()), False), T.StructField(&#39;embeddings&#39;, T.ArrayType(T.FloatType()), False) ]) @F.udf(T.ArrayType(annotationType)) def createTrainAnnotations(begin1, end1, begin2, end2, chunk1, chunk2, label1, label2): entity1 = sparknlp.annotation.Annotation(&quot;chunk&quot;, begin1, end1, chunk1, {&#39;entity&#39;: label1.upper(), &#39;sentence&#39;: &#39;0&#39;}, []) entity2 = sparknlp.annotation.Annotation(&quot;chunk&quot;, begin2, end2, chunk2, {&#39;entity&#39;: label2.upper(), &#39;sentence&#39;: &#39;0&#39;}, []) entity1.annotatorType = &quot;chunk&quot; entity2.annotatorType = &quot;chunk&quot; return [entity1, entity2] data = spark.read.option(&quot;header&quot;,&quot;true&quot;).format(&quot;csv&quot;).load(&quot;i2b2_clinical_rel_dataset.csv&quot;) data = data .withColumn(&quot;begin1i&quot;, F.expr(&quot;cast(firstCharEnt1 AS Int)&quot;)) .withColumn(&quot;end1i&quot;, F.expr(&quot;cast(lastCharEnt1 AS Int)&quot;)) .withColumn(&quot;begin2i&quot;, F.expr(&quot;cast(firstCharEnt2 AS Int)&quot;)) .withColumn(&quot;end2i&quot;, F.expr(&quot;cast(lastCharEnt2 AS Int)&quot;)) .where(&quot;begin1i IS NOT NULL&quot;) .where(&quot;end1i IS NOT NULL&quot;) .where(&quot;begin2i IS NOT NULL&quot;) .where(&quot;end2i IS NOT NULL&quot;) .withColumn( &quot;train_ner_chunks&quot;, createTrainAnnotations( &quot;begin1i&quot;, &quot;end1i&quot;, &quot;begin2i&quot;, &quot;end2i&quot;, &quot;chunk1&quot;, &quot;chunk2&quot;, &quot;label1&quot;, &quot;label2&quot; ).alias(&quot;train_ner_chunks&quot;, metadata={&#39;annotatorType&#39;: &quot;chunk&quot;})) documentAssembler = DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;sentences&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;token&quot;) words_embedder = WordEmbeddingsModel() .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;embeddings&quot;) pos_tagger = PerceptronModel() .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;pos_tags&quot;) dependency_parser = DependencyParserModel() .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols([&quot;sentences&quot;, &quot;pos_tags&quot;, &quot;tokens&quot;]) .setOutputCol(&quot;dependencies&quot;) reApproach = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) .setEpochsNumber(70) .setBatchSize(200) .setDropout(0.5) .setLearningRate(0.001) .setModelFile(&quot;/content/RE_in1200D_out20.pb&quot;) .setFixImbalance(True) .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;begin2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) .setOutputLogsPath(&#39;/content&#39;) train_pipeline = Pipeline(stages=[ documenter, tokenizer, words_embedder, pos_tagger, dependency_parser, reApproach ]) rel_model = train_pipeline.fit(data) import com.johnsnowlabs.nlp.{DocumentAssembler} import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.ner.{MedicalNerModel, NerConverter} import com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel import com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel import com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel package com.johnsnowlabs.nlp.annotators.re.RelationExtractionApproach() import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions._ val data = spark.read.option(&quot;header&quot;,true).csv(&quot;src/test/resources/re/gene_hpi.csv&quot;).limit(10) def createTrainAnnotations = udf { ( begin1:Int, end1:Int, begin2:Int, end2:Int, chunk1:String, chunk2:String, label1:String, label2:String) =&gt; { val an1 = Annotation(CHUNK,begin1,end1,chunk1,Map(&quot;entity&quot; -&gt; label1.toUpperCase,&quot;sentence&quot; -&gt; &quot;0&quot;)) val an2 = Annotation(CHUNK,begin2,end2,chunk2,Map(&quot;entity&quot; -&gt; label2.toUpperCase,&quot;sentence&quot; -&gt; &quot;0&quot;)) Seq(an1,an2) } } val metadataBuilder: MetadataBuilder = new MetadataBuilder() val meta = metadataBuilder.putString(&quot;annotatorType&quot;, CHUNK).build() val dataEncoded = data .withColumn(&quot;begin1i&quot;, expr(&quot;cast(firstCharEnt1 AS Int)&quot;)) .withColumn(&quot;end1i&quot;, expr(&quot;cast(lastCharEnt1 AS Int)&quot;)) .withColumn(&quot;begin2i&quot;, expr(&quot;cast(firstCharEnt2 AS Int)&quot;)) .withColumn(&quot;end2i&quot;, expr(&quot;cast(lastCharEnt2 AS Int)&quot;)) .where(&quot;begin1i IS NOT NULL&quot;) .where(&quot;end1i IS NOT NULL&quot;) .where(&quot;begin2i IS NOT NULL&quot;) .where(&quot;end2i IS NOT NULL&quot;) .withColumn( &quot;train_ner_chunks&quot;, createTrainAnnotations( col(&quot;begin1i&quot;), col(&quot;end1i&quot;), col(&quot;begin2i&quot;), col(&quot;end2i&quot;), col(&quot;chunk1&quot;), col(&quot;chunk2&quot;), col(&quot;label1&quot;), col(&quot;label2&quot;) ).as(&quot;train_ner_chunks&quot;,meta)) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;sentence&quot;) .setOutputCol(&quot;sentences&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentences&quot;)) .setOutputCol(&quot;tokens&quot;) val embedder = ParallelDownload(WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;embeddings&quot;)) val posTagger = ParallelDownload(PerceptronModel .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;posTags&quot;)) val nerTagger = ParallelDownload(MedicalNerModel .pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner_tags&quot;)) val nerConverter = new NerConverter() .setInputCols(Array(&quot;sentences&quot;, &quot;tokens&quot;, &quot;ner_tags&quot;)) .setOutputCol(&quot;nerChunks&quot;) val depencyParser = ParallelDownload(DependencyParserModel .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;sentences&quot;, &quot;posTags&quot;, &quot;tokens&quot;)) .setOutputCol(&quot;dependencies&quot;)) val re = new RelationExtractionApproach() .setInputCols(Array(&quot;embeddings&quot;, &quot;posTags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;)) .setOutputCol(&quot;rel&quot;) .setLabelColumn(&quot;target_rel&quot;) .setEpochsNumber(30) .setBatchSize(200) .setlearningRate(0.001f) .setValidationSplit(0.05f) .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;end2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) val pipeline = new Pipeline() .setStages(Array( documentAssembler, tokenizer, embedder, posTagger, nerTagger, nerConverter, depencyParser, re).parallelDownload) val model = pipeline.fit(dataEncoded) Entity Resolution Those models predict what are the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.). SentenceEntityResolver Contains all the parameters and methods to train a SentenceEntityResolverModel. The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g. BertSentenceEmbeddings and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use SentenceEntityResolverModel and see the Models Hub for available models. Input Annotator Types: SENTENCE_EMBEDDINGS Output Annotator Type: ENTITY Python API: SentenceEntityResolverApproach Scala API: SentenceEntityResolverApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline # Training a SNOMED resolution model using BERT sentence embeddings # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. documentAssembler = DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;bert_embeddings&quot;) snomedTrainingPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, bertEmbeddings ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with bertExtractor = SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols([&quot;bert_embeddings&quot;]) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(False) snomedModel = bertExtractor.fit(snomedData) // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData) ChunkEntityResolver Contains all the parameters and methods to train a ChunkEntityResolverModel. It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset. (e.g. ICD-10, RxNorm, SNOMED etc.) To use pretrained models please use ChunkEntityResolverModel and see the Models Hub for available models. Input Annotator Types: TOKEN, WORD_EMBEDDINGS Output Annotator Type: ENTITY Python API: ChunkEntityResolverApproach Scala API: ChunkEntityResolverApproach Show Example PythonScala import sparknlp from sparknlp.base import * from sparknlp.common import * from sparknlp.annotator import * from sparknlp.training import * import sparknlp_jsl from sparknlp_jsl.base import * from sparknlp_jsl.annotator import * from pyspark.ml import Pipeline # Training a SNOMED model # Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data # and their labels. document = DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) chunk = Doc2Chunk() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;chunk&quot;) token = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) chunkEmb = ChunkEmbeddings() .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) snomedTrainingPipeline = Pipeline().setStages([ document, chunk, token, embeddings, chunkEmb ]) snomedTrainingModel = snomedTrainingPipeline.fit(data) snomedData = snomedTrainingModel.transform(data).cache() # Then the Resolver can be trained with snomedExtractor = ChunkEntityResolverApproach() .setInputCols([&quot;token&quot;, &quot;chunk_embeddings&quot;]) .setOutputCol(&quot;recognized&quot;) .setNeighbours(1000) .setAlternatives(25) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setEnableWmd(True).setEnableTfidf(True).setEnableJaccard(True) .setEnableSorensenDice(True).setEnableJaroWinkler(True).setEnableLevenshtein(True) .setDistanceWeights([1, 2, 2, 1, 1, 1]) .setAllDistancesMetadata(True) .setPoolingStrategy(&quot;MAX&quot;) .setThreshold(1e32) model = snomedExtractor.fit(snomedData) // Training a SNOMED resolution model using BERT sentence embeddings // Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels. val documentAssembler = new DocumentAssembler() .setInputCol(&quot;normalized_text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val bertEmbeddings = BertSentenceEmbeddings.pretrained(&quot;sent_biobert_pubmed_base_cased&quot;) .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;bert_embeddings&quot;) val snomedTrainingPipeline = new Pipeline().setStages(Array( documentAssembler, sentenceDetector, bertEmbeddings )) val snomedTrainingModel = snomedTrainingPipeline.fit(data) val snomedData = snomedTrainingModel.transform(data).cache() // Then the Resolver can be trained with val bertExtractor = new SentenceEntityResolverApproach() .setNeighbours(25) .setThreshold(1000) .setInputCols(&quot;bert_embeddings&quot;) .setNormalizedCol(&quot;normalized_text&quot;) .setLabelCol(&quot;label&quot;) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDIAN&quot;) .setCaseSensitive(false) val snomedModel = bertExtractor.fit(snomedData)",
    "url": "/docs/en/licensed_training",
    "relUrl": "/docs/en/licensed_training"
  },
  "1257": {
    "id": "1257",
    "title": "Version Compatibility",
    "content": "Spark NLP for Healthcare Spark NLP (Public) 4.3.2 4.3.2 4.3.1 4.3.1 4.3.0 4.3.0 4.2.8 4.2.8 4.2.7 4.2.7 4.2.4 4.2.4 4.2.3 4.2.4 4.2.2 4.2.2 4.2.1 4.2.1 4.2.0 4.2.0 4.1.0 4.1.0 4.0.2 4.0.2 4.0.0 4.0.0 3.5.3 3.4.4 3.5.2 3.4.4 3.5.1 3.4.3 3.5.0 3.4.2 3.4.2 3.4.2 3.4.1 3.4.1 3.4.0 3.4.0 3.3.4 3.3.4 3.3.2 3.3.2 3.3.1 3.3.1 3.3.0 3.3.0 3.2.3 3.2.3 3.2.2 3.2.2 3.2.1 3.2.1 3.2.0 3.2.1 3.1.3 3.1.3 3.1.2 3.1.2 3.1.1 3.1.0 3.1.0 3.1.0 3.0.3 3.0.3 3.0.2 3.0.2 3.0.1 3.0.1 3.0.0 3.0.1 2.7.6 2.7.4 2.7.5 2.7.4 2.7.4 2.7.3 2.7.3 2.7.3 2.7.2 2.6.5 2.7.1 2.6.4 2.7.0 2.6.3 2.6.2 2.6.2 2.6.0 2.6.0 2.5.5 2.5.5 2.5.3 2.5.3 2.5.2 2.5.2 2.5.0 2.5.0 2.4.7 2.4.5 2.4.6 2.4.5 2.4.5 2.4.5 2.4.2 2.4.2 2.4.1 2.4.1 2.4.0 2.4.0 2.3.6 2.3.6 2.3.5 2.3.5 2.3.4 2.3.4 Spark NLP for Healthcare Spark OCR 4.3.0 4.3.1 4.2.4 4.3.0 4.2.3 4.2.4 4.2.1 4.2.0 4.1.0 4.1.0 4.0.0 4.0.0 3.5.3 3.13.0 3.5.1 3.12.0 3.5.0 3.11.0 3.4.2 3.11.0 3.4.1 3.11.0 3.4.0 3.11.0 3.3.4 3.10.0 3.3.2 3.9.0 3.3.1 3.9.0",
    "url": "/docs/en/licensed_version_compatibility",
    "relUrl": "/docs/en/licensed_version_compatibility"
  },
  "1258": {
    "id": "1258",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/light_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/base/light_pipeline.html"
  },
  "1259": {
    "id": "1259",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/light_pipelines.html",
    "relUrl": "/api/python/user_guide/light_pipelines.html"
  },
  "1260": {
    "id": "1260",
    "title": "The nlp.load() function",
    "content": "The nlp.load() method takes in one or multiple nlp pipeline, model or component references separated by whitespaces. See the Model Namespace for an overview of all possible nlp references. NLP will induce the following reference format for any query to the load method: language.component_type.dataset.embeddings i.e.: en.sentiment.twitter.use It is possible to omit many parts of the query and the nlp module will provide the best possible defaults, like embeddings for choosing a dataset. The NLP Namespace also provides a few aliases which make referencing a model even easier! This makes it possible to get predictions by only referencing the component name Examples for aliases are nlp.load(‘bert’) or nlp.load(‘sentiment’) It is possible to omit the language prefix and start the query with : component_type.dataset.embeddings the nlp module will automatically set the language to english in this case. The nlp.load() method returns a NLU pipeline object which provides predictions : from johnsnowlabs import nlp pipeline = nlp.load(&#39;sentiment&#39;) pipeline.predict(&quot;I love this Documentation! It&#39;s so good!&quot;) This is equal to: from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&quot;I love this Documentation! It&#39;s so good!&quot;) Load Parameters The load method provides for now just one parameter verbose. Setting nlp.load(nlp_reference, verbose=True) will generate log outputs that can be helpful for troubleshooting. If you encounter any errors, please run Verbose mode and post your output on our Github Issues page. Description Parameter name NLP reference of the model request Path to a locally stored Spark NLP Model or Pipeline path Whether to load GPU jars or not. Set to True to enable. gpu Whether to load M1 jars or not. Set to True to enable. m1_chip Whether to use caching for the nlp.display() functions or not. Set to True to enable streamlit_caching Configuring loaded models To configure your model or pipeline, first load a NLP component and use the print_components() function. The print outputs tell you at which index of the pipe_components attribute which NLP component is located. Via setters which are named according to the parameter values a model can be configured # example for configuring the first element in the component_list pipe = nlp.load(&#39;en.sentiment.twitter&#39;) pipe.generate_class_metadata_table() document_assembler_model = pipe.components[0].model document_assembler_model.setCleanupMode(&#39;inplace&#39;) This will print -At pipe.pipe_components[0].model : document_assembler with configurable parameters: -- Param Name [ cleanupMode ] : Param Info : possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full currently Configured as : disabled --At pipe.pipe_components[1].model : glove with configurable parameters: -- Param Name [ dimension ] : Param Info : Number of embedding dimensions currently Configured as : 512 -At pipe.pipe_components[2].model : sentiment_dl with configurable parameters: - Param Name [ threshold ] : Param Info : The minimum threshold for the final result otherwise it will be neutral currently Configured as : 0.6 Param Name [ thresholdLabel ] : Param Info : In case the score is less than threshold, what should be the label. Default is neutral. currently Configured as : neutral Param Name [ classes ] : Param Info : get the tags used to trained this NerDLModel currently Configured as : [&#39;positive&#39;, &#39;negative&#39;] Namespace The NLP name space describes the collection of all models, pipelines and components available in NLP and supported by the nlp.load() method. You can view it on the Name Space page",
    "url": "/docs/en/jsl/load_api",
    "relUrl": "/docs/en/jsl/load_api"
  },
  "1261": {
    "id": "1261",
    "title": "Legal Document Splitting - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/long_document_splitting",
    "relUrl": "/long_document_splitting"
  },
  "1262": {
    "id": "1262",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/longformer_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/longformer_embeddings.html"
  },
  "1263": {
    "id": "1263",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_question_answering.html"
  },
  "1264": {
    "id": "1264",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification.html"
  },
  "1265": {
    "id": "1265",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/longformer_for_token_classification.html"
  },
  "1266": {
    "id": "1266",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/marian_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/marian_transformer.html"
  },
  "1267": {
    "id": "1267",
    "title": "Mental Health - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/mental_health",
    "relUrl": "/mental_health"
  },
  "1268": {
    "id": "1268",
    "title": "Middle Eastern Languages - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/middle_eastern_languages",
    "relUrl": "/middle_eastern_languages"
  },
  "1269": {
    "id": "1269",
    "title": "Experiment Tracking",
    "content": "",
    "url": "/docs/en/mlflow",
    "relUrl": "/docs/en/mlflow"
  },
  "1270": {
    "id": "1270",
    "title": "Spellbook",
    "content": "Default Component References See and also the John Snow Labs Modelhub and also the John Snow Labs Model Repository for further information about the models and pipelines. Each String in the NLP reference column can be passed to nlp.load() to get the corresponding model wrapped inside a NLP Pipeline. Language nlp.load() Reference Spark NLP Reference Component Type English yake yake pipe English xlnet xlnet_base_cased pipe English use tfhub_use pipe English toxic multiclassifierdl_use_toxic pipe English tokenize spark_nlp_tokenizer pipe English t5 t5_base pipe English summarize t5_base pipe English stopwords stopwords_en pipe English stem stemmer pipe English spell spellcheck_dl pipe English spell.symmetric spellcheck_sd pipe English spell.norivg spellcheck_norvig pipe English spam classifierdl_use_spam pipe English sentiment sentimentdl_glove_imdb pipe English sentiment.vivekn sentiment_vivekn pipe English sentiment.twitter analyze_sentimentdl_use_twitter model English sentiment.twitter.use analyze_sentimentdl_use_twitter model English sentiment.imdb analyze_sentimentdl_use_imdb model English sentiment.imdb.use analyze_sentimentdl_use_imdb pipe English sentiment.imdb.glove sentimentdl_glove_imdb pipe English sentence_detector sentence_detector_dl pipe English sentence_detector.pragmatic pragmatic_sentence_detector pipe English sentence_detector.deep sentence_detector_dl model English sarcasm classifierdl_use_sarcasm model English questions classifierdl_use_trec50 model English pos pos_anc model English pos.ud_ewt pos_ud_ewt model English pos.anc pos_anc model English norm_document normalizer model English norm normalizer model English ngram ngram model English ner onto_recognize_entities_sm model English ner.onto onto_recognize_entities_sm model English ner.onto.sm onto_recognize_entities_sm model English ner.onto.glove.6B_300d onto_300 model English ner.onto.glove.6B_100d onto_100 model English ner.dl recognize_entities_dl model English ner.dl.glove.6B_100d ner_dl model English ner.dl.bert ner_dl_bert model English ner.conll recognize_entities_dl model English ner.bert recognize_entities_bert model English match.chunks match_chunks model English lemma lemma_antbnc model English lemma.antbnc lemma_antbnc model English lang detect_language_375 model English grammar_correctness t5_base model English glove glove_100d model English explain explain_document_ml model English explain.ml explain_document_ml model English explain.dl explain_document_dl model English emotion classifierdl_use_emotion model English embed_sentence tfhub_use model English embed_sentence.use_lg tfhub_use_lg model English embed_sentence.use tfhub_use model English embed_sentence.tfhub_use_lg tfhub_use_lg model English embed_sentence.tfhub_use tfhub_use model English embed_sentence.small_bert_L2_128 sent_small_bert_L2_128 model English embed_sentence.electra sent_electra_small_uncased model English embed_sentence.bert sent_small_bert_L2_128 model English embed_chunk chunk_embeddings model English embed glove_100d model English embed.xlnet_large_cased xlnet_large_cased model English embed.xlnet_base_cased xlnet_base_cased model English embed.xlnet xlnet_base_cased model English embed.glove glove_100d model English embed.glove.840B_300 glove_840B_300 model English embed.glove.100d glove_100d model English embed.elmo elmo model English embed.electra electra_small_uncased model English embed.biobert_pubmed_pmc_base_cased biobert_pubmed_pmc_base_cased model English embed.biobert_pubmed_large_cased biobert_pubmed_large_cased model English embed.biobert_pubmed_base_cased biobert_pubmed_base_cased model English embed.biobert_pmc_base_cased biobert_pmc_base_cased model English embed.biobert_discharge_base_cased biobert_discharge_base_cased model English embed.biobert_clinical_base_cased biobert_clinical_base_cased model English embed.biobert biobert_pubmed_base_cased model English embed.bert_large_uncased bert_large_uncased model English embed.bert_large_cased bert_large_cased model English embed.bert_base_uncased bert_base_uncased model English embed.bert_base_cased bert_base_cased model English embed.bert bert_base_uncased model English embed.albert_xxlarge_uncased albert_xxlarge_uncased model English embed.albert_xlarge_uncased albert_xlarge_uncased model English embed.albert_large_uncased albert_large_uncased model English embed.albert_base_uncased albert_base_uncased model English elmo elmo model English electra electra_small_uncased model English e2e multiclassifierdl_use_e2e model English dependency dependency_conllu model English dep dependency_typed_conllu model English dep.untyped dependency_conllu model English dep.untyped.conllu dependency_conllu model English dep.typed dependency_typed_conllu model English dep.typed.conllu dependency_typed_conllu model English cyberbullying classifierdl_use_cyberbullying model English covidbert covidbert_large_uncased model English clean.stop clean_stop model English clean.slang clean_slang model English classify analyze_sentiment model English classify.trec6 classifierdl_use_trec6 model English classify.trec6.use classifierdl_use_trec6 model English classify.trec50 classifierdl_use_trec50 model English classify.trec50.use classifierdl_use_trec50 model English classify.spam classifierdl_use_spam model English classify.spam.use classifierdl_use_spam model English classify.sentiment_t5 t5_base model English classify.sarcasm classifierdl_use_sarcasm model English classify.sarcasm.use classifierdl_use_sarcasm model English classify.questions classifierdl_use_trec50 model English classify.lang detect_language_375 model English classify.fakenews classifierdl_use_fakenews model English classify.fakenews.use classifierdl_use_fakenews model English classify.emotion classifierdl_use_emotion model English classify.emotion.use classifierdl_use_emotion model English classify.cyberbullying classifierdl_use_cyberbullying model English classify.cyberbullying.use classifierdl_use_cyberbullying model English chunk default_chunker model English biobert biobert_pubmed_base_cased model English bert small_bert_L2_128 model English answer_question t5_base model English albert albert_base_uncased model Model references | Language Name(s) | nlp.load() Reference | Spark NLP Reference | |:———————————————————————————————————————-|:—————————————————————————————————————————————————————————————————————————————————|:———————————————————————————————————————————————————————————————————————————————————————–| | Aequian | vn.answer_question.xlm_roberta.base | xlm_roberta_qa_xlm_roberta_base_vietnamese | | Aequian | roberta | distilroberta_base | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.pos | pos_proiel | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.lemma | lemma_proiel | | Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic | cu.lemma.proiel | lemma_proiel | | Gothic | got.pos.proiel | pos_proiel | | Gothic | got.lemma | lemma_proiel | | Gothic | got.lemma.proiel | lemma_proiel | | Latin | la.stopwords | stopwords_la | | Latin | la.pos | pos_perseus | | Latin | la.pos.udante | pos_udante | | Latin | la.pos.proiel | pos_proiel | | Latin | la.pos.perseus | pos_perseus | | Latin | la.pos.llct | pos_llct | | Latin | la.pos.ittb | pos_ittb | | Latin | la.lemma | lemma_proiel | | Latin | la.lemma.udante | lemma_udante | | Latin | la.lemma.proiel | lemma_proiel | | Latin | la.lemma.perseus | lemma_perseus | | Latin | la.lemma.llct | lemma_llct | | Latin | la.lemma.ittb | lemma_ittb | | Sanskrit | sa.stopwords | stopwords_iso | | Sanskrit | sa.pos | pos_vedic | | Sanskrit | sa.lemma | lemma_vedic | | Sanskrit | sa.embed.w2v_cc_300d | w2v_cc_300d | | Esperanto | xx.eo.marian.translate_to.vi | opus_mt_vi_eo | | Esperanto | xx.eo.marian.translate_to.tr | opus_mt_tr_eo | | Esperanto | xx.eo.marian.translate_to.sv | opus_mt_sv_eo | | Esperanto | xx.eo.marian.translate_to.sh | opus_mt_sh_eo | | Esperanto | xx.eo.marian.translate_to.ru | opus_mt_ru_eo | | Esperanto | xx.eo.marian.translate_to.ro | opus_mt_ro_eo | | Esperanto | xx.eo.marian.translate_to.pt | opus_mt_pt_eo | | Esperanto | xx.eo.marian.translate_to.pl | opus_mt_pl_eo | | Esperanto | xx.eo.marian.translate_to.nl | opus_mt_nl_eo | | Esperanto | xx.eo.marian.translate_to.lt | opus_mt_lt_eo | | Esperanto | xx.eo.marian.translate_to.it | opus_mt_it_eo | | Esperanto | xx.eo.marian.translate_to.is | opus_mt_is_eo | | Esperanto | xx.eo.marian.translate_to.hu | opus_mt_hu_eo | | Esperanto | xx.eo.marian.translate_to.he | opus_mt_he_eo | | Esperanto | xx.eo.marian.translate_to.fr | opus_mt_fr_eo | | Esperanto | xx.eo.marian.translate_to.fi | opus_mt_fi_eo | | Esperanto | xx.eo.marian.translate_to.es | opus_mt_es_eo | | Esperanto | xx.eo.marian.translate_to.en | opus_mt_eo_en | | Esperanto | xx.eo.marian.translate_to.el | opus_mt_el_eo | | Esperanto | xx.eo.marian.translate_to.de | opus_mt_de_eo | | Esperanto | xx.eo.marian.translate_to.da | opus_mt_da_eo | | Esperanto | xx.eo.marian.translate_to.cs | opus_mt_cs_eo | | Esperanto | xx.eo.marian.translate_to.bg | opus_mt_bg_eo | | Esperanto | xx.eo.marian.translate_to.ar | opus_mt_ar_eo | | Esperanto | xx.eo.marian.translate_to.af | opus_mt_af_eo | | Esperanto | eo.stopwords | stopwords_eo | | Esperanto | eo.embed.w2v_cc_300d | w2v_cc_300d | | Volapük | vo.embed.w2v_cc_300d | w2v_cc_300d | | Coptic | cop.pos | pos_scriptorium | | Coptic | cop.lemma | lemma_scriptorium | | Coptic | cop.lemma.scriptorium | lemma_scriptorium | | Afro-Asiatic languages | xx.afa.marian.translate_to.en | opus_mt_afa_en | | Afro-Asiatic languages | xx.afa.marian.translate_to.afa | opus_mt_afa_afa | | Atlantic-Congo languages | xx.alv.marian.translate_to.en | opus_mt_alv_en | | Austro-Asiatic languages | xx.aav.marian.translate_to.en | opus_mt_aav_en | | Baltic languages | xx.bat.marian.translate_to.en | opus_mt_bat_en | | Bantu languages | xx.bnt.marian.translate_to.en | opus_mt_bnt_en | | Basque (family) | xx.euq.marian.translate_to.en | opus_mt_euq_en | | Berber languages | xx.ber.marian.translate_to.fr | opus_mt_fr_ber | | Berber languages | xx.ber.marian.translate_to.es | opus_mt_es_ber | | Berber languages | xx.ber.marian.translate_to.en | opus_mt_ber_en | | Celtic languages | xx.cel.marian.translate_to.en | opus_mt_cel_en | | Cushitic languages | xx.cus.marian.translate_to.en | opus_mt_cus_en | | Dravidian languages | xx.dra.marian.translate_to.en | opus_mt_dra_en | | East Slavic languages | xx.zle.marian.translate_to.zle | opus_mt_zle_zle | | East Slavic languages | xx.zle.marian.translate_to.en | opus_mt_zle_en | | Eastern Malayo-Polynesian languages | xx.pqe.marian.translate_to.en | opus_mt_pqe_en | | Finno-Ugrian languages | xx.fiu.marian.translate_to.fiu | opus_mt_fiu_fiu | | Finno-Ugrian languages | xx.fiu.marian.translate_to.en | opus_mt_fiu_en | | Germanic languages | xx.gem.marian.translate_to.gem | opus_mt_gem_gem | | Germanic languages | xx.gem.marian.translate_to.en | opus_mt_gem_en | | Greek languages | xx.grk.marian.translate_to.en | opus_mt_grk_en | | Indic languages | xx.inc.marian.translate_to.inc | opus_mt_inc_inc | | Indic languages | xx.inc.marian.translate_to.en | opus_mt_inc_en | | Indo-European languages | xx.ine.marian.translate_to.ine | opus_mt_ine_ine | | Multilingual | xx.classify.wiki_21 | ld_wiki_tatoeba_cnn_21 | | Multilingual | xx.classify.wiki_21.bigru | ld_tatoeba_bigru_21 | | Multilingual | xx.classify.token_xlm_roberta.token_classifier_ner_40_lang | xlm_roberta_token_classifier_ner_40_lang | | Multilingual | xx.answer_question.xquad_tydiqa.bert.cased | bert_qa_bert_multi_cased_finedtuned_xquad_tydiqa_goldp | | Multilingual | xx.answer_question.xquad.bert.uncased | bert_qa_bert_multi_uncased_finetuned_xquadv1 | | Multilingual | xx.answer_question.xquad.bert.cased | bert_qa_bert_multi_cased_finetuned_xquadv1 | | Multilingual | xx.answer_question.xlm_roberta.distilled | xlm_roberta_qa_distill_xlm_mrc | | Multilingual | xx.answer_question.tydiqa.multi_lingual_bert | bert_qa_Part_1_mBERT_Model_E1 | | Multilingual | xx.answer_question.tydiqa.bert | bert_qa_telugu_bertu_tydiqa | | Multilingual | xx.answer_question.squad.distil_bert.en_de_es_tuned.by_ZYW | distilbert_qa_squad_en_de_es_model | | Multilingual | xx.answer_question.squad.distil_bert._en_de_es_vi_zh_tuned.by_ZYW | distilbert_qa_squad_en_de_es_vi_zh_model | | Multilingual | xx.answer_question.roberta | roberta_qa_ft_lr_cu_leolin12345 | | Multilingual | xx.answer_question.distil_bert.vi_zh_es_tuned.by_ZYW | distilbert_qa_en_de_vi_zh_es_model | | Multilingual | xx.answer_question.distil_bert.en_de_tuned.by_ZYW | distilbert_qa_en_de_model | | Multilingual | xx.answer_question.distil_bert.en_de_es_tuned.by_ZYW | distilbert_qa_en_de_es_model | | Multilingual | xx.answer_question.chaii.xlm_roberta | xlm_roberta_qa_xlm_roberta_qa_chaii | Pipeline references Language Name(s) nlp.load() Reference Spark NLP Reference Aequian lang detect_language_375 Aequian lang.bigru detect_language_bigru_21 Aequian lang.99 detect_language_99 Aequian lang.95 detect_language_95 Aequian lang.7 detect_language_7 Aequian lang.43 detect_language_43 Aequian lang.231 detect_language_231 Aequian lang.220 detect_language_220 Aequian lang.21 detect_language_21 Aequian lang.20 detect_language_20 Esperanto xx.eo.translate_to.vi translate_vi_eo Esperanto xx.eo.translate_to.tr translate_tr_eo Esperanto xx.eo.translate_to.sv translate_sv_eo Esperanto xx.eo.translate_to.sh translate_sh_eo Esperanto xx.eo.translate_to.ru translate_ru_eo Esperanto xx.eo.translate_to.ro translate_ro_eo Esperanto xx.eo.translate_to.pt translate_pt_eo Esperanto xx.eo.translate_to.pl translate_pl_eo Esperanto xx.eo.translate_to.nl translate_nl_eo Esperanto xx.eo.translate_to.lt translate_lt_eo Esperanto xx.eo.translate_to.it translate_it_eo Esperanto xx.eo.translate_to.is translate_is_eo Esperanto xx.eo.translate_to.hu translate_hu_eo Esperanto xx.eo.translate_to.he translate_he_eo Esperanto xx.eo.translate_to.fr translate_fr_eo Esperanto xx.eo.translate_to.fi translate_fi_eo Esperanto xx.eo.translate_to.es translate_es_eo Esperanto xx.eo.translate_to.en translate_eo_en Esperanto xx.eo.translate_to.el translate_el_eo Esperanto xx.eo.translate_to.de translate_de_eo Esperanto xx.eo.translate_to.da translate_da_eo Esperanto xx.eo.translate_to.cs translate_cs_eo Esperanto xx.eo.translate_to.bg translate_bg_eo Esperanto xx.eo.translate_to.ar translate_ar_eo Esperanto xx.eo.translate_to.af translate_af_eo Afro-Asiatic languages xx.afa.translate_to.en translate_afa_en Afro-Asiatic languages xx.afa.translate_to.afa translate_afa_afa Atlantic-Congo languages xx.alv.translate_to.en translate_alv_en Austro-Asiatic languages xx.aav.translate_to.en translate_aav_en Baltic languages xx.bat.translate_to.en translate_bat_en Bantu languages xx.bnt.translate_to.en translate_bnt_en Basque (family) xx.euq.translate_to.en translate_euq_en Berber languages xx.ber.translate_to.fr translate_fr_ber Berber languages xx.ber.translate_to.es translate_es_ber Berber languages xx.ber.translate_to.en translate_ber_en Celtic languages xx.cel.translate_to.en translate_cel_en Cushitic languages xx.cus.translate_to.en translate_cus_en Dravidian languages xx.dra.translate_to.en translate_dra_en East Slavic languages xx.zle.translate_to.zle translate_zle_zle East Slavic languages xx.zle.translate_to.en translate_zle_en Eastern Malayo-Polynesian languages xx.pqe.translate_to.en translate_pqe_en Finno-Ugrian languages xx.fiu.translate_to.fiu translate_fiu_fiu Finno-Ugrian languages xx.fiu.translate_to.en translate_fiu_en Germanic languages xx.gem.translate_to.gem translate_gem_gem Germanic languages xx.gem.translate_to.en translate_gem_en Greek languages xx.grk.translate_to.en translate_grk_en Indic languages xx.inc.translate_to.inc translate_inc_inc Indic languages xx.inc.translate_to.en translate_inc_en Indo-European languages xx.ine.translate_to.ine translate_ine_ine Indo-European languages xx.ine.translate_to.en translate_ine_en Indo-Iranian languages xx.iir.translate_to.iir translate_iir_iir Indo-Iranian languages xx.iir.translate_to.en translate_iir_en Italic languages xx.itc.translate_to.itc translate_itc_itc Italic languages xx.itc.translate_to.en translate_itc_en Mon-Khmer languages xx.mkh.translate_to.en translate_mkh_en Niger-Kordofanian languages xx.nic.translate_to.en translate_nic_en North Germanic languages xx.gmq.translate_to.gmq translate_gmq_gmq North Germanic languages xx.gmq.translate_to.en translate_gmq_en Romance languages xx.roa.translate_to.en translate_roa_en Salishan languages xx.sal.translate_to.en translate_sal_en Semitic languages xx.sem.translate_to.sem translate_sem_sem Semitic languages xx.sem.translate_to.en translate_sem_en Slavic languages xx.sla.translate_to.sla translate_sla_sla Slavic languages xx.sla.translate_to.en translate_sla_en South Caucasian languages xx.ccs.translate_to.en translate_ccs_en South Slavic languages xx.zls.translate_to.zls translate_zls_zls South Slavic languages xx.zls.translate_to.en translate_zls_en Turkic languages xx.trk.translate_to.en translate_trk_en Uralic languages xx.urj.translate_to.urj translate_urj_urj Uralic languages xx.urj.translate_to.en translate_urj_en West Germanic languages xx.gmw.translate_to.gmw translate_gmw_gmw West Germanic languages xx.gmw.translate_to.en translate_gmw_en West Slavic languages xx.zlw.translate_to.zlw translate_zlw_zlw West Slavic languages xx.zlw.translate_to.en translate_zlw_en Artificial languages xx.art.translate_to.en translate_art_en French-based creoles and pidgins xx.cpf.translate_to.en translate_cpf_en Portuguese-based creoles and pidgins xx.cpp.translate_to.en translate_cpp_en Portuguese-based creoles and pidgins xx.cpp.translate_to.cpp translate_cpp_cpp Caucasian languages xx.cau.translate_to.en translate_cau_en Philippine languages xx.phi.translate_to.en translate_phi_en Afrikaans xx.af.translate_to.sv translate_sv_af Afrikaans xx.af.translate_to.ru translate_ru_af Afrikaans xx.af.translate_to.nl translate_nl_af Afrikaans xx.af.translate_to.fr translate_fr_af Afrikaans xx.af.translate_to.fi translate_fi_af Afrikaans xx.af.translate_to.es translate_es_af Afrikaans xx.af.translate_to.eo translate_eo_af Afrikaans xx.af.translate_to.en translate_af_en Afrikaans xx.af.translate_to.de translate_de_af American Sign Language xx.ase.translate_to.sv translate_sv_ase American Sign Language xx.ase.translate_to.fr translate_fr_ase American Sign Language xx.ase.translate_to.es translate_es_ase American Sign Language xx.ase.translate_to.en translate_ase_en American Sign Language xx.ase.translate_to.de translate_de_ase Argentine Sign Language xx.aed.translate_to.es translate_es_aed Armenian xx.hy.translate_to.ru translate_ru_hy Armenian xx.hy.translate_to.en translate_hy_en Basque xx.eu.translate_to.ru translate_ru_eu Basque xx.eu.translate_to.es translate_es_eu Basque xx.eu.translate_to.en translate_eu_en Basque xx.eu.translate_to.de translate_de_eu Bemba (Zambia) xx.bem.translate_to.sv translate_sv_bem Bemba (Zambia) xx.bem.translate_to.fr translate_fr_bem Bemba (Zambia) xx.bem.translate_to.fi translate_fi_bem Bemba (Zambia) xx.bem.translate_to.en translate_bem_en Bengali xx.bn.translate_to.en translate_bn_en Bislama xx.bi.translate_to.sv translate_sv_bi Bislama xx.bi.translate_to.fr translate_fr_bi Bislama xx.bi.translate_to.es translate_es_bi Bislama xx.bi.translate_to.en translate_bi_en Bislama xx.bi.translate_to.de translate_de_bi Brazilian Sign Language xx.bzs.translate_to.sv translate_sv_bzs Brazilian Sign Language xx.bzs.translate_to.fr translate_fr_bzs Brazilian Sign Language xx.bzs.translate_to.fi translate_fi_bzs Brazilian Sign Language xx.bzs.translate_to.es translate_es_bzs Brazilian Sign Language xx.bzs.translate_to.en translate_bzs_en Brazilian Sign Language xx.bzs.translate_to.de translate_de_bzs Bulgarian xx.bg.translate_to.zh translate_zh_bg Bulgarian xx.bg.translate_to.uk translate_uk_bg Bulgarian xx.bg.translate_to.sv translate_sv_bg Bulgarian xx.bg.translate_to.ru translate_ru_bg Bulgarian xx.bg.translate_to.ja translate_ja_bg Bulgarian xx.bg.translate_to.it translate_it_bg Bulgarian xx.bg.translate_to.fr translate_fr_bg Bulgarian xx.bg.translate_to.fi translate_fi_bg Bulgarian xx.bg.translate_to.es translate_es_bg Bulgarian xx.bg.translate_to.eo translate_eo_bg Bulgarian xx.bg.translate_to.en translate_bg_en Bulgarian xx.bg.translate_to.de translate_de_bg Castilian, Spanish xx.es.translate_to.zne translate_zne_es Castilian, Spanish xx.es.translate_to.zai translate_zai_es Castilian, Spanish xx.es.translate_to.yo translate_yo_es Castilian, Spanish xx.es.translate_to.xh translate_xh_es Castilian, Spanish xx.es.translate_to.war translate_war_es Castilian, Spanish xx.es.translate_to.vsl translate_vsl_es Castilian, Spanish xx.es.translate_to.vi translate_vi_es Castilian, Spanish xx.es.translate_to.ve translate_ve_es Castilian, Spanish xx.es.translate_to.uk translate_uk_es Castilian, Spanish xx.es.translate_to.tzo translate_tzo_es Castilian, Spanish xx.es.translate_to.ty translate_ty_es Castilian, Spanish xx.es.translate_to.tw translate_tw_es Castilian, Spanish xx.es.translate_to.tvl translate_tvl_es Castilian, Spanish xx.es.translate_to.tum translate_tum_es Castilian, Spanish xx.es.translate_to.ts translate_ts_es Castilian, Spanish xx.es.translate_to.tr translate_tr_es Castilian, Spanish xx.es.translate_to.toi translate_toi_es Castilian, Spanish xx.es.translate_to.to translate_to_es Castilian, Spanish xx.es.translate_to.tn translate_tn_es Castilian, Spanish xx.es.translate_to.tll translate_tll_es Castilian, Spanish xx.es.translate_to.tl translate_tl_es Castilian, Spanish xx.es.translate_to.swc translate_swc_es Castilian, Spanish xx.es.translate_to.sv translate_sv_es Castilian, Spanish xx.es.translate_to.st translate_st_es Castilian, Spanish xx.es.translate_to.ssp translate_ssp_es Castilian, Spanish xx.es.translate_to.srn translate_srn_es Castilian, Spanish xx.es.translate_to.sq translate_sq_es Castilian, Spanish xx.es.translate_to.sn translate_sn_es Castilian, Spanish xx.es.translate_to.sm translate_sm_es Castilian, Spanish xx.es.translate_to.sl translate_sl_es Castilian, Spanish xx.es.translate_to.sk translate_sk_es Castilian, Spanish xx.es.translate_to.sg translate_sg_es Castilian, Spanish xx.es.translate_to.rw translate_rw_es Castilian, Spanish xx.es.translate_to.run translate_run_es Castilian, Spanish xx.es.translate_to.ru translate_ru_es Castilian, Spanish xx.es.translate_to.rn translate_rn_es Castilian, Spanish xx.es.translate_to.prl translate_prl_es Castilian, Spanish xx.es.translate_to.pon translate_pon_es Castilian, Spanish xx.es.translate_to.pl translate_pl_es Castilian, Spanish xx.es.translate_to.pis translate_pis_es Castilian, Spanish xx.es.translate_to.pap translate_pap_es Castilian, Spanish xx.es.translate_to.pag translate_pag_es Castilian, Spanish xx.es.translate_to.ny translate_ny_es Castilian, Spanish xx.es.translate_to.nso translate_nso_es Castilian, Spanish xx.es.translate_to.no translate_no_es Castilian, Spanish xx.es.translate_to.nl translate_nl_es Castilian, Spanish xx.es.translate_to.niu translate_niu_es Castilian, Spanish xx.es.translate_to.mt translate_mt_es Castilian, Spanish xx.es.translate_to.mk translate_mk_es Castilian, Spanish xx.es.translate_to.mh translate_mh_es Castilian, Spanish xx.es.translate_to.mg translate_mg_es Castilian, Spanish xx.es.translate_to.mfs translate_mfs_es Castilian, Spanish xx.es.translate_to.mfe translate_mfe_es Castilian, Spanish xx.es.translate_to.lv translate_lv_es Castilian, Spanish xx.es.translate_to.lus translate_lus_es Castilian, Spanish xx.es.translate_to.lue translate_lue_es Castilian, Spanish xx.es.translate_to.lua translate_lua_es Castilian, Spanish xx.es.translate_to.lu translate_lu_es Castilian, Spanish xx.es.translate_to.lt translate_lt_es Castilian, Spanish xx.es.translate_to.loz translate_loz_es Castilian, Spanish xx.es.translate_to.ln translate_ln_es Castilian, Spanish xx.es.translate_to.lg translate_lg_es Castilian, Spanish xx.es.translate_to.kqn translate_kqn_es Castilian, Spanish xx.es.translate_to.ko translate_ko_es Castilian, Spanish xx.es.translate_to.kg translate_kg_es Castilian, Spanish xx.es.translate_to.ja translate_ja_es Castilian, Spanish xx.es.translate_to.it translate_it_es Castilian, Spanish xx.es.translate_to.iso translate_iso_es Castilian, Spanish xx.es.translate_to.is translate_is_es Castilian, Spanish xx.es.translate_to.ilo translate_ilo_es Castilian, Spanish xx.es.translate_to.ig translate_ig_es Castilian, Spanish xx.es.translate_to.id translate_id_es Castilian, Spanish xx.es.translate_to.ht translate_ht_es Castilian, Spanish xx.es.translate_to.hr translate_hr_es Castilian, Spanish xx.es.translate_to.he translate_he_es Castilian, Spanish xx.es.translate_to.ha translate_ha_es Castilian, Spanish xx.es.translate_to.guw translate_guw_es Castilian, Spanish xx.es.translate_to.gl translate_gl_es Castilian, Spanish xx.es.translate_to.gil translate_gil_es Castilian, Spanish xx.es.translate_to.gaa translate_gaa_es Castilian, Spanish xx.es.translate_to.fr translate_fr_es Castilian, Spanish xx.es.translate_to.fi translate_fi_es Castilian, Spanish xx.es.translate_to.eu translate_eu_es Castilian, Spanish xx.es.translate_to.et translate_et_es Castilian, Spanish xx.es.translate_to.es translate_es_es Castilian, Spanish xx.es.translate_to.eo translate_eo_es Castilian, Spanish xx.es.translate_to.en translate_es_en Castilian, Spanish xx.es.translate_to.ee translate_ee_es Castilian, Spanish xx.es.translate_to.de translate_de_es Castilian, Spanish xx.es.translate_to.da translate_da_es Castilian, Spanish xx.es.translate_to.csn translate_csn_es Castilian, Spanish xx.es.translate_to.csg translate_csg_es Castilian, Spanish xx.es.translate_to.crs translate_crs_es Castilian, Spanish xx.es.translate_to.chk translate_chk_es Castilian, Spanish xx.es.translate_to.ceb translate_ceb_es Castilian, Spanish xx.es.translate_to.ca translate_ca_es Castilian, Spanish xx.es.translate_to.bzs translate_bzs_es Castilian, Spanish xx.es.translate_to.bi translate_bi_es Castilian, Spanish xx.es.translate_to.bg translate_bg_es Castilian, Spanish xx.es.translate_to.ber translate_ber_es Castilian, Spanish xx.es.translate_to.bem translate_bem_es Castilian, Spanish xx.es.translate_to.be translate_be_es Castilian, Spanish xx.es.translate_to.bcl translate_bcl_es Castilian, Spanish xx.es.translate_to.az translate_az_es Castilian, Spanish xx.es.translate_to.ase translate_ase_es Castilian, Spanish xx.es.translate_to.ar translate_ar_es Castilian, Spanish xx.es.translate_to.af translate_af_es Castilian, Spanish xx.es.translate_to.aed translate_aed_es Castilian, Spanish es.ner entity_recognizer_sm Castilian, Spanish es.ner.sm entity_recognizer_sm Castilian, Spanish es.ner.md entity_recognizer_md Castilian, Spanish es.ner.lg entity_recognizer_lg Castilian, Spanish es.explain explain_document_sm Castilian, Spanish es.explain.sm explain_document_sm Castilian, Spanish es.explain.md explain_document_md Castilian, Spanish es.explain.lg explain_document_lg Catalan, Valencian xx.ca.translate_to.uk translate_uk_ca Catalan, Valencian xx.ca.translate_to.pt translate_pt_ca Catalan, Valencian xx.ca.translate_to.nl translate_nl_ca Catalan, Valencian xx.ca.translate_to.it translate_it_ca Catalan, Valencian xx.ca.translate_to.fr translate_fr_ca Catalan, Valencian xx.ca.translate_to.es translate_es_ca Catalan, Valencian xx.ca.translate_to.en translate_ca_en Catalan, Valencian xx.ca.translate_to.de translate_de_ca Cebuano xx.ceb.translate_to.sv translate_sv_ceb Cebuano xx.ceb.translate_to.fr translate_fr_ceb Cebuano xx.ceb.translate_to.fi translate_fi_ceb Cebuano xx.ceb.translate_to.es translate_es_ceb Cebuano xx.ceb.translate_to.en translate_ceb_en Central Bikol xx.bcl.translate_to.sv translate_sv_bcl Central Bikol xx.bcl.translate_to.fr translate_fr_bcl Central Bikol xx.bcl.translate_to.fi translate_fi_bcl Central Bikol xx.bcl.translate_to.es translate_es_bcl Central Bikol xx.bcl.translate_to.en translate_bcl_en Central Bikol xx.bcl.translate_to.de translate_de_bcl Chewa, Chichewa, Nyanja xx.ny.translate_to.sv translate_sv_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.fr translate_fr_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.fi translate_fi_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.es translate_es_ny Chewa, Chichewa, Nyanja xx.ny.translate_to.en translate_ny_en Chewa, Chichewa, Nyanja xx.ny.translate_to.de translate_de_ny Chilean Sign Language xx.csg.translate_to.es translate_es_csg Chuukese xx.chk.translate_to.sv translate_sv_chk Chuukese xx.chk.translate_to.en translate_chk_en Colombian Sign Language xx.csn.translate_to.es translate_es_csn Congo Swahili xx.swc.translate_to.sv translate_sv_swc Congo Swahili xx.swc.translate_to.fr translate_fr_swc Congo Swahili xx.swc.translate_to.fi translate_fi_swc Congo Swahili xx.swc.translate_to.es translate_es_swc Congo Swahili xx.swc.translate_to.en translate_swc_en Croatian xx.hr.translate_to.sv translate_sv_hr Croatian xx.hr.translate_to.fr translate_fr_hr Croatian xx.hr.translate_to.fi translate_fi_hr Croatian xx.hr.translate_to.es translate_es_hr Croatian xx.hr.translate_to.de translate_de_hr Czech xx.cs.translate_to.uk translate_uk_cs Czech xx.cs.translate_to.sv translate_sv_cs Czech xx.cs.translate_to.fi translate_fi_cs Czech xx.cs.translate_to.es translate_es_cs Czech xx.cs.translate_to.eo translate_eo_cs Czech xx.cs.translate_to.en translate_cs_en Czech xx.cs.translate_to.de translate_de_cs Danish xx.da.translate_to.ru translate_ru_da Danish xx.da.translate_to.no translate_no_da Danish xx.da.translate_to.ja translate_ja_da Danish xx.da.translate_to.es translate_es_da Danish xx.da.translate_to.eo translate_eo_da Danish xx.da.translate_to.en translate_da_en Danish xx.da.translate_to.de translate_de_da Danish da.ner entity_recognizer_sm Danish da.ner.sm entity_recognizer_sm Danish da.ner.md entity_recognizer_md Danish da.ner.lg entity_recognizer_lg Danish da.explain explain_document_sm Danish da.explain.sm explain_document_sm Danish da.explain.md explain_document_md Danish da.explain.lg explain_document_lg Dholuo, Luo (Kenya and Tanzania) xx.luo.translate_to.en translate_luo_en Dutch, Flemish xx.nl.translate_to.zh translate_zh_nl Dutch, Flemish xx.nl.translate_to.uk translate_uk_nl Dutch, Flemish xx.nl.translate_to.sv translate_sv_nl Dutch, Flemish xx.nl.translate_to.no translate_no_nl Dutch, Flemish xx.nl.translate_to.ja translate_ja_nl Dutch, Flemish xx.nl.translate_to.fi translate_fi_nl Dutch, Flemish xx.nl.translate_to.es translate_es_nl Dutch, Flemish xx.nl.translate_to.eo translate_eo_nl Dutch, Flemish xx.nl.translate_to.en translate_nl_en Dutch, Flemish xx.nl.translate_to.de translate_de_nl Dutch, Flemish xx.nl.translate_to.ca translate_ca_nl Dutch, Flemish xx.nl.translate_to.af translate_af_nl Dutch, Flemish nl.ner entity_recognizer_sm Dutch, Flemish nl.ner.sm entity_recognizer_sm Dutch, Flemish nl.ner.md entity_recognizer_md Dutch, Flemish nl.ner.lg entity_recognizer_lg Dutch, Flemish nl.explain explain_document_sm Dutch, Flemish nl.explain.sm explain_document_sm Dutch, Flemish nl.explain.md explain_document_md Dutch, Flemish nl.explain.lg explain_document_lg Efik xx.efi.translate_to.sv translate_sv_efi Efik xx.efi.translate_to.fr translate_fr_efi Efik xx.efi.translate_to.fi translate_fi_efi Efik xx.efi.translate_to.es translate_es_efi Efik xx.efi.translate_to.en translate_efi_en Efik xx.efi.translate_to.de translate_de_efi English xx.en.translate_to.zlw translate_en_zlw English xx.en.translate_to.zls translate_en_zls English xx.en.translate_to.zle translate_en_zle English xx.en.translate_to.zh translate_en_zh English xx.en.translate_to.xh translate_en_xh English xx.en.translate_to.vi translate_en_vi English xx.en.translate_to.urj translate_en_urj English xx.en.translate_to.ur translate_en_ur English xx.en.translate_to.umb translate_en_umb English xx.en.translate_to.uk translate_en_uk English xx.en.translate_to.ty translate_en_ty English xx.en.translate_to.tw translate_en_tw English xx.en.translate_to.tvl translate_en_tvl English xx.en.translate_to.tut translate_en_tut English xx.en.translate_to.ts translate_en_ts English xx.en.translate_to.trk translate_en_trk English xx.en.translate_to.tpi translate_en_tpi English xx.en.translate_to.toi translate_en_toi English xx.en.translate_to.to translate_en_to English xx.en.translate_to.tn translate_en_tn English xx.en.translate_to.tll translate_en_tll English xx.en.translate_to.tl translate_en_tl English xx.en.translate_to.tiv translate_en_tiv English xx.en.translate_to.ti translate_en_ti English xx.en.translate_to.tdt translate_en_tdt English xx.en.translate_to.swc translate_en_swc English xx.en.translate_to.sw translate_en_sw English xx.en.translate_to.sv translate_en_sv English xx.en.translate_to.st translate_en_st English xx.en.translate_to.ss translate_en_ss English xx.en.translate_to.sq translate_en_sq English xx.en.translate_to.sn translate_en_sn English xx.en.translate_to.sm translate_en_sm English xx.en.translate_to.sla translate_en_sla English xx.en.translate_to.sk translate_en_sk English xx.en.translate_to.sit translate_en_sit English xx.en.translate_to.sg translate_en_sg English xx.en.translate_to.sem translate_en_sem English xx.en.translate_to.sal translate_en_sal English xx.en.translate_to.rw translate_en_rw English xx.en.translate_to.run translate_en_run English xx.en.translate_to.ru translate_en_ru English xx.en.translate_to.roa translate_en_roa English xx.en.translate_to.ro translate_en_ro English xx.en.translate_to.rnd translate_en_rnd English xx.en.translate_to.rn translate_en_rn English xx.en.translate_to.pqw translate_en_pqw English xx.en.translate_to.pqe translate_en_pqe English xx.en.translate_to.poz translate_en_poz English xx.en.translate_to.pon translate_en_pon English xx.en.translate_to.pis translate_en_pis English xx.en.translate_to.phi translate_en_phi English xx.en.translate_to.pap translate_en_pap English xx.en.translate_to.pag translate_en_pag English xx.en.translate_to.om translate_en_om English xx.en.translate_to.nyk translate_en_nyk English xx.en.translate_to.ny translate_en_ny English xx.en.translate_to.nso translate_en_nso English xx.en.translate_to.nl translate_en_nl English xx.en.translate_to.niu translate_en_niu English xx.en.translate_to.nic translate_en_nic English xx.en.translate_to.ng translate_en_ng English xx.en.translate_to.mul translate_en_mul English xx.en.translate_to.mt translate_en_mt English xx.en.translate_to.mr translate_en_mr English xx.en.translate_to.mos translate_en_mos English xx.en.translate_to.ml translate_en_ml English xx.en.translate_to.mkh translate_en_mkh English xx.en.translate_to.mk translate_en_mk English xx.en.translate_to.mh translate_en_mh English xx.en.translate_to.mg translate_en_mg English xx.en.translate_to.mfe translate_en_mfe English xx.en.translate_to.map translate_en_map English xx.en.translate_to.lus translate_en_lus English xx.en.translate_to.luo translate_en_luo English xx.en.translate_to.lun translate_en_lun English xx.en.translate_to.lue translate_en_lue English xx.en.translate_to.lua translate_en_lua English xx.en.translate_to.lu translate_en_lu English xx.en.translate_to.loz translate_en_loz English xx.en.translate_to.ln translate_en_ln English xx.en.translate_to.lg translate_en_lg English xx.en.translate_to.kwy translate_en_kwy English xx.en.translate_to.kwn translate_en_kwn English xx.en.translate_to.kqn translate_en_kqn English xx.en.translate_to.kj translate_en_kj English xx.en.translate_to.kg translate_en_kg English xx.en.translate_to.jap translate_en_jap English xx.en.translate_to.itc translate_en_itc English xx.en.translate_to.it translate_en_it English xx.en.translate_to.iso translate_en_iso English xx.en.translate_to.is translate_en_is English xx.en.translate_to.ine translate_en_ine English xx.en.translate_to.inc translate_en_inc English xx.en.translate_to.ilo translate_en_ilo English xx.en.translate_to.iir translate_en_iir English xx.en.translate_to.ig translate_en_ig English xx.en.translate_to.id translate_en_id English xx.en.translate_to.hy translate_en_hy English xx.en.translate_to.hu translate_en_hu English xx.en.translate_to.ht translate_en_ht English xx.en.translate_to.ho translate_en_ho English xx.en.translate_to.hil translate_en_hil English xx.en.translate_to.hi translate_en_hi English xx.en.translate_to.he translate_en_he English xx.en.translate_to.ha translate_en_ha English xx.en.translate_to.gv translate_en_gv English xx.en.translate_to.guw translate_en_guw English xx.en.translate_to.grk translate_en_grk English xx.en.translate_to.gmw translate_en_gmw English xx.en.translate_to.gmq translate_en_gmq English xx.en.translate_to.gl translate_en_gl English xx.en.translate_to.gil translate_en_gil English xx.en.translate_to.gem translate_en_gem English xx.en.translate_to.gaa translate_en_gaa English xx.en.translate_to.ga translate_en_ga English xx.en.translate_to.fr translate_en_fr English xx.en.translate_to.fj translate_en_fj English xx.en.translate_to.fiu translate_en_fiu English xx.en.translate_to.fi translate_en_fi English xx.en.translate_to.euq translate_en_euq English xx.en.translate_to.eu translate_en_eu English xx.en.translate_to.et translate_en_et English xx.en.translate_to.es translate_en_es English xx.en.translate_to.eo translate_en_eo English xx.en.translate_to.el translate_en_el English xx.en.translate_to.efi translate_en_efi English xx.en.translate_to.ee translate_en_ee English xx.en.translate_to.dra translate_en_dra English xx.en.translate_to.de translate_en_de English xx.en.translate_to.da translate_en_da English xx.en.translate_to.cy translate_en_cy English xx.en.translate_to.cus translate_en_cus English xx.en.translate_to.cs translate_en_cs English xx.en.translate_to.crs translate_en_crs English xx.en.translate_to.cpp translate_en_cpp English xx.en.translate_to.cpf translate_en_cpf English xx.en.translate_to.chk translate_en_chk English xx.en.translate_to.cel translate_en_cel English xx.en.translate_to.ceb translate_en_ceb English xx.en.translate_to.ca translate_en_ca English xx.en.translate_to.bzs translate_en_bzs English xx.en.translate_to.bnt translate_en_bnt English xx.en.translate_to.bi translate_en_bi English xx.en.translate_to.bg translate_en_bg English xx.en.translate_to.ber translate_en_ber English xx.en.translate_to.bem translate_en_bem English xx.en.translate_to.bcl translate_en_bcl English xx.en.translate_to.bat translate_en_bat English xx.en.translate_to.az translate_en_az English xx.en.translate_to.ar translate_en_ar English xx.en.translate_to.alv translate_en_alv English xx.en.translate_to.afa translate_en_afa English xx.en.translate_to.af translate_en_af English xx.en.translate_to.aav translate_en_aav English en.spell check_spelling_dl English en.spell.dl check_spelling_dl English en.spell.context check_spelling_dl English en.sentiment analyze_sentiment English en.sentiment.twitter analyze_sentimentdl_use_twitter English en.sentiment.imdb analyze_sentimentdl_use_imdb English en.sentiment.imdb.use analyze_sentimentdl_use_imdb English en.sentiment.glove analyze_sentimentdl_glove_imdb English en.sentiment.glove.imdb analyze_sentimentdl_glove_imdb English en.ner recognize_entities_dl English en.ner.onto.sm onto_recognize_entities_sm English en.ner.onto.lg onto_recognize_entities_lg English en.ner.onto.large onto_recognize_entities_electra_large English en.ner.onto.electra.small onto_recognize_entities_electra_small English en.ner.onto.electra.base onto_recognize_entities_electra_base English en.ner.onto.bert.tiny onto_recognize_entities_bert_tiny English en.ner.onto.bert.small onto_recognize_entities_bert_small English en.ner.onto.bert.mini onto_recognize_entities_bert_mini English en.ner.onto.bert.medium onto_recognize_entities_bert_medium English en.ner.onto.bert.large onto_recognize_entities_bert_large English en.ner.onto.bert.base onto_recognize_entities_bert_base English en.ner.dl recognize_entities_dl English en.ner.conll recognize_entities_dl English en.ner.bert recognize_entities_bert English en.match.chunks match_chunks English en.explain explain_document_ml English en.explain.ml explain_document_ml English en.explain.dl explain_document_dl English en.clean.stop clean_stop English en.clean.slang clean_slang English en.classify analyze_sentiment English en.classify.trec50.component_list classifierdl_use_trec50_pipeline English en.classify.sentiment analyze_sentiment English en.classify.sentiment.glove analyze_sentimentdl_glove_imdb English en.classify.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Ewe xx.ee.translate_to.sv translate_sv_ee Ewe xx.ee.translate_to.fr translate_fr_ee Ewe xx.ee.translate_to.fi translate_fi_ee Ewe xx.ee.translate_to.es translate_es_ee Ewe xx.ee.translate_to.en translate_ee_en Ewe xx.ee.translate_to.de translate_de_ee Fijian xx.fj.translate_to.sv translate_sv_fj Fijian xx.fj.translate_to.fr translate_fr_fj Fijian xx.fj.translate_to.fi translate_fi_fj Fijian xx.fj.translate_to.es translate_es_fj Fijian xx.fj.translate_to.en translate_fj_en Fijian xx.fj.translate_to.de translate_de_fj Finnish Sign Language xx.fse.translate_to.fi translate_fi_fse Finnish xx.fi.translate_to.zne translate_zne_fi Finnish xx.fi.translate_to.zh translate_zh_fi Finnish xx.fi.translate_to.yo translate_yo_fi Finnish xx.fi.translate_to.war translate_war_fi Finnish xx.fi.translate_to.uk translate_uk_fi Finnish xx.fi.translate_to.ty translate_ty_fi Finnish xx.fi.translate_to.tw translate_tw_fi Finnish xx.fi.translate_to.tvl translate_tvl_fi Finnish xx.fi.translate_to.ts translate_ts_fi Finnish xx.fi.translate_to.toi translate_toi_fi Finnish xx.fi.translate_to.tll translate_tll_fi Finnish xx.fi.translate_to.swc translate_swc_fi Finnish xx.fi.translate_to.sv translate_sv_fi Finnish xx.fi.translate_to.st translate_st_fi Finnish xx.fi.translate_to.sl translate_sl_fi Finnish xx.fi.translate_to.sk translate_sk_fi Finnish xx.fi.translate_to.sg translate_sg_fi Finnish xx.fi.translate_to.ru translate_ru_fi Finnish xx.fi.translate_to.ro translate_ro_fi Finnish xx.fi.translate_to.pon translate_pon_fi Finnish xx.fi.translate_to.pis translate_pis_fi Finnish xx.fi.translate_to.pap translate_pap_fi Finnish xx.fi.translate_to.pag translate_pag_fi Finnish xx.fi.translate_to.nso translate_nso_fi Finnish xx.fi.translate_to.no translate_no_fi Finnish xx.fi.translate_to.nl translate_nl_fi Finnish xx.fi.translate_to.niu translate_niu_fi Finnish xx.fi.translate_to.mt translate_mt_fi Finnish xx.fi.translate_to.mk translate_mk_fi Finnish xx.fi.translate_to.mh translate_mh_fi Finnish xx.fi.translate_to.lv translate_lv_fi Finnish xx.fi.translate_to.lus translate_lus_fi Finnish xx.fi.translate_to.lue translate_lue_fi Finnish xx.fi.translate_to.lua translate_lua_fi Finnish xx.fi.translate_to.lu translate_lu_fi Finnish xx.fi.translate_to.loz translate_loz_fi Finnish xx.fi.translate_to.lg translate_lg_fi Finnish xx.fi.translate_to.ko translate_ko_fi Finnish xx.fi.translate_to.ja translate_ja_fi Finnish xx.fi.translate_to.iso translate_iso_fi Finnish xx.fi.translate_to.is translate_is_fi Finnish xx.fi.translate_to.ilo translate_ilo_fi Finnish xx.fi.translate_to.ig translate_ig_fi Finnish xx.fi.translate_to.id translate_id_fi Finnish xx.fi.translate_to.hu translate_hu_fi Finnish xx.fi.translate_to.ht translate_ht_fi Finnish xx.fi.translate_to.hr translate_hr_fi Finnish xx.fi.translate_to.hil translate_hil_fi Finnish xx.fi.translate_to.he translate_he_fi Finnish xx.fi.translate_to.ha translate_ha_fi Finnish xx.fi.translate_to.guw translate_guw_fi Finnish xx.fi.translate_to.gil translate_gil_fi Finnish xx.fi.translate_to.gaa translate_gaa_fi Finnish xx.fi.translate_to.fse translate_fse_fi Finnish xx.fi.translate_to.fi translate_fi_fi Finnish xx.fi.translate_to.et translate_et_fi Finnish xx.fi.translate_to.es translate_es_fi Finnish xx.fi.translate_to.eo translate_eo_fi Finnish xx.fi.translate_to.en translate_fi_en Finnish xx.fi.translate_to.el translate_el_fi Finnish xx.fi.translate_to.efi translate_efi_fi Finnish xx.fi.translate_to.ee translate_ee_fi Finnish xx.fi.translate_to.de translate_de_fi Finnish xx.fi.translate_to.da translate_da_fi Finnish xx.fi.translate_to.cs translate_cs_fi Finnish xx.fi.translate_to.crs translate_crs_fi Finnish xx.fi.translate_to.ceb translate_ceb_fi Finnish xx.fi.translate_to.bzs translate_bzs_fi Finnish xx.fi.translate_to.bg translate_bg_fi Finnish xx.fi.translate_to.bem translate_bem_fi Finnish xx.fi.translate_to.bcl translate_bcl_fi Finnish xx.fi.translate_to.af translate_af_fi Finnish fi.ner entity_recognizer_sm Finnish fi.ner.sm entity_recognizer_sm Finnish fi.ner.md entity_recognizer_md Finnish fi.ner.lg entity_recognizer_lg Finnish fi.explain explain_document_sm Finnish fi.explain.sm explain_document_sm Finnish fi.explain.md explain_document_md Finnish fi.explain.lg explain_document_lg French xx.fr.translate_to.zne translate_zne_fr French xx.fr.translate_to.yo translate_yo_fr French xx.fr.translate_to.yap translate_yap_fr French xx.fr.translate_to.xh translate_xh_fr French xx.fr.translate_to.wls translate_wls_fr French xx.fr.translate_to.war translate_war_fr French xx.fr.translate_to.vi translate_vi_fr French xx.fr.translate_to.uk translate_uk_fr French xx.fr.translate_to.ty translate_ty_fr French xx.fr.translate_to.tw translate_tw_fr French xx.fr.translate_to.tvl translate_tvl_fr French xx.fr.translate_to.tum translate_tum_fr French xx.fr.translate_to.ts translate_ts_fr French xx.fr.translate_to.tr translate_tr_fr French xx.fr.translate_to.toi translate_toi_fr French xx.fr.translate_to.to translate_to_fr French xx.fr.translate_to.tn translate_tn_fr French xx.fr.translate_to.tll translate_tll_fr French xx.fr.translate_to.tiv translate_tiv_fr French xx.fr.translate_to.th translate_th_fr French xx.fr.translate_to.swc translate_swc_fr French xx.fr.translate_to.sv translate_sv_fr French xx.fr.translate_to.st translate_st_fr French xx.fr.translate_to.srn translate_srn_fr French xx.fr.translate_to.sn translate_sn_fr French xx.fr.translate_to.sm translate_sm_fr French xx.fr.translate_to.sl translate_sl_fr French xx.fr.translate_to.sk translate_sk_fr French xx.fr.translate_to.sg translate_sg_fr French xx.fr.translate_to.rw translate_rw_fr French xx.fr.translate_to.ru translate_ru_fr French xx.fr.translate_to.ro translate_ro_fr French xx.fr.translate_to.rnd translate_rnd_fr French xx.fr.translate_to.rn translate_rn_fr French xx.fr.translate_to.pon translate_pon_fr French xx.fr.translate_to.pl translate_pl_fr French xx.fr.translate_to.pis translate_pis_fr French xx.fr.translate_to.pap translate_pap_fr French xx.fr.translate_to.nso translate_nso_fr French xx.fr.translate_to.no translate_no_fr French xx.fr.translate_to.nl translate_nl_fr French xx.fr.translate_to.niu translate_niu_fr French xx.fr.translate_to.mt translate_mt_fr French xx.fr.translate_to.ms translate_ms_fr French xx.fr.translate_to.mk translate_mk_fr French xx.fr.translate_to.lv translate_lv_fr French xx.fr.translate_to.lus translate_lus_fr French xx.fr.translate_to.lue translate_lue_fr French xx.fr.translate_to.lua translate_lua_fr French xx.fr.translate_to.lu translate_lu_fr French xx.fr.translate_to.lt translate_lt_fr French xx.fr.translate_to.loz translate_loz_fr French xx.fr.translate_to.ln translate_ln_fr French xx.fr.translate_to.lg translate_lg_fr French xx.fr.translate_to.kwy translate_kwy_fr French xx.fr.translate_to.kqn translate_kqn_fr French xx.fr.translate_to.ko translate_ko_fr French xx.fr.translate_to.kg translate_kg_fr French xx.fr.translate_to.ja translate_ja_fr French xx.fr.translate_to.it translate_it_fr French xx.fr.translate_to.iso translate_iso_fr French xx.fr.translate_to.is translate_is_fr French xx.fr.translate_to.ig translate_ig_fr French xx.fr.translate_to.id translate_id_fr French xx.fr.translate_to.hu translate_hu_fr French xx.fr.translate_to.ht translate_ht_fr French xx.fr.translate_to.hr translate_hr_fr French xx.fr.translate_to.he translate_he_fr French xx.fr.translate_to.ha translate_ha_fr French xx.fr.translate_to.guw translate_guw_fr French xx.fr.translate_to.gil translate_gil_fr French xx.fr.translate_to.gaa translate_gaa_fr French xx.fr.translate_to.fj translate_fj_fr French xx.fr.translate_to.fi translate_fi_fr French xx.fr.translate_to.et translate_et_fr French xx.fr.translate_to.es translate_es_fr French xx.fr.translate_to.eo translate_eo_fr French xx.fr.translate_to.en translate_fr_en French xx.fr.translate_to.el translate_el_fr French xx.fr.translate_to.efi translate_efi_fr French xx.fr.translate_to.ee translate_ee_fr French xx.fr.translate_to.de translate_de_fr French xx.fr.translate_to.da translate_da_fr French xx.fr.translate_to.cs translate_cs_fr French xx.fr.translate_to.crs translate_crs_fr French xx.fr.translate_to.chk translate_chk_fr French xx.fr.translate_to.ceb translate_ceb_fr French xx.fr.translate_to.ca translate_ca_fr French xx.fr.translate_to.bzs translate_bzs_fr French xx.fr.translate_to.bi translate_bi_fr French xx.fr.translate_to.bg translate_bg_fr French xx.fr.translate_to.ber translate_ber_fr French xx.fr.translate_to.bem translate_bem_fr French xx.fr.translate_to.bcl translate_bcl_fr French xx.fr.translate_to.ase translate_ase_fr French xx.fr.translate_to.ar translate_ar_fr French xx.fr.translate_to.af translate_af_fr French fr.ner entity_recognizer_lg French fr.ner.md entity_recognizer_md French fr.ner.lg entity_recognizer_lg French fr.explain explain_document_lg French fr.explain.md explain_document_md French fr.explain.lg explain_document_lg Ga xx.gaa.translate_to.sv translate_sv_gaa Ga xx.gaa.translate_to.fr translate_fr_gaa Ga xx.gaa.translate_to.fi translate_fi_gaa Ga xx.gaa.translate_to.es translate_es_gaa Ga xx.gaa.translate_to.en translate_gaa_en Ga xx.gaa.translate_to.de translate_de_gaa Galician xx.gl.translate_to.pt translate_pt_gl Galician xx.gl.translate_to.es translate_es_gl Galician xx.gl.translate_to.en translate_gl_en Ganda xx.lg.translate_to.sv translate_sv_lg Ganda xx.lg.translate_to.fr translate_fr_lg Ganda xx.lg.translate_to.fi translate_fi_lg Ganda xx.lg.translate_to.en translate_lg_en Georgian xx.ka.translate_to.en translate_ka_en German xx.de.translate_to.zh translate_zh_de German xx.de.translate_to.vi translate_vi_de German xx.de.translate_to.uk translate_uk_de German xx.de.translate_to.tl translate_tl_de German xx.de.translate_to.rn translate_rn_de German xx.de.translate_to.pl translate_pl_de German xx.de.translate_to.pap translate_pap_de German xx.de.translate_to.pag translate_pag_de German xx.de.translate_to.ny translate_ny_de German xx.de.translate_to.nso translate_nso_de German xx.de.translate_to.no translate_no_de German xx.de.translate_to.niu translate_niu_de German xx.de.translate_to.ms translate_ms_de German xx.de.translate_to.lt translate_lt_de German xx.de.translate_to.loz translate_loz_de German xx.de.translate_to.ln translate_ln_de German xx.de.translate_to.ko translate_ko_de German xx.de.translate_to.ja translate_ja_de German xx.de.translate_to.it translate_it_de German xx.de.translate_to.is translate_is_de German xx.de.translate_to.ilo translate_ilo_de German xx.de.translate_to.ig translate_ig_de German xx.de.translate_to.hu translate_hu_de German xx.de.translate_to.hil translate_hil_de German xx.de.translate_to.he translate_he_de German xx.de.translate_to.guw translate_guw_de German xx.de.translate_to.gaa translate_gaa_de German xx.de.translate_to.fr translate_fr_de German xx.de.translate_to.fi translate_fi_de German xx.de.translate_to.eu translate_eu_de German xx.de.translate_to.et translate_et_de German xx.de.translate_to.es translate_es_de German xx.de.translate_to.eo translate_eo_de German xx.de.translate_to.en translate_de_en German xx.de.translate_to.efi translate_efi_de German xx.de.translate_to.ee translate_ee_de German xx.de.translate_to.de translate_de_de German xx.de.translate_to.da translate_da_de German xx.de.translate_to.cs translate_cs_de German xx.de.translate_to.crs translate_crs_de German xx.de.translate_to.ca translate_ca_de German xx.de.translate_to.bg translate_bg_de German xx.de.translate_to.bcl translate_bcl_de German xx.de.translate_to.ase translate_ase_de German xx.de.translate_to.ar translate_ar_de German xx.de.translate_to.af translate_af_de German de.ner.recognizer entity_recognizer_md German de.ner.recognizer.md entity_recognizer_md German de.ner.recognizer.lg entity_recognizer_lg German de.explain.document explain_document_md German de.explain.document.md explain_document_md German de.explain.document.lg explain_document_lg Gilbertese xx.gil.translate_to.sv translate_sv_gil Gilbertese xx.gil.translate_to.fr translate_fr_gil Gilbertese xx.gil.translate_to.fi translate_fi_gil Gilbertese xx.gil.translate_to.es translate_es_gil Gilbertese xx.gil.translate_to.en translate_gil_en Gilbertese xx.gil.translate_to.de translate_de_gil Greenlandic, Kalaallisut xx.kl.translate_to.en translate_kl_en Gun xx.guw.translate_to.sv translate_sv_guw Gun xx.guw.translate_to.fr translate_fr_guw Gun xx.guw.translate_to.fi translate_fi_guw Gun xx.guw.translate_to.es translate_es_guw Gun xx.guw.translate_to.en translate_guw_en Gun xx.guw.translate_to.de translate_de_guw Haitian, Haitian Creole xx.ht.translate_to.sv translate_sv_ht Haitian, Haitian Creole xx.ht.translate_to.fr translate_fr_ht Haitian, Haitian Creole xx.ht.translate_to.fi translate_fi_ht Haitian, Haitian Creole xx.ht.translate_to.es translate_es_ht Haitian, Haitian Creole xx.ht.translate_to.en translate_ht_en Haitian, Haitian Creole xx.ht.translate_to.de translate_de_ht Hausa xx.ha.translate_to.sv translate_sv_ha Hausa xx.ha.translate_to.fr translate_fr_ha Hausa xx.ha.translate_to.fi translate_fi_ha Hausa xx.ha.translate_to.es translate_es_ha Hausa xx.ha.translate_to.en translate_ha_en Hausa xx.ha.translate_to.de translate_de_ha Hebrew xx.he.translate_to.zh translate_zh_he Hebrew xx.he.translate_to.uk translate_uk_he Hebrew xx.he.translate_to.sv translate_sv_he Hebrew xx.he.translate_to.ru translate_ru_he Hebrew xx.he.translate_to.ja translate_ja_he Hebrew xx.he.translate_to.it translate_it_he Hebrew xx.he.translate_to.fr translate_fr_he Hebrew xx.he.translate_to.fi translate_fi_he Hebrew xx.he.translate_to.es translate_es_he Hebrew xx.he.translate_to.eo translate_eo_he Hebrew xx.he.translate_to.de translate_de_he Hebrew xx.he.translate_to.ar translate_ar_he Hebrew he.explain_document explain_document_lg Hebrew he.explain_document.lg explain_document_lg Hiligaynon xx.hil.translate_to.sv translate_sv_hil Hiligaynon xx.hil.translate_to.fr translate_fr_hil Hiligaynon xx.hil.translate_to.fi translate_fi_hil Hiligaynon xx.hil.translate_to.es translate_es_hil Hiligaynon xx.hil.translate_to.en translate_hil_en Hiligaynon xx.hil.translate_to.de translate_de_hil Hindi xx.hi.translate_to.en translate_hi_en Hiri Motu xx.ho.translate_to.sv translate_sv_ho Hiri Motu xx.ho.translate_to.fr translate_fr_ho Hiri Motu xx.ho.translate_to.fi translate_fi_ho Hiri Motu xx.ho.translate_to.es translate_es_ho Hiri Motu xx.ho.translate_to.en translate_ho_en Hiri Motu xx.ho.translate_to.de translate_de_ho Hungarian xx.hu.translate_to.uk translate_uk_hu Hungarian xx.hu.translate_to.sv translate_sv_hu Hungarian xx.hu.translate_to.ko translate_ko_hu Hungarian xx.hu.translate_to.ja translate_ja_hu Hungarian xx.hu.translate_to.fr translate_fr_hu Hungarian xx.hu.translate_to.fi translate_fi_hu Hungarian xx.hu.translate_to.eo translate_eo_hu Hungarian xx.hu.translate_to.en translate_hu_en Hungarian xx.hu.translate_to.de translate_de_hu Icelandic xx.is.translate_to.sv translate_sv_is Icelandic xx.is.translate_to.it translate_it_is Icelandic xx.is.translate_to.fi translate_fi_is Icelandic xx.is.translate_to.es translate_es_is Icelandic xx.is.translate_to.en translate_is_en Icelandic xx.is.translate_to.de translate_de_is Igbo xx.ig.translate_to.sv translate_sv_ig Igbo xx.ig.translate_to.fr translate_fr_ig Igbo xx.ig.translate_to.fi translate_fi_ig Igbo xx.ig.translate_to.es translate_es_ig Igbo xx.ig.translate_to.en translate_ig_en Igbo xx.ig.translate_to.de translate_de_ig Iloko xx.ilo.translate_to.sv translate_sv_ilo Iloko xx.ilo.translate_to.fr translate_fr_ilo Iloko xx.ilo.translate_to.fi translate_fi_ilo Iloko xx.ilo.translate_to.es translate_es_ilo Iloko xx.ilo.translate_to.en translate_ilo_en Iloko xx.ilo.translate_to.de translate_de_ilo Indonesian xx.id.translate_to.sv translate_sv_id Indonesian xx.id.translate_to.fr translate_fr_id Indonesian xx.id.translate_to.fi translate_fi_id Indonesian xx.id.translate_to.es translate_es_id Indonesian xx.id.translate_to.en translate_id_en Irish xx.ga.translate_to.en translate_ga_en Isoko xx.iso.translate_to.sv translate_sv_iso Isoko xx.iso.translate_to.fr translate_fr_iso Isoko xx.iso.translate_to.fi translate_fi_iso Isoko xx.iso.translate_to.es translate_es_iso Isoko xx.iso.translate_to.en translate_iso_en Isoko xx.iso.translate_to.de translate_de_iso Isthmus Zapotec xx.zai.translate_to.es translate_es_zai Italian xx.it.translate_to.zh translate_zh_it Italian xx.it.translate_to.vi translate_vi_it Italian xx.it.translate_to.uk translate_uk_it Italian xx.it.translate_to.ms translate_ms_it Italian xx.it.translate_to.lt translate_lt_it Italian xx.it.translate_to.ja translate_ja_it Italian xx.it.translate_to.is translate_is_it Italian xx.it.translate_to.he translate_he_it Italian xx.it.translate_to.fi translate_fi_it Italian xx.it.translate_to.es translate_es_it Italian xx.it.translate_to.eo translate_eo_it Italian xx.it.translate_to.en translate_it_en Italian xx.it.translate_to.de translate_de_it Italian xx.it.translate_to.ca translate_ca_it Italian xx.it.translate_to.bg translate_bg_it Italian xx.it.translate_to.ar translate_ar_it Italian it.ner entity_recognizer_md Italian it.ner.md entity_recognizer_md Italian it.ner.lg entity_recognizer_lg Italian it.explain.document explain_document_md Italian it.explain.document.md explain_document_md Italian it.explain.document.lg explain_document_lg Japanese xx.ja.translate_to.en translate_ja_en Kabyle xx.kab.translate_to.en translate_kab_en Kaonde xx.kqn.translate_to.sv translate_sv_kqn Kaonde xx.kqn.translate_to.fr translate_fr_kqn Kaonde xx.kqn.translate_to.fi translate_fi_kqn Kaonde xx.kqn.translate_to.en translate_kqn_en Kinyarwanda xx.rw.translate_to.sv translate_sv_rw Kinyarwanda xx.rw.translate_to.fr translate_fr_rw Kinyarwanda xx.rw.translate_to.fi translate_fi_rw Kinyarwanda xx.rw.translate_to.es translate_es_rw Kinyarwanda xx.rw.translate_to.en translate_rw_en Korean xx.ko.translate_to.en translate_ko_en Korean ko.explain_document explain_document_lg Korean ko.explain_document.lg explain_document_lg Kuanyama, Kwanyama xx.kj.translate_to.en translate_kj_en Kwangali xx.kwn.translate_to.en translate_kwn_en Lingala xx.ln.translate_to.sv translate_sv_ln Lingala xx.ln.translate_to.fr translate_fr_ln Lingala xx.ln.translate_to.fi translate_fi_ln Lingala xx.ln.translate_to.es translate_es_ln Lingala xx.ln.translate_to.en translate_ln_en Lingala xx.ln.translate_to.de translate_de_ln Lithuanian xx.lt.translate_to.tr translate_tr_lt Lithuanian xx.lt.translate_to.ru translate_ru_lt Lithuanian xx.lt.translate_to.pl translate_pl_lt Lithuanian xx.lt.translate_to.it translate_it_lt Lithuanian xx.lt.translate_to.es translate_es_lt Lithuanian xx.lt.translate_to.de translate_de_lt Lozi xx.loz.translate_to.fr translate_fr_loz Lozi xx.loz.translate_to.es translate_es_loz Lozi xx.loz.translate_to.en translate_loz_en Lozi xx.loz.translate_to.de translate_de_loz Luba-Katanga xx.lu.translate_to.sv translate_sv_lu Luba-Katanga xx.lu.translate_to.fr translate_fr_lu Luba-Katanga xx.lu.translate_to.fi translate_fi_lu Luba-Katanga xx.lu.translate_to.en translate_lu_en Luba-Lulua xx.lua.translate_to.sv translate_sv_lua Luba-Lulua xx.lua.translate_to.fr translate_fr_lua Luba-Lulua xx.lua.translate_to.fi translate_fi_lua Luba-Lulua xx.lua.translate_to.es translate_es_lua Luba-Lulua xx.lua.translate_to.en translate_lua_en Luba-Lulua xx.lua.translate_to.de translate_de_lua Lunda xx.lun.translate_to.en translate_lun_en Lushai xx.lus.translate_to.sv translate_sv_lus Lushai xx.lus.translate_to.fr translate_fr_lus Lushai xx.lus.translate_to.fi translate_fi_lus Lushai xx.lus.translate_to.es translate_es_lus Lushai xx.lus.translate_to.en translate_lus_en Luvale xx.lue.translate_to.sv translate_sv_lue Luvale xx.lue.translate_to.fr translate_fr_lue Luvale xx.lue.translate_to.fi translate_fi_lue Luvale xx.lue.translate_to.en translate_lue_en Macedonian xx.mk.translate_to.fi translate_fi_mk Macedonian xx.mk.translate_to.es translate_es_mk Macedonian xx.mk.translate_to.en translate_mk_en Malayalam xx.ml.translate_to.en translate_ml_en Maltese xx.mt.translate_to.sv translate_sv_mt Maltese xx.mt.translate_to.fr translate_fr_mt Maltese xx.mt.translate_to.fi translate_fi_mt Maltese xx.mt.translate_to.es translate_es_mt Maltese xx.mt.translate_to.en translate_mt_en Maltese xx.mt.translate_to.de translate_de_mt Manx xx.gv.translate_to.en translate_gv_en Marathi xx.mr.translate_to.en translate_mr_en Marshallese xx.mh.translate_to.sv translate_sv_mh Marshallese xx.mh.translate_to.fr translate_fr_mh Marshallese xx.mh.translate_to.fi translate_fi_mh Marshallese xx.mh.translate_to.en translate_mh_en Mexican Sign Language xx.mfs.translate_to.es translate_es_mfs Modern Greek (1453-) xx.el.translate_to.sv translate_sv_el Modern Greek (1453-) xx.el.translate_to.fr translate_fr_el Modern Greek (1453-) xx.el.translate_to.fi translate_fi_el Modern Greek (1453-) xx.el.translate_to.es translate_es_el Modern Greek (1453-) xx.el.translate_to.eo translate_eo_el Modern Greek (1453-) xx.el.translate_to.de translate_de_el Modern Greek (1453-) xx.el.translate_to.ar translate_ar_el Moldavian, Moldovan, Romanian xx.ro.translate_to.sv translate_sv_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.fr translate_fr_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.fi translate_fi_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.es translate_es_ro Moldavian, Moldovan, Romanian xx.ro.translate_to.eo translate_eo_ro Morisyen xx.mfe.translate_to.sv translate_sv_mfe Morisyen xx.mfe.translate_to.fr translate_fr_mfe Morisyen xx.mfe.translate_to.fi translate_fi_mfe Morisyen xx.mfe.translate_to.en translate_mfe_en Mossi xx.mos.translate_to.sv translate_sv_mos Mossi xx.mos.translate_to.fr translate_fr_mos Mossi xx.mos.translate_to.fi translate_fi_mos Mossi xx.mos.translate_to.en translate_mos_en Ndonga xx.ng.translate_to.en translate_ng_en Niuean xx.niu.translate_to.sv translate_sv_niu Niuean xx.niu.translate_to.fr translate_fr_niu Niuean xx.niu.translate_to.fi translate_fi_niu Niuean xx.niu.translate_to.es translate_es_niu Niuean xx.niu.translate_to.en translate_niu_en Niuean xx.niu.translate_to.de translate_de_niu Northern Sotho, Pedi, Sepedi xx.nso.translate_to.sv translate_sv_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.fr translate_fr_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.fi translate_fi_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.es translate_es_nso Northern Sotho, Pedi, Sepedi xx.nso.translate_to.en translate_nso_en Northern Sotho, Pedi, Sepedi xx.nso.translate_to.de translate_de_nso Nyaneka xx.nyk.translate_to.en translate_nyk_en Pangasinan xx.pag.translate_to.sv translate_sv_pag Pangasinan xx.pag.translate_to.fr translate_fr_pag Pangasinan xx.pag.translate_to.fi translate_fi_pag Pangasinan xx.pag.translate_to.es translate_es_pag Pangasinan xx.pag.translate_to.en translate_pag_en Pangasinan xx.pag.translate_to.de translate_de_pag Panjabi, Punjabi xx.pa.translate_to.en translate_pa_en Papiamento xx.pap.translate_to.sv translate_sv_pap Papiamento xx.pap.translate_to.fr translate_fr_pap Papiamento xx.pap.translate_to.fi translate_fi_pap Papiamento xx.pap.translate_to.es translate_es_pap Papiamento xx.pap.translate_to.en translate_pap_en Papiamento xx.pap.translate_to.de translate_de_pap Peruvian Sign Language xx.prl.translate_to.es translate_es_prl Pijin xx.pis.translate_to.sv translate_sv_pis Pijin xx.pis.translate_to.fr translate_fr_pis Pijin xx.pis.translate_to.fi translate_fi_pis Pijin xx.pis.translate_to.es translate_es_pis Pijin xx.pis.translate_to.en translate_pis_en Pijin xx.pis.translate_to.de translate_de_pis Pohnpeian xx.pon.translate_to.sv translate_sv_pon Pohnpeian xx.pon.translate_to.fr translate_fr_pon Pohnpeian xx.pon.translate_to.fi translate_fi_pon Pohnpeian xx.pon.translate_to.es translate_es_pon Pohnpeian xx.pon.translate_to.en translate_pon_en Pohnpeian xx.pon.translate_to.de translate_de_pon Polish xx.pl.translate_to.uk translate_uk_pl Polish xx.pl.translate_to.no translate_no_pl Polish xx.pl.translate_to.lt translate_lt_pl Polish xx.pl.translate_to.ja translate_ja_pl Polish xx.pl.translate_to.fr translate_fr_pl Polish xx.pl.translate_to.es translate_es_pl Polish xx.pl.translate_to.eo translate_eo_pl Polish xx.pl.translate_to.en translate_pl_en Polish xx.pl.translate_to.de translate_de_pl Polish xx.pl.translate_to.ar translate_ar_pl Polish pl.ner entity_recognizer_sm Polish pl.ner.sm entity_recognizer_sm Polish pl.ner.md entity_recognizer_md Polish pl.ner.lg entity_recognizer_lg Polish pl.explain explain_document_sm Polish pl.explain.sm explain_document_sm Polish pl.explain.md explain_document_md Polish pl.explain.lg explain_document_lg Portuguese xx.pt.translate_to.uk translate_uk_pt Portuguese xx.pt.translate_to.tl translate_tl_pt Portuguese xx.pt.translate_to.ja translate_ja_pt Portuguese xx.pt.translate_to.gl translate_gl_pt Portuguese xx.pt.translate_to.eo translate_eo_pt Portuguese xx.pt.translate_to.ca translate_ca_pt Portuguese pt.ner entity_recognizer_sm Portuguese pt.ner.sm entity_recognizer_sm Portuguese pt.ner.md entity_recognizer_md Portuguese pt.ner.lg entity_recognizer_lg Portuguese pt.explain explain_document_sm Portuguese pt.explain.sm explain_document_sm Portuguese pt.explain.md explain_document_md Portuguese pt.explain.lg explain_document_lg Rundi xx.rn.translate_to.es translate_es_rn Rundi xx.rn.translate_to.en translate_rn_en Rundi xx.run.translate_to.sv translate_sv_run Rundi xx.run.translate_to.fr translate_fr_run Rundi xx.run.translate_to.fi translate_fi_run Rundi xx.run.translate_to.en translate_run_en Russian xx.ru.translate_to.vi translate_vi_ru Russian xx.ru.translate_to.uk translate_uk_ru Russian xx.ru.translate_to.sv translate_sv_ru Russian xx.ru.translate_to.sl translate_sl_ru Russian xx.ru.translate_to.rn translate_rn_ru Russian xx.ru.translate_to.no translate_no_ru Russian xx.ru.translate_to.lv translate_lv_ru Russian xx.ru.translate_to.lt translate_lt_ru Russian xx.ru.translate_to.ko translate_ko_ru Russian xx.ru.translate_to.ka translate_ka_ru Russian xx.ru.translate_to.ja translate_ja_ru Russian xx.ru.translate_to.hy translate_hy_ru Russian xx.ru.translate_to.he translate_he_ru Russian xx.ru.translate_to.fr translate_fr_ru Russian xx.ru.translate_to.fi translate_fi_ru Russian xx.ru.translate_to.eu translate_eu_ru Russian xx.ru.translate_to.et translate_et_ru Russian xx.ru.translate_to.es translate_es_ru Russian xx.ru.translate_to.eo translate_eo_ru Russian xx.ru.translate_to.en translate_ru_en Russian xx.ru.translate_to.da translate_da_ru Russian xx.ru.translate_to.bg translate_bg_ru Russian xx.ru.translate_to.ar translate_ar_ru Russian xx.ru.translate_to.af translate_af_ru Russian ru.ner entity_recognizer_sm Russian ru.ner.sm entity_recognizer_sm Russian ru.ner.md entity_recognizer_md Russian ru.ner.lg entity_recognizer_lg Russian ru.explain explain_document_sm Russian ru.explain.sm explain_document_sm Russian ru.explain.md explain_document_md Russian ru.explain.lg explain_document_lg Ruund xx.rnd.translate_to.sv translate_sv_rnd Ruund xx.rnd.translate_to.fr translate_fr_rnd Ruund xx.rnd.translate_to.en translate_rnd_en Samoan xx.sm.translate_to.sv translate_sv_sm Samoan xx.sm.translate_to.fr translate_fr_sm Samoan xx.sm.translate_to.fi translate_fi_sm Samoan xx.sm.translate_to.es translate_es_sm Samoan xx.sm.translate_to.en translate_sm_en San Salvador Kongo xx.kwy.translate_to.sv translate_sv_kwy San Salvador Kongo xx.kwy.translate_to.fr translate_fr_kwy San Salvador Kongo xx.kwy.translate_to.en translate_kwy_en Sango xx.sg.translate_to.sv translate_sv_sg Sango xx.sg.translate_to.fr translate_fr_sg Sango xx.sg.translate_to.fi translate_fi_sg Sango xx.sg.translate_to.es translate_es_sg Sango xx.sg.translate_to.en translate_sg_en Seselwa Creole French xx.crs.translate_to.sv translate_sv_crs Seselwa Creole French xx.crs.translate_to.fr translate_fr_crs Seselwa Creole French xx.crs.translate_to.fi translate_fi_crs Seselwa Creole French xx.crs.translate_to.es translate_es_crs Seselwa Creole French xx.crs.translate_to.en translate_crs_en Seselwa Creole French xx.crs.translate_to.de translate_de_crs Shona xx.sn.translate_to.sv translate_sv_sn Shona xx.sn.translate_to.fr translate_fr_sn Shona xx.sn.translate_to.fi translate_fi_sn Shona xx.sn.translate_to.es translate_es_sn Shona xx.sn.translate_to.en translate_sn_en Slovak xx.sk.translate_to.sv translate_sv_sk Slovak xx.sk.translate_to.fr translate_fr_sk Slovak xx.sk.translate_to.fi translate_fi_sk Slovak xx.sk.translate_to.en translate_sk_en Slovenian xx.sl.translate_to.uk translate_uk_sl Slovenian xx.sl.translate_to.sv translate_sv_sl Slovenian xx.sl.translate_to.ru translate_ru_sl Slovenian xx.sl.translate_to.fr translate_fr_sl Slovenian xx.sl.translate_to.fi translate_fi_sl Slovenian xx.sl.translate_to.es translate_es_sl Southern Sotho xx.st.translate_to.sv translate_sv_st Southern Sotho xx.st.translate_to.fr translate_fr_st Southern Sotho xx.st.translate_to.fi translate_fi_st Southern Sotho xx.st.translate_to.es translate_es_st Southern Sotho xx.st.translate_to.en translate_st_en Sranan Tongo xx.srn.translate_to.sv translate_sv_srn Sranan Tongo xx.srn.translate_to.fr translate_fr_srn Sranan Tongo xx.srn.translate_to.fi translate_fi_srn Sranan Tongo xx.srn.translate_to.es translate_es_srn Sranan Tongo xx.srn.translate_to.en translate_srn_en Swati xx.ss.translate_to.en translate_ss_en Swedish xx.sv.translate_to.zne translate_zne_sv Swedish xx.sv.translate_to.zh translate_zh_sv Swedish xx.sv.translate_to.yo translate_yo_sv Swedish xx.sv.translate_to.yap translate_yap_sv Swedish xx.sv.translate_to.xh translate_xh_sv Swedish xx.sv.translate_to.wls translate_wls_sv Swedish xx.sv.translate_to.war translate_war_sv Swedish xx.sv.translate_to.uk translate_uk_sv Swedish xx.sv.translate_to.ty translate_ty_sv Swedish xx.sv.translate_to.tw translate_tw_sv Swedish xx.sv.translate_to.tvl translate_tvl_sv Swedish xx.sv.translate_to.tum translate_tum_sv Swedish xx.sv.translate_to.ts translate_ts_sv Swedish xx.sv.translate_to.tr translate_tr_sv Swedish xx.sv.translate_to.tpi translate_tpi_sv Swedish xx.sv.translate_to.toi translate_toi_sv Swedish xx.sv.translate_to.to translate_to_sv Swedish xx.sv.translate_to.tn translate_tn_sv Swedish xx.sv.translate_to.tll translate_tll_sv Swedish xx.sv.translate_to.tiv translate_tiv_sv Swedish xx.sv.translate_to.swc translate_swc_sv Swedish xx.sv.translate_to.sv translate_sv_sv Swedish xx.sv.translate_to.st translate_st_sv Swedish xx.sv.translate_to.srn translate_srn_sv Swedish xx.sv.translate_to.sq translate_sq_sv Swedish xx.sv.translate_to.sn translate_sn_sv Swedish xx.sv.translate_to.sl translate_sl_sv Swedish xx.sv.translate_to.sk translate_sk_sv Swedish xx.sv.translate_to.sg translate_sg_sv Swedish xx.sv.translate_to.rw translate_rw_sv Swedish xx.sv.translate_to.run translate_run_sv Swedish xx.sv.translate_to.ru translate_ru_sv Swedish xx.sv.translate_to.ro translate_ro_sv Swedish xx.sv.translate_to.rnd translate_rnd_sv Swedish xx.sv.translate_to.pon translate_pon_sv Swedish xx.sv.translate_to.pl translate_pl_sv Swedish xx.sv.translate_to.pis translate_pis_sv Swedish xx.sv.translate_to.pag translate_pag_sv Swedish xx.sv.translate_to.nso translate_nso_sv Swedish xx.sv.translate_to.no translate_no_sv Swedish xx.sv.translate_to.nl translate_nl_sv Swedish xx.sv.translate_to.niu translate_niu_sv Swedish xx.sv.translate_to.mt translate_mt_sv Swedish xx.sv.translate_to.lv translate_lv_sv Swedish xx.sv.translate_to.lus translate_lus_sv Swedish xx.sv.translate_to.lue translate_lue_sv Swedish xx.sv.translate_to.lua translate_lua_sv Swedish xx.sv.translate_to.lu translate_lu_sv Swedish xx.sv.translate_to.lt translate_lt_sv Swedish xx.sv.translate_to.loz translate_loz_sv Swedish xx.sv.translate_to.lg translate_lg_sv Swedish xx.sv.translate_to.kwy translate_kwy_sv Swedish xx.sv.translate_to.kqn translate_kqn_sv Swedish xx.sv.translate_to.ko translate_ko_sv Swedish xx.sv.translate_to.kg translate_kg_sv Swedish xx.sv.translate_to.ja translate_ja_sv Swedish xx.sv.translate_to.it translate_it_sv Swedish xx.sv.translate_to.iso translate_iso_sv Swedish xx.sv.translate_to.is translate_is_sv Swedish xx.sv.translate_to.ilo translate_ilo_sv Swedish xx.sv.translate_to.ig translate_ig_sv Swedish xx.sv.translate_to.id translate_id_sv Swedish xx.sv.translate_to.hu translate_hu_sv Swedish xx.sv.translate_to.ht translate_ht_sv Swedish xx.sv.translate_to.hr translate_hr_sv Swedish xx.sv.translate_to.he translate_he_sv Swedish xx.sv.translate_to.ha translate_ha_sv Swedish xx.sv.translate_to.guw translate_guw_sv Swedish xx.sv.translate_to.gil translate_gil_sv Swedish xx.sv.translate_to.gaa translate_gaa_sv Swedish xx.sv.translate_to.fr translate_fr_sv Swedish xx.sv.translate_to.fi translate_fi_sv Swedish xx.sv.translate_to.et translate_et_sv Swedish xx.sv.translate_to.eo translate_eo_sv Swedish xx.sv.translate_to.en translate_sv_en Swedish xx.sv.translate_to.el translate_el_sv Swedish xx.sv.translate_to.efi translate_efi_sv Swedish xx.sv.translate_to.ee translate_ee_sv Swedish xx.sv.translate_to.cs translate_cs_sv Swedish xx.sv.translate_to.crs translate_crs_sv Swedish xx.sv.translate_to.chk translate_chk_sv Swedish xx.sv.translate_to.ceb translate_ceb_sv Swedish xx.sv.translate_to.bzs translate_bzs_sv Swedish xx.sv.translate_to.bi translate_bi_sv Swedish xx.sv.translate_to.bg translate_bg_sv Swedish xx.sv.translate_to.bem translate_bem_sv Swedish xx.sv.translate_to.bcl translate_bcl_sv Swedish xx.sv.translate_to.ase translate_ase_sv Swedish xx.sv.translate_to.am translate_am_sv Swedish xx.sv.translate_to.af translate_af_sv Swedish sv.ner entity_recognizer_sm Swedish sv.ner.sm entity_recognizer_sm Swedish sv.ner.md entity_recognizer_md Swedish sv.ner.lg entity_recognizer_lg Swedish sv.explain explain_document_sm Swedish sv.explain.sm explain_document_sm Swedish sv.explain.md explain_document_md Swedish sv.explain.lg explain_document_lg Tagalog xx.tl.translate_to.pt translate_pt_tl Tagalog xx.tl.translate_to.fr translate_fr_tl Tagalog xx.tl.translate_to.es translate_es_tl Tagalog xx.tl.translate_to.en translate_tl_en Tagalog xx.tl.translate_to.de translate_de_tl Tahitian xx.ty.translate_to.sv translate_sv_ty Tahitian xx.ty.translate_to.fr translate_fr_ty Tahitian xx.ty.translate_to.fi translate_fi_ty Tahitian xx.ty.translate_to.es translate_es_ty Tai xx.taw.translate_to.en translate_taw_en Tetela xx.tll.translate_to.sv translate_sv_tll Tetela xx.tll.translate_to.fr translate_fr_tll Tetela xx.tll.translate_to.fi translate_fi_tll Tetela xx.tll.translate_to.es translate_es_tll Tetela xx.tll.translate_to.en translate_tll_en Thai xx.th.translate_to.sv translate_sv_th Thai xx.th.translate_to.en translate_th_en Tigrinya xx.ti.translate_to.en translate_ti_en Tiv xx.tiv.translate_to.sv translate_sv_tiv Tiv xx.tiv.translate_to.fr translate_fr_tiv Tiv xx.tiv.translate_to.fi translate_fi_tiv Tiv xx.tiv.translate_to.en translate_tiv_en Tok Pisin xx.tpi.translate_to.sv translate_sv_tpi Tok Pisin xx.tpi.translate_to.fr translate_fr_tpi Tok Pisin xx.tpi.translate_to.fi translate_fi_tpi Tok Pisin xx.tpi.translate_to.es translate_es_tpi Tok Pisin xx.tpi.translate_to.en translate_tpi_en Tonga (Tonga Islands) xx.to.translate_to.sv translate_sv_to Tonga (Tonga Islands) xx.to.translate_to.fr translate_fr_to Tonga (Tonga Islands) xx.to.translate_to.fi translate_fi_to Tonga (Tonga Islands) xx.to.translate_to.es translate_es_to Tonga (Tonga Islands) xx.to.translate_to.en translate_to_en Tonga (Zambia) xx.toi.translate_to.sv translate_sv_toi Tonga (Zambia) xx.toi.translate_to.fi translate_fi_toi Tonga (Zambia) xx.toi.translate_to.en translate_toi_en Tsonga xx.ts.translate_to.sv translate_sv_ts Tsonga xx.ts.translate_to.fr translate_fr_ts Tsonga xx.ts.translate_to.fi translate_fi_ts Tsonga xx.ts.translate_to.en translate_ts_en Tswana xx.tn.translate_to.sv translate_sv_tn Tswana xx.tn.translate_to.fr translate_fr_tn Tswana xx.tn.translate_to.fi translate_fi_tn Tswana xx.tn.translate_to.es translate_es_tn Tswana xx.tn.translate_to.en translate_tn_en Tumbuka xx.tum.translate_to.sv translate_sv_tum Tumbuka xx.tum.translate_to.fr translate_fr_tum Tumbuka xx.tum.translate_to.en translate_tum_en Turkish xx.tr.translate_to.uk translate_uk_tr Turkish xx.tr.translate_to.lt translate_lt_tr Turkish xx.tr.translate_to.ja translate_ja_tr Turkish xx.tr.translate_to.fi translate_fi_tr Turkish xx.tr.translate_to.en translate_tr_en Turkish xx.tr.translate_to.bg translate_bg_tr Turkish xx.tr.translate_to.az translate_az_tr Turkish xx.tr.translate_to.ar translate_ar_tr Tuvalu xx.tvl.translate_to.sv translate_sv_tvl Tuvalu xx.tvl.translate_to.fr translate_fr_tvl Tuvalu xx.tvl.translate_to.fi translate_fi_tvl Tuvalu xx.tvl.translate_to.es translate_es_tvl Tuvalu xx.tvl.translate_to.en translate_tvl_en Twi xx.tw.translate_to.sv translate_sv_tw Twi xx.tw.translate_to.fr translate_fr_tw Twi xx.tw.translate_to.fi translate_fi_tw Twi xx.tw.translate_to.es translate_es_tw Tzotzil xx.tzo.translate_to.es translate_es_tzo Ukrainian xx.uk.translate_to.zh translate_zh_uk Ukrainian xx.uk.translate_to.tr translate_tr_uk Ukrainian xx.uk.translate_to.sv translate_sv_uk Ukrainian xx.uk.translate_to.sl translate_sl_uk Ukrainian xx.uk.translate_to.sh translate_sh_uk Ukrainian xx.uk.translate_to.ru translate_ru_uk Ukrainian xx.uk.translate_to.pt translate_pt_uk Ukrainian xx.uk.translate_to.pl translate_pl_uk Ukrainian xx.uk.translate_to.no translate_no_uk Ukrainian xx.uk.translate_to.nl translate_nl_uk Ukrainian xx.uk.translate_to.it translate_it_uk Ukrainian xx.uk.translate_to.hu translate_hu_uk Ukrainian xx.uk.translate_to.he translate_he_uk Ukrainian xx.uk.translate_to.fr translate_fr_uk Ukrainian xx.uk.translate_to.fi translate_fi_uk Ukrainian xx.uk.translate_to.es translate_es_uk Ukrainian xx.uk.translate_to.en translate_uk_en Ukrainian xx.uk.translate_to.de translate_de_uk Ukrainian xx.uk.translate_to.cs translate_cs_uk Ukrainian xx.uk.translate_to.ca translate_ca_uk Ukrainian xx.uk.translate_to.bg translate_bg_uk Umbundu xx.umb.translate_to.sv translate_sv_umb Umbundu xx.umb.translate_to.en translate_umb_en Urdu xx.ur.translate_to.hi translate_hi_ur Urdu xx.ur.translate_to.en translate_ur_en Venda xx.ve.translate_to.sv translate_sv_ve Venda xx.ve.translate_to.fr translate_fr_ve Venda xx.ve.translate_to.fi translate_fi_ve Venda xx.ve.translate_to.es translate_es_ve Venda xx.ve.translate_to.en translate_ve_en Vietnamese xx.vi.translate_to.zh translate_zh_vi Vietnamese xx.vi.translate_to.ru translate_ru_vi Vietnamese xx.vi.translate_to.ja translate_ja_vi Vietnamese xx.vi.translate_to.it translate_it_vi Vietnamese xx.vi.translate_to.fr translate_fr_vi Vietnamese xx.vi.translate_to.es translate_es_vi Vietnamese xx.vi.translate_to.en translate_vi_en Vietnamese xx.vi.translate_to.de translate_de_vi Wallisian xx.wls.translate_to.sv translate_sv_wls Wallisian xx.wls.translate_to.fr translate_fr_wls Wallisian xx.wls.translate_to.fi translate_fi_wls Wallisian xx.wls.translate_to.es translate_es_wls Wallisian xx.wls.translate_to.en translate_wls_en Walloon xx.wa.translate_to.en translate_wa_en Waray (Philippines) xx.war.translate_to.sv translate_sv_war Waray (Philippines) xx.war.translate_to.fr translate_fr_war Waray (Philippines) xx.war.translate_to.fi translate_fi_war Waray (Philippines) xx.war.translate_to.es translate_es_war Waray (Philippines) xx.war.translate_to.en translate_war_en Welsh xx.cy.translate_to.en translate_cy_en Wolaitta, Wolaytta xx.wal.translate_to.en translate_wal_en Xhosa xx.xh.translate_to.sv translate_sv_xh Xhosa xx.xh.translate_to.fr translate_fr_xh Xhosa xx.xh.translate_to.fi translate_fi_xh Xhosa xx.xh.translate_to.es translate_es_xh Xhosa xx.xh.translate_to.en translate_xh_en Yapese xx.yap.translate_to.sv translate_sv_yap Yapese xx.yap.translate_to.fr translate_fr_yap Yapese xx.yap.translate_to.fi translate_fi_yap Yapese xx.yap.translate_to.en translate_yap_en Yoruba xx.yo.translate_to.sv translate_sv_yo Yoruba xx.yo.translate_to.fr translate_fr_yo Yoruba xx.yo.translate_to.fi translate_fi_yo Yoruba xx.yo.translate_to.es translate_es_yo Yoruba xx.yo.translate_to.en translate_yo_en Yucatec Maya, Yucateco xx.yua.translate_to.es translate_es_yua Zande (individual language) xx.zne.translate_to.sv translate_sv_zne Zande (individual language) xx.zne.translate_to.fr translate_fr_zne Zande (individual language) xx.zne.translate_to.fi translate_fi_zne Albanian xx.sq.translate_to.sv translate_sv_sq Albanian xx.sq.translate_to.fi translate_fi_sq Albanian xx.sq.translate_to.en translate_sq_en Arabic xx.ar.translate_to.tr translate_tr_ar Arabic xx.ar.translate_to.ru translate_ru_ar Arabic xx.ar.translate_to.pl translate_pl_ar Arabic xx.ar.translate_to.ja translate_ja_ar Arabic xx.ar.translate_to.it translate_it_ar Arabic xx.ar.translate_to.he translate_he_ar Arabic xx.ar.translate_to.fr translate_fr_ar Arabic xx.ar.translate_to.es translate_es_ar Arabic xx.ar.translate_to.en translate_ar_en Arabic xx.ar.translate_to.el translate_el_ar Arabic xx.ar.translate_to.de translate_de_ar Azerbaijani xx.az.translate_to.tr translate_tr_az Azerbaijani xx.az.translate_to.en translate_az_en Chinese xx.zh.translate_to.es translate_es_zh Chinese xx.zh.translate_to.en translate_zh_en Estonian xx.et.translate_to.sv translate_sv_et Estonian xx.et.translate_to.ru translate_ru_et Estonian xx.et.translate_to.fi translate_fi_et Estonian xx.et.translate_to.es translate_es_et Estonian xx.et.translate_to.en translate_et_en Estonian xx.et.translate_to.de translate_de_et Kongo xx.kg.translate_to.sv translate_sv_kg Kongo xx.kg.translate_to.fr translate_fr_kg Kongo xx.kg.translate_to.fi translate_fi_kg Kongo xx.kg.translate_to.es translate_es_kg Kongo xx.kg.translate_to.en translate_kg_en Kongo xx.kg.translate_to.de translate_de_kg Latvian xx.lv.translate_to.sv translate_sv_lv Latvian xx.lv.translate_to.ru translate_ru_lv Latvian xx.lv.translate_to.fi translate_fi_lv Latvian xx.lv.translate_to.en translate_lv_en Malagasy xx.mg.translate_to.fi translate_fi_mg Malagasy xx.mg.translate_to.en translate_mg_en Malay (macrolanguage) xx.ms.translate_to.zh translate_zh_ms Malay (macrolanguage) xx.ms.translate_to.ms translate_ms_ms Malay (macrolanguage) xx.ms.translate_to.ja translate_ja_ms Malay (macrolanguage) xx.ms.translate_to.it translate_it_ms Malay (macrolanguage) xx.ms.translate_to.fr translate_fr_ms Malay (macrolanguage) xx.ms.translate_to.de translate_de_ms Norwegian xx.no.translate_to.uk translate_uk_no Norwegian xx.no.translate_to.sv translate_sv_no Norwegian xx.no.translate_to.ru translate_ru_no Norwegian xx.no.translate_to.pl translate_pl_no Norwegian xx.no.translate_to.no translate_no_no Norwegian xx.no.translate_to.nl translate_nl_no Norwegian xx.no.translate_to.fr translate_fr_no Norwegian xx.no.translate_to.fi translate_fi_no Norwegian xx.no.translate_to.es translate_es_no Norwegian xx.no.translate_to.de translate_de_no Norwegian xx.no.translate_to.da translate_da_no Norwegian no.ner entity_recognizer_sm Norwegian no.ner.sm entity_recognizer_sm Norwegian no.ner.md entity_recognizer_md Norwegian no.ner.lg entity_recognizer_lg Norwegian no.explain explain_document_sm Norwegian no.explain.sm explain_document_sm Norwegian no.explain.md explain_document_md Norwegian no.explain.lg explain_document_lg Oromo xx.om.translate_to.en translate_om_en Persian fa.ner.dl recognize_entities_dl Serbo-Croatian xx.sh.translate_to.uk translate_uk_sh Serbo-Croatian xx.sh.translate_to.ja translate_ja_sh Serbo-Croatian xx.sh.translate_to.eo translate_eo_sh Swahili (macrolanguage) xx.sw.translate_to.fi translate_fi_sw Multiple languages xx.mul.translate_to.en translate_mul_en Multilingual xx.jap.translate_to.en translate_jap_en Multilingual xx.classify.lang detect_language_375 Multilingual xx.classify.lang.bigru detect_language_bigru_21 Multilingual xx.classify.lang.99 detect_language_99 Multilingual xx.classify.lang.95 detect_language_95 Multilingual xx.classify.lang.7 detect_language_7 Multilingual xx.classify.lang.43 detect_language_43 Multilingual xx.classify.lang.231 detect_language_231 Multilingual xx.classify.lang.220 detect_language_220 Multilingual xx.classify.lang.21 detect_language_21 Multilingual xx.classify.lang.20 detect_language_20 Healthcare Model references Language Name(s) NLU Reference Spark NLP Reference Castilian, Spanish es.resolve.snomed robertaresolve_snomed Castilian, Spanish es.med_ner ner_diag_proc Castilian, Spanish es.med_ner.roberta_ner_diag_proc roberta_ner_diag_proc Castilian, Spanish es.med_ner.neoplasm ner_neoplasms Castilian, Spanish es.med_ner.living_species ner_living_species Castilian, Spanish es.med_ner.living_species.roberta ner_living_species_roberta Castilian, Spanish es.med_ner.living_species.bert ner_living_species_bert Castilian, Spanish es.med_ner.living_species.300 ner_living_species_300 Castilian, Spanish es.med_ner.diag_proc ner_diag_proc Castilian, Spanish es.med_ner.deid.subentity ner_deid_subentity Castilian, Spanish es.med_ner.deid.subentity.roberta ner_deid_subentity_roberta_augmented Castilian, Spanish es.med_ner.deid.generic ner_deid_generic Castilian, Spanish es.med_ner.deid.generic.roberta ner_deid_generic_roberta_augmented Castilian, Spanish es.embed.sciwiki_300d embeddings_sciwiki_300d Castilian, Spanish es.embed.sciwiki.50d embeddings_sciwiki_50d Castilian, Spanish es.embed.sciwiki.300d embeddings_sciwiki_300d Castilian, Spanish es.embed.sciwiki.150d embeddings_sciwiki_150d Castilian, Spanish es.embed.scielowiki.50d embeddings_scielowiki_50d Castilian, Spanish es.embed.scielowiki.300d embeddings_scielowiki_300d Castilian, Spanish es.embed.scielowiki.150d embeddings_scielowiki_150d Castilian, Spanish es.embed.scielo300d embeddings_scielo_300d Castilian, Spanish es.embed.scielo.50d embeddings_scielo_50d Castilian, Spanish es.embed.scielo.300d embeddings_scielo_300d Castilian, Spanish es.embed.scielo.150d embeddings_scielo_150d Castilian, Spanish es.embed.roberta_base_biomedical roberta_base_biomedical Catalan, Valencian ca.med_ner.living_species ner_living_species English en.t5.mediqa t5_base_mediqa_mnli English en.spell.drug_norvig spellcheck_drug_norvig English en.spell.clinical spellcheck_clinical English en.snomed_to_umls snomed_umls_mapper English en.snomed_to_icdo snomed_icdo_mapper English en.snomed_to_icd10cm snomed_icd10cm_mapper English en.rxnorm_to_umls rxnorm_umls_mapper English en.rxnorm_to_ndc rxnorm_ndc_mapper English en.resolve sbiobertresolve_cpt English en.resolve.umls_drug_substance sbiobertresolve_umls_drug_substance English en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome English en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs English en.resolve.umls sbiobertresolve_umls_major_concepts English en.resolve.umls.findings sbiobertresolve_umls_findings English en.resolve.snomed_drug sbiobertresolve_snomed_drug English en.resolve.snomed_conditions sbertresolve_snomed_conditions English en.resolve.snomed_body_structure_med sbertresolve_snomed_bodyStructure_med English en.resolve.snomed_body_structure sbiobertresolve_snomed_bodyStructure English en.resolve.snomed sbiobertresolve_snomed_auxConcepts English en.resolve.snomed.findings_int sbiobertresolve_snomed_findings_int English en.resolve.snomed.findings sbiobertresolve_snomed_findings English en.resolve.snomed.aux_concepts_int sbiobertresolve_snomed_auxConcepts_int English en.resolve.snomed.aux_concepts sbiobertresolve_snomed_auxConcepts English en.resolve.rxnorm_ndc sbiobertresolve_rxnorm_ndc English en.resolve.rxnorm_disposition sbiobertresolve_rxnorm_disposition English en.resolve.rxnorm_disposition.sbert sbertresolve_rxnorm_disposition English en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment English en.resolve.rxnorm sbiobertresolve_rxnorm English en.resolve.rxnorm.disposition sbertresolve_rxnorm_disposition English en.resolve.rxnorm.disposition.sbert sbertresolve_rxnorm_disposition English en.resolve.rxnorm.augmented_re sbiobertresolve_rxnorm_augmented_re English en.resolve.rxnen.med_ner.deid_subentityorm_augmented sbiobertresolve_rxnorm_augmented English en.resolve.rxcui sbiobertresolve_rxcui English en.resolve.ndc sbiobertresolve_ndc English en.resolve.mesh sbiobertresolve_mesh English en.resolve.loinc_uncased sbluebertresolve_loinc_uncased English en.resolve.loinc_cased sbiobertresolve_loinc_cased English en.resolve.loinc sbiobertresolve_loinc English en.resolve.loinc.biobert sbiobertresolve_loinc English en.resolve.loinc.augmented sbiobertresolve_loinc_augmented English en.resolve.icdo_augmented sbiobertresolve_icdo_augmented English en.resolve.icdo sbiobertresolve_icdo English en.resolve.icdo.base sbiobertresolve_icdo_base English en.resolve.icd10pcs sbiobertresolve_icd10pcs English en.resolve.icd10cm_generalised sbiobertresolve_icd10cm_generalised English en.resolve.icd10cm sbiobertresolve_icd10cm English en.resolve.icd10cm.slim_billable_hcc_med sbertresolve_icd10cm_slim_billable_hcc_med English en.resolve.icd10cm.slim_billable_hcc sbiobertresolve_icd10cm_slim_billable_hcc English en.resolve.icd10cm.augmented_billable sbiobertresolve_icd10cm_augmented_billable_hcc English en.resolve.icd10cm.augmented sbiobertresolve_icd10cm_augmented English en.resolve.hcpcs sbiobertresolve_hcpcs English en.resolve.hcc sbiobertresolve_hcc_augmented English en.resolve.hcc.augmented sbiobertresolve_hcc_augmented English en.resolve.cpt sbiobertresolve_cpt English en.resolve.cpt.procedures_measurements sbiobertresolve_cpt_procedures_measurements_augmented English en.resolve.cpt.procedures_augmented sbiobertresolve_cpt_procedures_augmented English en.resolve.cpt.augmented sbiobertresolve_cpt_augmented English en.resolve.clinical_snomed_procedures_measurements sbiobertresolve_clinical_snomed_procedures_measurements English en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym English en.resolve.HPO sbiobertresolve_HPO English en.relation redl_bodypart_direction_biobert English en.relation.zeroshot_biobert re_zeroshot_biobert English en.relation.test_result_date re_test_result_date English en.relation.temporal_events_clinical re_temporal_events_clinical English en.relation.temporal_events redl_temporal_events_biobert English en.relation.humen_phenotype_gene redl_human_phenotype_gene_biobert English en.relation.drugprot redl_drugprot_biobert English en.relation.drugprot.clinical re_drugprot_clinical English en.relation.drug_drug_interaction redl_drug_drug_interaction_biobert English en.relation.date redl_date_clinical_biobert English en.relation.clinical redl_clinical_biobert English en.relation.chemprot redl_chemprot_biobert English en.relation.bodypart.procedure redl_bodypart_procedure_test_biobert English en.relation.bodypart.problem redl_bodypart_problem_biobert English en.relation.bodypart.direction redl_bodypart_direction_biobert English en.relation.adverse_drug_events.clinical re_ade_clinical English en.relation.adverse_drug_events.clinical.biobert redl_ade_biobert English en.relation.ade_clinical re_ade_clinical English en.relation.ade_biobert re_ade_biobert English en.relation.ade redl_ade_biobert English en.pos.clinical pos_clinical English en.norm_drugs drug_normalizer English en.ner.drug_development_trials bert_token_classifier_drug_development_trials English en.ner.clinical_trials_abstracts ner_clinical_trials_abstracts English en.mesh_to_umls mesh_umls_mapper English en.med_ner jsl_ner_wip_clinical English en.med_ner.tumour nerdl_tumour_demo English en.med_ner.supplement_clinical ner_supplement_clinical English en.med_ner.risk_factors ner_risk_factors English en.med_ner.risk_factors.biobert ner_risk_factors_biobert English en.med_ner.radiology ner_radiology English en.med_ner.radiology.wip_greedy_biobert jsl_rd_ner_wip_greedy_biobert English en.med_ner.radiology.wip_clinical ner_radiology_wip_clinical English en.med_ner.posology ner_posology English en.med_ner.posology.small ner_posology_small English en.med_ner.posology.large_biobert ner_posology_large_biobert English en.med_ner.posology.large ner_posology_large English en.med_ner.posology.healthcare ner_posology_healthcare English en.med_ner.posology.greedy ner_posology_greedy English en.med_ner.posology.experimental ner_posology_experimental English en.med_ner.posology.biobert ner_posology_biobert English en.med_ner.pathogen ner_pathogen English en.med_ner.nihss ner_nihss English en.med_ner.medmentions ner_medmentions_coarse English en.med_ner.measurements ner_measurements_clinical English en.med_ner.living_species ner_living_species English en.med_ner.living_species.token_bert bert_token_classifier_ner_living_species English en.med_ner.living_species.biobert ner_living_species_biobert English en.med_ner.jsl_slim ner_jsl_slim English en.med_ner.jsl_greedy_biobert ner_jsl_greedy_biobert English en.med_ner.jsl ner_jsl English en.med_ner.jsl.wip.clinical jsl_ner_wip_clinical English en.med_ner.jsl.wip.clinical.rd jsl_rd_ner_wip_greedy_clinical English en.med_ner.jsl.wip.clinical.modifier jsl_ner_wip_modifier_clinical English en.med_ner.jsl.wip.clinical.greedy jsl_ner_wip_greedy_clinical English en.med_ner.jsl.enriched_biobert ner_jsl_enriched_biobert English en.med_ner.jsl.enriched ner_jsl_enriched English en.med_ner.jsl.biobert ner_jsl_biobert English en.med_ner.human_phenotype.go_clinical ner_human_phenotype_go_clinical English en.med_ner.human_phenotype.go_biobert ner_human_phenotype_go_biobert English en.med_ner.human_phenotype.gene_clinical ner_human_phenotype_gene_clinical English en.med_ner.human_phenotype.gene_biobert ner_human_phenotype_gene_biobert English en.med_ner.healthcare ner_healthcare English en.med_ner.genetic_variants ner_genetic_variants English en.med_ner.financial_contract ner_financial_contract English en.med_ner.events_healthcre ner_events_healthcare English en.med_ner.events_clinical ner_events_clinical English en.med_ner.events_biobert ner_events_biobert English en.med_ner.drugsgreedy ner_drugs_greedy English en.med_ner.drugs ner_drugs English en.med_ner.drugs.large ner_drugs_large English en.med_ner.drugprot_clinical ner_drugprot_clinical English en.med_ner.diseases ner_diseases English en.med_ner.diseases.large ner_diseases_large English en.med_ner.diseases.biobert ner_diseases_biobert English en.med_ner.deid_subentity_augmented_i2b2 ner_deid_subentity_augmented_i2b2 English en.med_ner.deid ner_deidentify_dl English en.med_ner.deid.synthetic ner_deid_synthetic English en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented English en.med_ner.deid.sd_large ner_deid_sd_large English en.med_ner.deid.sd ner_deid_sd English en.med_ner.deid.large ner_deid_large English en.med_ner.deid.generic_augmented ner_deid_generic_augmented English en.med_ner.deid.enriched_biobert ner_deid_enriched_biobert English en.med_ner.deid.enriched ner_deid_enriched English en.med_ner.deid.biobert ner_deid_biobert English en.med_ner.deid.augmented ner_deid_augmented English en.med_ner.covid_trials ner_covid_trials English en.med_ner.clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts English en.med_ner.clinical_trials bert_sequence_classifier_rct_biobert English en.med_ner.clinical ner_clinical English en.med_ner.clinical.biobert ner_clinical_biobert English en.med_ner.chexpert ner_chexpert English en.med_ner.chemprot ner_chemprot_biobert English en.med_ner.chemprot.clinical ner_chemprot_clinical English en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot English en.med_ner.chemicals ner_chemicals English en.med_ner.chemd ner_chemd_clinical English en.med_ner.cellular ner_cellular English en.med_ner.cellular.biobert ner_cellular_biobert English en.med_ner.cancer ner_cancer_genetics English en.med_ner.bionlp ner_bionlp English en.med_ner.bionlp.biobert ner_bionlp_biobert English en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm English en.med_ner.biomarker ner_biomarker English en.med_ner.bacterial_species ner_bacterial_species English en.med_ner.aspect_sentiment ner_aspect_based_sentiment English en.med_ner.anatomy ner_anatomy English en.med_ner.anatomy.coarse_biobert ner_anatomy_coarse_biobert English en.med_ner.anatomy.coarse ner_anatomy_coarse English en.med_ner.anatomy.biobert ner_anatomy_biobert English en.med_ner.admission_events ner_events_admission_clinical English en.med_ner.ade_biobert ner_ade_biobert English en.med_ner.ade.clinical_bert ner_ade_clinicalbert English en.med_ner.ade.clinical ner_ade_clinical English en.med_ner.ade.ade_healthcare ner_ade_healthcare English en.med_ner.abbreviation_clinical ner_abbreviation_clinical English en.map_entity.snomed_to_umls snomed_umls_mapper English en.map_entity.snomed_to_icdo snomed_icdo_mapper English en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper English en.map_entity.section_headers_normalized normalized_section_header_mapper English en.map_entity.rxnorm_to_umls rxnorm_umls_mapper English en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper English en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper English en.map_entity.rxnorm_resolver rxnorm_mapper English en.map_entity.mesh_to_umls mesh_umls_mapper English en.map_entity.icdo_to_snomed icdo_snomed_mapper English en.map_entity.icd10cm_to_umls icd10cm_umls_mapper English en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper English en.map_entity.drug_to_action_treatment drug_action_treatment_mapper English en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper English en.map_entity.abbreviation_to_definition abbreviation_mapper English en.icdo_to_snomed icdo_snomed_mapper English en.icd10cm_to_umls icd10cm_umls_mapper English en.icd10cm_to_snomed icd10cm_snomed_mapper English en.extract_relation.nihss redl_nihss_biobert English en.embed_sentence.bluebert.mli sbluebert_base_uncased_mli English en.embed_sentence.biobert.rxnorm sbiobert_jsl_rxnorm_cased English en.embed_sentence.biobert.mli sbiobert_base_cased_mli English en.embed_sentence.biobert.jsl_umls_cased sbiobert_jsl_umls_cased English en.embed_sentence.biobert.jsl_cased sbiobert_jsl_cased English en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased English en.embed_sentence.bert.jsl_tiny_uncased sbert_jsl_tiny_uncased English en.embed_sentence.bert.jsl_tiny_umls_uncased sbert_jsl_tiny_umls_uncased English en.embed_sentence.bert.jsl_mini_uncased sbert_jsl_mini_uncased English en.embed_sentence.bert.jsl_mini_umlsuncased sbert_jsl_mini_umls_uncased English en.embed_sentence.bert.jsl_medium_uncased sbert_jsl_medium_uncased English en.embed_sentence.bert.jsl_medium_umls_uncased sbert_jsl_medium_umls_uncased English en.embed.glove.icdoem_2ng embeddings_icdoem_2ng English en.embed.glove.icdoem embeddings_icdoem English en.embed.glove.healthcare_100d embeddings_healthcare_100d English en.embed.glove.healthcare embeddings_healthcare English en.embed.glove.clinical embeddings_clinical English en.embed.glove.biovec embeddings_biovec English en.detect_sentence.clinical sentence_detector_dl_healthcare English en.de_identify deidentify_rb English en.de_identify.rules deid_rules English en.de_identify.rb_no_regex deidentify_rb_no_regex English en.de_identify.rb deidentify_rb English en.de_identify.large deidentify_large English en.de_identify.clinical deidentify_enriched_clinical English en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim English en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl English en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs English en.classify.token_bert.ner_deid bert_token_classifier_ner_deid English en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical English en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals English en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria English en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy English en.classify.token_bert.ner_ade bert_token_classifier_ner_ade English en.classify.token_bert.chemicals bert_token_classifier_ner_chemicals English en.classify.token_bert.cellular bert_token_classifier_ner_cellular English en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp English en.classify.stress bert_sequence_classifier_stress English en.classify.pico classifierdl_pico_biobert English en.classify.pico.seq_biobert bert_sequence_classifier_pico_biobert English en.classify.gender.seq_biobert bert_sequence_classifier_gender_biobert English en.classify.gender.sbert classifierdl_gender_sbert English en.classify.gender.biobert classifierdl_gender_biobert English en.classify.bert_sequence.question_statement_clinical bert_sequence_classifier_question_statement_clinical English en.classify.ade.seq_distilbert distilbert_sequence_classifier_ade English en.classify.ade.seq_biobert bert_sequence_classifier_ade English en.classify.ade.conversational classifierdl_ade_conversational_biobert English en.classify.ade.clinicalbert classifierdl_ade_clinicalbert English en.classify.ade.clinical classifierdl_ade_clinicalbert English en.classify.ade.biobert classifierdl_ade_biobert English en.assert assertion_dl English en.assert.radiology assertion_dl_radiology English en.assert.large assertion_dl_large English en.assert.jsl_large assertion_jsl_large English en.assert.jsl assertion_jsl English en.assert.healthcare assertion_dl_healthcare English en.assert.biobert assertion_dl_biobert French fr.med_ner.living_species ner_living_species French fr.med_ner.living_species.bert ner_living_species_bert French fr.med_ner.deid_subentity ner_deid_subentity French fr.med_ner.deid_generic ner_deid_generic Galician gl.med_ner.living_species ner_living_species German de.resolve.snomed sbertresolve_snomed German de.resolve.icd10gm sbertresolve_icd10gm German de.med_ner ner_healthcare_slim German de.med_ner.traffic ner_traffic German de.med_ner.legal ner_legal German de.med_ner.deid_subentity ner_deid_subentity German de.med_ner.deid_generic ner_deid_generic German de.embed w2v_cc_300d German de.embed.w2v w2v_cc_300d Italian it.med_ner.living_species ner_living_species Italian it.med_ner.living_species.bert ner_living_species_bert Italian it.med_ner.deid_subentity ner_deid_subentity Italian it.med_ner.deid_generic ner_deid_generic Moldavian, Moldovan, Romanian ro.med_ner.living_species.bert ner_living_species_bert Moldavian, Moldovan, Romanian ro.med_ner.deid.subentity ner_deid_subentity Moldavian, Moldovan, Romanian ro.med_ner.deid.subentity.bert ner_deid_subentity_bert Moldavian, Moldovan, Romanian ro.med_ner.clinical ner_clinical Moldavian, Moldovan, Romanian ro.embed.clinical.bert.base_cased ner_clinical_bert Portuguese pt.med_ner.living_species ner_living_species Portuguese pt.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Portuguese pt.med_ner.living_species.roberta ner_living_species_roberta Portuguese pt.med_ner.living_species.bert ner_living_species_bert Portuguese pt.med_ner.deid ner_deid_generic Portuguese pt.med_ner.deid.subentity ner_deid_subentity Portuguese pt.med_ner.deid.generic ner_deid_generic Healthcare Pipeline references Language Name(s) nlp.load() Reference Spark NLP Reference English en.snomed.umls.mapping snomed_umls_mapping English en.rxnorm.umls.mapping rxnorm_umls_mapping English en.recognize_entities.posology recognize_entities_posology English en.mesh.umls.mapping mesh_umls_mapping English en.med_ner.profiling_clinical ner_profiling_clinical English en.med_ner.profiling_biobert ner_profiling_biobert English en.med_ner.pathogen.pipeline ner_pathogen_pipeline English en.med_ner.clinical_trials_abstracts.pipe ner_clinical_trials_abstracts_pipeline English en.med_ner.biomedical_bc2gm.pipeline ner_biomedical_bc2gm_pipeline English en.map_entity.snomed_to_icdo.pipe snomed_icdo_mapping English en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping English en.map_entity.rxnorm_to_ndc.pipe rxnorm_ndc_mapping English en.map_entity.icdo_to_snomed.pipe icdo_snomed_mapping English en.map_entity.icd10cm_to_snomed.pipe icd10cm_snomed_mapping English en.icd10cm.umls.mapping icd10cm_umls_mapping English en.explain_doc.era explain_clinical_doc_era English en.explain_doc.carp explain_clinical_doc_carp French fr.deid_obfuscated clinical_deidentification Moldavian, Moldovan, Romanian ro.deid.clinical clinical_deidentification",
    "url": "/docs/en/jsl/namespace",
    "relUrl": "/docs/en/jsl/namespace"
  },
  "1271": {
    "id": "1271",
    "title": "Models",
    "content": "All the models available in the Annotation Lab are listed in this page. The models are either trained within the Annotation Lab, uploaded to Annotation Lab by admin users, or downloaded from NLP Models Hub. General information about the models like labels/categories and the source (downloaded/trained/uploaded) is viewable. It is possible to delete any model, or redownload failed ones from the options available under the more action menu on each model. All available models are listed in the Spark NLP Pipeline Config on the Setup Page of any project and are ready to be included in the Labeling Config for pre-annotation. Auto download of model dependencies Starting from version 2.8.0, Annotation Lab automatically downloads all the necessary dependencies along with the model saving users valuable time from manually downloading the dependencies. Previously, users had to first download the model from the Models Hub page (e.g. ner_healthcare_de) and then again download the necessary embeddings required to train the model (e.g. w2v_cc_300d). Custom Model Upload Custom models can be uploaded using the Upload button present in the top right corner of the page. The labels predicted by this model need to be specified in the upload form. Note: The models to upload need to be Spark NLP compatible.",
    "url": "/docs/en/alab/models",
    "relUrl": "/docs/en/alab/models"
  },
  "1272": {
    "id": "1272",
    "title": "Available Models and Pipelines",
    "content": "",
    "url": "/models",
    "relUrl": "/models"
  },
  "1273": {
    "id": "1273",
    "title": "Models Hub",
    "content": "Annotation Lab offers tight integration with NLP Models Hub. Any compatible model and embeddings can be downloaded and made available to the Annotation Lab users for pre-annotations either from within the application or via manual upload. NLP Models HUB page is accessible from the left navigation panel by users in the Admins group. The Models Hub page lists all the pre-trained models and embeddings from NLP Models Hub that are compatible with the Spark NLP version present in the Annotation Lab. Search Search features are offered to help users identify the models they need based on their names. Additional information such as Library Edition, task for which the model was build as well as publication date are also available on the model tile. Language of the model/embeddings is also available as well as a direct link to the model description page on the NLP Models Hub where you can get more details about the model and usage examples. Filter Users can use the Edition filter to search models specific to an edition. It includes all supported NLP editions: Healthcare, Opensource, Legal, Finance, and Visual. When selecting one option, e.g. “Legal”, users will be presented with all available models for that specific domain. This will ease the exploration of available models, which can then easily be downloaded and used within Annotation Lab projects. To make searching models/embeddings more efficient, Annotation Lab offers a Language filter. Users can select models/embeddings on the Models Hub page according to their language preference. Download By selecting one or multiple models from the list, users can download those to the Annotation Lab. The licensed (Healthcare, Visual, Finance or Legal) models and embeddings are available to download only when a valid license is present. One restriction on models download/upload is related to the available disk space. Any model download requires that the double of its size is available on the local storage. If enough space is not available then the download cannot proceed. Disk usage view, search, and filter features are available on the upper section of the Models Hub page. Benchmarking For the licensed models, benchmarking information is available on the Models Hub page. To check this click on the icon on the lower right side of the model tile. The benchmarking information can be used to guide the selection of the model you include in your project configuration.",
    "url": "/docs/en/alab/models_hub",
    "relUrl": "/docs/en/alab/models_hub"
  },
  "1274": {
    "id": "1274",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/multi_classifier_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/multi_classifier_dl.html"
  },
  "1275": {
    "id": "1275",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/multi_date_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/multi_date_matcher.html"
  },
  "1276": {
    "id": "1276",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/multi_document_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/multi_document_assembler.html"
  },
  "1277": {
    "id": "1277",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/n_gram_generator.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/n_gram_generator.html"
  },
  "1278": {
    "id": "1278",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_approach.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_approach.html"
  },
  "1279": {
    "id": "1279",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_converter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_converter.html"
  },
  "1280": {
    "id": "1280",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_crf.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_crf.html"
  },
  "1281": {
    "id": "1281",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_dl.html"
  },
  "1282": {
    "id": "1282",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/ner_overwriter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/ner_overwriter.html"
  },
  "1283": {
    "id": "1283",
    "title": "NLP Pipelines",
    "content": "Concepts Spark ML provides a set of Machine Learning applications that can be build using two main components: Estimators and Transformers. The Estimators have a method called fit() which secures and trains a piece of data to such application. The Transformer is generally the result of a fitting process and applies changes to the the target dataset. These components have been embedded to be applicable to Spark NLP. Pipelines are a mechanism for combining multiple estimators and transformers in a single workflow. They allow multiple chained transformations along a Machine Learning task. For more information please refer to Spark ML library. Annotation The basic result of a NLP operation is an annotation. It’s structure includes: annotatorType: the type of annotator that generated the current annotation begin: the begin of the matched content relative to raw-text end: the end of the matched content relative to raw-text result: the main output of the annotation metadata: content of matched result and additional information embeddings: (new in 2.0) contains vector mappings if required This object is automatically generated by annotators after a transform process. No manual work is required. However, it is important to clearly understand the structure of an annotation to be able too efficiently use it. Annotators Annotators are the spearhead of NLP functions in Spark NLP. There are two forms of annotators: Annotator Approaches: are those who represent a Spark ML Estimator and require a training stage. They have a function called fit(data) which trains a model based on some data. They produce the second type of annotator which is an annotator model or transformer. Annotator Models: are spark models or transformers, meaning they have a transform(data) function. This function takes as input a dataframe to which it adds a new column containing the result of the current annotation. All transformers are additive, meaning they append to current data, never replace or delete previous information. Both forms of annotators can be included in a Pipeline. All annotators included in a Pipeline will be automatically executed in the defined order and will transform the data accordingly. A Pipeline is turned into a PipelineModel after the fit() stage. The Pipeline can be saved to disk and re-loaded at any time. Common Functions setInputCols(column_names): Takes a list of column names of annotations required by this annotator. Those are generated by the annotators which precede the current annotator in the pipeline. setOutputCol(column_name): Defines the name of the column containing the result of the current annotator. Use this name as an input for other annotators down the pipeline requiring the outputs generated by the current annotator. Quickly annotate some text You can run these examples using Python or Scala. The easiest way to run the python examples is by starting a pyspark jupyter notebook including the spark-nlp package: $ java -version # should be Java 8 (Oracle or OpenJDK) $ conda create -n sparknlp python=3.7 -y $ conda activate sparknlp # spark-nlp by default is based on pyspark 3.x $ pip install spark-nlp==4.2.2 pyspark==3.2.1 jupyter $ jupyter notebook Explain Document ML Spark NLP offers a variety of pretrained pipelines that will help you get started, and get a sense of how the library works. We are constantly working on improving the available content. You can checkout a demo application of the Explain Document ML pipeline here: View Demo Downloading and using a pretrained pipeline Explain Document ML (explain_document_ml) is a pretrained pipeline that does a little bit of everything NLP related. Let’s try it out in scala. Note that the first time you run the below code it might take longer since it downloads the pretrained pipeline from our servers! from johnsnowlabs import nlp spark = nlp.start() explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) annotations = explain_document_pipeline.annotate(&quot;We are very happy about SparkNLP&quot;) print(annotations) OUTPUT: { &#39;stem&#39;: [&#39;we&#39;, &#39;ar&#39;, &#39;veri&#39;, &#39;happi&#39;, &#39;about&#39;, &#39;sparknlp&#39;], &#39;checked&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;lemma&#39;: [&#39;We&#39;, &#39;be&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;document&#39;: [&#39;We are very happy about SparkNLP&#39;], &#39;pos&#39;: [&#39;PRP&#39;, &#39;VBP&#39;, &#39;RB&#39;, &#39;JJ&#39;, &#39;IN&#39;, &#39;NNP&#39;], &#39;token&#39;: [&#39;We&#39;, &#39;are&#39;, &#39;very&#39;, &#39;happy&#39;, &#39;about&#39;, &#39;SparkNLP&#39;], &#39;sentence&#39;: [&#39;We are very happy about SparkNLP&#39;] } As you can see the explain_document_ml is able to annotate any “document” providing as output a list of stems, check-spelling, lemmas, part of speech tags, tokens and sentence boundary detection and all this “out-of-the-box”!. Using a pretrained pipeline with spark dataframes You can also use the pipeline with a spark dataframe. You just need to create first a spark dataframe with a column named “text” that will work as the input for the pipeline and then use the .transform() method to run the pipeline over that dataframe and store the outputs of the different components in a spark dataframe. Remember than when starting jupyter notebook from pyspark or when running the spark-shell for scala, a Spark Session is started in the background by default within the namespace ‘scala’. from johnsnowlabs import nlp spark = nlp.start() sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] # spark is the Spark Session automatically started by pyspark. data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) # Download the pretrained pipeline from Johnsnowlab&#39;s servers explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] # Transform &#39;data&#39; and store output in a new &#39;annotations_df&#39; dataframe annotations_df = explain_document_pipeline.transform(data) # Show the results annotations_df.show() OUTPUT: +--+--+--+--+--+--+--+--+ | text| document| sentence| token| checked| lemma| stem| pos| +--+--+--+--+--+--+--+--+ |Hello, this is an...|[[document, 0, 33...|[[document, 0, 33...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, He...|[[token, 0, 4, he...|[[pos, 0, 4, UH, ...| |And this is a sec...|[[document, 0, 29...|[[document, 0, 29...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, An...|[[token, 0, 2, an...|[[pos, 0, 2, CC, ...| +--+--+--+--+--+--+--+--+ Manipulating pipelines The output of the previous DataFrame was in terms of Annotation objects. This output is not really comfortable to deal with, as you can see by running the code: annotations_df.select(&quot;token&quot;).show(truncate=False) OUTPUT: +--+ |token | +--+ |[[token, 0, 4, Hello, [sentence -&gt; 0], [], []], [token, 5, 5, ,, [sentence -&gt; 0], [], []], [token, 7, 10, this, [sentence -&gt; 0], [], []], [token, 12, 13, is, [sentence -&gt; 0], [], []], [token, 15, 16, an, [sentence -&gt; 0], [], []], [token, 18, 24, example, [sentence -&gt; 0], [], []], [token, 26, 33, sentence, [sentence -&gt; 0], [], []]]| |[[token, 0, 2, And, [sentence -&gt; 0], [], []], [token, 4, 7, this, [sentence -&gt; 0], [], []], [token, 9, 10, is, [sentence -&gt; 0], [], []], [token, 12, 12, a, [sentence -&gt; 0], [], []], [token, 14, 19, second, [sentence -&gt; 0], [], []], [token, 21, 28, sentence, [sentence -&gt; 0], [], []], [token, 29, 29, ., [sentence -&gt; 0], [], []]] | +--+ What if we want to deal with just the resulting annotations? We can use the Finisher annotator, retrieve the Explain Document ML pipeline, and add them together in a Spark ML Pipeline. Remember that pretrained pipelines expect the input column to be named “text”. from johnsnowlabs import nlp spark = nlp.start() finisher = nlp.Finisher().setInputCols([&quot;token&quot;, &quot;lemmas&quot;, &quot;pos&quot;]) explain_pipeline_model = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;).model pipeline = nlp.Pipeline() .setStages([ explain_pipeline_model, finisher ]) sentences = [ [&#39;Hello, this is an example sentence&#39;], [&#39;And this is a second sentence.&#39;] ] data = spark.createDataFrame(sentences).toDF(&quot;text&quot;) model = pipeline.fit(data) annotations_finished_df = model.transform(data) annotations_finished_df.select(&#39;finished_token&#39;).show(truncate=False) OUTPUT: +-+ |finished_token | +-+ |[Hello, ,, this, is, an, example, sentence]| |[And, this, is, a, second, sentence, .] | +-+ Setup your own pipeline Annotator types Every annotator has a type. Those annotators that share a type, can be used interchangeably, meaning you could use any of them when needed. For example, when a token type annotator is required by another annotator, such as a sentiment analysis annotator, you can either provide a normalized token or a lemma, as both are of type token. DocumentAssembler: Getting data in In order to get through the NLP process, we need to get raw data annotated. There is a special transformer that does this for us: the DocumentAssembler, it creates the first annotation of type Document which may be used by annotators down the road. documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) Sentence detection and tokenization In this quick example, we now proceed to identify the sentences in the input document. SentenceDetector requires a Document annotation, which is provided by the DocumentAssembler output, and it’s itself a Document type token. The Tokenizer requires a Document annotation type. That means it works both with DocumentAssembler or SentenceDetector output. In the following example we use the sentence output. sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;Sentence&quot;) regexTokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) Spark NLP also includes another special transformer, called Finisher to show tokens in a human language. finisher = nlp.Finisher() .setInputCols([&quot;token&quot;]) .setCleanAnnotations(False) Finisher: Getting data out At the end of each pipeline or any stage that was done by Spark NLP, you may want to get results out whether onto another pipeline or simply write them on disk. The Finisher annotator helps you to clean the metadata (if it’s set to true) and output the results into an array: finisher = nlp.Finisher() .setInputCols([&quot;token&quot;]) .setIncludeMetadata(True) If you need to have a flattened DataFrame (each sub-array in a new column) from any annotations other than struct type columns, you can use explode function from Spark SQL. You can also use Apache Spark functions (SQL) to manipulate the output DataFrame in any way you need. Here we combine the tokens and NER results together: from johnsnowlabs import nlp df.withColumn(&quot;tmp&quot;, nlp.F.explode(&quot;chunk&quot;)).select(&quot;tmp.*&quot;) Using Spark ML Pipeline Now we want to put all this together and retrieve the results, we use a Pipeline for this. We use the same data in fit() that we will use in transform since none of the pipeline stages have a training stage. from johnsnowlabs import nlp pipeline = nlp.Pipeline() .setStages([ documentAssembler, sentenceDetector, regexTokenizer, finisher ]) OUTPUT: +-+ |finished_token | +-+ |[hello, ,, this, is, an, example, sentence]| +-+ Using Spark NLP’s LightPipeline LightPipeline is a Spark NLP specific Pipeline class equivalent to Spark ML Pipeline. The difference is that it’s execution does not hold to Spark principles, instead it computes everything locally (but in parallel) in order to achieve fast results when dealing with small amounts of data. This means, we do not input a Spark Dataframe, but a string or an Array of strings instead, to be annotated. To create Light Pipelines, you need to input an already trained (fit) Spark ML Pipeline. It’s transform() stage is converted into annotate() instead. from johnsnowlabs import nlp explain_document_pipeline = nlp.PretrainedPipeline(&quot;explain_document_ml&quot;) lightPipeline = nlp.LightPipeline(explain_document_pipeline.model) OUTPUT: explain_document_ml download started this may take some time. Approx size to download 9.4 MB [OK!] lightPipeline.annotate(&quot;Hello world, please annotate my text&quot;) OUTPUT: {&#39;stem&#39;: [&#39;hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;pleas&#39;, &#39;annot&#39;, &#39;my&#39;, &#39;text&#39;], &#39;checked&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;lemma&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;i&#39;, &#39;text&#39;], &#39;document&#39;: [&#39;Hello world, please annotate my text&#39;], &#39;pos&#39;: [&#39;UH&#39;, &#39;NN&#39;, &#39;,&#39;, &#39;VB&#39;, &#39;NN&#39;, &#39;PRP$&#39;, &#39;NN&#39;], &#39;token&#39;: [&#39;Hello&#39;, &#39;world&#39;, &#39;,&#39;, &#39;please&#39;, &#39;annotate&#39;, &#39;my&#39;, &#39;text&#39;], &#39;sentence&#39;: [&#39;Hello world, please annotate my text&#39;]} Training annotators Training methodology Training your own annotators is a key concept when dealing with real life scenarios. Any of the annotators provided above, such as pretrained pipelines and models, can be applied out-of-the-box to a specific use case, but better results are obtained when they are fine-tuned to your specific use-case. Dealing with real life problems ofter requires training your own models. In Spark NLP, we support three ways of training a custom annotator: Train from a dataset. Most annotators are capable of training from a dataset passed to fit() method just as Spark ML does. Annotators that use the suffix Approach are such trainable annotators. Training from fit() is the standard behavior in Spark ML. Annotators have different schema requirements for training. Check the reference to see what are the requirements of each annotators. Training from an external source: Some of our annotators train from an external file or folder passed to the annotator as a param. You will see such ones as setCorpus() or setDictionary() param setter methods, allowing you to configure the input to use. You can set Spark NLP to read them as Spark datasets or LINE_BY_LINE which is usually faster for small files. Last but not least, some of our annotators are Deep Learning based. These models may be trained with the standard AnnotatorApproach API just like any other annotator. For more advanced users, we also allow importing your own graphs or even training from Python and converting them into an AnnotatorModel. Spark ML Pipelines SparkML Pipelines are a uniform structure that helps creating and tuning practical machine learning pipelines. Spark NLP integrates with them seamlessly so it is important to have this concept handy. Once a Pipeline is trained with fit(), it becomes a PipelineModel Example: from johnsnowlabs import nlp pipeline = nlp.Pipeline().setStages([...]) LightPipeline LightPipelines are Spark ML pipelines converted into a single machine but multithreaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences is roughly a good maximum). To use them, simply plug in a trained (fitted) pipeline. Example: from johnsnowlabs import nlp nlp.LightPipeline(someTrainedPipeline).annotate(someStringOrArray) Functions: annotate(string or string[]): returns dictionary list of annotation results fullAnnotate(string or string[]): returns dictionary list of entire annotations content For more details please refer to Using Spark NLP’s LightPipelines. RecursivePipeline Recursive pipelines are SparkNLP specific pipelines that allow a Spark ML Pipeline to know about itself on every Pipeline Stage task, allowing annotators to utilize this same pipeline against external resources to process them in the same way the user decides. Only some of our annotators take advantage of this. RecursivePipeline behaves exactly the same as normal Spark ML pipelines, so they can be used with the same intention. Example: from johnsnowlabs import nlp recursivePipeline = nlp.RecursivePipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, lemmatizer, finisher ]) Params and Features Annotator parameters SparkML uses ML Params to store pipeline parameter maps. In SparkNLP, we also use Features, which are a way to store parameter maps that are larger than just a string or a boolean. These features are serialized as either Parquet or RDD objects, allowing much faster and scalable annotator information. Features are also broadcasted among executors for better performance.",
    "url": "/docs/en/jsl/nlp_pipes",
    "relUrl": "/docs/en/jsl/nlp_pipes"
  },
  "1284": {
    "id": "1284",
    "title": "NLP Server",
    "content": "This is a ready to use NLP Server for analyzing text documents using NLU library. Over 4500+ industry grade NLP Models in 300+ Languages are available to use via a simple and intuitive UI, without writing a line of code. For more expert users and more complex tasks, NLP Server also provides a REST API that can be used to process high amounts of data. The models, refered to as spells, are provided by the NLU library and powered by the most widely used NLP library in the industry, Spark NLP. NLP Server is free for everyone to download and use. There is no limitation in the amount of text to analyze. You can setup NLP-Server as a Docker Machine in any enviroment or get it via the AWS Marketplace in just 1 click. Web UI The Web UI is accessible at the following URL: http://localhost:5000/ It allows a very simple and intuitive interaction with the NLP Server. As a first step the user chooses the spell from the first dropdown. All NLU spells are available. Then the user has to provide a text document for analysis. This can be done by either copy/pasting text on the text box, or by uploading a csv/json file. After selecting the grouping option, the user clicks on the Preview button to get the results for the first 10 rows of text. REST API NLP Server includes a REST API which can be used to process any amount of data using NLU. Once you deploy the NLP Server, you can access the API documentation at the following URL http://localhost:5000/docs. Integrate via the Rest API Rest APIs are a popular way to integrate different services into one common platform. NLP Server offers its own API to offer a quick programmatic integration with customers’ services and applications. Bellow is a quick overview of the provided endpoints. More details are provided in the API documentation available http://localhost:5000/docs. Start to analyze Endpoint : /results Method : POST Content-Type (Format) : multipart/form-data Parameters: Spell – the spell that you want to use for this analyze (if you want to run multiple spells you should join them with space character) Data – The data to analyse that can be a single text or an array of strings or files. Grouping – can be choosen from [“document”, “sentence”, “entity”, “word”]. The default value is “” for automatic selection based on spell. Format – The format of the provided input. The default value is “text”. Response: uuid – the unique identifier for the analysis process. Check the status of an analysis process Endpoint : /results/{uuid}/status Method : GET Content-Type (Format) : application/json Response: code – the status code that can be one of “progress”, “success”, “failure”, “broken spell”, “invalid license”, “licensed spell with no license” message – the status message Get the results After ensuring the status of an analysis is “success” you can get the results: Endpoint : /results/{uuid} Method : GET Content-Type (Format) : application/json Parameters: target – if the specified target is “preview” you only get a small part of results. Response: A JSON object that contains the results generated by the spell (each spell has their own specific keys) How to use in Python import requests # Invoke Processing with tokenization spell r = requests.post(f&#39;http://localhost:5000/api/results&#39;,json={&quot;spell&quot;: &quot;tokenize&quot;,&quot;data&quot;: &quot;I love NLU! &lt;3&quot;}) # Use the uuid to get your processed data uuid = r.json()[&#39;uuid&#39;] # Get status of processing r = requests.get(f&#39;http://localhost:5000/api/results/{uuid}/status&#39;).json &gt;&gt;&gt; {&#39;status&#39;: {&#39;code&#39;: &#39;success&#39;, &#39;message&#39;: None}} # Get results r = requests.get(f&#39;http://localhost:5000/api/results/{uuid}&#39;).json() &gt;&gt;&gt; {&#39;sentence&#39;: {&#39;0&#39;: [&#39;I love NLU! &lt;3&#39;]}, &#39;document&#39;: {&#39;0&#39;: &#39;I love NLU! &lt;3&#39;}, &#39;token&#39;: {&#39;0&#39;: [&#39;I&#39;, &#39;love&#39;, &#39;NLU&#39;, &#39;!&#39;, &#39;&lt;3&#39;]}} Import a license key Thanks to the close integration between NLP Server and https://my.JohnSnowLabs.com website, users can easily select and import one of the available licenses to be used on NLP Server. The steps to execute for this are: 1.Click on Login via MYJSL button on the menu bar. 2.In the pop-up window click on the Authorize button. 3.After redirecting back to NLP Server click on the Choose License button. 4.In the modal choose the license that you want to use and then click on the Select button. 5.After the above steps you will see this success alert on the top right of the page. That confirms the import of license completed successfully.",
    "url": "/docs/en/nlp_server/nlp_server",
    "relUrl": "/docs/en/nlp_server/nlp_server"
  },
  "1285": {
    "id": "1285",
    "title": "Healthcare Models and Domains overview",
    "content": "This page gives you an overview of every healthcare problem and domain that can be solved with NLU for healthcare models, together with concrete examples. See this notebook and the accompanying video below for an introduction to every healthcare domain. Medical Named Entity Recognition (NER) Named entities are sub-strings in a text that can be classified into catogires of a domain. For example, in the String &quot;Tesla is a great stock to invest in &quot; , the sub-string &quot;Tesla&quot; is a named entity, it can be classified with the label company by an ML algorithm. Named entities can easily be extracted by the various pre-trained Deep Learning based NER algorithms provided by NLU. NER models can be trained for many different domains and aquire expert domain knowledge in each of them. JSL provides a wide array of experts for various Medical, Helathcare and Clinical domains This algorithm is provided by Spark NLP for Healthcare’s MedicalNerModel Domain Description Sample NLU Spells Sample Entities Sample Predicted Labels Reference Links ADE (Adverse Drug Events) Find adverse drug event (ADE) related entities med_ner.ade_biobert Aspirin , vomiting DRUG, ADE CADEC, Twimed Anatomy Find body parts, anatomical sites a nd reference related entities med_ner.anatomy tubules, nasopharyngeal aspirates, embryoid bodies, NK cells, Mitochondrial, tracheoesophageal fistulas, heart, colon cancer, cervical, central nervous system Tissue_structure, Organism_substance, Developing_anatomical_structure, Cell, Cellular_component, Immaterial_anatomical_entity, organ, Pathological_formation, Organism_subdivision, Anatomical_system AnEM Cellular/Molecular Biology Find Genes, Molecules, Cell or general Biology related entities med_ner.cellular.biobert human T-cell leukemia virus type 1 Tax-responsive , primary T lymphocytes, E1A-immortalized, Spi-B mRNA, zeta-globin DNA, Cell_type, Cell_line, RNA, Protein JNLPBA Chemical/Genes/Proteins Find Chemical, Gene and Protein related entities med_ner.chemprot.clinical nitrogen , β-amyloid , NF-kappaB CHEMICAL, GENE-Y, GENE-N ChemProt Chemical Compounds Find general chemical compound related entities med_ner.chemicals resveratrol , β-polyphenol CHEM Dataset by John Snow Labs Drug Chemicals Find chemical and drug related entities med_ner.drugs potassium , anthracyclines, taxanes DrugChem.DrugChem.DrugChem i2b2 + FDA Posology/Drugs Find posology and drug related entities med_ner.posology.biobert 5000 units, Aspirin, 14 days, tablets, daily, topically, 30 mg DOSAGE, DRUG, DURATION, FORM, FREQUENCY, ROUTE, STRENGTH. i2b2 + FDA Risk Factors Find risk factor of patient related entities med_ner.risk_factors.biobert coronary artery disease, hypertension, Smokes 2 packs of cigarettes per day, morbid obesity, Actos, Works in School, diabetic, diabetic CAD, HYPERTENSION, SMOKER, OBESE, FAMILY_HIST, MEDICATION, PHI, HYPERLIPIDEMIA, DIABETES De-identification and Heart Disease Risk Factors Challenge datasets cancer Genetics Find cancer and genetics related entities med_ner.cancer human, Kir 3.3, GIRK3, potassium, GIRK, chromosome 1q21-23, pancreas, tissues, fat andskeletal muscle, KCNJ9, Type II, breast cancer, patients, anthracyclines, taxanes, vinorelbine, patients, breast, vinorelbine inpatients, anthracyclines Amino_acid, Anatomical_system, cancer, Cell, Cellular_component, Developing_anatomical_Structure , Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism , Organism_subdivision, Simple_chemical, Tissue CG TASK of BioNLP 2013 Diseases Find disease related entities med_ner.diseases.biobert the cyst, a large Prolene suture, a very small incisional hernia, the hernia cavity, omentum, the hernia, the wound lesion, The lesion, the existing scar, the cyst, the wound, this cyst down to its base, a small incisional hernia, The cyst Disease CG TASK of BioNLP 2013 Bacterial Species Find bacterial species related entities med_ner.bacterial_species Neisseria wadsworthii, N. bacilliformis, Spirochaeta litoralis SPECIES Dataset by John Snow Labs Medical Problem/Test/Treatment Find medical problem,test and treatment related entities med_ner.healthcare respiratory tract infection , Ourexpression studies, atorvastatin PROBLEM, TEST, TREATMENT i2b2 Clinical Admission Events Find clinical admission event related entities med_ner.admission_events 2007, 12 AM, Headache, blood sample, presented, emergency room, daily DATE, TIME, PROBLEM, TEST, TREATMENT, OCCURENCE, CLINICAL_DEPT, EVIDENTIAL, DURATION, FREQUENCY, ADMISSION, DISCHARGE Custom i2b2, enriched with Events Genetic Variants Find genetic variant related entities en.med_ner.genetic_variants rs1061170, p.S45P, T13046C DNAMutation, ProteinMutation, SNP TMVAR PHI (Protected Healthcare Information) Find PHI(Protected Healthcare) related entities en.med_ner.deid 2093-01-13, David Hale, Hendrickson,&lt;br&gt; Ora, 7194334, 01/13/93, Oliveira, 25-year-old, 1-11-2000, Cocke County Baptist Hospital, 0295 Keats Street., (302) 786-5227, Brothers Coal-Mine MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE n2c2 i2b2-PHI Social Determinants / Demographic Data Find Social Determinants and Demographic Data Related Entities med_ner.jsl.enriched 21-day-old, male, congestion, mom, suctioning yellow discharge, she, problems with his breathing, perioral cyanosis, retractions, mom, Tylenol, His, his, respiratory congestion, He, tired, fussy, albuterol Age, Diagnosis, Dosage, Drug_Name, Frequency, Gender, Lab_Name, Lab_Result, Symptom_Name Dataset by John Snow Labs General Clinical Find General Clinical Entities med_ner.jsl.wip.clinical.modifier 28-year-old, female, gestational, diabetes, mellitus, eight, years, prior, type, two, diabetes, mellitus, T2DM, HTG-induced, pancreatitis, three, years, prior, acute, hepatitis, obesity, body, mass, index, BMI, kg/m2, polyuria, polydipsia, poor, appetite, vomiting, Two, weeks, prior, she, five-day, course Injury_or_Poisoning, Direction, Test, Admission_Discharge, Death_Entity, Relationship_Status, Duration, Respiration, Hyperlipidemia, Birth_Entity, Age, Labour_Delivery, Family_History_Header, BMI, Temperature, Alcohol, Kidney_Disease, Oncological, Medical_History_Header, Cerebrovascular_Disease, Oxygen_Therapy, O2_Saturation, Psychological_Condition, Heart_Disease, Employment, Obesity, Disease_Syndrome_Disorder, Pregnancy, ImagingFindings, Procedure, Medical_Device, Race_Ethnicity, Section_Header, Symptom, Treatment, Substance, Route, Drug_Ingredient, Blood_Pressure, Diet, External_body_part_or_region, LDL, VS_Finding, Allergen, EKG_Findings, Imaging_Technique, Triglycerides, RelativeTime, Gender, Pulse, Social_History_Header, Substance_Quantity, Diabetes, Modifier, Internal_organ_or_component, Clinical_Dept, Form, Drug_BrandName, Strength, Fetus_NewBorn, RelativeDate, Height, Test_Result, Sexually_Active_or_Sexual_Orientation, Frequency, Time, Weight, Vaccine, Vital_Signs_Header, Communicable_Disease, Dosage, Overweight, Hypertension, HDL, Total_Cholesterol, Smoking, ` Dataset by John Snow Labs Radiology Find Radiology related entities med_ner.radiology.wip_clinical Bilateral, breast, ultrasound, ovoid mass, 0.5 x 0.5 x 0.4, cm, anteromedial aspect, left, shoulder, mass, isoechoic echotexture, muscle, internal color flow, benign fibrous tissue, lipoma ImagingTest, Imaging_Technique, ImagingFindings, OtherFindings, BodyPart, Direction, Test, Symptom, Disease_Syndrome_Disorder, Medical_Device, Procedure, Measurements, Units Dataset by John Snow Labs, MIMIC-CXR and MT Radiology texts Radiology Clinical JSL-V1 Find radiology related entities in clinical setting med_ner.radiology.wip_greedy_biobert Bilateral, breast, ultrasound, ovoid mass, 0.5 x 0.5 x 0.4, cm, anteromedial aspect, left, shoulder, mass, isoechoic echotexture, muscle, internal color flow, benign fibrous tissue, lipoma Test_Result, OtherFindings, BodyPart, ImagingFindings, Disease_Syndrome_Disorder, ImagingTest, Measurements, Procedure, Score, Test, Medical_Device, Direction, Symptom, Imaging_Technique, ManualFix, Units Dataset by John Snow Labs, Genes and Phenotypes Find Genes and Phenotypes (the observable physical properties of an organism) related entities med_ner.human_phenotype.gene_biobert APOC4 , polyhydramnios GENE, PHENOTYPE PGR_1, PGR_2 Normalized Genes and Phenotypes Find Normalized Genes and Phenotypes (the observable physical properties of an organism) related entities med_ner.human_phenotype.go_biobert protein complex oligomerization , defective platelet aggregation GO, HP PGR_1, PGR_2 Radiology Clinical JSL-V2 Find radiology related entities in clinical setting med_ner.jsl.wip.clinical.rd   Kidney_Disease, HDL, Diet, Test, Imaging_Technique, Triglycerides, Obesity, Duration, Weight, Social_History_Header, ImagingTest, Labour_Delivery, Disease_Syndrome_Disorder, Communicable_Disease, Overweight, Units, Smoking, Score, Substance_Quantity, Form, Race_Ethnicity, Modifier, Hyperlipidemia, ImagingFindings, Psychological_Condition, OtherFindings, Cerebrovascular_Disease, Date, Test_Result, VS_Finding, Employment, Death_Entity, Gender, Oncological, Heart_Disease, Medical_Device, Total_Cholesterol, ManualFix, Time, Route, Pulse, Admission_Discharge, RelativeDate, O2_Saturation, Frequency, RelativeTime, Hypertension, Alcohol, Allergen, Fetus_NewBorn, Birth_Entity, Age, Respiration, Medical_History_Header, Oxygen_Therapy, Section_Header, LDL, Treatment, Vital_Signs_Header, Direction, BMI, Pregnancy, Sexually_Active_or_Sexual_Orientation, Symptom, Clinical_Dept, Measurements, Height, Family_History_Header, Substance, Strength, Injury_or_Poisoning, Relationship_Status, Blood_Pressure, Drug, Temperature, ,EKG_Findings, Diabetes, BodyPart, Vaccine, Procedure, Dosage Dataset by John Snow Labs, General Medical Terms Find general medical terms and medical entities. med_ner.medmentions   Qualitative_Concept, Organization, Manufactured_Object, Amino_Acid, Peptide_or_Protein, Pharmacologic_Substance, Professional_or_Occupational_Group, Cell_Component, Neoplastic_Process, Substance, Laboratory_Procedure, Nucleic_Acid_Nucleoside_or_Nucleotide, Research_Activity, Gene_or_Genome, Indicator_Reagent_or_Diagnostic_Aid, Biologic_Function, Chemical, Mammal, Molecular_Function, Quantitative_Concept, Prokaryote, Mental_or_Behavioral_Dysfunction, Injury_or_Poisoning, Body_Location_or_Region, Spatial_Concept, Nucleotide_Sequence, Tissue, Pathologic_Function, Body_Substance, Fungus, Mental_Process, Medical_Device, Plant, Health_Care_Activity, Clinical_Attribute, Genetic_Function, Food, Therapeutic_or_Preventive_Procedure, Body_Part_Organ, Organ_Component, Geographic_Area, Virus, Biomedical_or_Dental_Material, Diagnostic_Procedure, Eukaryote, Anatomical_Structure, Organism_Attribute, Molecular_Biology_Research_Technique, Organic_Chemical, Cell, Daily_or_Recreational_Activity, Population_Group, Disease_or_Syndrome, Group, Sign_or_Symptom, Body_System MedMentions Entity Status Assertion Named Entities extracted by an NER model can be further classified into sub-classes or statuses, depending on the context of the sentence. See the following two examples : Billy hates having a headache Billy has a headache Billy said his father has regular headaches All sentences have the entity headache which is of class disease. But there is a semantic difference on what the actual status of the disease mentioned in text is. In the first and third sentence, Billy has no headache, but in the second sentence Billy actually has a sentence. The Entity Assertion Algorithms provided by JSL solve this problem. The disease entity can be classified into ABSENT for the first case and into PRESENT for the second case. The third case can be classified into PRESENT IN FAMILY. This has immense implications for various data analytical approaches in the helathcare domain. I.e. imagine you want you want to make a study about hearth attacks and survival rate of potential procedures. You can process all your digital patient notes with an Medical NER model and filter for documents that have the Hearth Attack entity. But your collected data will have wrong data entries because of the above mentioned Entity status problem. You cannot deduct that a document is talking about a patient having a hearth attack, unless you assert that the problem is actually there which is what the Resolutions algorithms do for you. Keep in mind: This is a simplified example, entities should actually be mapped to their according Terminology (ICD-10-CM/ICD-10-PCS, etc..) to solve disambiguity problems and based on their codes all analysis should be performed This algorithm is provided by Spark NLP for Healthcare’s AssertionDLModel Domain Description Spell Predicted Entities Examples Reference Dataset Radiology Predict status of Radiology related entities assert.radiology Confirmed, Negative, Suspected - Confirmed: X-Ray scan shows cancer in lung. - Negative : X-Ray scan shows no sign of cancer in lung. - Suspected :X-Ray raises suspicion of cancer in lung but does not confirm it. Internal Dataset by Annotated by John Snow Labs Healthcare/Clinical extended and Family JSL powerd Predict status of, Healthcare/Clinical/Family related entities. Additional training with JSL Dataset assert.jsl Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical - Present: Patient diagnosed with cancer in 1999 - Absent: No sign of cancer was shown by the scans - Possible: Tests indicate patient might have cancer - Planned: CT-Scan is scheduled for 23.03.1999 - Someoneelse: The patient gave Aspirin to daugther. - Past: The patient has no more headaches since the operation - Family: The patients father has cancer. - Hypotetical:Death could be possible. 2010 i2b2 + Data provided by JSL Healthcare/Clinical JSL powerd Predict status of Healthcare/Clinical related entities. Additional training with JSL Dataset assert.jsl_large present, absent, possible, planned, someoneelse, past - present: Patient diagnosed with cancer in 1999 - absent: No sign of cancer was shown by the scans - possible: Tests indicate patient might have cancer - planned: CT-Scan is scheduled for 23.03.1999 - someoneelse: The patient gave Aspirin to daugther - past: The patient has no more headaches since the operation 2010 i2b2 + Data provided by JSL Healthcare/Clinical classic Predict status of Healthcare/Clinical related entities assert.biobert present , absent, possible, conditional, associated_with_someone_else ,hypothetical - present: Patient diagnosed with cancer in 1999 - absent: No sign of cancer was shown by the scans - possible: Tests indicate patient might have cancer - conditional If the test is positive, patient has AIDS - associated_with_someone_else: The patients father has cancer. -hypothetical :Death could be possible. 2010 i2b2 Entity Resolution Named entities are sub-strings in a text that can be classified into catogires of a domain. For example, in the String &quot;Tesla is a great stock to invest in &quot; , the sub-string &quot;Tesla&quot; is a named entity, it can be classified with the label company by an ML algorithm. Named entities can easily be extracted by the various pre-trained Deep Learning based NER algorithms provided by NLU. After extracting named entities an entity resolution algorithm can be applied to the extracted named entities. The resolution algorithm classifies each extracted entitiy into a class, which reduces dimensionality of the data and has many useful applications. For example : “Tesla is a great stock to invest in “ “TSLA is a great stock to invest in “ “Tesla, Inc is a great company to invest in” The sub-strings Tesla , TSLA and Tesla, Inc are all named entities, that are classified with the labeld company by the NER algorithm. It tells us, all these 3 sub-strings are of type company, but we cannot yet infer that these 3 strings are actually referring to literally the same company. This exact problem is solved by the resolver algorithms, it would resolve all these 3 entities to a common name, like a company ID. This maps every reference of Tesla, regardless of how the string is represented, to the same ID. This example can analogusly be expanded to healthcare any any other text problems. In medical documents, the same disease can be referenced in many different ways. With NLU Healthcare you can leverage state of the art pre-trained NER models to extract Medical Named Entities (Diseases, Treatments, Posology, etc..) and resolve these to common healthcare disease codes. This algorithm is provided by Spark NLP for Healthcare’s SentenceEntitiyResolver Domain/Terminology Description Sample NLU Spells Sample Entities Sample Predicted Codes Reference Links ICD-10 / ICD-10-CM (International Classification of Diseases - Clinical Modification) Get ICD-10-CM codes of Medical and Clinical Entities. The ICD-10 Clinical Modification (ICD-10-CM) is a modification of the ICD-10, authorized by the World Health Organization, used as a source for diagnosis codes in the U.S. Be aware, ICD10-CM is often referred to as ICD10 resolve.icd10cm.augmented hypertension , gastritis I10, K2970 ICD-10-CM , WHO ICD-10-CM ICD-10-PCS (International Classification of Diseases - Procedure Coding System) Get ICD-10-PCS codes of Medical and Clinical Entities. The International Classification of Diseases, Procedure Coding System (ICD-10-PCS), is a U.S. cataloging system for procedural code It is maintaining by Centers for Medicare &amp; Medicaid Services resolve.icd10pcs hypertension , gastritis DWY18ZZ, 04723Z6 ICD10-PCS, CMS ICD-10-PCS ICD-O (International Classification of Diseases, Oncollogy) Topography &amp; Morphology codes Get ICD-0 codes of Medical and Clinical Entities. The International Classification of Diseases for Oncology (ICD-O), is a domain-specific extension of the International Statistical Classification of Diseases and Related Health Problems for tumor diseases. resolve.icdo.base metastatic lung cancer 9050/3+C38.3, 8001/3+C39.8 ICD-O Histology Behaviour dataset HCC (Hierachical Conditional Categories) Get HCC codes of Medical and Clinical Entities. Hierarchical condition category (HCC) relies on ICD-10 coding to assign risk scores to patients. Along with demographic factors (such as age and gender), insurance companies use HCC coding to assign patients a risk adjustment factor (RAF) score. resolve.hcc hypertension , gastritis 139, 188 HCC ICD-10-CM + HCC Billable Get ICD-10-CM and HCC codes of Medical and Clinical Entities. resolve.icd10cm.augmented_billable metastatic lung cancer C7800 + [&#39;1&#39;, &#39;1&#39;, &#39;8&#39;] ICD10-CM HCC CPT (Current Procedural Terminology) Get CPT codes of Medical and Clinical Entities. The Current Procedural Terminology(CPT) is developed by the American Medical Association (AMA) and used to assign codes to medical procedures/services/diagonstics. The codes are used to derive the amount of payment a healthcare provider may receives from insurance companies for the provided service.receives resolve.cpt.procedures_measurements calcium score, heart surgery 82310, 33257 CPT LOINC (Logical Observation Identifiers Names and Codes) Get LOINC codes of Medical and Clinical Entities. Logical Observation Identifiers Names and Codes (LOINC) developed by theU.S. organization Regenstrief Institute LOINC is a code system for identifying test observations. resolve.loinc acute hepatitis ,obesity 28083-4,50227-8 LOINC HPO (Human Phenotype Ontology) Get HPO codes of Medical and Clinical Entities. resolve.HPO cancer, bipolar disorder 0002664, 0007302, 0100753 HPO UMLS (Unified Medical Language System) CUI Get UMLS codes of Medical and Clinical Entities. resolve.umls.findings vomiting, polydipsia, hepatitis C1963281, C3278316, C1963279 UMLS SNOMED International (Systematized Nomenclature of Medicine) Get SNOMED (INT) codes of Medical and Clinical Entities. Defines sets of codes for entities in medical reports. resolve.snomed.findings_int hypertension 148439002 SNOMED SNOMED CT (Clinical Terms) Get SNOMED (CT) codes of Medical and Clinical Entities. resolve.snomed.findings hypertension 73578008 SNOMED SNOMED Conditions Get SNOMED Conditions codes of Medical and Clinical Entities. resolve.snomed_conditions schizophrenia 58214004 SNOMED RxNorm and RxCUI (Concept Uinque Indentifier) Get Normalized RxNorm and RxCUI codes of Medical, Clinical and Drug Entities. resolve.rxnorm 50 mg of eltrombopag oral 825427 [RxNorm Overview] [November 2020 RxNorm Clinical Drugs ontology graph] Entity Relationship Extraction Most sentences and documents have a lof of entities which can be extracted with NER. These entities alone already provide a lot of insight and information about your data, but there is even more information extractable… Each entity in a sentence always has some kind of relationship to every other entity in the sentence. In other words, each entity pair has a relationship ! If a sentence has N entities, there are NxN potential binary relationships and NxNxK for k-ary relationships. The RelationExtraction algortihms provided by JSL classify for each pair of entities what the type of relationship between is, based on some domain. A concrete use-case example: Lets say you want to analyze the survival rate of amputation procedures performed on the left hand. Using just NER, we could find all documents that mention the entity amputation , left and hand. The collected data will have wrong entries, imagine the following clinical note : The patients left foot and his right hand were amputated This record would be part of our analysis, if we just use NER with the above mentioned filtering. The RelationExtraction Algorithms provided by JSL solves this problem. The relation.bodypart.directions model can classify for each entity pair, wether they are related or not. In our example, it can classify that left and foot are related and that right and hand are related. Based on these classified relationships, we can easily enhance our filters and make sure no wrong records are used for our surival rate analysis. But what about the following sentence? The patients left hand was saved but his foot was amputated This would pass all the NER and Relationship filters defined sofar. But we can easily cover this case by using the relation.bodypart.procedures model, which can predict wether a procedure entity was peformed on some bodypart or not. In the last example, it can predict foot and amputated are related, buthand and amputated are not in relationship, aswell as left and amputated (since every entity pair gets a prediction). In conclusion, we can adjust our filters to additionaly verify that the amputation procedure is peformed on a hand and that this hand is in relationship with a direction entity with the value left. Keep in mind: This is a simplified example, entities should actually be mapped to their according Terminology (ICD-10-CM/ICD-10-PCS, etc..) to solve disambiguity problems and based on their codes all analysis should be performed These algorithms are provided by Spark NLP for Healthcare’s RelationExtraction and RelationExtractionDL Entity Relationship Extraction - Overview Domain Description Sample NLU Spells Predictable Relationships and Explanation Dates and Clinical Entities Predict binary temporal relationship between Date Entities and Clinical Entities relation.date - 1 for Date Entity and Clinical Entity are related. - 0 for Date Entity and Clinical Entity are not related Body Parts and Directions Predict binary direction relationship between Bodypart Entities and Direction Entities relation.bodypart.direction - 1 for Body Part and Direction are related - 0 for Body Part and Direction are not related Body Parts and Problems Predict binary location relationship between Bodypart Entities and Problem Entities relation.bodypart.problem - 1 for Body Part and Problem are related - 0 for Body Part and Problem are not related Body Parts and Procedures Predict binary application relationship between Bodypart Entities and Procedure Entities relation.bodypart.procedure - 1 for Body Part and Test/Procedure are related - 0 for Body Part and Test/Procedure are not related Adverse Effects between drugs (ADE) Predict binary effect relationship between Drugs Entities and Adverse Effects/Problem Entities relation.ade - 1 for Adverse Event Entity and Drug are related - 0 for Adverse Event Entity and Drug are not related Phenotype abnormalities,Genes and Diseases Predict binary caused by relationship between Phenotype Abnormality Entities, Gene Entities and Disease Entities relation.humen_phenotype_gene - 1 for Gene Entity and Phenotype Entity are related - 0 for Gene Entity and Phenotype Entity are not related Temporal events Predict multi-class temporal relationship between Time Entities and Event Entities relation.temporal_events - AFTER if Any Entity occured after Another Entity - BEFORE if Any Entity occured before Another Entity - OVERLAP if Any Entity during Another Entity Dates and Tests/Results Predict multi-class temporal cause,reasoning and conclusion relationship between Date Entities, Test Entities and Result Entities relation.test_result_date - relation.test_result_date - is_finding_of for Medical Entity is found because of Test Entity - is_result_of for Medical Entity reason for doing Test Entity - is_date_of for Date Entity relates to time of Test/Result - 0 : No relationship Clinical Problem, Treatment and Tests Predict multi-class cause,reasoning and effect relationship between Treatment Entities, Problem Entities and Test Entities relation.clinical - TrIP: A certain treatment has improved/cured a medical problem - TrWP: A patient’s medical problem has deteriorated or worsened because of treatment - TrCP: A treatment caused a medical problem - TrAP: A treatment administered for a medical problem - TrNAP: The administration of a treatment was avoided because of a medical problem - TeRP: A test has revealed some medical problem - TeCP: A test was performed to investigate a medical problem - PIP: Two problems are related to each other DDI Effects of using Multiple Drugs (Drug Drug Interaction) Predict multi-class effects, mechanisms and reasoning for DDI effects(Drug Drug Interaction) relationships between Drug Entities relation.drug_drug_interaction - DDI-advise when an advice/recommendation regarding aDrug Entity and Drug Entity is given - DDI-effect when Drug Entity and Drug Entity have an effect on the human body (pharmacodynamic mechanism). Including a clinical finding, signs or symptoms, an increased toxicity or therapeutic failure. - DDI-int when effect between Drug Entity and Drug Entity is already known and thus provides no additional information. - DDI-mechanism when ** Drug Entity** and Drug Entity are affected by an organism (pharmacokinetic). Such as the changes in levels or concentration in a drug. Used for DDIs that are described by their PK mechanism - DDI-false when a Drug Entity and Drug Entity have no interaction mentioned in the text Posology (Drugs, Dosage, Duration, Frequency,Strength) Predict multi-class posology relationships between Drug Entities,Dosage Entities,Strength Entities,Route Entities, Form Entities, Duration Entities and Frequency Entities relation.posology - DRUG-ADE if Problem Entity Adverse effect of Drug Entity - DRUG-DOSAGE if Dosage Entity refers to a Drug Entity - DRUG-DURATION if Duration Entity refers to a Drug Entity - DRUG-FORM if Mode/Form Entity refers to intake form of Drug Entity - DRUG-FREQUENCY if Frequency Entity refers to usage of Drug Entity - DRUG-REASON if Problem Entity is reason for taking Drug Entity - DRUG-ROUTE if Route Entity refer to administration method of Drug Entity - DRUG-STRENGTH if Strength Entity refers to Drug Entity Chemicals and Proteins Predict Regulator, Upregulator, Downregulator, Agonist, Antagonist, Modulator, Cofactor, Substrate relationships between Chemical Entities and Protein Entities relation.chemprot - CPR:1 if One ChemProt Entity is Part of of Another ChemProt Entity - CPR:2 if One ChemProt Entity is Regulator (Direct or Indirect) of Another ChemProt Entity - CPR:3 if One ChemProt Entity is Upregulator/Activator/Indirect Upregulator of Another ChemProt Entity - CPR:4 if One ChemProt Entity is Downregulator/Inhibitor/Indirect Downregulator of Another ChemProt Entity - CPR:5 if One ChemProt Entity is Agonist of Another ChemProt Entity - CPR:6 if One ChemProt Entity is Antagonist of Another ChemProt Entity - CPR:7 if One ChemProt Entity is Modulator (Activator/Inhibitor) of Another ChemProt Entity - CPR:8 if One ChemProt Entity is Cofactor of Another ChemProt Entity - CPR:9 if One ChemProt Entity is Substrate and product of of Another ChemProt Entity - CPR:10 if One ChemProt Entity is Not Related to Another ChemProt Entity Entity Relationship Extraction - Examples Domain Sentence With Relationships Predicted Relationships for Sample Sentence Reference Links Dates and Clinical Entities This 73 y/o patient had CT on 1/12/95, with cognitive decline since 8/11/94. - 1 for CT and1/12/95 - 0 for ** cognitive decline** and 1/12/95 - 1 for cognitive decline and 8/11/94 Internal Dataset by Annotated by John Snow Labs Body Parts and Directions MRI demonstrated infarction in the upper - brain stem , left cerebellum and right basil ganglia - 1 for uppper and brain stem - 0 for upper and cerebellum - 1 for left and cerebellum Internal Dataset by Annotated by John Snow Labs Body Parts and Problems Patient reported numbness in his left hand and bleeding from ear. - 1 for numbness and hand - 0 for numbness and ear - 1 for bleeding and ear Internal Dataset by Annotated by John Snow Labs Body Parts and Procedures The chest was scanned with portable ultrasound and amputation was performed on foot - 1 for chest and portable ultrasound - 0 for chest and amputation - 1 for foot and amputation Internal Dataset by Annotated by John Snow Labs Adverse Effects between drugs (ADE) Taking Lipitor for 15 years, experienced much sever fatigue! Doctor moved me to voltaren 2 months ago , so far only experienced cramps - 1 for sever fatigue and Liptor - 0 for sever fatigue and voltaren - 0 for cramps and Liptor - 1 for cramps and voltaren Internal Dataset by Annotated by John Snow Labs Phenotype abnormalities,Genes and Diseases She has a retinal degeneration, hearing loss and renal failure, short stature, Mutations in the SH3PXD2B gene coding for the Tks4 protein are responsible for the autosomal recessive. - 1 for ** hearing loss** and SH3PXD2B - 0 for retinal degeneration and hearing loss - 1 for retinal degeneration and autosomal recessive PGR aclAntology Temporal events She is diagnosed with cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001 - OVERLAP for cancer and 1991 - AFTER for additted and Mayo Clinic - BEFORE for admitted and discharged Temporal JSL Dataset and n2c2 Dates and Tests/Results On 23 March 1995 a X-Ray applied to patient because of headache, found tumor in brain - is_finding_of for tumor ** and **X-Ray - is_result_of for headache ** and **X-Ray - is_date_of for 23 March 1995 ** and **X-Ray Internal Dataset by Annotated by John Snow Labs Clinical Problem, Treatment and Tests - TrIP : infection resolved with antibiotic course - TrWP : the tumor was growing despite the drain - TrCP: penicillin causes a rash - TrAP:Dexamphetamine for narcolepsy - TrNAP: Ralafen was not given because of ulcers - TeRP: an echocardiogram revealed a pericardial effusion - TeCP: chest x-ray for pneumonia - PIP: Azotemia presumed secondary to sepsis - TrIP for infection and antibiotic course - TrWP for tumor and drain - TrCP for penicillin andrash - TrAP for Dexamphetamine and narcolepsy - TrNAP for Ralafen and ulcers - TeRP for echocardiogram and pericardial effusion - TeCP for chest x-ray and pneumonia - PIP for Azotemia and sepsis 2010 i2b2 relation challenge DDI Effects of using Multiple Drugs (Drug Drug Interaction) - DDI-advise: UROXATRALshould not be used in combination with other alpha-blockers - DDI-effect: Chlorthalidone may potentiate the action of other antihypertensive drugs - DDI-int : The interaction of omeprazole and ketoconazole has been established - DDI-mechanism : Grepafloxacin may inhibit the metabolism of theobromine - DDI-false : Aspirin does not interact with Chlorthalidone - DDI-advise for UROXATRAL and alpha-blockers - DDI-effect for Chlorthalidone and antihypertensive drugs - DDI-int for omeprazole and ketoconazole - DDI-mechanism for Grepafloxacin and theobromine - DDI-false for Aspirin and Chlorthalidone DDI Extraction corpus Posology (Drugs, Dosage, Duration, Frequency,Strength) - DRUG-ADE: had a headache after taking Paracetamol - DRUG-DOSAGE: took 0.5ML of** Celstone** - DRUG-DURATION: took Aspirin daily for two weeks - DRUG-FORM: took Aspirin as tablets - DRUG-FREQUENCY : Aspirin usage is weekly - DRUG-REASON : Took Aspirin because of headache - DRUG-ROUTE: Aspirin taken orally - DRUG-STRENGTH: 2mg of Aspirin - DRUG-ADE for headache and Paracetamol - DRUG-DOSAGE for 0.5ML and ** Celstone** - DRUG-DURATION for Aspirin and for two weeks - DRUG-FORM for Aspirin and tablets - DRUG-FREQUENCY for Aspirin and weekly - DRUG-REASON for Aspirin and headache - DRUG-ROUTE for Aspirin and orally - DRUG-STRENGTH for 2mg and Aspirin Magge, Scotch, Gonzalez-Hernandez (2018) Chemicals and Proteins - CPR:1 (Part of) : The amino acid sequence of the rabbit alpha(2A)-adrenoceptor has many interesting properties. - CPR:2 (Regulator) : Triacsin inhibited ACS activity - CPR:3 (Upregulator) : Ibandronate increases the expression of the FAS gene - CPR:4 (Downregulator) : Vitamin C treatment resulted in reduced C-Rel nuclear translocation - CPR:5 (Agonist) : Reports show tricyclic antidepressants act as agnonists at distinct opioid receptors - CPR:6 (Antagonist) : GDC-0152 is a drug triggers tumor cell apoptosis by selectively antagonizing LAPs - CPR:7 (Modulator) : Hydrogen sulfide is a allosteric modulator of ATP-sensitive potassium channels - CPR:8 (Cofactor) : polyinosinic:polycytidylic acid ** and the **IFNα/β demonstrate capability of endogenous IFN. - CPR:9 (Substrate) : ZIP9 plays an important role in the transport and toxicity of Cd(2+) cells - CPR:10 (Not Related) **: Studies indicate that **GSK-3β inhibition by palinurin cannot be competed out by ATP - CPR:1 (Part of) for amino acid and rabbit alpha(2A)-adrenoceptor - CPR:2 (Regulator) for Triacsin and ACS - CPR:3 (Upregulator) for Ibandronate and FAS gene - CPR:4 (Downregulator) for Vitamin C and C-Rel - CPR:5 (Agonist) for tricyclic antidepressants and opioid receptors - CPR:6 (Antagonist) (Antagonist) for GDC-0152 and LAPs - CPR:7 (Modulator) for Hydrogen sulfide and ATP-sensitive potassium channels - CPR:8 (Cofactor) for polyinosinic:polycytidylic acid ** and **IFNα/β - CPR:9 (Substrate) for ZIP9 and Cd(2+) cells - CPR:10 (Not Related) ** for **GSK-3β and ATP ChemProt Paper",
    "url": "/docs/en/jsl/nlu_for_healthcare",
    "relUrl": "/docs/en/jsl/nlu_for_healthcare"
  },
  "1286": {
    "id": "1286",
    "title": "OCR models overview",
    "content": "This page gives you an overview of every OCR model in NLU which are provided by Spark OCR. Additionally you can refer to the OCR tutorial Notebooks OCR Tutorial for extracting Text from Image/PDF/DOC(X) files OCR Tutorial for extracting Tables from Image/PDF/DOC(X) files Overview of all OCR features Overview of OCR Text Extractors These models grab the text directly from your input file and returns it as a Pandas DataFrame NLU Spell Transformer Class nlp.load(img2text) ImageToText nlp.load(pdf2text) PdfToText nlp.load(doc2text) DocToText Overview of OCR Table Extractors These models grab all Table data from the files detected and return a list of Pandas DataFrames, containing Pandas DataFrame for every table detected NLU Spell Transformer Class nlp.load(pdf2table) PdfToTextTable nlp.load(ppt2table) PptToTextTable nlp.load(doc2table) DocToTextTable File Path handling for OCR Models When your nlu pipeline contains a ocr spell the predict method will accept the following inputs : a string pointing to a folder or to a file a list, numpy array or Pandas Series containing paths pointing to folders or files a Pandas Dataframe or Spark Dataframe containing a column named path which has one path entry per row pointing to folders or files For every path in the input passed to the predict() method, nlu will distinguish between two cases: If the path points to a file, nlu will apply OCR transformers to it, if the file type is processable with the currently loaded OCR pipeline. If the path points to a folder, nlu will recursively search for files in the folder and sub-folders which have file types which are applicable with the loaded OCR pipeline. NLU checks the file endings to determine whether the OCR models can be applied or not, i.e. .pdf, .img etc.. If your files lack these endings, NLU will not process them. Image to Text Sample image: nlu.load(&#39;img2text&#39;).predict(&#39;path/to/haiku.png&#39;) Output of IMG OCR: text “The Old Pond” by Matsuo Basho An old silent pond A frog jumps into the pond— Splash! Silence again. PDF to Text Sample PDF: nlu.load(&#39;pdf2text&#39;).predict(&#39;path/to/haiku.pdf&#39;) Output of PDF OCR: text “Lighting One Candle” by Yosa Buson The light of a candle Is transferred to another candle— Spring twilight DOCX to text Sample DOCX: nlu.load(&#39;doc2text&#39;).predict(&#39;path/to/haiku.docx&#39;) Output of DOCX OCR: text “In a Station of the Metro” by Ezra Pound The apparition of these faces in the crowd; Petals on a wet, black bough. PDF with Tables Sample PDF: nlu.load(&#39;pdf2table&#39;).predict(&#39;/path/to/sample.pdf&#39;) Output of PDF Table OCR : mpg cyl disp hp drat wt qsec vs am gear 21 6 160 110 3.9 2.62 16.46 0 1 4 21 6 160 110 3.9 2.875 17.02 0 1 4 22.8 4 108 93 3.85 2.32 18.61 1 1 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 18.7 8 360 175 3.15 3.44 17.02 0 0 3 13.3 8 350 245 3.73 3.84 15.41 0 0 3 19.2 8 400 175 3.08 3.845 17.05 0 0 3 27.3 4 79 66 4.08 1.935 18.9 1 1 4 26 4 120.3 91 4.43 2.14 16.7 0 1 5 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 15.8 8 351 264 4.22 3.17 14.5 0 1 5 19.7 6 145 175 3.62 2.77 15.5 0 1 5 15 8 301 335 3.54 3.57 14.6 0 1 5 21.4 4 121 109 4.11 2.78 18.6 1 1 4 DOCX with Tables Sample DOCX: nlu.load(&#39;doc2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of DOCX Table OCR : Screen Reader Responses Share JAWS 853 49% NVDA 238 14% Window-Eyes 214 12% System Access 181 10% VoiceOver 159 9% PPT with Tables Sample PPT with two tables: nlu.load(&#39;ppt2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of PPT Table OCR : Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa and Sepal.Length Sepal.Width Petal.Length Petal.Width Species 6.7 3.3 5.7 2.5 virginica 6.7 3 5.2 2.3 virginica 6.3 2.5 5 1.9 virginica 6.5 3 5.2 2 virginica 6.2 3.4 5.4 2.3 virginica 5.9 3 5.1 1.8 virginica Combine OCR and NLP models Sample image containing named entities from U.S. Presidents Wikipedia: nlu.load(&#39;img2text ner&#39;).predict(&#39;path/to/presidents.png&#39;) Output of image OCR and NER NLP : entities_ner entities_ner_class entities_ner_confidence Four CARDINAL 0.9986 Abraham Lincoln PERSON 0.705514 John F. Kennedy), PERSON 0.966533 one CARDINAL 0.9457 Richard Nixon, PERSON 0.71895 John Tyler PERSON 0.9929 first ORDINAL 0.9811 The Twenty-fifth Amendment LAW 0.548033 Constitution LAW 0.9762 Tyler’s CARDINAL 0.5329 1967 DATE 0.8926 Richard Nixon PERSON 0.99515 first ORDINAL 0.9588 Gerald Ford PERSON 0.996 Spiro Agnew’s PERSON 0.99165 1973 DATE 0.9438 Ford PERSON 0.8337 second ORDINAL 0.9119 Nelson Rockefeller PERSON 0.98615 1967 DATE 0.589 Authorize NLU for OCR You need a set of credentials to access the licensed OCR features. You can grab one here Authorize anywhere via providing via JSON file If you provide a JSON file with credentials, nlu will check whether there are only OCR or also Healthcare secrets. If both are contained in the JSON file, nlu will give you access to healthcare and OCR features, if only one of them is present you will be accordingly only authorized for one set of the features. You can specify the location of your secrets.json like this : path = &#39;/path/to/secrets.json&#39; nlu.auth(path).load(&#39;licensed_model&#39;).predict(data) Authorize via providing String parameters You can manually enter your secrets and authorize nlu for OCR and Healthcare features import nlu AWS_ACCESS_KEY_ID = &#39;YOUR_SECRETS&#39; AWS_SECRET_ACCESS_KEY = &#39;cgsHeZR+YOUR_SECRETS&#39; OCR_SECRET = &#39;YOUR_SECRETS&#39; JSL_SECRET = &#39;YOUR_SECRETS&#39; OCR_LICENSE = &quot;YOUR_SECRETS&quot; SPARK_NLP_LICENSE = &#39;YOUR_SECRETS&#39; # this will automatically install the OCR library and NLP Healthcare library when credentials are provided nlu.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET, OCR_LICENSE, OCR_SECRET)",
    "url": "/docs/en/jsl/nlu_for_ocr",
    "relUrl": "/docs/en/jsl/nlu_for_ocr"
  },
  "1287": {
    "id": "1287",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/normalizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/normalizer.html"
  },
  "1288": {
    "id": "1288",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/norvig_sweeting.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/norvig_sweeting.html"
  },
  "1289": {
    "id": "1289",
    "title": "1-liner Tutorial Notebooks",
    "content": "The following tables give an overview on the different tutorials with the 1-liners. The tables are grouped by category. Embeddings Tutorials Overview Tutorial Description 1-liners used Open In Colab Dataset and Paper References Albert Word Embeddings albert, sentiment pos albert emotion Albert-Paper, Albert on Github, Albert on TensorFlow, T-SNE, T-SNE-Albert, Albert_Embedding Bert Word Embeddings bert, pos sentiment emotion bert Bert-Paper, Bert Github, T-SNE, T-SNE-Bert, Bert_Embedding BIOBERT Word Embeddings biobert , sentiment pos biobert emotion BioBert-Paper, Bert Github , BERT: Deep Bidirectional Transformers, Bert Github, T-SNE, T-SNE-Biobert, Biobert_Embedding COVIDBERT Word Embeddings covidbert, sentiment covidbert pos CovidBert-Paper, Bert Github, T-SNE, T-SNE-CovidBert, Covidbert_Embedding ELECTRA Word Embeddings electra, sentiment pos en.embed.electra emotion Electra-Paper, T-SNE, T-SNE-Electra, Electra_Embedding ELMO Word Embeddings elmo, sentiment pos elmo emotion ELMO-Paper, Elmo-TensorFlow, T-SNE, T-SNE-Elmo, Elmo-Embedding GLOVE Word Embeddings glove, sentiment pos glove emotion Glove-Paper, T-SNE, T-SNE-Glove , Glove_Embedding XLNET Word Embeddings xlnet, sentiment pos xlnet emotion XLNet-Paper, Bert Github, T-SNE, T-SNE-XLNet, Xlnet_Embedding Multiple Word-Embeddings and Part of Speech in 1 Line of code bert electra elmo glove xlnet albert pos Bert-Paper, Albert-Paper, ELMO-Paper, Electra-Paper, XLNet-Paper, Glove-Paper Text Preprocessing and Cleaning Tutorial Description 1-liners used Open In Colab Dataset and Paper References Normalzing norm - Detect sentences sentence_detector.deep, sentence_detector.pragmatic, xx.sentence_detector Sentence Detector Spellchecking n.a. n.a. - Stemming en.stem, de.stem - Stopwords removal stopwords Stopwords Tokenization tokenize - Normalization of Documents norm_document - Sequence to Sequence Tutorial Description 1-liners used Open In Colab Dataset and Paper References Open and Closed book question answering with Google’s T5 en.t5 , answer_question T5-Paper, T5-Model Overview of every task available with T5 en.t5.base T5-Paper, T5-Model Translate between more than 200 Languages in 1 line of code with Marian Models tr.translate_to.fr, en.translate_to.fr ,fr.translate_to.he , en.translate_to.de Marian-Papers, Translation-Pipeline (En to Fr), Translation-Pipeline (En to Ger) Sentence Embeddings Tutorial Description 1-liners used Open In Colab Dataset and Paper References BERT Sentence Embeddings embed_sentence.bert, pos sentiment embed_sentence.bert Bert-Paper, Bert Github, Bert-Sentence_Embedding ELECTRA Sentence Embeddings embed_sentence.electra, pos sentiment embed_sentence.electra Electra Paper, Sentence-Electra-Embedding USE Sentence Embeddings use, pos sentiment use emotion Universal Sentence Encoder, USE-TensorFlow, Sentence-USE-Embedding Sentence similarity using BERT embeddings embed_sentence.bert, use en.embed_sentence.electra embed_sentence.bert Bert-Paper, Bert Github, Bert-Sentence_Embedding Part of Speech Tutorial Description 1-liners used Open In Colab Dataset and Paper References Part of Speech tagging pos Part of Speech Named Entity Recognition (NER) Tutorial Description 1-liners used Open In Colab Dataset and Paper References NER Aspect Airline ATIS en.ner.aspect.airline NER Airline Model, Atis intent Dataset NLU-NER_CONLL_2003_5class_example ner NER-Piple Named-entity recognition with Deep Learning ONTO NOTES ner.onto NER_Onto Aspect based NER-Sentiment-Restaurants en.ner.aspect_sentiment - Multilingual Tasks Tutorial Description 1-liners used Open In Colab Dataset and Paper References Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Chinese zh.segment_words, zh.pos, zh.ner, zh.translate_to.en Translation-Pipeline (Zh to En) Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Japanese ja.segment_words, ja.pos, ja.ner, ja.translate_to.en Translation-Pipeline (Ja to En) Detect Named Entities (NER), Part of Speech Tags (POS) and Tokenize in Korean ko.segment_words, ko.pos, ko.ner.kmou.glove_840B_300d, ko.translate_to.en - Matchers Tutorial Description 1-liners used Open In Colab Dataset and Paper References Date Matching match.datetime - Dependency Parsing Tutorial Description 1-liners used Open In Colab Dataset and Paper References Typed Dependency Parsing dep Dependency Parsing Untyped Dependency Parsing dep.untyped - Classifiers Tutorial Description 1-liners used Open In Colab Dataset and Paper References E2E Classification e2e e2e-Model Language Classification lang - Cyberbullying Classification classify.cyberbullying Cyberbullying-Classifier Sentiment Classification for Twitter emotion Emotion detection Fake News Classification en.classify.fakenews Fakenews-Classifier Intent Classification en.classify.intent.airline Airline-Intention classifier, Atis-Dataset Question classification based on the TREC dataset en.classify.questions Question-Classifier Sarcasm Classification en.classify.sarcasm Sarcasm-Classifier Sentiment Classification for Twitter en.sentiment.twitter Sentiment_Twitter-Classifier Sentiment Classification for Movies en.sentiment.imdb Sentiment_imdb-Classifier Spam Classification en.classify.spam Spam-Classifier Toxic text classification en.classify.toxic Toxic-Classifier Unsupervised keyword extraction using the YAKE algorithm yake - Notebook for Classification of Banking Queries en.classify.distilbert_sequence.banking77 DistilBERT Sequence Classification - Banking77 Notebook for Classification of Intent in Texts en.ner.snips Identify intent in general text - SNIPS dataset Notebook for classification of Similar Questions en.classify.questionpair Question Pair Classifier Notebook for Classification of Questions vs Statements en.classify.question_vs_statement Bert for Sequence Classification (Question vs Statement) Notebook for Classification of News into 4 classes en.classify.distilbert_sequence.ag_news DistilBERT Sequence Classification Base - AG News (distilbert_base_sequence_classifier_ag_news) Chunkers Tutorial Description 1-liners used Open In Colab Dataset and Paper References Grammatical Chunk Matching match.chunks - Getting n-Grams ngram - Healthcare Tutorial Description 1-liners used Open In Colab Dataset and Paper References Assertion en.med_ner.clinical en.assert, en.med_ner.clinical.biobert en.assert.biobert, … Healthcare-NER, NER_Clinical-Classifier, Toxic-Classifier De-Identification Model overview med_ner.jsl.wip.clinical en.de_identify, med_ner.jsl.wip.clinical en.de_identify.clinical, … NER-Clinical Drug Normalization norm_drugs - Entity Resolution med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical, med_ner.jsl.wip.clinical en.resolve.icd10cm, … NER-Clinical, Entity-Resolver clinical Medical Named Entity Recognition en.med_ner.ade.clinical, en.med_ner.ade.clinical_bert, en.med_ner.anatomy,en.med_ner.anatomy.biobert, … - Relation Extraction en.med_ner.jsl.wip.clinical.greedy en.relation, en.med_ner.jsl.wip.clinical.greedy en.relation.bodypart.problem, … - Visualization Tutorial Description 1-liners used Open In Colab Dataset and Paper References Visualization of NLP-Models with Spark-NLP and NLU ner, dep.typed, med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in, med_ner.jsl.wip.clinical resolve.icd10cm NER-Piple, Dependency Parsing, NER-Clinical, Entity-Resolver (Chunks) clinical Example Notebooks on Kaggle, Examination on real life Problems. Tutorial Description 1-liners used Open In Colab Dataset and Paper References NLU Covid-19 Emotion Showcase emotion Emotion detection NLU Covid-19 Sentiment Showcase sentiment Sentiment classification NLU Airline Emotion Demo emotion Emotion detection NLU Airline Sentiment Demo sentiment Sentiment classification Release Notebooks Tutorial Description 1-liners used Open In Colab Dataset and Paper References Bengali NER Hindi Embeddings for 30 Models bn.ner, bn.lemma, ja.lemma, am.lemma, bh.lemma, en.ner.onto.bert.small_l2_128,.. Bengali-NER, Bengali-Lemmatizer, Japanese-Lemmatizer, Amharic-Lemmatizer Entity Resolution med_ner.jsl.wip.clinical en.resolve.umls, med_ner.jsl.wip.clinical en.resolve.loinc, med_ner.jsl.wip.clinical en.resolve.loinc.biobert - Crash-Course Tutorial Description 1-liners used Open In Colab Dataset and Paper References NLU 20 Minutes Crashcourse - the fast Data Science route spell, sentiment, pos, ner, yake, en.t5, emotion, answer_question, en.t5.base … T5-Model, Part of Speech, NER-Piple, Emotion detection , Spellchecker, Sentiment classification Natural Language Processing (NLP) Tutorial Description 1-liners used Open In Colab Dataset and Paper References Chapter 0: Intro: 1-liners sentiment, pos, ner, bert, elmo, embed_sentence.bert Part of Speech, NER-Piple, Sentiment classification, Elmo-Embedding, Bert-Sentence_Embedding Chapter 1: NLU base-features with some classifiers on testdata emotion, yake, stem Emotion detection Chapter 2: Translation between 300+ langauges with Marian tr.translate_to.en, en.translate_to.fr, en.translate_to.he Translation-Pipeline (En to Fr), Translation (En to He) Chapter 3: Answer questions and summarize Texts with T5 answer_question, en.t5, en.t5.base T5-Model Chapter 4: Overview of T5-Tasks en.t5.base T5-Model NLU-Crashcourse Graph AI Tutorial Description 1-liners used Open In Colab Dataset and Paper References Graph NLU 20 Minutes Crashcourse - State of the Art Text Mining for Graphs spell, sentiment, pos, ner, yake, emotion, med_ner.jsl.wip.clinical, … Part of Speech, NER-Piple, Emotion detection, Spellchecker, Sentiment classification Healthcare-Training Tutorial Description 1-liners used Open In Colab Dataset and Paper References Healthcare med_ner.human_phenotype.gene_biobert, med_ner.ade_biobert, med_ner.anatomy, med_ner.bacterial_species,… - Multilingual-Training Tutorial Description 1-liners used Open In Colab Dataset and Paper References Part 0: Intro: 1-liners spell, sentiment, pos, ner, bert, elmo, embed_sentence.bert Bert-Paper, Bert Github, T-SNE, T-SNE-Bert , Part of Speech, NER-Piple, Spellchecker, Sentiment classification, Elmo-Embedding , Bert-Sentence_Embedding Part 1: Quick Start, base-features with some classifiers on Testdata yake, stem, ner, emotion NER-Piple, Emotion detection Part 2: Translate between 200+ Languages in 1 line of code with Marian-Models en.translate_to.de, en.translate_to.fr, en.translate_to.he Translation-Pipeline (En to Fr), Translation-Pipeline (En to Ger), Translation (En to He) Part 3: More Multilingual NLP-translations for Asian Languages with Marian en.translate_to.hi, en.translate_to.ru, en.translate_to.zh Translation (En to Hi), Translation (En to Ru), Translation (En to Zh) Part 4: Unsupervised Chinese Keyword Extraction, NER and Translation from chinese news zh.translate_to.en, zh.segment_words, yake, zh.lemma, zh.ner Translation-Pipeline (Zh to En), Zh-Lemmatizer Part 5: Multilingual sentiment classifier training for 100+ languages train.sentiment, xx.embed_sentence.labse train.sentiment n.a. Sentence_Embedding.Labse Part 6: Question-answering and Text-summarization with T5-Modell answer_question, en.t5, en.t5.base T5-Paper Part 7: Overview of all tasks available with T5 en.t5.base T5-Paper Part 8: Overview of some of the Multilingual modes with State Of the Art accuracy (1-liner) bn.lemma, ja.lemma, am.lemma, bh.lemma, zh.segment_words, … Bengali-Lemmatizer, Japanese-Lemmatizer , Amharic-Lemmatizer Multilinigual-Examples Tutorial Description 1-liners used Open In Colab Dataset and Paper References Overview of some Multilingual modes avaiable with State Of the Art accuracy (1-liner) bn.ner.cc_300d, ja.ner, zh.ner, th.ner.lst20.glove_840B_300D, ar.ner Bengali-NER NLU 20 Minutes Crashcourse - the fast Data Science route    ",
    "url": "/docs/en/jsl/notebooks",
    "relUrl": "/docs/en/jsl/notebooks"
  },
  "1290": {
    "id": "1290",
    "title": "Visual NLP (Spark OCR)",
    "content": "Spark OCR is another commercial extension of Spark NLP for optical character recognition from images, scanned PDF documents, Microsoft DOCX and DICOM files. If you want to try it out on your own documents click on the below button: Try Free Spark OCR is built on top of Apache Spark and offers the following capabilities: Image pre-processing algorithms to improve text recognition results: Adaptive thresholding &amp; denoising Skew detection &amp; correction Adaptive scaling Layout Analysis &amp; region detection Image cropping Removing background objects Text recognition, by combining NLP and OCR pipelines: Extracting text from images (optical character recognition) Support English, German, French, Spanish, Russian, Vietnamese and Arabic languages Extracting data from tables Recognizing and highlighting named entities in PDF documents Masking sensitive text in order to de-identify images Table detection and recognition from images Signature detection Visual document understanding Document classification Visual NER Output generation in different formats: PDF, images, or DICOM files with annotated or masked entities Digital text for downstream processing in Spark NLP or other libraries Structured data formats (JSON and CSV), as files or Spark data frames Scale out: distribute the OCR jobs across multiple nodes in a Spark cluster. Frictionless unification of OCR, NLP, ML &amp; DL pipelines. Spark OCR Workshop If you prefer learning by example, click the button below to checkout the workshop repository full of fresh examples. Spark OCR Workshop Below, you can follow a more theoretical and thorough quick start guide. Quickstart Examples Images The following code example creates an OCR Pipeline for processing image(s). The image file(s) can contain complex layout like columns, tables, images inside. PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to image files&quot; // Read image files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Transform binary content to image val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define Pipeline val pipeline = new Pipeline() pipeline.setStages(Array( binaryToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image files&quot; # Read image files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Transform binary content to image binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define Pipeline pipeline = PipelineModel(stages=[ binaryToImage, ocr ]) data = pipeline.transform(df) data.show() Scanned PDF files Next sample provides an example of OCR Pipeline for processing PDF files containing image data. In this case, the PdfToImage transformer is used to convert PDF file to a set of images. PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to pdf files&quot; // Read pdf files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Transform PDF file to the image val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( pdfToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to pdf files&quot; # Read pdf files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Transform PDF file to the image pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ pdfToImage, ocr ]) data = pipeline.transform(df) data.show() PDF files (scanned or text) In the following code example we will create OCR Pipeline for processing PDF files that contain text or image data. For each PDF file, this pipeline will: extract the text from document and save it to the text column if text contains less than 10 characters (so the document isn’t PDF with text layout) it will process the PDF file as a scanned document: convert PDF file to an image detect and split image to regions run OCR and save output to the text column PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to PDF files&quot; // Read PDF files as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) // Extract text from PDF text layout val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) // In case of `text` column contains less then 10 characters, // pipeline run PdfToImage as fallback method val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setFallBackCol(&quot;text&quot;) .setMinSizeBeforeFallback(10) // OCR val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( pdfToText, pdfToImage, ocr )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to PDF files&quot; # Read PDF files as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) # Extract text from PDF text layout pdfToText = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) # In case of `text` column contains less then 10 characters, # pipeline run PdfToImage as fallback method pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setFallBackCol(&quot;text&quot;) .setMinSizeBeforeFallback(10) # OCR ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ pdfToText, pdfToImage, ocr, ]) data = pipeline.transform(df) data.show() Images (streaming mode) Next code segments provide an example of streaming OCR pipeline. It processes images and stores results to memory table. PythonScala val imagePath = &quot;path folder with images&quot; val batchDataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath).limit(1) val pipeline = new Pipeline() pipeline.setStages(Array( binaryToImage, binarizer, ocr )) val modelPipeline = pipeline.fit(batchDataFrame) // Read files in streaming mode val dataFrame = spark.readStream .format(&quot;binaryFile&quot;) .schema(batchDataFrame.schema) .load(imagePath) // Call pipeline and store results to &#39;results&#39; memory table val query = modelPipeline.transform(dataFrame) .select(&quot;text&quot;, &quot;exception&quot;) .writeStream .format(&quot;memory&quot;) .queryName(&quot;results&quot;) .start() imagePath = &quot;path folder with images&quot; batchDataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath).limit(1) pipeline = Pipeline() pipeline.setStages(Array( binaryToImage, binarizer, ocr )) modelPipeline = pipeline.fit(batchDataFrame) # Read files in streaming mode dataFrame = spark.readStream .format(&quot;binaryFile&quot;) .schema(batchDataFrame.schema) .load(imagePath) # Call pipeline and store results to &#39;results&#39; memory table query = modelPipeline.transform(dataFrame) .select(&quot;text&quot;, &quot;exception&quot;) .writeStream() .format(&quot;memory&quot;) .queryName(&quot;results&quot;) .start() For getting results from memory table following code could be used: PythonScala spark.table(&quot;results&quot;).select(&quot;path&quot;, &quot;text&quot;).show() spark.table(&quot;results&quot;).select(&quot;path&quot;, &quot;text&quot;).show() More details about Spark Structured Streaming could be found in spark documentation. Advanced Topics Error Handling Pipeline execution would not be interrupted in case of the runtime exceptions while processing some records. In this case OCR transformers would fill exception column that contains transformer name and exception. NOTE: Storing runtime errors to the exception field allows to process batch of files. Output Here is an output with exception when try to process js file using OCR pipeline: PythonScala result.select(&quot;path&quot;, &quot;text&quot;, &quot;exception&quot;).show(2, false) result.select(&quot;path&quot;, &quot;text&quot;, &quot;exception&quot;).show(2, False) +-+-+--+ |path |text |exception | +-+-+--+ |file:jquery-1.12.3.js | |BinaryToImage_c0311dc62161: Can&#39;t open file as image.| |file:image.png |I prefer the morning flight through Denver |null | +-+-+--+ Performance In case of big count of text PDF’s in dataset need have manual partitioning for avoid skew in partitions and effective utilize resources. For example the randomization could be used.",
    "url": "/docs/en/ocr",
    "relUrl": "/docs/en/ocr"
  },
  "1291": {
    "id": "1291",
    "title": "Installation",
    "content": "Spark OCR is built on top of Apache Spark. Currently, it supports 3.0., 2.4. and 2.3.* versions of Spark. It is recommended to have basic knowledge of the framework and a working environment before using Spark OCR. Refer to Spark documentation to get started with Spark. Spark OCR requires: Scala 2.11 or 2.12 related to the Spark version Python 3.7 + (in case using PySpark) Before you start, make sure that you have: Spark OCR jar file (or secret for download it) Spark OCR python wheel file License key If you don’t have a valid subscription yet and you want to test out the Spark OCR library press the button below: Try Free Spark OCR from Scala You can start a spark REPL with Scala by running in your terminal a spark-shell including the com.johnsnowlabs.nlp:spark-ocr_2.11:1.0.0 package: spark-shell --jars #### The #### is a secret url only available for license users. If you have purchased a license but did not receive it please contact us at info@johnsnowlabs.com. Start Spark OCR Session The following code will initialize the spark session in case you have run the jupyter notebook directly. If you have started the notebook using pyspark this cell is just ignored. Initializing the spark session takes some seconds (usually less than 1 minute) as the jar from the server needs to be loaded. The #### in .config(“spark.jars”, “####”) is a secret code, if you have not received it please contact us at info@johnsnowlabs.com. import org.apache.spark.sql.SparkSession val spark = SparkSession .builder() .appName(&quot;Spark OCR&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;4G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;2G&quot;) .config(&quot;spark.jars&quot;, &quot;####&quot;) .getOrCreate() Spark OCR from Python Install Python package Install python package using pip: pip install spark-ocr==1.8.0.spark24 --extra-index-url #### --ignore-installed The #### is a secret url only available for license users. If you have purchased a license but did not receive it please contact us at info@johnsnowlabs.com. Start Spark OCR Session Manually from pyspark.sql import SparkSession spark = SparkSession .builder .appName(&quot;Spark OCR&quot;) .master(&quot;local[*]&quot;) .config(&quot;spark.driver.memory&quot;, &quot;4G&quot;) .config(&quot;spark.driver.maxResultSize&quot;, &quot;2G&quot;) .config(&quot;spark.jars&quot;, &quot;https://pypi.johnsnowlabs.com/####&quot;) .getOrCreate() Using Start function Another way to initialize SparkSession with Spark OCR to use start function in Python. Start function has following params: Param name Type Default Description secret string None Secret for download Spark OCR jar file jar_path string None Path to jar file in case you need to run spark session offline extra_conf SparkConf None Extra spark configuration master_url string local[*] Spark master url nlp_version string None Spark NLP version for add it Jar to session nlp_internal boolean/string None Run Spark session with Spark NLP Internal if set to ‘True’ or specify version nlp_secret string None Secret for get Spark NLP Internal jar keys_file string keys.json Name of the json file with license, secret and aws keys For start Spark session with Spark NLP please specify version of it in nlp_version param. Example: from sparkocr import start spark = start(secret=secret, nlp_version=&quot;2.4.4&quot;) Databricks The installation process to Databricks includes following steps: Installing Spark OCR library to Databricks and attaching it to the cluster Same step for Spark OCR python wheel file Adding license key Adding cluster init script for install dependencies Please look databricks python helpers for simplify install init script. Example notebooks: Spark OCR Databricks python notebooks Spark OCR Databricks Scala notebooks",
    "url": "/docs/en/ocr_install",
    "relUrl": "/docs/en/ocr_install"
  },
  "1292": {
    "id": "1292",
    "title": "Object detection",
    "content": "ImageHandwrittenDetector ImageHandwrittenDetector is a DL model for detect handwritten text on the image. It’s based on Cascade Region-based CNN network. Detector support following labels: ‘signature’ ‘date’ ‘name’ ‘title’ ‘address’ ‘others’ Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.5 Score threshold for output regions. outputLabels Array[String]   White list for output labels. labels Array[String]   List of labels Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect signature signature_detector = ImageHandwrittenDetector .pretrained(&quot;image_signature_detector_gsa0628&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;signature_regions&quot;) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;signature_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, signature_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect signature val signature_detector = ImageHandwrittenDetector .pretrained(&quot;image_signature_detector_gsa0628&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;signature_regions&quot;) val draw_regions = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;signature_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, signature_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) Output: ImageTextDetector ImageTextDetector is a DL model for detecting text on the image. It’s based on CRAFT network architecture. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.9 Score threshold for output regions. Regions with an area below the threshold won’t be returned. sizeThreshold int 5 Threshold for the area of the detected regions. textThreshold float 0.4f Threshold for the score of a region potentially containing text. The region score represents the probability that a given pixel is the center of the character. Higher values for this threshold will result in that only regions for which the confidence of containing text is high will be returned. linkThreshold float 0.4f Threshold for the the link(affinity) score. The link score represents the space allowed between adjacent characters to be considered as a single word. width integer 0 Scale width to this value, if 0 use original width height integer 0 Scale height to this value, if 0 use original height Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect text text_detector = ImageTextDetector .pretrained(&quot;text_detection_v1&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setSizeThreshold(10) .setScoreThreshold(0.9) .setLinkThreshold(0.4) .setTextThreshold(0.2) .setWidth(1512) .setHeight(2016) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect text val text_detector = ImageTextDetector .pretrained(&quot;text_detection_v1&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) val draw_regions = new ImageTextDetector() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) .setSizeThreshold(10) .setScoreThreshold(0.9) .setLinkThreshold(0.4) .setTextThreshold(0.2) .setWidth(1512) .setHeight(2016) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) Output: ImageTextDetectorV2 ImageTextDetectorV2 is a DL model for detecting text on images. It is based on the CRAFT network architecture with refiner net. Refiner net runs as postprocessing, and is able to merge single words regions into lines. Currently, it’s available only on Python side. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.7 Score threshold for output regions. sizeThreshold int 10 Threshold for height of the detected regions. Regions with a height below the threshold won’t be returned. textThreshold float 0.4f Threshold for the score of a region potentially containing text. The region score represents the probability that a given pixel is the center of the character. Higher values for this threshold will result in that only regions for which the confidence of containing text is high will be returned. linkThreshold float 0.4f Threshold for the the link(affinity) score. The link score represents the space allowed between adjacent characters to be considered as a single word. width integer 1280 Width of the desired input image. Image will be resized to this width. withRefiner boolean false Enable to run refiner net as postprocessing step. Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect text text_detector = ImageTextDetectorV2 .pretrained(&quot;image_text_detector_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setScoreThreshold(0.5) .setTextThreshold(0.2) .setSizeThreshold(10) .setWithRefiner(True) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;text_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, text_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) not implemented",
    "url": "/docs/en/ocr_object_detection",
    "relUrl": "/docs/en/ocr_object_detection"
  },
  "1293": {
    "id": "1293",
    "title": "Spark OCR 2.3.x (Licensed)",
    "content": "Spark NLP comes with an OCR module that can read both PDF files and scanned images (requires Tesseract 4.x+). Installation Installing Tesseract As mentioned above, if you are dealing with scanned images instead of test-selectable PDF files you need to install tesseract 4.x+ on all the nodes in your cluster. Here how you can install it on Ubuntu/Debian: apt-get install tesseract-ocr In Databricks this command may result in installing tesseract 3.x instead of version 4.x. You can simply run this init script to install tesseract 4.x in your Databricks cluster: #!/bin/bash sudo apt-get install -y g++ # or clang++ (presumably) sudo apt-get install -y autoconf automake libtool sudo apt-get install -y pkg-config sudo apt-get install -y libpng-dev sudo apt-get install -y libjpeg8-dev sudo apt-get install -y libtiff5-dev sudo apt-get install -y zlib1g-dev ​ wget http://www.leptonica.org/source/leptonica-1.74.4.tar.gz tar xvf leptonica-1.74.4.tar.gz cd leptonica-1.74.4 ./configure make sudo make install ​ git clone --single-branch --branch 4.1 https://github.com/tesseract-ocr/tesseract.git cd tesseract ./autogen.sh ./configure make sudo make install sudo ldconfig ​ tesseract -v Quick start Let’s read a PDF file: import com.johnsnowlabs.nlp._ val ocrHelper = new OcrHelper() //If you do this locally you can use file:/// or hdfs:/// if the files are hosted in Hadoop val dataset = ocrHelper.createDataset(spark, &quot;/tmp/sample_article.pdf&quot;) If you are trying to extract text from scanned images in the format of PDF, please keep in mind to use these configs: ocrHelper.setPreferredMethod(&quot;image&quot;) ocrHelper.setFallbackMethod(false) ocrHelper.setMinSizeBeforeFallback(0) Configuration setPreferredMethod(text/image = text) either text or image will work. Defaults to text. Text mode works better and faster for digital or text scanned PDFs setFallbackMethod(boolean) on true, when text or image fail, it will fallback to the alternate method setMinSizeBeforeFallback(int = 1) number of characters to have at a minimum, before falling back. setPageSegMode(int = 3) image mode page segmentation mode setEngineMode(int = 1) image mode engine mode setPageIteratorLevel(int = 0) image mode page iteratior level setScalingFactor(float) Specifies the scaling factor to apply to images, in both axes, before OCR. It can scale up the image(factor &gt; 1.0) or scale it down(factor &lt; 1.0) setSplitPages(boolean = true) Whether to split pages into different rows and documents setSplitRegions(boolean = true) Whether to split by document regions. Works only in image mode. Enables split pages as well. setIncludeConfidence(boolean = false) setAutomaticSkewCorrection(use: boolean, half_angle: double = 5.0, resolution: double = 1.0) setAutomaticSizeCorrection(use: boolean, desired_size: int = 34) setEstimateNoise(string) image mode estimator noise level useErosion(use: boolean, kernel_size: int = 2, kernel_shape: Int = 0) image mode erosion Utilizing Spark NLP OCR Module Spark NLP OCR Module is not included within Spark NLP. It is not an annotator and not an extension to Spark ML. You can use OcrHelper to directly create spark dataframes from PDF. This will hold entire documents in single rows, meant to be later processed by a SentenceDetector. This way, you won’t be breaking the content in rows as if you were reading a standard document. Metadata columns are added automatically and will include page numbers, file name and other useful information per row. Python code from pyspark.sql import SparkSession from sparknlp.ocr import OcrHelper from sparknlp import DocumentAssembler data = OcrHelper().createDataset(spark = spark, input_path = &quot;/your/example.pdf&quot; ) documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;) annotations = documentAssembler.transform(data) annotations.columns [&#39;text&#39;, &#39;pagenum&#39;, &#39;method&#39;, &#39;noiselevel&#39;, &#39;confidence&#39;, &#39;positions&#39;, &#39;filename&#39;, &#39;document&#39;] Scala code import com.johnsnowlabs.nlp.util.io.OcrHelper import com.johnsnowlabs.nlp.DocumentAssembler val myOcrHelper = new OcrHelper val data = myOcrHelper.createDataset(spark, &quot;/your/example.pdf&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;) val annotations = documentAssembler.transform(data) annotations.columns Array[String] = Array(text, pagenum, method, noiselevel, confidence, positions, filename, document) … where the text column of the annotations spark dataframe includes the text content of the PDF, pagenum the page number, etc… Creating an Array of Strings from PDF (For LightPipeline) Another way, would be to simply create an array of strings. This is useful for example if you are parsing a small amount of pdf files and would like to use LightPipelines instead. See an example below. Scala code import com.johnsnowlabs.nlp.util.io.OcrHelper import com.johnsnowlabs.nlp.{DocumentAssembler,LightPipeline} import com.johnsnowlabs.nlp.annotator.SentenceDetector import org.apache.spark.ml.Pipeline val myOcrHelper = new OcrHelper val raw = myOcrHelper.createMap(&quot;/pdfs/&quot;) val documentAssembler = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) val lightPipeline = new LightPipeline(new Pipeline().setStages(Array(documentAssembler, sentenceDetector)).fit(Seq.empty[String].toDF(&quot;text&quot;))) val annotations = ligthPipeline.annotate(raw.values.toArray) Now to get the whole first PDF content in your /pdfs/ folder you can use: annotations(0)(&quot;document&quot;)(0) and to get the third sentence found in that first pdf: annotations(0)(&quot;sentence&quot;)(2) To get from the fifth pdf the second sentence: annotations(4)(&quot;sentence&quot;)(1) Similarly, the whole content of the fifth pdf can be retrieved by: annotations(4)(&quot;document&quot;)(0)",
    "url": "/docs/en/ocr_old",
    "relUrl": "/docs/en/ocr_old"
  },
  "1294": {
    "id": "1294",
    "title": "Pipeline components",
    "content": "PDF processing Next section describes the transformers that deal with PDF files with the purpose of extracting text and image data from PDF files. PdfToText PDFToText extracts text from selectable PDF (with text layout). Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Parameters Param name Type Default Description splitPage bool true Whether it needed to split document to pages textStripper   TextStripperType.PDF_TEXT_STRIPPER Extract unstructured text sort bool false Sort text during extraction with TextStripperType.PDF_LAYOUT_STRIPPER partitionNum int 0 Force repartition dataframe if set to value more than 0. onlyPageNum bool false Extract only page numbers. extractCoordinates bool false Extract coordinates and store to the positions column storeSplittedPdf bool false Store one page pdf’s for process it using PdfToImage. Output Columns Param name Type Default Column Data Description outputCol string text extracted text pageNumCol string pagenum page number or 0 when splitPage = false NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf with text layout&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) transformer = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(True) data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.PdfToText val pdfPath = &quot;path to pdf with text layout&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val transformer = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(true) val data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() Output: +-+-+ |pagenum|text | +-+-+ |0 |This is a page. | |1 |This is another page. | |2 |Yet another page. | +-+-+ PdfToImage PdfToImage renders PDF to an image. To be used with scanned PDF documents. Output dataframe contains total_pages field with total number of pages. For process pdf with a big number of pages prefer to split pdf by setting splitNumBatch param. Number of partitions should be equal to number of cores/executors. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the PDF document originCol string path path to the original file fallBackCol string text extracted text from previous method for detect if need to run transformer as fallBack Parameters Param name Type Default Description splitPage bool true whether it needed to split document to pages minSizeBeforeFallback int 10 minimal count of characters to extract to decide, that the document is the PDF with text layout imageType ImageType ImageType.TYPE_BYTE_GRAY type of the image resolution int 300 Output image resolution in dpi keepInput boolean false Keep input column in dataframe. By default it is dropping. partitionNum int 0 Number of Spark RDD partitions (0 value - without repartition) binarization boolean false Enable/Disable binarization image after extract image. binarizationParams Array[String] null Array of Binarization params in key=value format. splitNumBatch int 0 Number of partitions or size of partitions, related to the splitting strategy. partitionNumAfterSplit int 0 Number of Spark RDD partitions after splitting pdf document (0 value - without repartition). splittingStategy SplittingStrategy SplittingStrategy.FIXED_SIZE_OF_PARTITION Splitting strategy. Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) pageNumCol string pagenum page number or 0 when splitPage = false Example: PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdfToImage = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(True) data = pdfToImage.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.PdfToImage val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;pagenum&quot;) .setSplitPage(true) val data = pdfToImage.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() ImageToPdf ImageToPdf transform image to Pdf document. If dataframe contains few records for same origin path, it groups image by origin column and create multipage PDF document. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string content binary representation of the PDF document Example: Read images and store them as single page PDF documents. PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) # Define transformer for convert to Image struct binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for store to PDF imageToPdf = ImageToPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;content&quot;) # Call transformers image_df = binaryToImage.transform(df) pdf_df = pdfToImage.transform(image_df) pdf_df.select(&quot;content&quot;).show() import com.johnsnowlabs.ocr.transformers._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) // Define transformer for convert to Image struct val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) // Define transformer for store to PDF val imageToPdf = new ImageToPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;content&quot;) // Call transformers val image_df = binaryToImage.transform(df) val pdf_df = pdfToImage.transform(image_df) pdf_df.select(&quot;content&quot;).show() TextToPdf TextToPdf renders ocr results to PDF document as text layout. Each symbol will render to the same position with the same font size as in original image or PDF. If dataframe contains few records for same origin path, it groups image by origin column and create multipage PDF document. Input Columns Param name Type Default Column Data Description inputCol string positions column with positions struct inputImage string image image struct (Image schema) inputText string text column name with recognized text originCol string path path to the original file inputContent string content column name with binary representation of original PDF file Output Columns Param name Type Default Column Data Description outputCol string pdf binary representation of the PDF document Example: Read PDF document, run OCR and render results to PDF document. PythonScala from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_image = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image_raw&quot;) binarizer = ImageBinarizer() .setInputCol(&quot;image_raw&quot;) .setOutputCol(&quot;image&quot;) .setThreshold(130) ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setIgnoreResolution(False) .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) .setConfidenceThreshold(60) textToPdf = TextToPdf() .setInputCol(&quot;positions&quot;) .setInputImage(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) pipeline = PipelineModel(stages=[ pdf_to_image, binarizer, ocr, textToPdf ]) result = pipeline.transform(df).collect() # Store to file for debug with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(result[0].pdf) import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers._ val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToImage = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image_raw&quot;) .setResolution(400) val binarizer = new ImageBinarizer() .setInputCol(&quot;image_raw&quot;) .setOutputCol(&quot;image&quot;) .setThreshold(130) val ocr = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setIgnoreResolution(false) .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) .setConfidenceThreshold(60) val textToPdf = new TextToPdf() .setInputCol(&quot;positions&quot;) .setInputImage(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( pdfToImage, binarizer, ocr, textToPdf )) val modelPipeline = pipeline.fit(df) val pdf = modelPipeline.transform(df) val pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) // store to file val tmpFile = Files.createTempFile(suffix=&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) PdfAssembler PdfAssembler group single page PDF documents by the filename and assemble muliplepage PDF document. Input Columns Param name Type Default Column Data Description inputCol string page_pdf binary representation of the PDF document originCol string path path to the original file pageNumCol string pagenum for compatibility with another transformers Output Columns Param name Type Default Column Data Description outputCol string pdf binary representation of the PDF document Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_image = PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setKeepInput(True) # Run OCR and render results to PDF ocr = ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf_page&quot;) # Assemble multipage PDF pdf_assembler = PdfAssembler() .setInputCol(&quot;pdf_page&quot;) .setOutputCol(&quot;pdf&quot;) pipeline = PipelineModel(stages=[ pdf_to_image, ocr, pdf_assembler ]) pdf = pipeline.transform(df) pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) # store pdf to file with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(pdfContent[0].pdf) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdf_to_image = new PdfToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setKeepInput(True) // Run OCR and render results to PDF val ocr = new ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf_page&quot;) // Assemble multipage PDF val pdf_assembler = new PdfAssembler() .setInputCol(&quot;pdf_page&quot;) .setOutputCol(&quot;pdf&quot;) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdf_to_image, ocr, pdf_assembler )) val pdf = pipeline.fit(df).transform(df) val pdfContent = pdf.select(&quot;pdf&quot;).collect().head.getAs[Array[Byte]](0) // store to pdf file val tmpFile = Files.createTempFile(&quot;with_regions_&quot;, s&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) PdfDrawRegions PdfDrawRegions transformer for drawing regions to Pdf document. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the PDF document originCol string path path to the original file inputRegionsCol string region input column which contain regions Parameters Param name Type Default Description lineWidth integer 1 line width for draw regions Output Columns Param name Type Default Column Data Description outputCol string pdf_regions binary representation of the PDF document Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) entity_extractor = TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;./sparkocr/resources/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) position_finder = PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) draw = PdfDrawRegions() .setInputRegionsCol(&quot;coordinates&quot;) .setOutputCol(&quot;pdf_with_regions&quot;) .setInputCol(&quot;content&quot;) .setLineWidth(1) pipeline = Pipeline(stages=[ pdf_to_text, document_assembler, sentence_detector, tokenizer, entity_extractor, position_finder, draw ]) pdfWithRegions = pipeline.fit(df).transform(df) pdfContent = pdfWithRegions.select(&quot;pdf_regions&quot;).collect().head.getAs[Array[Byte]](0) # store to pdf to tmp file with open(&quot;test.pdf&quot;, &quot;wb&quot;) as file: file.write(pdfContent[0].pdf_regions) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) val positionFinder = new PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) val pdfDrawRegions = new PdfDrawRegions() .setInputRegionsCol(&quot;coordinates&quot;) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentenceDetector, tokenizer, entityExtractor, positionFinder, pdfDrawRegions )) val pdfWithRegions = pipeline.fit(df).transform(df) val pdfContent = pdfWithRegions.select(&quot;pdf_regions&quot;).collect().head.getAs[Array[Byte]](0) // store to pdf to tmp file val tmpFile = Files.createTempFile(&quot;with_regions_&quot;, s&quot;.pdf&quot;).toAbsolutePath.toString val fos = new FileOutputStream(tmpFile) fos.write(pdfContent) fos.close() println(tmpFile) Results: PdfToTextTable Extract tables from Pdf document page. Input is a column with binary representation of PDF document. As output generate column with tables and tables text chunks coordinates (rows/cols). Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Parameters Param name Type Default Description pageIndex integer -1 Page index to extract Tables. guess bool false A logical indicating whether to guess the locations of tables on each page. method string decide Identifying the prefered method of table extraction: basic, spreadsheet. Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text_table = PdfToTextTable() pdf_to_text_table.setInputCol(&quot;content&quot;) pdf_to_text_table.setOutputCol(&quot;table&quot;) pdf_to_text_table.setPageIndex(1) pdf_to_text_table.setMethod(&quot;basic&quot;) table = pdf_to_text_table.transform(df) # Show first row table.select(table[&quot;table.chunks&quot;].getItem(1)[&quot;chunkText&quot;]).show(1, False) import java.io.FileOutputStream import java.nio.file.Files import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToTextTable = new PdfToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;table&quot;) .pdf_to_text_table.setPageIndex(1) .pdf_to_text_table.setMethod(&quot;basic&quot;) table = pdfToTextTable.transform(df) // Show first row table.select(table[&quot;table.chunks&quot;].getItem(1)[&quot;chunkText&quot;]).show(1, False) Output: ++ |table.chunks AS chunks#760[1].chunkText | ++ |[Mazda RX4, 21.0, 6, , 160.0, 110, 3.90, 2.620, 16.46, 0, 1, 4, 4]| ++ DOCX processing Next section describes the transformers that deal with DOCX files with the purpose of extracting text and table data from it. DocToText DocToText extracts text from the DOCX document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the DOCX document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text extracted text pageNumCol string pagenum for compatibility with another transformers NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToText val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) val data = transformer.transform(df) data.select(&quot;pagenum&quot;, &quot;text&quot;).show() DocToTextTable DocToTextTable extracts table data from the DOCX documents. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PDF document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) data = transformer.transform(df) data.select(&quot;tables&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToTextTable val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) val data = transformer.transform(df) data.select(&quot;tables&quot;).show() DocToPdf DocToPdf convert DOCX document to PDF document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the DOCX document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text binary representation of the PDF document NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = DocToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) data = transformer.transform(df) data.select(&quot;pdf&quot;).show() import com.johnsnowlabs.ocr.transformers.DocToPdf val docPath = &quot;path to docx with text layout&quot; // Read DOCX file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new DocToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.select(&quot;pdf&quot;).show() PptToTextTable PptToTextTable extracts table data from the PPT and PPTX documents. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PPT document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol TableContainer tables Extracted tables NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to docx with text layout&quot; # Read PPT file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = PptToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) data = transformer.transform(df) data.select(&quot;tables&quot;).show() import com.johnsnowlabs.ocr.transformers.PptToTextTable val docPath = &quot;path to docx with text layout&quot; // Read PPT file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new PptToTextTable() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;tables&quot;) val data = transformer.transform(df) data.select(&quot;tables&quot;).show() PptToPdf PptToPdf convert PPT and PPTX documents to PDF document. Input Columns Param name Type Default Column Data Description inputCol string text binary representation of the PPT document originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string text binary representation of the PDF document NOTE: For setting parameters use setParamName method. Example PythonScala from sparkocr.transformers import * docPath = &quot;path to PPT with text layout&quot; # Read DOCX file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(docPath) transformer = PptToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) data = transformer.transform(df) data.select(&quot;pdf&quot;).show() import com.johnsnowlabs.ocr.transformers.PptToPdf val docPath = &quot;path to docx with text layout&quot; // Read PPT file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(docPath) val transformer = new PptToPdf() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.select(&quot;pdf&quot;).show() Dicom processing DicomToImage DicomToImage transforms dicom object (loaded as binary file) to image struct. Input Columns Param name Type Default Column Data Description inputCol string content binary dicom object originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) pageNumCol integer pagenum page (image) number begin from 0 metadataCol string metadata Output column name for dicom metatdata ( json formatted ) Scala example: PythonScala from sparkocr.transformers import * dicomPath = &quot;path to dicom files&quot; # Read dicom file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(dicomPath) dicomToImage = DicomToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setMetadataCol(&quot;meta&quot;) data = dicomToImage.transform(df) data.select(&quot;image&quot;, &quot;pagenum&quot;, &quot;meta&quot;).show() import com.johnsnowlabs.ocr.transformers.DicomToImage val dicomPath = &quot;path to dicom files&quot; // Read dicom file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(dicomPath) val dicomToImage = new DicomToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setMetadataCol(&quot;meta&quot;) val data = dicomToImage.transform(df) data.select(&quot;image&quot;, &quot;pagenum&quot;, &quot;meta&quot;).show() ImageToDicom ImageToDicom transforms image to Dicom document. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file metadataCol string metadata dicom metatdata ( json formatted ) Output Columns Param name Type Default Column Data Description outputCol string dicom binary dicom object Scala example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image file&quot; # Read image file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) image_df = binaryToImage.transform(df) imageToDicom = ImageToDicom() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;dicom&quot;) data = imageToDicom.transform(image_df) data.select(&quot;dicom&quot;).show() import com.johnsnowlabs.ocr.transformers.ImageToDicom val imagePath = &quot;path to image file&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToDicom = new ImageToDicom() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;dicom&quot;) val data = imageToDicom.transform(df) data.select(&quot;dicom&quot;).show() Image pre-processing Next section describes the transformers for image pre-processing: scaling, binarization, skew correction, etc. BinaryToImage BinaryToImage transforms image (loaded as binary file) to image struct. Input Columns Param name Type Default Column Data Description inputCol string content binary representation of the image originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string image extracted image struct (Image schema) Scala example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) binaryToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) data = binaryToImage.transform(df) data.select(&quot;image&quot;).show() import com.johnsnowlabs.ocr.transformers.BinaryToImage val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(imagePath) val binaryToImage = new BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) val data = binaryToImage.transform(df) data.select(&quot;image&quot;).show() GPUImageTransformer GPUImageTransformer allows to run image pre-processing operations on GPU. It supports the following operations: Scaling Otsu thresholding Huang thresholding Erosion Dilation GPUImageTransformer allows to add few operations. To add operations you need to call one of the methods with params: Method name Params Description addScalingTransform factor Scale image by scaling factor. addOtsuTransform   The automatic thresholder utilizes the Otsu threshold method. addHuangTransform   The automatic thresholder utilizes the Huang threshold method. addDilateTransform width, height Computes the local maximum of a pixels rectangular neighborhood. The rectangles size is specified by its half-width and half-height. addErodeTransform width, height Computes the local minimum of a pixels rectangular neighborhood. The rectangles size is specified by its half-width and half-height Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description imageType ImageType ImageType.TYPE_BYTE_BINARY Type of the output image gpuName string ”” GPU device name. Output Columns Param name Type Default Column Data Description outputCol string transformed_image image struct (Image schema) Example: PythonScala from sparkocr.transformers import * from sparkocr.enums import ImageType from sparkocr.utils import display_images imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) transformer = GPUImageTransformer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;transformed_image&quot;) .addHuangTransform() .addScalingTransform(3) .addDilateTransform(2, 2) .setImageType(ImageType.TYPE_BYTE_BINARY) pipeline = PipelineModel(stages=[ binary_to_image, transformer ]) result = pipeline.transform(df) display_images(result, &quot;transformed_image&quot;) import com.johnsnowlabs.ocr.transformers.GPUImageTransformer import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new GPUImageTransformer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;transformed_image&quot;) .addHuangTransform() .addScalingTransform(3) .addDilateTransform(2, 2) .setImageType(ImageType.TYPE_BYTE_BINARY) val data = transformer.transform(df) data.storeImage(&quot;transformed_image&quot;) ImageBinarizer ImageBinarizer transforms image to binary color schema, based on threshold. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description threshold int 170   Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) binirizer = ImageBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setThreshold(100) data = binirizer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageBinarizer import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val binirizer = new ImageBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setThreshold(100) val data = binirizer.transform(df) data.storeImage(&quot;binary_image&quot;) Original image: Binarized image with 100 threshold: ImageAdaptiveBinarizer Supported Methods: OTSU. Returns a single intensity threshold that separate pixels into two classes, foreground and background. Gaussian local thresholding. Thresholds the image using a locally adaptive threshold that is computed using a local square region centered on each pixel. The threshold is equal to the gaussian weighted sum of the surrounding pixels times the scale. Sauvola. Is a Local thresholding technique that are useful for images where the background is not uniform. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description width float 90 Width of square region. method TresholdingMethod TresholdingMethod.GAUSSIAN Method used to determine adaptive threshold. scale float 1.1f Scale factor used to adjust threshold. imageType ImageType ImageType.TYPE_BYTE_BINARY Type of the output image Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_image imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) adaptive_thresholding = ImageAdaptiveBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binarized_image&quot;) .setWidth(100) .setScale(1.1) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val binirizer = new ImageAdaptiveBinarizer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;binary_image&quot;) .setWidth(100) .setScale(1.1) val data = binirizer.transform(df) data.storeImage(&quot;binary_image&quot;) ImageAdaptiveThresholding Compute a threshold mask image based on local pixel neighborhood and apply it to image. Also known as adaptive or dynamic thresholding. The threshold value is the weighted mean for the local neighborhood of a pixel subtracted by a constant. Supported methods: GAUSSIAN MEAN MEDIAN WOLF SINGH Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description blockSize int 170 Odd size of pixel neighborhood which is used to calculate the threshold value (e.g. 3, 5, 7, …, 21, …). method AdaptiveThresholdingMethod AdaptiveThresholdingMethod.GAUSSIAN Method used to determine adaptive threshold for local neighbourhood in weighted mean image. offset int   Constant subtracted from weighted mean of neighborhood to calculate the local threshold value. Default offset is 0. mode string   The mode parameter determines how the array borders are handled, where cval is the value when mode is equal to ‘constant’ cval int   Value to fill past edges of input if mode is ‘constant’. Output Columns Param name Type Default Column Data Description outputCol string binarized_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_image imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) adaptive_thresholding = ImageAdaptiveThresholding() .setInputCol(&quot;scaled_image&quot;) .setOutputCol(&quot;binarized_image&quot;) .setBlockSize(21) .setOffset(73) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) // Implemented only for Python Original image: Binarized image: ImageScaler ImageScaler scales image by provided scale factor or needed output size. It supports keeping original ratio of image by padding the image in case fixed output size. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scaleFactor double 1.0 scale factor keepRatio boolean false Keep original ratio of image width int 0 Output width of image height int 0 Outpu height of imgae Output Columns Param name Type Default Column Data Description outputCol string scaled_image scaled image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) transformer = ImageScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setScaleFactor(0.5) data = transformer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setScaleFactor(0.5) val data = transformer.transform(df) data.storeImage(&quot;scaled_image&quot;) ImageAdaptiveScaler ImageAdaptiveScaler detects font size and scales image for have desired font size. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description desiredSize int 34 desired size of font in pixels Output Columns Param name Type Default Column Data Description outputCol string scaled_image scaled image struct (Image schema) Example: PythonScala from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) transformer = ImageAdaptiveScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setDesiredSize(34) data = transformer.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageAdaptiveScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageAdaptiveScaler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;scaled_image&quot;) .setDesiredSize(34) val data = transformer.transform(df) data.storeImage(&quot;scaled_image&quot;) ImageSkewCorrector ImageSkewCorrector detects skew of the image and rotates it. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description rotationAngle double 0.0 rotation angle automaticSkewCorrection boolean true enables/disables adaptive skew correction halfAngle double 5.0 half the angle(in degrees) that will be considered for correction resolution double 1.0 The step size(in degrees) that will be used for generating correction angle candidates Output Columns Param name Type Default Column Data Description outputCol string corrected_image corrected image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.utils import display_images imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) skew_corrector = ImageSkewCorrector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setAutomaticSkewCorrection(True) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, skew_corrector ]) data = pipeline.transform(df) display_images(data, &quot;corrected_image&quot;) import com.johnsnowlabs.ocr.transformers.ImageSkewCorrector import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageSkewCorrector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setAutomaticSkewCorrection(true) val data = transformer.transform(df) data.storeImage(&quot;corrected_image&quot;) Original image: Corrected image: ImageNoiseScorer ImageNoiseScorer computes noise score for each region. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string regions regions Parameters Param name Type Default Description method NoiseMethod string NoiseMethod.RATIO method of computation noise score Output Columns Param name Type Default Column Data Description outputCol string noisescores noise score for each region Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * from sparkocr.enums import NoiseMethod imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) # Define transformer for detect regions layoutAnalyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) # Define transformer for compute noise level for each region noisescorer = ImageNoiseScorer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;noiselevel&quot;) .setInputRegionsCol(&quot;regions&quot;) .setMethod(NoiseMethod.VARIANCE) # Define pipeline pipeline = Pipeline() pipeline.setStages(Array( layoutAnalyzer, noisescorer )) data = pipeline.transform(df) data.select(&quot;path&quot;, &quot;noiselevel&quot;).show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageNoiseScorer, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.NoiseMethod import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) // Define transformer for compute noise level for each region val noisescorer = new ImageNoiseScorer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;noiselevel&quot;) .setInputRegionsCol(&quot;regions&quot;) .setMethod(NoiseMethod.VARIANCE) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, noisescorer )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = modelPipeline.transform(df) data.select(&quot;path&quot;, &quot;noiselevel&quot;).show() Output: ++--+ |path |noiselevel | ++--+ |file:./noisy.png |[32.01805641767766, 32.312916551193354, 29.99257352247787, 30.62470388308217]| ++--+ ImageRemoveObjects python only ImageRemoveObjects to remove background objects. It supports removing: objects less than elements of font with minSizeFont size objects less than minSizeObject holes less than minSizeHole objects more than maxSizeObject Input Columns Param name Type Default Column Data Description inputCol string None image struct (Image schema) Parameters Param name Type Default Description minSizeFont int 10 Min size font in pt. minSizeObject int None Min size of object which will keep on image [*]. connectivityObject int 0 The connectivity defining the neighborhood of a pixel. minSizeHole int None Min size of hole which will keep on image[ *]. connectivityHole int 0 The connectivity defining the neighborhood of a pixel. maxSizeObject int None Max size of object which will keep on image [*]. connectivityMaxObject int 0 The connectivity defining the neighborhood of a pixel. [*] : None value disables removing objects. Output Columns Param name Type Default Column Data Description outputCol string None scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) remove_objects = ImageRemoveObjects() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setMinSizeObject(20) pipeline = PipelineModel(stages=[ binary_to_image, remove_objects ]) data = pipeline.transform(df) // Implemented only for Python ImageMorphologyOperation python only ImageMorphologyOperationis a transformer for applying morphological operations to image. It supports following operation: Erosion Dilation Opening Closing Input Columns Param name Type Default Column Data Description inputCol string None image struct (Image schema) Parameters Param name Type Default Description operation MorphologyOperationType MorphologyOperationType.OPENING Operation type kernelShape KernelShape KernelShape.DISK Kernel shape. kernelSize int 1 Kernel size in pixels. Output Columns Param name Type Default Column Data Description outputCol string None scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setOperation(MorphologyOperationType.OPENING) adaptive_thresholding = ImageAdaptiveThresholding() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;corrected_image&quot;) .setBlockSize(75) .setOffset(0) opening = ImageMorphologyOperation() .setInputCol(&quot;corrected_image&quot;) .setOutputCol(&quot;opening_image&quot;) .setkernelSize(1) pipeline = PipelineModel(stages=[ binary_to_image, adaptive_thresholding, opening ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;corrected_image&quot;).collect(): display_image(r.image) display_image(r.corrected_image) // Implemented only for Python Original image: Opening image: ImageCropper ImageCropperis a transformer for cropping image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description cropRectangle Rectangle Rectangle(0,0,0,0) Image rectangle. cropSquareType CropSquareType CropSquareType.TOP_LEFT Type of square. Output Columns Param name Type Default Column Data Description outputCol string cropped_image scaled image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) .setOperation(MorphologyOperationType.OPENING) cropper = ImageCropper() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cropped_image&quot;) .setCropRectangle((0, 0, 200, 110)) pipeline = PipelineModel(stages=[ binary_to_image, cropper ]) result = pipeline.transform(df) for r in result.select(&quot;image&quot;, &quot;cropped_image&quot;).collect(): display_image(r.image) display_image(r.cropped_image) import com.johnsnowlabs.ocr.transformers.ImageAdaptiveScaler import com.johnsnowlabs.ocr.OcrContext.implicits._ import java.awt.Rectangle val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val rectangle: Rectangle = new Rectangle(0, 0, 200, 110) val cropper: ImageCropper = new ImageCropper() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cropped_image&quot;) .setCropRectangle(rectangle) val data = transformer.transform(df) data.storeImage(&quot;cropped_image&quot;) Splitting image to regions ImageLayoutAnalyzer ImageLayoutAnalyzer analyzes the image and determines regions of text. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode Output Columns Param name Type Default Column Data Description outputCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val data = layoutAnalyzer.transform(df) data.show() ImageSplitRegions ImageSplitRegions splits image into regions. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Parameters Param name Type Default Description explodeCols Array[string]   Columns which need to explode rotated boolean False Support rotated regions Output Columns Param name Type Default Column Data Description outputCol string region_image image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) splitter = ImageSplitRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;region_image&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer, splitter ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val splitter = new ImageSplitRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;region_image&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, splitter )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = pipeline.transform(df) data.show() ImageDrawAnnotations ImageDrawAnnotations draw annotations with label and score to the image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputChunksCol string region array of Annotation Parameters Param name Type Default Description lineWidth Int 4 Line width for draw rectangles fontSize Int 12 Font size for render labels and score rectColor Color Color.black Color of lines Output Columns Param name Type Default Column Data Description outputCol string image_with_chunks image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) draw_annotations = ImageDrawAnnotations() .setInputCol(&quot;image&quot;) .setInputChunksCol(&quot;token&quot;) .setOutputCol(&quot;image_with_annotations&quot;) .setFilledRect(False) .setFontSize(40) .setRectColor(Color.red) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, tokenizer, image_with_annotations ]) result = pipeline.transform(df) import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val draw_annotations = new ImageDrawAnnotations() .setInputCol(&quot;image&quot;) .setInputChunksCol(&quot;token&quot;) .setOutputCol(&quot;image_with_annotations&quot;) .setFilledRect(False) .setFontSize(40) .setRectColor(Color.red) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, tokenizer, draw_annotations )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) ImageDrawRegions ImageDrawRegions draw regions with label and score to the image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) inputRegionsCol string region array of [Coordinaties]ocr_structures#coordinate-schema) Parameters Param name Type Default Description lineWidth Int 4 Line width for draw rectangles fontSize Int 12 Font size for render labels and score rotated boolean False Support rotated regions Output Columns Param name Type Default Column Data Description outputCol string image_with_regions image struct (Image schema) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect regions layout_analyzer = ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) draw = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, layout_analyzer, draw ]) data = pipeline.transform(df) data.show() import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.{ImageSplitRegions, ImageLayoutAnalyzer} import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect regions val layoutAnalyzer = new ImageLayoutAnalyzer() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;regions&quot;) val draw = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setRegionCol(&quot;regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( layoutAnalyzer, draw )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val data = pipeline.transform(df) data.show() Characters recognition Next section describes the estimators for OCR ImageToText ImageToText runs OCR for input image, return recognized text to outputCol and positions with font size to ‘positionsCol’ column. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language Language Language.ENG language confidenceThreshold int 0 Confidence threshold. ignoreResolution bool false Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. pdfCoordinates bool false Transform coordinates in positions to PDF points. modelData string   Path to the local model data. modelType ModelType ModelType.BASE Model type downloadModelData bool false Download model data from JSL S3 withSpaces bool false Include spaces to output positions. keepLayout bool false Keep layout of text at result. outputSpaceCharacterWidth int 8 Output space character width in pts for layout keeper. Output Columns Param name Type Default Column Data Description outputCol string text Recognized text positionsCol string positions Positions of each block of text (related to pageIteratorLevel) in PageMatrix Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setOcrParams([&quot;preserve_interword_spaces=1&quot;, ]) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToText import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setOcrParams(Array(&quot;preserve_interword_spaces=1&quot;)) val data = transformer.transform(df) print(data.select(&quot;text&quot;).collect()[0].text) Image: Output: FOREWORD Electronic design engineers are the true idea men of the electronic industries. They create ideas and use them in their designs, they stimu- late ideas in other designers, and they borrow and adapt ideas from others. One could almost say they feed on and grow on ideas. ImageToTextV2 ImageToTextV2 is based on the transformers architecture, and combines CV and NLP in one model. It is a visual encoder-decoder model. The Encoder is based on ViT, and the decoder on RoBERTa model. ImageToTextV2 can work on CPU, but GPU is preferred in order to achieve acceptable performance. ImageToTextV2 can receive regions representing single line texts, or regions coming from a text detection model. Input Columns Param name Type Default Column Data Description inputCols Array[string] [image] Can use as input image struct (Image schema) and regions. Parameters Param name Type Default Description lineTolerance integer 15 Line tolerance in pixels. It’s used for grouping text regions by lines. borderWidth integer 5 A value of more than 0 enables to border text regions with width equal to the value of the parameter. spaceWidth integer 10 A value of more than 0 enables to add white spaces between words on the image. Output Columns Param name Type Default Column Data Description outputCol string text Recognized text Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) text_detector = ImageTextDetectorV2 .pretrained(&quot;image_text_detector_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text_regions&quot;) .setWithRefiner(True) .setSizeThreshold(20) ocr = ImageToTextV2.pretrained(&quot;ocr_base_printed&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;image&quot;, &quot;text_regions&quot;]) .setOutputCol(&quot;text&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, text_detector, ocr ]) data = pipeline.transform(df) data.show() not implemented Image: Output: STARBUCKS STORE #10208 11302 EUCLID AVENUE CLEVELAND, OH (216) 229-0749 CHK 664290 12/07/2014 06:43 PM 1912003 DRAWER: 2. REG: 2 VT PEP MOCHA 4.95 SBUX CARD 4.95 XXXXXXXXXXXX3228 SUBTOTAL $4.95 TOTAL $4.95 CHANGE DUE $0.00 - CHECK CLOSED 12/07/2014 06:43 PM SBUX CARD X3228 NEW BALANCE: 37.45 CARD IS REGISTERED ImageToTextPdf ImageToTextPdf runs OCR for input image, render recognized text to the PDF as an invisible text layout with an original image. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) originCol string path path to the original file pageNumCol string pagenum for compatibility with another transformers Parameters Param name Type Default Description ocrParams array of strings [] Array of Ocr params in key=value format. Output Columns Param name Type Default Column Data Description outputCol string pdf Recognized text rendered to PDF PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToTextPdf() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;pdf&quot;) val data = transformer.transform(df) data.show() ImageToHocr ImageToHocr runs OCR for input image, return recognized text and bounding boxes to outputCol column in HOCR format. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language string eng language ignoreResolution bool true Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. Output Columns Param name Type Default Column Data Description outputCol string hocr Recognized text Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToHocr import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val data = transformer.transform(df) print(data.select(&quot;hocr&quot;).collect()[0].hocr) Image: Output: &lt;div class=&#39;ocr_page&#39; id=&#39;page_1&#39; title=&#39;image &quot;&quot;; bbox 0 0 1280 467; ppageno 0&#39;&gt; &lt;div class=&#39;ocr_carea&#39; id=&#39;block_1_1&#39; title=&quot;bbox 516 80 780 114&quot;&gt; &lt;p class=&#39;ocr_par&#39; id=&#39;par_1_1&#39; lang=&#39;eng&#39; title=&quot;bbox 516 80 780 114&quot;&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_1&#39; title=&quot;bbox 516 80 780 114; baseline 0 -1; x_size 44; x_descenders 11; x_ascenders 11&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_1&#39; title=&#39;bbox 516 80 780 114; x_wconf 96&#39;&gt;FOREWORD&lt;/span&gt; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;div class=&#39;ocr_carea&#39; id=&#39;block_1_2&#39; title=&quot;bbox 40 237 1249 425&quot;&gt; &lt;p class=&#39;ocr_par&#39; id=&#39;par_1_2&#39; lang=&#39;eng&#39; title=&quot;bbox 40 237 1249 425&quot;&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_2&#39; title=&quot;bbox 122 237 1249 282; baseline 0.001 -12; x_size 45; x_descenders 12; x_ascenders 13&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_2&#39; title=&#39;bbox 122 237 296 270; x_wconf 96&#39;&gt;Electronic&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_3&#39; title=&#39;bbox 308 237 416 281; x_wconf 96&#39;&gt;design&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_4&#39; title=&#39;bbox 428 243 588 282; x_wconf 96&#39;&gt;engineers&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_5&#39; title=&#39;bbox 600 250 653 271; x_wconf 96&#39;&gt;are&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_6&#39; title=&#39;bbox 665 238 718 271; x_wconf 96&#39;&gt;the&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_7&#39; title=&#39;bbox 731 246 798 272; x_wconf 97&#39;&gt;true&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_8&#39; title=&#39;bbox 810 238 880 271; x_wconf 96&#39;&gt;idea&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_9&#39; title=&#39;bbox 892 251 963 271; x_wconf 96&#39;&gt;men&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_10&#39; title=&#39;bbox 977 238 1010 272; x_wconf 96&#39;&gt;of&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_11&#39; title=&#39;bbox 1021 238 1074 271; x_wconf 96&#39;&gt;the&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_12&#39; title=&#39;bbox 1086 239 1249 272; x_wconf 96&#39;&gt;electronic&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_3&#39; title=&quot;bbox 41 284 1248 330; baseline 0.002 -13; x_size 44; x_descenders 11; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_13&#39; title=&#39;bbox 41 284 214 318; x_wconf 96&#39;&gt;industries.&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_14&#39; title=&#39;bbox 227 284 313 328; x_wconf 96&#39;&gt;They&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_15&#39; title=&#39;bbox 324 292 427 319; x_wconf 96&#39;&gt;create&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_16&#39; title=&#39;bbox 440 285 525 319; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_17&#39; title=&#39;bbox 537 286 599 318; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_18&#39; title=&#39;bbox 611 298 668 319; x_wconf 96&#39;&gt;use&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_19&#39; title=&#39;bbox 680 286 764 319; x_wconf 96&#39;&gt;them&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_20&#39; title=&#39;bbox 777 291 808 319; x_wconf 96&#39;&gt;in&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_21&#39; title=&#39;bbox 821 286 900 319; x_wconf 96&#39;&gt;their&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_22&#39; title=&#39;bbox 912 286 1044 330; x_wconf 96&#39;&gt;designs,&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_23&#39; title=&#39;bbox 1058 286 1132 330; x_wconf 93&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_24&#39; title=&#39;bbox 1144 291 1248 320; x_wconf 92&#39;&gt;stimu-&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_4&#39; title=&quot;bbox 42 332 1247 378; baseline 0.002 -14; x_size 44; x_descenders 12; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_25&#39; title=&#39;bbox 42 332 103 364; x_wconf 97&#39;&gt;late&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_26&#39; title=&#39;bbox 120 332 204 365; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_27&#39; title=&#39;bbox 223 337 252 365; x_wconf 96&#39;&gt;in&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_28&#39; title=&#39;bbox 271 333 359 365; x_wconf 96&#39;&gt;other&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_29&#39; title=&#39;bbox 376 333 542 377; x_wconf 96&#39;&gt;designers,&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_30&#39; title=&#39;bbox 561 334 625 366; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_31&#39; title=&#39;bbox 643 334 716 377; x_wconf 96&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_32&#39; title=&#39;bbox 734 334 855 366; x_wconf 96&#39;&gt;borrow&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_33&#39; title=&#39;bbox 873 334 934 366; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_34&#39; title=&#39;bbox 954 335 1048 378; x_wconf 96&#39;&gt;adapt&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_35&#39; title=&#39;bbox 1067 334 1151 367; x_wconf 96&#39;&gt;ideas&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_36&#39; title=&#39;bbox 1169 334 1247 367; x_wconf 96&#39;&gt;from&lt;/span&gt; &lt;/span&gt; &lt;span class=&#39;ocr_line&#39; id=&#39;line_1_5&#39; title=&quot;bbox 40 379 1107 425; baseline 0.002 -13; x_size 45; x_descenders 12; x_ascenders 12&quot;&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_37&#39; title=&#39;bbox 40 380 151 412; x_wconf 96&#39;&gt;others.&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_38&#39; title=&#39;bbox 168 383 238 412; x_wconf 96&#39;&gt;One&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_39&#39; title=&#39;bbox 252 379 345 412; x_wconf 96&#39;&gt;could&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_40&#39; title=&#39;bbox 359 380 469 413; x_wconf 96&#39;&gt;almost&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_41&#39; title=&#39;bbox 483 392 537 423; x_wconf 96&#39;&gt;say&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_42&#39; title=&#39;bbox 552 381 626 424; x_wconf 96&#39;&gt;they&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_43&#39; title=&#39;bbox 641 381 712 414; x_wconf 96&#39;&gt;feed&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_44&#39; title=&#39;bbox 727 393 767 414; x_wconf 96&#39;&gt;on&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_45&#39; title=&#39;bbox 783 381 845 414; x_wconf 96&#39;&gt;and&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_46&#39; title=&#39;bbox 860 392 945 425; x_wconf 97&#39;&gt;grow&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_47&#39; title=&#39;bbox 959 393 999 414; x_wconf 96&#39;&gt;on&lt;/span&gt; &lt;span class=&#39;ocrx_word&#39; id=&#39;word_1_48&#39; title=&#39;bbox 1014 381 1107 414; x_wconf 95&#39;&gt;ideas.&lt;/span&gt; &lt;/span&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; ImageBrandsToText ImageBrandsToText runs OCR for specified brands of input image, return recognized text to outputCol and positions with font size to ‘positionsCol’ column. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description pageSegMode PageSegmentationMode AUTO page segmentation mode pageIteratorLevel PageIteratorLevel BLOCK page iteration level ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language string eng language confidenceThreshold int 0 Confidence threshold. ignoreResolution bool true Ignore resolution from metadata of image. ocrParams array of strings [] Array of Ocr params in key=value format. brandsCoords string   Json with coordinates of brands. Output Columns Param name Type Default Column Data Description outputCol structure image_brands Structure with recognized text from brands. textCol string text Recognized text positionsCol string positions Positions of each block of text (related to pageIteratorLevel) Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageBrandsToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setBrandsCoords(&quot;&quot;&quot;[ { &quot;name&quot;:&quot;part_one&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:286, &quot;y&quot;:65, &quot;width&quot;:542, &quot;height&quot;:342 } }, { &quot;name&quot;:&quot;part_two&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:828, &quot;y&quot;:65, &quot;width&quot;:1126, &quot;height&quot;:329 } } ]&quot;&quot;&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr ]) data = pipeline.transform(df) data.show() import com.johnsnowlabs.ocr.transformers.ImageToText import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val transformer = new ImageBrandsToText() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;text&quot;) .setBrandsCoordsStr( &quot;&quot;&quot; [ { &quot;name&quot;:&quot;part_one&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:286, &quot;y&quot;:65, &quot;width&quot;:542, &quot;height&quot;:342 } }, { &quot;name&quot;:&quot;part_two&quot;, &quot;rectangle&quot;:{ &quot;x&quot;:828, &quot;y&quot;:65, &quot;width&quot;:1126, &quot;height&quot;:329 } } ] &quot;&quot;&quot;.stripMargin) val data = transformer.transform(df) print(data.select(&quot;text&quot;).collect()[0].text) Other Next section describes the extra transformers PositionFinder PositionFinder find the position of input text entities in the original document. Input Columns Param name Type Default Column Data Description inputCols string image Input annotations columns pageMatrixCol string   Column name for Page Matrix schema Parameters Param name Type Default Description matchingWindow int 10 Textual range to match in context, applies in both direction windowPageTolerance boolean true whether or not to increase tolerance as page number grows padding int 5 padding for area Output Columns Param name Type Default Column Data Description outputCol string   Name of output column for store coordinates. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) entity_extractor = TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;./sparkocr/resources/test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) position_finder = PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) pipeline = Pipeline(stages=[ pdf_to_text, document_assembler, sentence_detector, tokenizer, entity_extractor, position_finder ]) results = pipeline.fit(df).transform(df) results.show() import com.johnsnowlabs.ocr.transformers._ import com.johnsnowlabs.nlp.{DocumentAssembler, SparkAccessor} import com.johnsnowlabs.nlp.annotators._ import com.johnsnowlabs.nlp.util.io.ReadAs val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val entityExtractor = new TextMatcher() .setInputCols(&quot;sentence&quot;, &quot;token&quot;) .setEntities(&quot;test-chunks.txt&quot;, ReadAs.TEXT) .setOutputCol(&quot;entity&quot;) val positionFinder = new PositionFinder() .setInputCols(&quot;entity&quot;) .setOutputCol(&quot;coordinates&quot;) .setPageMatrixCol(&quot;positions&quot;) .setMatchingWindow(10) .setPadding(2) // Create pipeline val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentenceDetector, tokenizer, entityExtractor, positionFinder )) val results = pipeline.fit(df).transform(df) results.show() UpdateTextPosition UpdateTextPosition update output text and keep old coordinates of original document. Input Columns Param name Type Default Column Data Description inputCol string positions Сolumn name with original positions struct InputText string replace_text Column name for New Text to replace Old one Output Columns Param name Type Default Column Data Description outputCol string output_positions Name of output column for updated positions struct. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparknlp.annotator import * from sparknlp.base import * pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setPageNumCol(&quot;page&quot;) .setSplitPage(False) document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;tokens&quot;) spell = NorvigSweetingModel().pretrained(&quot;spellcheck_norvig&quot;, &quot;en&quot;) .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;spell&quot;) tokenAssem = TokenAssembler() .setInputCols(&quot;spell&quot;) .setOutputCol(&quot;newDocs&quot;) updatedText = UpdateTextPosition() .setInputCol(&quot;positions&quot;) .setOutputCol(&quot;output_positions&quot;) .setInputText(&quot;newDocs.result&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, spell, tokenAssem, updatedText ]) results = pipeline.fit(df).transform(df) results.show() import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector import com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingModel import com.johnsnowlabs.nlp.{DocumentAssembler, TokenAssembler} import com.johnsnowlabs.ocr.transformers._ import org.apache.spark.ml.Pipeline val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val token = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;tokens&quot;) val spell = NorvigSweetingModel.pretrained(&quot;spellcheck_norvig&quot;, &quot;en&quot;) .setInputCols(&quot;tokens&quot;) .setOutputCol(&quot;spell&quot;) val tokenAssem = new TokenAssembler() .setInputCols(&quot;spell&quot;) .setOutputCol(&quot;newDocs&quot;) val updatedText = new UpdateTextPosition() .setInputCol(&quot;positions&quot;) .setOutputCol(&quot;output_positions&quot;) .setInputText(&quot;newDocs.result&quot;) val pipeline = new Pipeline() .setStages(Array( pdfToText, documentAssembler, sentence, token, spell, tokenAssem, updatedText )) val results = pipeline.fit(df).transform(df) results.show() FoundationOneReportParser FoundationOneReportParser is a transformer for parsing FoundationOne reports. Current implementation supports parsing patient info, genomic, biomarker findings and gene lists from appendix. Output format is json. Input Columns Param name Type Default Column Data Description inputCol string text Сolumn name with text of report originCol string path path to the original file Output Columns Param name Type Default Column Data Description outputCol string report Name of output column with report in json format. Example: PythonScala from pyspark.ml import Pipeline from sparkocr.transformers import * from sparkocr.enums import TextStripperType pdfPath = &quot;path to pdf&quot; # Read PDF file as binary file df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) pdf_to_text = PdfToText() pdf_to_text.setInputCol(&quot;content&quot;) pdf_to_text.setOutputCol(&quot;text&quot;) pdf_to_text.setSplitPage(False) pdf_to_text.setTextStripper(TextStripperType.PDF_LAYOUT_TEXT_STRIPPER) genomic_parser = FoundationOneReportParser() genomic_parser.setInputCol(&quot;text&quot;) genomic_parser.setOutputCol(&quot;report&quot;) report = genomic_parser.transform(pdf_to_text.transform(df)).collect() import com.johnsnowlabs.ocr.transformers._ import org.apache.spark.ml.Pipeline val pdfPath = &quot;path to pdf&quot; // Read PDF file as binary file val df = spark.read.format(&quot;binaryFile&quot;).load(pdfPath) val pdfToText = new PdfToText() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;text&quot;) .setSplitPage(false) .setTextStripper(TextStripperType.PDF_LAYOUT_TEXT_STRIPPER) val genomicsParser = new FoundationOneReportParser() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;report&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( pdfToText, genomicsParser )) val modelPipeline = pipeline.fit(df) val report = modelPipeline.transform(df) Output: { &quot;Patient&quot; : { &quot;disease&quot; : &quot;Unknown primary melanoma&quot;, &quot;name&quot; : &quot;Lekavich Gloria&quot;, &quot;date_of_birth&quot; : &quot;11 November 1926&quot;, &quot;sex&quot; : &quot;Female&quot;, &quot;medical_record&quot; : &quot;11111&quot; }, &quot;Physician&quot; : { &quot;ordering_physician&quot; : &quot;Genes Pinley&quot;, &quot;medical_facility&quot; : &quot;Health Network Cancer Institute&quot;, &quot;additional_recipient&quot; : &quot;Nath&quot;, &quot;medical_facility_id&quot; : &quot;202051&quot;, &quot;pathologist&quot; : &quot;Manqju Nwath&quot; }, &quot;Specimen&quot; : { &quot;specimen_site&quot; : &quot;Rectum&quot;, &quot;specimen_id&quot; : &quot;AVS 1A&quot;, &quot;specimen_type&quot; : &quot;Slide&quot;, &quot;date_of_collection&quot; : &quot;20 March 2015&quot;, &quot;specimen_received&quot; : &quot;30 March 2015 &quot; }, &quot;Biomarker_findings&quot; : [ { &quot;name&quot; : &quot;Tumor Mutation Burden&quot;, &quot;state&quot; : &quot;TMB-Low (3Muts/Mb)&quot;, &quot;actionability&quot; : &quot;No therapies or clinical trials. &quot; } ], &quot;Genomic_findings&quot; : [ { &quot;name&quot; : &quot;FLT3&quot;, &quot;state&quot; : &quot;amplification&quot;, &quot;therapies_with_clinical_benefit_in_patient_tumor_type&quot; : [ &quot;none&quot; ], &quot;therapies_with_clinical_benefit_in_other_tumor_type&quot; : [ &quot;Sorafenib&quot;, &quot;Sunitinib&quot;, &quot;Ponatinib&quot; ] } ], &quot;Appendix&quot; : { &quot;dna_gene_list&quot; : [ &quot;ABL1&quot;, &quot;ACVR1B&quot;, &quot;AKT1&quot;, .... ], &quot;dna_gene_list_rearrangement&quot; : [ &quot;ALK&quot;, &quot;BCL2&quot;, &quot;BCR&quot;, .... ], &quot;additional_assays&quot; : [ &quot;Tumor Mutation Burden (TMB)&quot;, &quot;Microsatellite Status (MS)&quot; ] } } HocrDocumentAssembler HocrDocumentAssembler prepares data into a format that is processable by Spark NLP. Output Annotator Type: DOCUMENT Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Output Columns Param name Type Default Column Data Description outputCol string document Name of output column. Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) hocr_document_assembler = HocrDocumentAssembler() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;document&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, hocr_document_assembler ]) result = pipeline.transform(df) result.select(&quot;document&quot;).show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val hocrDocumentAssembler = HocrDocumentAssembler() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;document&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, hocrDocumentAssembler )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;document&quot;).show() Output: +--+ | document | +--+ | [[document, 0, 4392, Patient Nam Financial Numbe Random Hospital...| +--+ HocrTokenizer HocrTokenizer prepares into a format that is processable by Spark NLP. HocrTokenizer puts to metadata coordinates and ocr confidence. Output Annotator Type: TOKEN Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document. Output Columns Param name Type Default Column Data Description outputCol string token Name of output column. Example: PythonScala from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, tokenizer ]) result = pipeline.transform(df) result.select(&quot;token&quot;).show() import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, tokenizer )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;token&quot;).show() Output: +--+ | token | +--+ | [[token, 0, 6, patient, [x -&gt; 2905, y -&gt; 527, height -&gt; 56, | | confidence -&gt; 95, word -&gt; Patient, width -&gt; 230], []], [token, 8, | |10, nam, [x -&gt; 3166, y -&gt; 526, height -&gt; 55, confidence -&gt; 95, word | |-&gt; Nam, width -&gt; 158], []] ... | +--+",
    "url": "/docs/en/ocr_pipeline_components",
    "relUrl": "/docs/en/ocr_pipeline_components"
  },
  "1295": {
    "id": "1295",
    "title": "Spark OCR release notes",
    "content": "4.3.3 Release date: 14-03-2023 We’re glad to announce that Visual NLP 😎 4.3.3 has been released. Highlights New parameter keepOriginalEncoding in PdfToHocr. New Yolo-based table and form detector. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved. Fixes in AlabReader Fixes in HocrToTextTable. New parameter keepOriginalEncoding in PdfToHocr Now you can choose to make PdfToHocr return an ASCII normalized version of the characters present in the PDF(keepOriginalEncoding=False) or to return the original Unicode character(keepOriginalEncoding=True). Source PDF, Keeping the encoding, Not keeping it, New Yolo-based Table and Form detector This new model allows to distinguish between forms and tables, so you can apply different downstream processing afterwards. Check a full example of utilization in this notebook. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved Memory utilization has been improved to make it more GC friendly. The practical result is that big jobs are more stable, and less likely to get restarted because of exhausting resources. Fixes in AlabReader AlabReader has been improved to fix some bugs, and to improve the performance. Fixes in HocrToTextTable HocrToTextTable has been improved in order to better handle some corner cases in which the last rows of tables were being missed. This release of Visual NLP is compatible with version 4.3.1 of Spark-NLP and version 4.3.1 of Spark NLP for Healthcare. Previous versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/ocr_release_notes",
    "relUrl": "/docs/en/spark_ocr_versions/ocr_release_notes"
  },
  "1296": {
    "id": "1296",
    "title": "Structures and helpers",
    "content": "Schemas Image Schema Images are loaded as a DataFrame with a single column called “image.” It is a struct-type column, that contains all information about image: image: struct (nullable = true) | |-- origin: string (nullable = true) | |-- height: integer (nullable = false) | |-- width: integer (nullable = false) | |-- nChannels: integer (nullable = false) | |-- mode: integer (nullable = false) | |-- resolution: integer (nullable = true) | |-- data: binary (nullable = true) Fields Field name Type Description origin string source URI height integer image height in pixels width integer image width in pixels nChannels integer number of color channels mode ImageType the data type and channel order the data is stored in resolution integer resolution of image in dpi data binary image data in a binary format NOTE: Image data stored in a binary format. Image data is represented as a 3-dimensional array with the dimension shape (height, width, nChannels) and array values of type t specified by the mode field. Coordinate Schema element: struct (containsNull = true) | | |-- index: integer (nullable = false) | | |-- page: integer (nullable = false) | | |-- x: float (nullable = false) | | |-- y: float (nullable = false) | | |-- width: float (nullable = false) | | |-- height: float (nullable = false) Field name Type Description index integer Chunk index page integer Page number x float The lower left x coordinate y float The lower left y coordinate width float The width of the rectangle height float The height of the rectangle score float The score of the object label string The label of the object PageMatrix Schema element: struct (containsNull = true) | | |-- mappings: array[struct] (nullable = false) Field name Type Description mappings Array[Mapping] Array of mappings Mapping Schema element: struct (containsNull = true) | | |-- c: string (nullable = false) | | |-- p: integer (nullable = false) | | |-- x: float (nullable = false) | | |-- y: float (nullable = false) | | |-- width: float (nullable = false) | | |-- height: float (nullable = false) | | |-- fontSize: integer (nullable = false) Field name Type Description c string Character p integer Page number x float The lower left x coordinate y float The lower left y coordinate width float The width of the rectangle height float The height of the rectangle fontSize integer Font size in points Enums PageSegmentationMode OSD_ONLY: Orientation and script detection only. AUTO_OSD: Automatic page segmentation with orientation and script detection. AUTO_ONLY: Automatic page segmentation, but no OSD, or OCR. AUTO: Fully automatic page segmentation, but no OSD. SINGLE_COLUMN: Assume a single column of text of variable sizes. SINGLE_BLOCK_VERT_TEXT: Assume a single uniform block of vertically aligned text. SINGLE_BLOCK: Assume a single uniform block of text. SINGLE_LINE: Treat the image as a single text line. SINGLE_WORD: Treat the image as a single word. CIRCLE_WORD: Treat the image as a single word in a circle. SINGLE_CHAR: Treat the image as a single character. SPARSE_TEXT: Find as much text as possible in no particular order. SPARSE_TEXT_OSD: Sparse text with orientation and script detection. EngineMode TESSERACT_ONLY: Legacy engine only. OEM_LSTM_ONLY: Neural nets LSTM engine only. TESSERACT_LSTM_COMBINED: Legacy + LSTM engines. DEFAULT: Default, based on what is available. PageIteratorLevel BLOCK: Block of text/image/separator line. PARAGRAPH: Paragraph within a block. TEXTLINE: Line within a paragraph. WORD: Word within a text line. SYMBOL: Symbol/character within a word. Language ENG: English FRA: French SPA: Spanish RUS: Russian DEU: German VIE: Vietnamese ARA: Arabic ModelType BASE: Block of text/image/separator line. BEST: Paragraph within a block. FAST: Line within a paragraph. ImageType TYPE_BYTE_GRAY TYPE_BYTE_BINARY TYPE_3BYTE_BGR TYPE_4BYTE_ABGR NoiseMethod VARIANCE RATIO KernelShape SQUARE DIAMOND DISK OCTAHEDRON OCTAGON STAR MorphologyOperationType OPENING CLOSING EROSION DILATION CropSquareType TOP_LEFT TOP_CENTER TOP_RIGHT CENTER_LEFT CENTER CENTER_RIGHT BOTTOM_LEFT BOTTOM_CENTER BOTTOM_RIGHT SplittingStrategy FIXED_NUMBER_OF_PARTITIONS FIXED_SIZE_OF_PARTITION AdaptiveThresholdingMethod GAUSSIAN MEAN MEDIAN WOLF SINGH TresholdingMethod GAUSSIAN OTSU SAUVOLA WOLF CellDetectionAlgos CONTOURS - Detect cells in bordered tables MORPHOPS - Detected calls in: bordered, borderless and combined tables TableOutputFormat TABLE - Table struct format CSV - Comma separated CSV OCR implicits asImage asImage transforms binary content to Image schema. Parameters Param name Type Default Description outputCol string image output column name contentCol string content input column name with binary content pathCol string path input column name with path to original file Example: import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) df.show() storeImage storeImage stores the image(s) to tmp location and return Dataset with path(s) to stored image files. Parameters Param name Type Default Description inputColumn string   input column name with image struct formatName string png image format name prefix string sparknlp_ocr_ prefix for output file Example: import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) df.storeImage(&quot;image&quot;) showImages Show images on Databrics notebook. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “800” width of image show_meta boolean true enable/disable displaying metadata of image Jupyter Python helpers display_image Show single image with metadata in Jupyter notebook. Parameters Param name Type Default Description width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_image from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_image(BinaryToImage().transform(images_example_df).collect()[0].image) display_images Show images from dataframe. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_images from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_images(BinaryToImage().transform(images_example_df), limit=3) display_images_horizontal Show one or more images per row from dataframe. Parameters Param name Type Default Description fields string image comma separated input column names with image struct limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_images_horizontal display_images_horizontal(df_with_few_image_fields, fields=&quot;images, image_with_regions&quot;, limit=10) display_pdf Show pdf from dataframe. Parameters Param name Type Default Description field string content input column with binary representation of pdf limit integer 5 count of rows for display width string “600” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.utils import display_pdf pdf_df = spark.read.format(&quot;binaryFile&quot;).load(pdf_path) display_pdf(pdf_df) display_pdf_file Show pdf file using embedded pdf viewer. Parameters Param name Type Default Description pdf string   Path to the file name size integer size=(600, 500) count of rows for display Example: from sparkocr.utils import display_pdf_file display_pdf_file(&quot;path to the pdf file&quot;) Example output: display_table Display table from the dataframe. display_tables Display tables from the dataframe. It is useful for display results of table recognition from the multipage documents/few tables per page. Example output: Databricks Python helpers display_images Show images from dataframe. Parameters Param name Type Default Description field string image input column name with image struct limit integer 5 count of rows for display width string “800” width of image show_meta boolean true enable/disable displaying metadata of image Example: from sparkocr.databricks import display_images from sparkocr.transformers import BinaryToImage images_path = &quot;/tmp/ocr/images/*.tif&quot; images_example_df = spark.read.format(&quot;binaryFile&quot;).load(images_path).cache() display_images(BinaryToImage().transform(images_example_df), limit=3)",
    "url": "/docs/en/ocr_structures",
    "relUrl": "/docs/en/ocr_structures"
  },
  "1297": {
    "id": "1297",
    "title": "Table recognition",
    "content": "ImageTableDetector ImageTableDetector is a DL model for detecting tables on the image. It’s based on CascadeTabNet which used Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet). Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description scoreThreshold float 0.9 Score threshold for output regions. applyCorrection boolean false Enable correction of results. Output Columns Param name Type Default Column Data Description outputCol string table_regions array of [Coordinaties]ocr_structures#coordinate-schema) Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect tables val table_detector = ImageTableDetector .pretrained(&quot;general_model_table_detection_v2&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;table_regions&quot;) val draw_regions = new ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;table_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, table_detector, draw_regions ]) val data = pipeline.transform(df) data.storeImage(&quot;image_with_regions&quot;) from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect tables table_detector = ImageTableDetector .pretrained(&quot;general_model_table_detection_v2&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCol(&quot;image&quot;) .setOutputCol(&quot;table_regions&quot;) draw_regions = ImageDrawRegions() .setInputCol(&quot;image&quot;) .setInputRegionsCol(&quot;table_regions&quot;) .setOutputCol(&quot;image_with_regions&quot;) pipeline = PipelineModel(stages=[ binary_to_image, table_detector, draw_regions ]) data = pipeline.transform(df) display_images(data, &quot;image_with_regions&quot;) Output: ImageTableCellDetector ImageTableCellDetector detect cells in a table image. It’s based on an image processing algorithm that detects horizontal and vertical lines. Current implementation support few algorithm for extract cells: CellDetectionAlgos.CONTOURS works only for bordered tables. CellDetectionAlgos.MORPHOPS works for bordered, borderless and combined tables. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) Parameters Param name Type Default Description algoType CellDetectionAlgos CellDetectionAlgos.CONTOURS Algorithm for detect cells. algoParams string row_treshold=0.05,row_treshold_wide=1.0, row_min_wide=5,column_treshold=0.05, column_treshold_wide=5,column_min_wide=5 Parameters of ‘MORPHOPS’ cells detection algorithm drawDetectedLines boolean false Enable to draw detected lines to the output image keepOriginalLines boolean false Keep original images on the output image Output Columns Param name Type Default Column Data Description outputCol string cells array of coordinates of cells outputImageCol string output_image output image Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect cells val transformer = new ImageTableCellDetector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) val data = transformer.transform(df) data.select(&quot;cells&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) # Define transformer for detect cells transformer = ImageTableCellDetector .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) .setAlgoParams(&quot;row_treshold=0.05&quot;) pipeline = PipelineModel(stages=[ binary_to_image, transformer ]) data = pipeline.transform(df) data.select(&quot;cells&quot;).show() Image: Output:* +-+ | cells | +-+ ||[[[[15, 17, 224, 53]], [[241, 17, 179, 53]], [[423, 17, | | 194, 53]], [[619, 17, 164, 53]] .... | +-+ ImageCellsToTextTable ImageCellsToTextTable runs OCR for cells regions on image, return recognized text to outputCol as TableContainer structure. Input Columns Param name Type Default Column Data Description inputCol string image image struct (Image schema) cellsCol string celss Array of cells Parameters Param name Type Default Description strip bool true Strip output text. margin bool 1 Margin of cells in pixelx. pageSegMode PageSegmentationMode AUTO page segmentation mode ocrEngineMode EngineMode LSTM_ONLY OCR engine mode language Language Language.ENG language ocrParams array of strings [] Array of Ocr params in key=value format. pdfCoordinates bool false Transform coordinates in positions to PDF points. modelData string   Path to the local model data. modelType ModelType ModelType.BASE Model type downloadModelData bool false Download model data from JSL S3 outputFormat TableOutputFormat TableOutputFormat.TABLE Output format Output Columns Param name Type Default Column Data Description outputCol string table Recognized text as TableContainer Example: PythonScala import org.apache.spark.ml.Pipeline import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) // Define transformer for detect cells val cell_detector = new ImageTableCellDetector() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;cells&quot;) val table_recognition = new ImageCellsToTextTable() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;tables&quot;) .setMargin(2) // Define pipeline val pipeline = new Pipeline() pipeline.setStages(Array( cell_detector, table_recognition )) val modelPipeline = pipeline.fit(spark.emptyDataFrame) val results = modelPipeline.transform(df) results.select(&quot;tables&quot;) .withColumn(&quot;cells&quot;, explode(col(&quot;tables.chunks&quot;))) .select((0 until 7).map(i =&gt; col(&quot;cells&quot;)(i).getField(&quot;chunkText&quot;).alias(s&quot;col$i&quot;)): _*) .show(false) from pyspark.ml import PipelineModel import pyspark.sql.functions as f from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() binary_to_image.setImageType(ImageType.TYPE_BYTE_GRAY) binary_to_image.setInputCol(&quot;content&quot;) cell_detector = TableCellDetector() cell_detector.setInputCol(&quot;image&quot;) cell_detector.setOutputCol(&quot;cells&quot;) cell_detector.setKeepInput(True) table_recognition = ImageCellsToTextTable() table_recognition.setInputCol(&quot;image&quot;) table_recognition.setCellsCol(&#39;cells&#39;) table_recognition.setMargin(2) table_recognition.setStrip(True) table_recognition.setOutputCol(&#39;table&#39;) pipeline = PipelineModel(stages=[ binary_to_image, cell_detector, table_recognition ]) result = pipeline.transform(df) results.select(&quot;table&quot;) .withColumn(&quot;cells&quot;, f.explode(f.col(&quot;table.chunks&quot;))) .select([f.col(&quot;cells&quot;)[i].getField(&quot;chunkText&quot;).alias(f&quot;col{i}&quot;) for i in range(0, 7)]) .show(20, False) Image: Output: +-+-+--++--++-+ |col0 |col1 |col2 |col3 |col4 |col5 |col6 | +-+-+--++--++-+ |Order Date|Region |Rep |Item |Units|Unit Cost|Total | |1/23/10 |Ontario|Kivell |Binder|50 |$19.99 |$999.50| |2/9/10 |Ontario|Jardine |Pencil|36 |$4.99 |$179.64| |2/26/10 |Ontario|Gill |Pen |27 |$19.99 |$539.73| |3/15/10 |Alberta|Sorvino |Pencil|56 |$2.99 |$167.44| |4/1/10 |Quebec |Jones |Binder|60 |$4.99 |$299.40| |4/18/10 |Ontario|Andrews |Pencil|75 |$1.99 |$149.25| |5/5/10 |Ontario|Jardine |Pencil|90 |$4.99 |$449.10| |5/22/10 |Alberta|Thompson|Pencil|32 |$1.99 |$63.68 | +-+-+--++--++-+",
    "url": "/docs/en/ocr_table_recognition",
    "relUrl": "/docs/en/ocr_table_recognition"
  },
  "1298": {
    "id": "1298",
    "title": "Visual document understanding",
    "content": "NLP models are great at processing digital text, but many real-word applications use documents with more complex formats. For example, healthcare systems often include visual lab results, sequencing reports, clinical trial forms, and other scanned documents. When we only use an NLP approach for document understanding, we lose layout and style information - which can be vital for document image understanding. New advances in multi-modal learning allow models to learn from both the text in documents (via NLP) and visual layout (via computer vision). We provide multi-modal visual document understanding, built on Spark OCR based on the LayoutLM architecture. It achieves new state-of-the-art accuracy in several downstream tasks, including form understanding (from 70.7 to 79.3), receipt understanding (from 94.0 to 95.2) and document image classification (from 93.1 to 94.4). Please check also webinar: Visual Document Understanding with Multi-Modal Image &amp; Text Mining in Spark OCR 3 VisualDocumentClassifier VisualDocumentClassifier is a DL model for document classification using text and layout data. Currently available pretrained model on the Tobacco3482 dataset, that contains 3482 images belonging to 10 different classes (Resume, News, Note, Advertisement, Scientific, Report, Form, Letter, Email and Memo) Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Parameters Param name Type Default Description maxSentenceLength int 128 Maximum sentence length. caseSensitive boolean false Determines whether model is case sensitive. confidenceThreshold float 0f Confidence threshold. Output Columns Param name Type Default Column Data Description labelCol string label Name of output column with the predicted label. confidenceCol string confidence Name of output column with confidence. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val visualDocumentClassifier = VisualDocumentClassifier .pretrained(&quot;visual_document_classifier_tobacco3482&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setMaxSentenceLength(128) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) .setConfidenceCol(&quot;conf&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, visualDocumentClassifier )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;label&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) document_classifier = VisualDocumentClassifier() .pretrained(&quot;visual_document_classifier_tobacco3482&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setMaxSentenceLength(128) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) .setConfidenceCol(&quot;conf&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, document_classifier, ]) result = pipeline.transform(df) result.select(&quot;label&quot;).show() Output: ++ | label| ++ |Letter| ++ VisualDocumentNER VisualDocumentNER is a DL model for NER documents using text and layout data. Currently available pre-trained model on the SROIE dataset. The dataset has 1000 whole scanned receipt images. Input Columns Param name Type Default Column Data Description inputCol string hocr Сolumn name with HOCR of the document Parameters Param name Type Default Description maxSentenceLength int 512 Maximum sentence length. caseSensitive boolean false Determines whether model is case sensitive. whiteList Array[String]   Whitelist of output labels Output Columns Param name Type Default Column Data Description outputCol string entities Name of output column with entities Annotation. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; // Read image file as binary file val df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) .asImage(&quot;image&quot;) val imageToHocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) val visualDocumentNER = VisualDocumentNER .pretrained(&quot;visual_document_NER_SROIE0526&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setMaxSentenceLength(512) .setInputCol(&quot;hocr&quot;) val pipeline = new Pipeline() pipeline.setStages(Array( imageToHocr, visualDocumentNER )) val modelPipeline = pipeline.fit(df) val result = modelPipeline.transform(df) result.select(&quot;entities&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binary_to_image = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) document_ner = VisualDocumentNer() .pretrained(&quot;visual_document_NER_SROIE0526&quot;, &quot;en&quot;, &quot;public/ocr/models&quot;) .setMaxSentenceLength(512) .setInputCol(&quot;hocr&quot;) .setLabelCol(&quot;label&quot;) # Define pipeline pipeline = PipelineModel(stages=[ binary_to_image, ocr, document_ner, ]) result = pipeline.transform(df) result.select(&quot;entities&quot;).show() Output: +-+ |entities | +-+ |[[entity, 0, 0, O, [word -&gt; 0£0, token -&gt; 0£0], []], [entity, 0, 0, | | B-COMPANY, [word -&gt; AEON, token -&gt; aeon], []], [entity, 0, 0, B-COMPANY,| | [word -&gt; CO., token -&gt; co], ... | +-+ VisualDocumentNERv2 VisualDocumentNERv2 is a DL model for NER documents which is an improved version of VisualDocumentNER. There is available pretrained model trained on FUNSD dataset. The dataset comprises 199 real, fully annotated, scanned forms. Input Columns Param name Type Default Column Data Description inputCols Array[String]   Сolumn names for tokens of the document and image Parameters Param name Type Default Description maxSentenceLength int 512 Maximum sentence length. whiteList Array[String]   Whitelist of output labels Output Columns Param name Type Default Column Data Description outputCol string entities Name of output column with entities Annotation. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; var dataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath) var bin2imTransformer = new BinaryToImage() bin2imTransformer.setImageType(ImageType.TYPE_3BYTE_BGR) val ocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(false) .setOcrParams(Array(&quot;preserve_interword_spaces=0&quot;)) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val visualDocumentNER = VisualDocumentNERv2 .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols(Array(&quot;token&quot;, &quot;image&quot;)) val pipeline = new Pipeline() .setStages(Array( bin2imTransformer, ocr, tokenizer, visualDocumentNER )) val results = pipeline .fit(dataFrame) .transform(dataFrame) .select(&quot;entities&quot;) .cache() result.select(&quot;entities&quot;).show() from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(False) .setOcrParams([&quot;preserve_interword_spaces=0&quot;]) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) ner = VisualDocumentNerV2() .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;token&quot;, &quot;image&quot;]) .setOutputCol(&quot;entities&quot;) pipeline = PipelineModel(stages=[ binToImage, ocr, tokenizer, ner ]) result = pipeline.transform(df) result.withColumn(&#39;filename&#39;, path _array.getItem(f.size(path_array)- 1)) .withColumn(&quot;exploded_entities&quot;, f.explode(&quot;entities&quot;)) .select(&quot;filename&quot;, &quot;exploded_entities&quot;) .show(truncate=False) Output sample: ++-+ |filename |exploded_entities | ++-+ |form1.jpg|[entity, 0, 6, i-answer, [x -&gt; 1027, y -&gt; 89, height -&gt; 19, confidence -&gt; 96, word -&gt; Version:, width -&gt; 90], []] | |form1.jpg|[entity, 25, 35, b-header, [x -&gt; 407, y -&gt; 190, height -&gt; 37, confidence -&gt; 96, word -&gt; Institution, width -&gt; 241], []] | |form1.jpg|[entity, 37, 40, i-header, [x -&gt; 667, y -&gt; 190, height -&gt; 37, confidence -&gt; 96, word -&gt; Name, width -&gt; 130], []] | |form1.jpg|[entity, 42, 52, b-question, [x -&gt; 498, y -&gt; 276, height -&gt; 19, confidence -&gt; 96, word -&gt; Institution, width -&gt; 113], []]| |form1.jpg|[entity, 54, 60, i-question, [x -&gt; 618, y -&gt; 276, height -&gt; 19, confidence -&gt; 96, word -&gt; Address, width -&gt; 89], []] | ++-+ FormRelationExtractor FormRelationExtractor detect relation between keys and values detected by VisualDocumentNERv2. It can detect relations only for key/value in same line. Input Columns Param name Type Default Column Data Description inputCol String   Column name for entities Annotation Parameters Param name Type Default Description lineTolerance int 15 Line tolerance in pixels. This is the space between lines that will be assumed. It is used for grouping text regions by lines. keyPattern String question Pattern of entity name for keys in form. valuePattern String answer Pattern of entity name for values in form. Output Columns Param name Type Default Column Data Description outputCol string relations Name of output column with relation Annotations. Example: PythonScala import com.johnsnowlabs.ocr.transformers.* import com.johnsnowlabs.ocr.OcrContext.implicits._ val imagePath = &quot;path to image&quot; var dataFrame = spark.read.format(&quot;binaryFile&quot;).load(imagePath) var bin2imTransformer = new BinaryToImage() bin2imTransformer.setImageType(ImageType.TYPE_3BYTE_BGR) val ocr = new ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(false) .setOcrParams(Array(&quot;preserve_interword_spaces=0&quot;)) val tokenizer = new HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) val visualDocumentNER = VisualDocumentNERv2 .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols(Array(&quot;token&quot;, &quot;image&quot;)) val relExtractor = new FormRelationExtractor() .setInputCol(&quot;entities&quot;) .setOutputCol(&quot;relations&quot;) val pipeline = new Pipeline() .setStages(Array( bin2imTransformer, ocr, tokenizer, visualDocumentNER, relExtractor )) val results = pipeline .fit(dataFrame) .transform(dataFrame) .select(&quot;relations&quot;) .cache() results.select(explode(&quot;relations&quot;)).show(3, False) from pyspark.ml import PipelineModel from sparkocr.transformers import * imagePath = &quot;path to image&quot; # Read image file as binary file df = spark.read .format(&quot;binaryFile&quot;) .load(imagePath) binToImage = BinaryToImage() .setInputCol(&quot;content&quot;) .setOutputCol(&quot;image&quot;) ocr = ImageToHocr() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;hocr&quot;) .setIgnoreResolution(False) .setOcrParams([&quot;preserve_interword_spaces=0&quot;]) tokenizer = HocrTokenizer() .setInputCol(&quot;hocr&quot;) .setOutputCol(&quot;token&quot;) ner = VisualDocumentNerV2() .pretrained(&quot;layoutlmv2_funsd&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) .setInputCols([&quot;token&quot;, &quot;image&quot;]) .setOutputCol(&quot;entities&quot;) rel_extractor = FormRelationExtractor() .setInputCol(&quot;entities&quot;) .setOutputCol(&quot;relations&quot;) pipeline = PipelineModel(stages=[ binToImage, ocr, tokenizer, ner, rel_extractor ]) result = pipeline.transform(df) result.select(explode(&quot;relations&quot;)).show(3, False) Output sample: ++ |col | ++ |[relation, 112, 134, Name: Dribbler, bbb, [bbox1 -&gt; 58 478 69 19, ...| |[relation, 136, 161, Study Date: 12-09-2006, 6:34, [bbox1 -&gt; 431 ... | |[relation, 345, 361, BP: 120 80 mmHg, [bbox1 -&gt; 790 478 30 19, ... | ++",
    "url": "/docs/en/ocr_visual_document_understanding",
    "relUrl": "/docs/en/ocr_visual_document_understanding"
  },
  "1299": {
    "id": "1299",
    "title": "Oncology - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/oncology",
    "relUrl": "/oncology"
  },
  "1300": {
    "id": "1300",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$Feature.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$Feature.html"
  },
  "1301": {
    "id": "1301",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/package$$Recursive.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/package$$Recursive.html"
  },
  "1302": {
    "id": "1302",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/recursive/package$$RecursiveModel.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/recursive/package$$RecursiveModel.html"
  },
  "1303": {
    "id": "1303",
    "title": "",
    "content": "",
    "url": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$WordData.html",
    "relUrl": "/api/com/johnsnowlabs/nlp/annotators/parser/dep/GreedyTransition/package$$WordData.html"
  },
  "1304": {
    "id": "1304",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/params_getters_setters.html",
    "relUrl": "/api/python/modules/sparknlp/internal/params_getters_setters.html"
  },
  "1305": {
    "id": "1305",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/pos/perceptron.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/pos/perceptron.html"
  },
  "1306": {
    "id": "1306",
    "title": "Pipelines",
    "content": "",
    "url": "/docs/en/pipelines",
    "relUrl": "/docs/en/pipelines"
  },
  "1307": {
    "id": "1307",
    "title": "Playground",
    "content": "The Playground feature of the NLP Lab allows users to deploy and test models, rules, and/or prompts without going through the project setup wizard. This simplifies the initial resources exploration, and facilitates experiments on custom data. Any model, rule, or prompt can now be selected and deployed for testing by clicking on the “Open in Playground” button. Experiment with Rules Rules can be deployed to the Playground from the rules page. When a particular rule is deployed in the playground, the user can also change the parameters of the rules via the rule definition form from the right side of the page. After saving the changes users need to click on the “Deploy” button to refresh the results of the pre-annotation on the provided text. Experiment with Prompts NLP Lab’s Playground also supports the deployment and testing of prompts. Users can quickly test the results of applying a prompt on custom text, can easily edit the prompt, save it, and deploy it right away to see the change in the pre-annotation results. Experiment with Models Any Classification, NER or Assertion Status model available on the NLP Lab can also be deployed to Playground for testing on custom text. Deployment of models and rules is supported by floating and air-gapped licenses. Healthcare, Legal, and Finance models require a license with their respective scopes to be deployed in Playground. Unlike pre-annotation servers, only one playground can be deployed at any given time. Direct Navigation to Active Playground Sessions Navigating between multiple projects to and from the playground experiments can be necessary, especially when you want to revisit a previously edited prompt or rule. This is why NLP Lab Playground now allow users to navigate to any active Playground session without having to redeploy the server. This feature enables users to check how their resources (models, rules and prompts) behave at project level, compare the preannotation results with ground truth, and quickly get back to experiments for modifying prompts or rules without losing progress or spending time on new deployments. This feature makes experimenting with NLP prompts and rules in a playground more efficient, streamlined, and productive. Automatic Deployment of Updated Rules/Prompts Another benefit of experimenting with NLP prompts and rules in the playground is the immediate feedback that you receive. When you make changes to the parameters of your rules or to the questions in your prompts, the updates are deployed instantly. Manually deploying the server is not necessary any more for changes made to Rules/Prompts to be reflected in the preannotation results. Once the changes are saved, by simply clicking on the Test button, updated results are presented. This allows you to experiment with a range of variables and see how each one affects the correctness and completeness of the results. The real-time feedback and immediate deployment of changes in the playground make it a powerful tool for pushing the boundaries of what is possible with language processing. Playground Server Destroyed after 5 Minutes of Inactivity When active, the NLP playground consumes resources from your server. For this reason, NLP Lab defines an idle time limit of 5 minutes after which the playground is automatically destroyed. This is done to ensure that the server resources are not being wasted on idle sessions. When the server is destroyed, a message is displayed, so users are aware that the session has ended. Users can view information regarding the reason for the Playground’s termination, and have the option to restart by pressing the Restart button. Playground Servers use Light Pipelines The replacement of regular preannotation pipelines with Light Pipelines has a significant impact on the performance of the NLP playground. Light pipelines allow for faster initial deployment, quicker pipeline update and fast processing of text data, resulting in overall quicker results in the UI. Direct Access to Model Details Page on the Playground Another useful feature of NLP Lab Playground is the ability to quickly and easily access information on the models being used. This information can be invaluable for users who are trying to gain a deeper understanding of the model’s inner workings and capabilities. In particular, by click on the model’s name it is now possible to navigate to the NLP Models hub page. This page provides users with additional details about the model, including its training data, architecture, and performance metrics. By exploring this information, users can gain a better understanding of the model’s strengths and weaknesses, and use this knowledge to make more informed decisions on how good the model is for the data they need to annotate.",
    "url": "/docs/en/alab/playground",
    "relUrl": "/docs/en/alab/playground"
  },
  "1308": {
    "id": "1308",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/pos.html",
    "relUrl": "/api/python/modules/sparknlp/training/pos.html"
  },
  "1309": {
    "id": "1309",
    "title": "Preannotation",
    "content": "Annotation Lab offers out-of-the-box support for Named Entity Recognition, Classification, Assertion Status, and Relations preannotations. These are extremely useful for bootstrapping any annotation project as the annotation team does not need to start the labeling from scratch but can leverage the existing knowledge transfer from domain experts to models. This way, the annotation efforts are significantly reduced. To run pre-annotation on one or several tasks, the Project Owner or the Manager must select the target tasks and click on the Pre-Annotate button from the top right side of the Tasks page. It will display a popup with information regarding the last deployment of the model server with the list of models deployed and the labels they predict. This information is crucial, especially when multiple users are doing training and deployment in parallel. So before doing preannotations on your tasks, carefully check the list of currently deployed models and their labels. If needed, users can deploy the models defined in the current project (based on the current Labeling Config) by clicking the Deploy button. After the deployment is complete, the preannotation can be triggered. Since Annotation Lab 3.0.0, multiple preannotation servers are available to preannotate the tasks of a project. The dialog box that opens when clicking the Pre-Annotate button on the Tasks page now lists available model servers in the options. Project Owners or Managers can now select the server to use. On selecting a model server, information about the configuration deployed on the server is shown on the popup so users can make an informed decision on which server to use. In case a preannotation server does not exist for the current project, the dialog box also offers the option to deploy a new server with the current project’s configuration. If this option is selected and enough resources are available (infrastructure capacity and a license if required) the server is deployed, and preannotation can be started. If there are no free resources, users can delete one or several existing servers from Clusters page under the Settings menu. Concurrency is not only supported between preannotation servers but also between training and preannotation. Users can have training running on one project and preannotation running on another project at the same time. Preannotation Approaches Pretrained Models On the Predefined Labels step of the Project Configuration page we can find the list of available models with their respective prediction labels. By selecting the relevant labels for your project and clicking the Add Label button you can add the predefined labels to your project configuration and take advantage of the Spark NLP auto labeling capabilities. In the example below, we are reusing the ner_posology model that comes with 7 labels related to drugs. In the same manner classification, assertion status or relation models can be added to the project configuration and used for preannotation purpose. Starting from version 4.3.0, Finance and Legal models downloaded from the Models Hub can be used for pre-annotation of NER, assertion status and classification projects. Visual NER models can now be downloaded from the NLP Models Hub, and used for pre-annotating image-based documents. Once you download the models from the Models Hub page, you can see the model’s label in the Predefined Label tab on the project configuration page. Rules Preannotation of NER projects can also be done using Rules. Rules are used to speed up the manual annotation process. Once a rule is defined, it is available for use in any project. However, for defining and running the rules we will need a [Healthcare NLP](/docs/en/licensed_install) license. In the example below, we are reusing the available rules for preannotation. Read more on how to create rules and reuse them to speed up the annotation process here. Text Preannotation Preannotation is available for projects with text contents as the tasks. When you setup a project to use existing Spark NLP models for pre-annotation, you can run the designated models on all of your tasks by pressing the Pre-Annotate button on the top-right corner of the Tasks page. As a result, all predicted labels for a given task will be available in the Prediction widget on the Labeling page. The predictions are not editable. You can only view and navigate those or compare those with older predictions. However, you can create a new completion based on a given prediction. All labels and relations from such a new completion are now editable. Visual Preannotation For running pre-annotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Pre-Annotate button from the upper right side of the Tasks Page. It will display a popup with information regarding the last deployment of the model server, including the list of models deployed and the labels they predict. Known Limitations: When bulk pre-annotation runs on many tasks, the pre-annotation can fail due to memory issues. Preannotation currently works at the token level, and does not merge all tokens of a chunk into one entity. Pipeline Limitations Loading too many models in the preannotation server is not memory efficient and may not be practically required. Starting from version 1.8.0, Annotation Lab supports maximum of five different models to be used for the preannotation server deployment. Another restriction for Annotation Lab versions older than 4.2.0 is that two models trained on different embeddings cannot be used together in the same project. The Labeling Config will throw validation errors in any of the cases above, and we cannot save the configuration preventing preannotation server deployment.",
    "url": "/docs/en/alab/preannotation",
    "relUrl": "/docs/en/alab/preannotation"
  },
  "1310": {
    "id": "1310",
    "title": "The predict() function",
    "content": "predict() expects either a column named ‘text’ in the dataframe passed to it, or alternatively it will assume the first column of the dataframe passed to it as the column it should predict for. Predict method Parameters Output metadata The NLP predict method has a boolean metadata parameter. When it is set to True, it output the confidence and additional metadata for each prediction. Its default value is False. nlp.load(&#39;lang&#39;).predict(&#39;What a wonderful day!&#39;) Output Level parameter predict() defines 4 output levels for the generated predictions. The output levels define how granular the predictions and outputs will be. Depending on your goal, may need to be output level should be adjusted. Token level: Outputs one row for every token in the input. One to many mapping. Chunk level: Outputs one row for every chunk in the input. One to many mapping. Sentence level: Outputs one row for every sentence the input. One to many mapping. Relation level output: Outputs one row for every relation predicted, i.e. . One to many. Document level output: Outputs one row for every document in the input. One to one mapping. predict() will try to infer the most useful output level automatically if an output level is not specified. The inferred output level will usually define the last element of the pipeline. Take a look at the different output levels Demo which goes over all the output levels. Document output level example Every row in the input data frame will be mapped to one row in the output dataframe. # outputs 1 row for 1 input document nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;document&#39;) document id checked sentiment_confidence sentiment I love data science! It is so much fun! It can… 0 [I, love, data, science, !, It, is, so, much, … ] [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] I love the city New-York 1 [I, love, the, city, New-York] [0.7342000007629395] [positive] Sentence output level example Every sentence in each row becomes a new row in the output dataframe. # will detect the 2 sentences and output 2 rows, one for each of the sentences. nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;sentence&#39;) sentence sentiment_confidence sentiment id checked I love data science! [0.7540] positive 0 [I, love, data, science, !, It, is, so, much, …] It is so much fun! [0.6121] positive 0 [I, love, data, science, !, It, is, so, much, …] It can also be quite helpful to people. [0.4895] positive 0 [I, love, data, science, !, It, is, so, much, …] I love the city New-York [0.7342] positive 1 [I, love, the, city, New-York] Chunk output level example Every chunk in each input row becomes a new row in the output dataframe. This is useful for components like the Named Entity Resolver. By setting output level to chunk, you will ensure ever Named Entity becomes one row in your datset. Named Entities are chunks. # &#39;New York&#39; is a Chunk. A chunk is an object that consists of multiple tokens, but it&#39;s not a sentence. nlp.load(&#39;ner&#39;).predict([&#39;Angela Merkel and Donald Trump dont share many opinions&#39;, &quot;Ashley wants to visit the Brandenburger Tor in Berlin&quot;], output_level=&#39;chunk&#39;,) entities ner_tag embeddings Angela Merkel PERSON [[-0.563759982585907, 0.26958999037742615, 0.3…,] Donald Trump PERSON [[-0.563759982585907, 0.26958999037742615, 0.3…,] Ashley PERSON [[0.24997000396251678, -0.12275999784469604, -…,] the Brandenburger Tor FAC [[0.24997000396251678, -0.12275999784469604, -…,] Berlin GPE [[0.24997000396251678, -0.12275999784469604, -…,] Token output level example Every token in each input row becomes a new row in the output dataframe. # Every token in our sentence will become a row nlp.load(&#39;sentiment&#39;).predict([&#39;I love data science! It is so much fun! It can also be quite helpful to people.&#39;, &#39;I love the city New-York&#39;], output_level=&#39;token&#39;) token checked sentiment_confidence sentiment I I [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] love love [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] data data [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] science science [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] ! ! [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] It It [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] is is [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] so so [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] much much [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] fun fun [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] ! ! [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] It It [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] can can [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] also also [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] be be [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] quite quite [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] helpful helpful [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] to to [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] people people [0.7540000081062317, 0.6121000051498413, 0.489… ] [positive, positive, positive] . . [0.7540000081062317, 0.6121000051498413, 0.489…] [positive, positive, positive] I I [0.7342000007629395] [positive] love love [0.7342000007629395] [positive] the the [0.7342000007629395] [positive] city city [0.7342000007629395] [positive] New-York New-York [0.7342000007629395] [positive] Output positions parameter By setting output_positions=True, the Dataframe generated will contain additional columns which describe the beginning and end of each feature inside of the original document. These additional _begining and _end columns let you infer the piece of the original input string that has been used to generate the output. If output level is set to a different output level than some features output level, the resulting features will be inside of lists If output level is set to the same output level as some feature, the generated positional features will be single integers positional : For token based components the positional features refer to the beginning and the end of the token inside the original document the text originates from. For sentence based components like sentence embeddings and different sentence classifiers the output of positional will describe the beginning and the end of the sentence that was used to generate the output. nlp.load(&#39;sentiment&#39;).predict(&#39;I love data science!&#39;, output_level=&#39;token&#39;, output_positions=True) checked checked_begin checked_end token id document_begin document_end sentence_begin sentence_end sentiment_confidence sentiment_begin sentiment_end sentiment I 0 0 I 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] love 2 5 love 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] data 7 10 data 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] science 12 18 science 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] ! 19 19 ! 0 [0] [78] [0, 21, 40] [19, 38, 78] [0.7540000081062317, 0.6121000051498413, 0.489…] [0, 21, 40] [19, 38, 78] [positive, positive, positive] Row origin inference for one to many mappings predict() will recycle the Pandas index from the input Dataframe. The index is useful if one row is mapped to many rows during prediction. The new rows which are generated from the input row will all have the same index as the original source row. I.e. if one sentence row gets split into many token rows, each token row will have the same index as the sentence row. NaN Handling Every NaN value is converted to a Python None variable which is reflected in the final dataframe If a column contains only NaN or None, it will be dropped Memory optimization recommendations Instead of passing your entire Pandas Dataframe to predict() you can pass only the columns which you need for later tasks. This saves memory and computation time and can be achieved like in the following example, which assumes latitude and longitude are irrelevant for later tasks. from johnsnowlabs import nlp import pandas as pd data = { &#39;tweet&#39;: [&#39;@CKL-IT the john snow labs library is awesome!&#39;, &#39;@MaziyarPanahi johnsnowlabs library is pretty cool&#39;, &#39;@JohnSnowLabs Try out the johnsnowlabs library!&#39;], &#39;tweet_location&#39;: [&#39;Berlin&#39;, &#39;Paris&#39;, &#39;United States&#39;], &#39;tweet_lattitude&#39; : [&#39;52.55035&#39;, &#39;48.858093&#39;, &#39;40.689247&#39;], &#39;tweet_longtitude&#39; : [&#39;13.39139&#39;, &#39;2.294694&#39;,&#39;-74.044502&#39;] } text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df[[&#39;tweet&#39;,&#39;tweet_location&#39;]]) Supported data types predict() supports all of the common Python data types and formats Pandas Dataframes Spark Dataframes Modin with Dask backend Modin with Ray backend 1-D Numpy arrays of Strings Strings Arrays of Strings Single strings from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict(&#39;This is just one string&#39;) Lists of strings from johnsnowlabs import nlp nlp.load(&#39;sentiment&#39;).predict([&#39;This is an array&#39;, &#39; Of strings!&#39;]) Pandas Dataframe One column must be named text and of object/string type or the first column will be used instead if no column named ‘text’ exists note : Passing the entire dataframe with additional features to the predict() method is very memory intensive. It is recommended to only pass the columns required for further downstream tasks to the predict() method. from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df) Pandas Series One column must be named text and of object/string type note : This way is the most memory efficient way from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_df = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_df[&#39;text&#39;]) Spark Dataframe One column must be named text and of string type or the first column will be used instead if no column named ‘text’ exists from johnsnowlabs import nlp import pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I dont like Sami&#39;]} text_pdf = pd.DataFrame(data) text_sdf = nlp.spark.createDataFrame(text_pdf) nlp.load(&#39;sentiment&#39;).predict(text_sdf) Modin Dataframe Supports Ray Dask backends One column must be named text and of string type or the first column will be used instead if no column named ‘text’ exists from johnsnowlabs import nlp import modin.pandas as pd data = {&quot;text&quot;: [&#39;This day sucks&#39;, &#39;I love this day&#39;, &#39;I don&#39;t like Sami&#39;]} text_pdf = pd.DataFrame(data) nlp.load(&#39;sentiment&#39;).predict(text_pdf)",
    "url": "/docs/en/jsl/predict_api",
    "relUrl": "/docs/en/jsl/predict_api"
  },
  "1311": {
    "id": "1311",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/pretrained/pretrained_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/pretrained/pretrained_pipeline.html"
  },
  "1312": {
    "id": "1312",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/pretrained_pipelines.html",
    "relUrl": "/api/python/user_guide/pretrained_pipelines.html"
  },
  "1313": {
    "id": "1313",
    "title": "Productionizing Spark NLP",
    "content": "",
    "url": "/docs/en/production-readiness",
    "relUrl": "/docs/en/production-readiness"
  },
  "1314": {
    "id": "1314",
    "title": "Productivity",
    "content": "Analytics Charts By default, the Analytics page is disabled for every project because computing the analytical charts is a resource-intensive task and might temporarily influence the responsiveness of the application, especially when triggered in parallel with other training/preannotation jobs. However, users can file a request to enable the Analytics page which can be approved by any admin user. The request is published on the Analytics Requests page, visible to any admin user. Once the admin user approves the request, any team member can access the Analytics page. A refresh button is present on the top-right corner of the Analytics page. The Analytics charts doesn’t automatically reflect the changes made by the annotators (like creating tasks, adding new completion, etc.). Updating the analytics to reflect the latest changes can be done using the refresh button. Task Analytics To access Task Analytics, navigate on the first tab of the Analytics Dashboard, called Tasks. The following blog post explains how to Improve Annotation Quality using Task Analytics in the Annotation Lab. Below are the charts included in the Tasks section. Total number of task in the Project Total number of task in a Project in last 30 days Breakdown of task in the Project by Status Breakdown of task by author Summary of task status for each annotator Total number of label occurrences across all completions Average number of label occurrences for each completion Total number of label occurrences across all completions for each annotator Total vs distinct count of labels across all completions Average number of tokens by label Total number of label occurrences that include numeric values Team Productivity To access Team Productivity charts, navigate on the second tab of the Analytics Dashboard, called Team Productivity. The following blog post explains how to Keep Track of Your Team Productivity in the Annotation Lab. Below are the charts included in the Team Productivity section. Total number of completions in the Project Total number of completions in the Project in the last 30 days Total number of completions for each Annotator Total number of completions submitted over time for each Annotator Average time spent by the Annotator in each task Total number of completions submitted over time Inter-Annotator Agreement (IAA) Starting from version 2.8.0, Inter Annotator Agreement(IAA) charts allow the comparison between annotations produced by Annotators, Reviewers, or Managers. Inter Annotator Agreement charts can be used by Annotators, Reviewers, and Managers for identifying contradictions or disagreements within the starred completions (Ground Truth). When multiple annotators work on same tasks, IAA charts are handy to measure how well the annotations created by different annotators align. IAA chart can also be used to identify outliers in the labeled data, or to compare manual annotations with model predictions. To access IAA charts, navigate on the third tab of the Analytics Dashboard of NER projects, called Inter-Annotator Agreement. Several charts should appear on the screen with a default selection of annotators to compare. The dropdown selections on top-left corner of each chart allow you to change annotators for comparison purposes. There is another dropdown to select the label type for filtering between NER labels and Assertion Status labels for projects containing both NER and Assertion Status entities. It is also possible to download the data generated for some chart in CSV format by clicking the download button just below the dropdown selectors. Note: Only the Submitted and starred (Ground Truth) completions are used to render these charts. The following blog post explains how your team can Reach Consensus Faster by Using IAA Charts in the Annotation Lab. Below are the charts included in the Inter-Annotator Agreement section. High-level IAA between annotators on all common tasks IAA between annotators for each label on all common tasks Comparison of annotations by annotator on each chunk Comparison of annotations by model and annotator (Ground Truth) on each chunk All chunks annotated by an annotator Frequency of labels on chunks annotated by an annotator Frequency of a label on chunks annotated by each annotator Download data used for charts CSV file for specific charts can be downloaded using the new download button which will call specific API endpoints: /api/projects/{project_name}/charts/{chart_type}/download_csv",
    "url": "/docs/en/alab/productivity",
    "relUrl": "/docs/en/alab/productivity"
  },
  "1315": {
    "id": "1315",
    "title": "Project Configuration",
    "content": "Annotation Lab currently supports multiple predefined project configurations. The most popular ones are Text Classification, Named Entity Recognition (NER) and Visual NER. Create a setup from scratch or customize a predefined one according to your needs. For customizing a predefined configuration, click on the corresponding link in the table above and then navigate to the Labeling configuration tab and manually edit or update it to contain the labels you want. After you finish editing the labels you want to define for your project click the “Save” button. Project templates We currently support multiple predefined project configurations. The most popular ones are Text Classification, Named Entity Recognition and Visual NER. Content Type The first step when creating a new project or customizing an existing one is to choose what content you need to annotate. Five content types are currently supported: Audio, HTML, Image, PDF and Text. For each content type a list of available templates is available. You can pick any one of those as a starting point in your project configuration. For customizing a predefined configuration, choose a Content Type and then a template from the list. Then navigate to the Customize Labels tab and manually edit/update the configuration to contain the labels you need. Users can add custom labels and choices in the project configuration from the Visual tab for both text and Visual NER projects. After you finish editing the labels click the “Save” button. Named Entity Recognition Named Entity Recognition (NER) refers to the identification and classification of entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc. The Annotation Lab offers support for two types of labels: Simple labels for NER or assertion models; Binary relations for relation extraction models. Assertion Labels The syntax for defining an Assertion Status label is the same as for the NER labels, with an additional attribute - assertion which should be set to true (see example below). This convention is defined by Annotation Lab users which we exploited for identifying the labels to include in the training and prediction of Assertion Models. A simple Labeling Config with Assertion Status defined should look like the following: &lt;View&gt; &lt;Labels name=&quot;ner&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;Medicine&quot; background=&quot;orange&quot; hotkey=&quot;_&quot;/&gt; &lt;Label value=&quot;Condition&quot; background=&quot;orange&quot; hotkey=&quot;_&quot;/&gt; &lt;Label value=&quot;Procedure&quot; background=&quot;green&quot; hotkey=&quot;8&quot;/&gt; &lt;Label value=&quot;Absent&quot; assertion=&quot;true&quot; background=&quot;red&quot; hotkey=&quot;Z&quot;/&gt; &lt;Label value=&quot;Past&quot; assertion=&quot;true&quot; background=&quot;red&quot; hotkey=&quot;X&quot;/&gt; &lt;/Labels&gt; &lt;View style=&quot;height: 250px; overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;/View&gt; NOTE: Notice assertion=”true” in Absent and Past labels, which marks each of those labels as Assertion Status Labels. Classification The choices tag is used as part of the classification projects to create a group of choices. It can be used for a single or multiple-class classification. According to the parameters used along with the choices tag, annotators can select single or multiple choices. Parameters The Choices tag supports the following parameters/attributes: Param Type Default Description required boolean false Verify if a choice is selected requiredMessage string   Show a message if the required validation fails choice single | multiple single Allow user to select single or multiple answer showInline boolean false Show choices in a single visual line perRegion boolean   Use this attribute to select an option for a specific region rather than the entire task &lt;!--text classification labeling config--&gt; &lt;View&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;Choices name=&quot;surprise&quot; toName=&quot;text&quot; choice=&quot;single&quot; required=&#39;true&#39; requiredMessage=&#39;Please select choice&#39;&gt; &lt;Choice value=&quot;surprise&quot;/&gt; &lt;Choice value=&quot;sadness&quot;/&gt; &lt;Choice value=&quot;fear&quot;/&gt; &lt;Choice value=&quot;joy&quot;/&gt; &lt;/Choices&gt; &lt;/View&gt; When using the perRegion attribute, choices can be defined for each chunk annotation as shown below: Relation Extraction Annotation Lab also offers support for relation extraction. Relations are introduced by simply specifying their label in the project configuration. &lt;Relations&gt; &lt;Relation value=&quot;CancerSize&quot; /&gt; &lt;Relation value=&quot;CancerLocation&quot;/&gt; &lt;Relation value=&quot;MetastasisLocation&quot;/&gt; &lt;/Relations&gt; Constraints for relation labeling While annotating projects with Relations between Entities, defining constraints (the direction, the domain, the co-domain) of relations is important. Annotation Lab offers a way to define such constraints by editing the Project Configuration. The Project Owner or Project Managers can specify which Relation needs to be bound to which Labels and in which direction. This will hide some Relations in Labeling Page for NER Labels which will simplify the annotation process and will avoid the creation of any incorrect relations in the scope of the project. To define such constraint, add allowed attribute to the tag: L1&gt;L2 means Relation can be created in the direction from Label L1 to Label L2, but not the other way around L1&lt;&gt;L2 means Relation can be created in either direction between Label L1 to Label L2 If the allowed attribute is not present in the tag, there is no such restriction. Below you can find a sample Project Configuration with constraints for Relation Labels: &lt;View&gt; &lt;Header value=&quot;Sample Project Configuration for Relations Annotation&quot;/&gt; &lt;Relations&gt; &lt;Relation value=&quot;Was In&quot; allowed=&quot;PERSON&gt;LOC&quot;/&gt; &lt;Relation value=&quot;Has Function&quot; allowed=&quot;LOC&gt;EVENT,PERSON&gt;MEDICINE&quot;/&gt; &lt;Relation value=&quot;Involved In&quot; allowed=&quot;PERSON&lt;&gt;EVENT&quot;/&gt; &lt;Relation value=&quot;No Constraints&quot;/&gt; &lt;/Relations&gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;PERSON&quot;/&gt; &lt;Label value=&quot;EVENT&quot;/&gt; &lt;Label value=&quot;MEDICINE&quot;/&gt; &lt;Label value=&quot;LOC&quot;/&gt; &lt;/Labels&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt;",
    "url": "/docs/en/alab/project_configuration",
    "relUrl": "/docs/en/alab/project_configuration"
  },
  "1316": {
    "id": "1316",
    "title": "Project Creation",
    "content": "New project Every project in Annotation Lab should have the following information: a unique name and a short description; a team of annotators, reviewers and a manager who will collaborate on the project; a configuration which specifies the type of annotations that will be created. You can create a new project using the dedicated wizard which will guide users through each step of the project creation and configuration process. Those steps are illustrated below. Project Description To open the project creation wizard click on the + New Project button on the Projects Dashboard, then provide the following information: a unique name or title; a sampling type which will define how the tasks assigned to annotators/reviewers will be served - randomly or sequentially; a short description that helps users quickly grasp the main purpose of the project; instructions for annotators or Annotation Guidelines which will help annotators and reviewers generate high quality annotations. NOTE: Reserved words cannot be used as project names. The use of keywords like count, permission, or name as project names generated UI glitches. To avoid such issues, these keywords are no longer accepted as project names. Adding Team Members When working in teams, projects can be shared with other team members. The user who creates a project is called a Project Owner. He/she has complete visibility and ownership of the project for its entire lifecycle. If the Project Owner is removed from the user database, then all his/her projects are transfered to a new project owner. The Project Owner can edit the project configuration, can import/export tasks, can create a project team that will work on his project and can access project analytics. When defining the project team, a project owner has access to three distinct roles: Annotator, Reviewer, and Manager. These are very useful for most of the workflows that our users follow. An Annotator is able to see the tasks which have been assigned to him or her and can create annotations on the documents. The Reviewer is able to see the work of the annotators and approve it or reject in case he finds issues that need to be solved. The Manager is able to see the work of the Annotators and of the Reviewers and he can assign tasks to team members. This is useful for eliminating work overlap and for a better management of the work load. To add a user to your project team, select your Project, then from the left side menu access the Setup option and then the Team option. On the Add Team Member page that opens, start typing the name of a user in the available text box. This will populate a list of available users having the username start with the characters you typed. From the dropdown select the user you want to add to your team. Select a role for the user and click on the Add to team button. In the Add Team Member page users can add/remove/update the team members even in the case of a large number of members. The team members are displayed in a tabular view. Each member has a priority assigned to them for CONLL export which can be changed by dragging users across the list. NOTE: The priority assigned for users in the Add Team Member page is taken into account by the Model Training script for differentiating among the available ground truth completions (when more than one is available for a task) in view of choosing the higer priority completion which will be used for model training. Learn more here. Project Configuration The Project Configuration itself is a multi-step process. The wizard will guide users through each step while providing useful information and hints for all available options. Clone You can create a copy of a project, by using the Clone option. The option to clone the project is also listed in the kebab menu of each project. The cloned project is differentiated as it contains cloned suffix in its project name. Export Projects can be exported. The option to export a project is listed in the kebab menu of each project. All project-related items such as tasks, project configuration, project members, task assignments, and comments are included in the export file. NOTE: Project export does not contain the model trained in the project as models are independent and not attached to a particular project. Import A project can be imported by uploading the project zip archive in the upload dialog box. When the project is imported back to Annotation Lab, all elements of the original project configuration will be included in the new copy. Project Grouping As the number of projects can grow significantly over time, for an easier management and organization of those, Annotation Lab allows project grouping. As such, a project owner can assign a group to one or several of his/her projects. Each group can be assigned a color which will be used to highlight projects included in that group. Once a project is assigned to a group, the group name will appear as a tag on the project tile. At any time a project can be remove from one group and added to another group. The list of visible projects can be filtered based on group name, or using the search functionality which applies to both group name and project name. Projects can be organized in custom groups, and each project card will inherit the group color so that the users can visually distinguish the projects easily in a large cluster of projects. The new color picker for the group is user-friendly and customizable.",
    "url": "/docs/en/alab/project_creation",
    "relUrl": "/docs/en/alab/project_creation"
  },
  "1317": {
    "id": "1317",
    "title": "Dashboard",
    "content": "When logging in to the Annotation Lab, the user sees the main Projects Dashboard. For each project, details like description, task counts, assigned groups, team members, etc. are available on the main dashboard so users can quickly identify the projects they need to work on, without navigating to the Project Details page. Projects can be filtered based on the creator: My Projects, created by the current user or Shared With Me, created by other users and shared with the current one. All Projects option combines the list of the projects created by the current user and those shared by others. The list of projects can be sorted according to the name of the project. Also, projects can be sorted in ascending or descending order according to the creation date. The filters associated with the Projects Dashboard are clear, simple, and precise to make the users more productive and efficient while working with a large number of projects. Searching features are also available and help users identify projects based on their name.",
    "url": "/docs/en/alab/project_dashboard",
    "relUrl": "/docs/en/alab/project_dashboard"
  },
  "1318": {
    "id": "1318",
    "title": "Prompts",
    "content": "NLP Lab offers support for prompt engineering. On the Prompts page, from the resources HUB, users can easily discover and explore the existing prompts or create new prompts for identifying entities or relations. Currently, NLP Lab supports prompts for Healthcare, Finance, and Legal domains applied using pre-trained question-answering language models published on the NLP Models Hub and available to download in one click. The main advantage behind the use of prompts in entity or relation recognition is the ease of definition. Non-technical domain experts can easily create prompts, test and edit them on the Playground on custom text snippets and, when ready, deploy them for pre-annotation as part of larger NLP projects. Together with rules, prompts are very handy in situations where no pre-trained models exist, for the target entities and domains. With rules and prompts the annotators never start their projects from scratch but can capitalize on the power of zero-shot models and rules to help them pre-annotate the simple entities and relations and speed up the annotation process. As such, the NLP Lab ensures fewer manual annotations are required from any given task. Creating NER Prompts NER prompts, can be used to identify entities in natural language text documents. Those can be created based on healthcare, finance, and legal zero-shot models selectable from the “Domain” dropdown. For one prompt, the user adds one or more questions for which the answer represents the target entity to annotate. Creating Relation Prompts Prompts can also be used to identify relations between entities for healthcare, finance, and legal domains. The domain-specific zero-shot model to use for detecting relation can be selected from the “Domain” dropdown. The relation prompts are defined by a pair of entities related by a predicate. The entities can be selected from the available dropdowns listing all entities available in the current NLP Lab (included in available NER models, prompts or rules) for the specified domain. Mix and Match models, rules, and prompts The project configuration page was simplified by grouping into one page all available resources that can be reused for pre-annotation: models, rules, and prompts. Users can easily mix and match the relevant resources and add them to their configuration. Note: One project configuration can only reuse the prompts defined by one single zero-shot model. Prompts created based on multiple zero-shot models (e.g. finance or legal or healthcare) cannot be mixed into the same project because of high resource consumption. Furthermore, all prompts require a license with a scope that matches the domain of the prompt. Zero-Shot Models available in the NLP Models Hub NLP Models Hub now lists the newly released zero-shot models that are used to define prompts. These models need to be downloaded to NLP Lab instance before prompts can be created. A valid license must be available for the models to be downloaded to NLP Lab.",
    "url": "/docs/en/alab/prompts",
    "relUrl": "/docs/en/alab/prompts"
  },
  "1319": {
    "id": "1319",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/properties.html",
    "relUrl": "/api/python/modules/sparknlp/common/properties.html"
  },
  "1320": {
    "id": "1320",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/pub_tator.html",
    "relUrl": "/api/python/modules/sparknlp/training/pub_tator.html"
  },
  "1321": {
    "id": "1321",
    "title": "Public Health - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/public_health",
    "relUrl": "/public_health"
  },
  "1322": {
    "id": "1322",
    "title": "",
    "content": "",
    "url": "/api/python/py-modindex.html",
    "relUrl": "/api/python/py-modindex.html"
  },
  "1323": {
    "id": "1323",
    "title": "Question Answering - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/question_answering",
    "relUrl": "/question_answering"
  },
  "1324": {
    "id": "1324",
    "title": "Quick Start",
    "content": "Installing Annotator &amp; PretrainedPipeline based pipelines You can create Finance Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the finance &amp; nlp module after installing the licensed libraries. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp from sparknlp.pretrained import PretrainedPipeline nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;finpipe_deid&quot;, &quot;en&quot;, &quot;finance/models&quot;) sample = &quot;&quot;&quot;CARGILL, INCORPORATED By: Pirkko Suominen Name: Pirkko Suominen Title: Director, Bio Technology Development, Date: 10/19/2011 BIOAMBER, SAS By: Jean-François Huc Name: Jean-François Huc Title: President Date: October 15, 2011 email : jeanfran@gmail.com phone : 1808733909 &quot;&quot;&quot; result = deid_pipeline.annotate(sample) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;deidentified&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Output: Masked with entity labels &lt;PARTY&gt;, &lt;PARTY&gt; By: &lt;SIGNING_PERSON&gt; Name: &lt;PARTY&gt;: &lt;SIGNING_TITLE&gt;, Date: &lt;EFFDATE&gt; &lt;PARTY&gt;, &lt;PARTY&gt; By: &lt;SIGNING_PERSON&gt; Name: &lt;PARTY&gt;: &lt;SIGNING_TITLE&gt;Date: &lt;EFFDATE&gt; email : &lt;EMAIL&gt; phone : &lt;PHONE&gt; Masked with chars [*****], [**********] By: [*************] Name: [*******************]: [**********************************] Center, Date: [********] [******], [*] By: [***************] Name: [**********************]: [*******]Date: [**************] email : [****************] phone : [********] Masked with fixed length chars ****, **** By: **** Name: ****: ****, Date: **** ****, **** By: **** Name: ****: ****Date: **** email : **** phone : **** Obfuscated MGT Trust Company, LLC., Clarus llc. By: Benjamin Dean Name: John Snow Labs Inc: Sales Manager, Date: 03/08/2025 Clarus llc., SESA CO. By: JAMES TURNER Name: MGT Trust Company, LLC.: Business ManagerDate: 11/7/2016 email : Tyrus@google.com phone : 78 834 854 Custom Pipes Alternatively you can compose Legal Annotators &amp; Open Source Annotators into a pipeline which offers the highest degree of customization. from johnsnowlabs import nlp,finance spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sparktokenizer = nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) zero_shot_ner = finance.ZeroShotNerModel.pretrained(&quot;finner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;finance/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [&#39;When was the company acquisition?&#39;, &#39;When was the company purchase agreement?&#39;], &quot;ORG&quot;: [&quot;Which company was acquired?&quot;], &quot;PRODUCT&quot;: [&quot;Which product?&quot;], &quot;PROFIT_INCREASE&quot;: [&quot;How much has the gross profit increased?&quot;], &quot;REVENUES_DECLINED&quot;: [&quot;How much has the revenues declined?&quot;], &quot;OPERATING_LOSS_2020&quot;: [&quot;Which was the operating loss in 2020&quot;], &quot;OPERATING_LOSS_2019&quot;: [&quot;Which was the operating loss in 2019&quot;] }) nerconverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages=[ documentAssembler, sparktokenizer, zero_shot_ner, nerconverter, ] ) sample_text = [&quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.&quot; &quot;We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of approximately $7,738,193 million in 2019.&quot;] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, nlp.StringType()).toDF(&quot;text&quot;)) res.select(nlp.F.explode(nlp.F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) .select(nlp.F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), nlp.F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)) .filter(&quot;ner_label!=&#39;O&#39;&quot;) .show(truncate=False) Output: ++--+ |chunk |ner_label | ++--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY AGREEMENT |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |ORG | |Delaware |STATE | |AFI Licensing LLC |ORG | |Delaware |ORG | |Seller |LICENSE_RECIPIENT| |perpetual, non- exclusive, royalty-free|LICENSE | ++--+",
    "url": "/docs/en/jsl/quickstart_finance",
    "relUrl": "/docs/en/jsl/quickstart_finance"
  },
  "1325": {
    "id": "1325",
    "title": "Quick Start",
    "content": "Installing Annotator &amp; PretrainedPipeline based pipelines You can create Legal Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the legal &amp; nlp module after installing the licensed libraries. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;legpipe_deid&quot;, &quot;en&quot;, &quot;legal/models&quot;) sample_2 = &quot;&quot;&quot;Pizza Fusion Holdings, Inc. Franchise Agreement This Franchise Agreement (the &quot;Agreement&quot;) is entered into as of the Agreement Date shown on the cover page between Pizza Fusion Holding, Inc., a Florida corporation, and the individual or legal entity identified on the cover page. Source: PF HOSPITALITY GROUP INC., 9/23/2015 1. RIGHTS GRANTED 1.1. Grant of Franchise. 1.1.1 We grant you the right, and you accept the obligation, to use the Proprietary Marks and the System to operate one Restaurant (the &quot;Franchised Business&quot;) at the Premises, in accordance with the terms of this Agreement. Source: PF HOSPITALITY GROUP INC., 9/23/2015 1.3. Our Limitations and Our Reserved Rights. The rights granted to you under this Agreement are not exclusive.sed Business. Source: PF HOSPITALITY GROUP INC., 9/23/2015 &quot;&quot;&quot; result = deid_pipeline.annotate(sample_2) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;deidentified&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Output: Masked with entity labels &lt;PARTY&gt;. &lt;DOC&gt; This &lt;DOC&gt; (the &lt;ALIAS&gt;) is entered into as of the Agreement Date shown on the cover page between &lt;PARTY&gt; a Florida corporation, and the individual or legal entity identified on the cover page. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; 1. &lt;PARTY&gt; 1.1. &lt;PARTY&gt;. 1.1.1 We grant you the right, and you accept the obligation, to use the &lt;PARTY&gt; and the System to operate one Restaurant (the &lt;ALIAS&gt;) at the Premises, in accordance with the terms of this Agreement. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; 1.3. Our &lt;PARTY&gt; and &lt;PARTY&gt;. The rights granted to you under this Agreement are not exclusive.sed Business. Source: &lt;PARTY&gt;., &lt;EFFDATE&gt; Masked with chars [************************]. [*****************] This [*****************] (the [*********]) is entered into as of the Agreement Date shown on the cover page between [*************************] a Florida corporation, and the individual or legal entity identified on the cover page. Source: [**********************]., [*******] 1. [************] 1.1. [****************]. 1.1.1 We grant you the right, and you accept the obligation, to use the [***************] and the System to operate one Restaurant (the [*******************]) at the Premises, in accordance with the terms of this Agreement. Source: [**********************]., [*******] 1.3. Our [*********] and [*****************]. The rights granted to you under this Agreement are not exclusive.sed Business. Source: [**********************]., [*******] Masked with fixed length chars ****. **** This **** (the ****) is entered into as of the Agreement Date shown on the cover page between **** a Florida corporation, and the individual or legal entity identified on the cover page. Source: ****., **** 1. **** 1.1. ****. 1.1.1 We grant you the right, and you accept the obligation, to use the **** and the System to operate one Restaurant (the ****) at the Premises, in accordance with the terms of this Agreement. Source: ****., **** 1.3. Our **** and ****. The rights granted to you under this Agreement are not exclusive.sed Business. Source: ****., **** Obfuscated SESA CO.. Estate Document This Estate Document (the (the &quot;Contract&quot;)) is entered into as of the Agreement Date shown on the cover page between Clarus llc. a Florida corporation, and the individual or legal entity identified on the cover page. Source: SESA CO.., 11/7/2016 1. SESA CO. 1.1. Clarus llc.. 1.1.1 We grant you the right, and you accept the obligation, to use the John Snow Labs Inc and the System to operate one Restaurant (the (the&quot; Agreement&quot;)) at the Premises, in accordance with the terms of this Agreement. Source: SESA CO.., 11/7/2016 1.3. Our MGT Trust Company, LLC. and John Snow Labs Inc. The rights granted to you under this Agreement are not exclusive.sed Business. Source: SESA CO.., 11/7/2016 Custom Pipes Alternatively you can compose Legal Annotators &amp; Open Source Annotators into a pipeline which offers the highest degree of customization. from johnsnowlabs import nlp,legal spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sparktokenizer = nlp.Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) zero_shot_ner = legal.ZeroShotNerModel.pretrained(&quot;legner_roberta_zeroshot&quot;, &quot;en&quot;, &quot;legal/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;DATE&quot;: [&#39;When was the company acquisition?&#39;, &#39;When was the company purchase agreement?&#39;, &quot;When was the agreement?&quot;], &quot;ORG&quot;: [&quot;Which company?&quot;], &quot;STATE&quot;: [&quot;Which state?&quot;], &quot;AGREEMENT&quot;: [&quot;What kind of agreement?&quot;], &quot;LICENSE&quot;: [&quot;What kind of license?&quot;], &quot;LICENSE_RECIPIENT&quot;: [&quot;To whom the license is granted?&quot;] }) nerconverter = nlp.NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages=[ documentAssembler, sparktokenizer, zero_shot_ner, nerconverter, ] ) sample_text = [&quot;In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.&quot;, &quot;In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.&quot;, &quot;This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the &#39;Effective Date&#39;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&#39;Seller&#39;) and AFI Licensing LLC, a Delaware company(&#39;Licensing&#39;)&quot; &quot;The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license&quot;] p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(&quot;text&quot;)) res.select(nlp.F.explode(nlp.F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) .select(nlp.F.expr(&quot;cols[&#39;0&#39;]&quot;).alias(&quot;chunk&quot;), nlp.F.expr(&quot;cols[&#39;3&#39;][&#39;entity&#39;]&quot;).alias(&quot;ner_label&quot;)) .filter(&quot;ner_label!=&#39;O&#39;&quot;) .show(truncate=False) Output: ++--+ |chunk |ner_label | ++--+ |March 2012 |DATE | |Vertro, Inc |ORG | |February 2017 |DATE | |asset purchase agreement |AGREEMENT | |NetSeer |ORG | |INTELLECTUAL PROPERTY AGREEMENT |AGREEMENT | |December 31, 2018 |DATE | |Armstrong Flooring |ORG | |Delaware |STATE | |AFI Licensing LLC |ORG | |Delaware |ORG | |Seller |LICENSE_RECIPIENT| |perpetual, non- exclusive, royalty-free|LICENSE | ++--+",
    "url": "/docs/en/jsl/quickstart_legal",
    "relUrl": "/docs/en/jsl/quickstart_legal"
  },
  "1326": {
    "id": "1326",
    "title": "Quick Start",
    "content": "You can create Medical Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the Medical &amp; nlp module after installing the licensed libraries. Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. when building a load&amp;predict based model you will follow these steps: Pick a model/pipeline/component you want to create from the Namespace Call the model = nlp.load(component) method which will return an auto-completed pipeline Call model.predict(&#39;that was easy&#39;) on some String input These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.start() medical_text = &#39;&#39;&#39; The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days&#39;&#39;&#39; nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).predict(medical_text) entity entity_class entity_confidence 5-month-old Age 0.9982 infant Age 0.9999 Monday RelativeDate 0.9983 cold Symptom 0.7517 cough Symptom 0.9969 runny nose Symptom 0.7796 for 2 days Duration 0.5479 nlp.load() defines additional components types usable in 1-liners which are only avaiable if a medical license is provided. Licensed Component Types : Component type nlp.load() base Medical Named Entity Recognition(NER) nlp.load(&#39;med.ner&#39;) Entity Resolution nlp.load(&#39;resolve&#39;) Entity Assertion nlp.load(&#39;assert&#39;) Entity Relation Classification nlp.load(&#39;relation&#39;) Entity De-Identification nlp.load(&#39;de_identify&#39;) Map Entities into Terminologies nlp.load(&#39;map_entity&#39;) Translate Entities from One Terminologies into Another Terminology nlp.load(&#39;&lt;Terminilogy&gt;_to_&lt;other_terminology&gt;&#39;) Drug Normalizers nlp.load(&#39;norm_drugs&#39;) Rule based NER with Context Matcher nlp.load(&#39;match.context&#39;) Annotator &amp; PretrainedPipeline based pipelines You can create Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the nlp module. nlp.PretrainedPipeline(&#39;pipe_name&#39;) gives access to Pretrained Pipelines from johnsnowlabs import nlp nlp.start() deid_pipeline = nlp.PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample = &quot;&quot;&quot;Name : Hendrickson, Ora, Record date: 2093-01-13, # 719435. Dr. John Green, ID: 1231511863, IP 203.120.223.13. He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93. Patient&#39;s VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver&#39;s license no:A334455B. Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com.&quot;&quot;&quot; result = deid_pipeline.annotate(sample) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) OUTPUT: Masked with entity labels Name : &lt;PATIENT&gt;, Record date: &lt;DATE&gt;, # &lt;MEDICALRECORD&gt;. Dr. &lt;DOCTOR&gt;, ID&lt;IDNUM&gt;, IP &lt;IPADDR&gt;. He is a &lt;AGE&gt; male was admitted to the &lt;HOSPITAL&gt; for cystectomy on &lt;DATE&gt;. Patient&#39;s VIN : &lt;VIN&gt;, SSN &lt;SSN&gt;, Driver&#39;s license &lt;DLN&gt;. Phone &lt;PHONE&gt;, &lt;STREET&gt;, &lt;CITY&gt;, E-MAIL: &lt;EMAIL&gt;. Masked with chars Name : [**************], Record date: [********], # [****]. Dr. [********], ID[**********], IP [************]. He is a [*********] male was admitted to the [**********] for cystectomy on [******]. Patient&#39;s VIN : [***************], SSN [**********], Driver&#39;s license [*********]. Phone [************], [***************], [***********], E-MAIL: [*************]. Masked with fixed length chars Name : ****, Record date: ****, # ****. Dr. ****, ID****, IP ****. He is a **** male was admitted to the **** for cystectomy on ****. Patient&#39;s VIN : ****, SSN ****, Driver&#39;s license ****. Phone ****, ****, ****, E-MAIL: ****. Obfuscated Name : Berneta Phenes, Record date: 2093-03-14, # Y5003067. Dr. Dr Gaston Margo, IDOX:8976967, IP 001.001.001.001. He is a 91 male was admitted to the MADONNA REHABILITATION HOSPITAL for cystectomy on 07-22-1994. Patient&#39;s VIN : 5eeee44ffff555666, SSN 999-84-3686, Driver&#39;s license S99956482. Phone 74 617 042, 1407 west stassney lane, Edmonton, E-MAIL: Carliss@hotmail.com. Custom Pipes Alternatively you can compose Annotators into a pipeline which offers the highest degree of customization from johnsnowlabs import nlp,medical spark = nlp.start() documentAssembler = nlp.DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetector() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) zero_shot_ner = medical.ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;NAME&quot;: [&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;], &quot;CITY&quot;: [&quot;Which city?&quot;, &quot;Which is the city?&quot;] }) ner_converter = medical.NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter]) zero_shot_ner_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) data = spark.createDataFrame([&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;, &quot;John is a man who works in London, London and London.&quot;], nlp.StringType()).toDF(&quot;text&quot;)",
    "url": "/docs/en/jsl/quickstart_medical",
    "relUrl": "/docs/en/jsl/quickstart_medical"
  },
  "1327": {
    "id": "1327",
    "title": "Quick Start",
    "content": "Load &amp; Predict 1 liner The johnsnowlabs library provides 2 simple methods with which most visual NLP tasks can be solved while achieving state-of-the-art results. The load and predict method. When building a load&amp;predict based model you will follow these steps: Pick a visual model/pipeline/component you want to create from the Namespace Call the model = ocr.load(&#39;visual_component&#39;) method which will return an auto-completed pipeline Call model.predict(&#39;path/to/image.png&#39;) with a path to a file or an array of paths These 3 steps can be boiled down to just 1 line from johnsnowlabs import nlp nlp.load(&#39;img2text&#39;).predict(&#39;path/to/haiku.png&#39;) jsl.load() defines 6 visual components types usable in 1-liners 1-liner Transformer Class nlp.load(&#39;img2text&#39;).predict(&#39;path/to/cat.png&#39;) ImageToText nlp.load(&#39;pdf2text&#39;).predict(&#39;path/to/taxes.pdf&#39;) PdfToText nlp.load(&#39;doc2text&#39;).predict(&#39;path/to/my_homework.docx&#39;) DocToText nlp.load(&#39;pdf2table&#39;).predict(&#39;path/to/data_tables.pdf&#39;) PdfToTextTable nlp.load(&#39;ppt2table&#39;).predict(&#39;path/to/great_presentation_with_tabular_data.pptx&#39;) PptToTextTable nlp.load(&#39;doc2table&#39;).predict(&#39;path/to/tabular_income_data.docx&#39;) DocToTextTable Custom Pipelines You can create Visual Annotator &amp; PretrainedPipeline based pipelines using all the classes attached to the visual module which gives you the highest degree of freedom from johnsnowlabs import nlp,visual spark = nlp.start(visual=True) # Load a PDF File and convert it into Spark DF format doc_example = visual.pkg_resources.resource_filename(&#39;sparkocr&#39;, &#39;resources/ocr/docs/doc2.docx&#39;) doc_example_df = spark.read.format(&quot;binaryFile&quot;).load(doc_example).cache() # Run the visual DocToText Annotator inside a pipe, recognize text and show the result pipe = nlp.PipelineModel(stages=[visual.DocToText().setInputCol(&quot;content&quot;).setOutputCol(&quot;text&quot;)]) result = pipe.transform(doc_example_df) print(result.take(1)[0].text) output:",
    "url": "/docs/en/jsl/quickstart_visual",
    "relUrl": "/docs/en/jsl/quickstart_visual"
  },
  "1328": {
    "id": "1328",
    "title": "NLP Lab (Annotation Lab)",
    "content": "The Free No-Code NLP Lab A highly efficient End-to-End No Code NLP platform for all enterprise teams that need to: Annotate Text &amp; Images Train &amp; Tune NLP Models Speedup with AI Assisted Annotation Test for Responsible AI Manage Projects &amp; Teams Enterprise Security &amp; Privacy All that without writing a line of code! Install on AWS Install on Azure Productivity Never start from scratch Keep Annotators in the Zone Reach agreement quickly Auto NLP Active learning Deliver an accurate model, not just labels Built for High Compliance Enterprise Environments Teamwork Projects &amp; Teams Workflows Security Analytics Resources General tutorials Annotation best practices Tips and tricks Quick Intro Annotation Lab evolved to become the NLP Lab. NLP Lab is a Free End-to-End No-Code platform for document labeling and AI/ML model training. It enables domain experts (e.g. nurses, doctors, lawyers, accountants, investors, etc.) to extract meaningful facts from text documents, images or PDFs and train models that will automatically predict those facts on new documents. This is done by using state-of-the-art Spark NLP pre-trained models or by tuning models to better handle specific use cases. Based on an auto-scaling architecture powered by Kubernetes, it can scale to many teams and projects. Enterprise-grade security is provided for free including support for air-gap environments, zero data sharing, role-based access, full audit trails, MFA, and identity provider integrations. It allows powerful experiments for model training and finetuning, model testing, and model deployment as API endpoints. There is no limitation on the number of users, projects, tasks, models, or trainings that can be run with this subscription. Healthcare and Visual features are available via BYOL. Included Features: Annotation support for Text, Image, Audio, Video and HTML content; High productivity annotation UI with keyboard shortcuts and pre-annotations; Support for text annotation in 250+ languages; Out-of-the-box support for the following NLP tasks: Classification, Named Entity Recognition, Assertion Status, and Relation Extraction; Support for projects and teams: 30+ project templates; unlimited projects and users, project import, export and cloning, project grouping; Task assignment, tagging, and comments; duplicate tasks identification; task searching and filtering; Consensus analysis and Inter Annotator Agreement charts; Performance dashboards; Enterprise-level security and privacy: role-based access control, role-based views, annotation versioning, full audit trail, Single Sign on; AI-Assisted Annotation: never start from scratch but reuse existing models to pre-annotate tasks with the latest Spark NLP models for classification, NER, assertion status, and relation detection; Full Models Hub integration: you can explore available models and embeddings, download them with the click of a button and reuse those in your project configuration. Train Classification, NER, and Assertion Status models: use default parameters or easily tune them on the UI for different experiments; Active Learning automatically trains new versions of your models once new annotations are available; API access to all features for easy integration into custom data analysis pipelines;",
    "url": "/docs/en/alab/quickstart",
    "relUrl": "/docs/en/alab/quickstart"
  },
  "1329": {
    "id": "1329",
    "title": "Quick Start",
    "content": "",
    "url": "/docs/en/quickstart",
    "relUrl": "/docs/en/quickstart"
  },
  "1330": {
    "id": "1330",
    "title": "Radiology - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/radiology",
    "relUrl": "/radiology"
  },
  "1331": {
    "id": "1331",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/read_as.html",
    "relUrl": "/api/python/modules/sparknlp/common/read_as.html"
  },
  "1332": {
    "id": "1332",
    "title": "Recognize Entities - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/recognize_entitie",
    "relUrl": "/recognize_entitie"
  },
  "1333": {
    "id": "1333",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/internal/recursive.html",
    "relUrl": "/api/python/modules/sparknlp/internal/recursive.html"
  },
  "1334": {
    "id": "1334",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/recursive_annotator_approach.html",
    "relUrl": "/api/python/modules/sparknlp/common/recursive_annotator_approach.html"
  },
  "1335": {
    "id": "1335",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/recursive_pipeline.html",
    "relUrl": "/api/python/modules/sparknlp/base/recursive_pipeline.html"
  },
  "1336": {
    "id": "1336",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/recursive_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/recursive_tokenizer.html"
  },
  "1337": {
    "id": "1337",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/regex_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/regex_matcher.html"
  },
  "1338": {
    "id": "1338",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/regex_tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/regex_tokenizer.html"
  },
  "1339": {
    "id": "1339",
    "title": "NLU release notes",
    "content": "NLU Version 4.0.0 OCR Visual Tables into Pandas DataFrames from PDF/DOC(X)/PPT files, 1000+ new state-of-the-art transformer models for Question Answering (QA) for over 30 languages, up to 700% speedup on GPU, 20 Biomedical models for over 8 languages, 50+ Terminology Code Mappers between RXNORM, NDC, UMLS,ICD10, ICDO, UMLS, SNOMED and MESH, Deidentification in Romanian, various Spark NLP helper methods and much more in 1 line of code with John Snow Labs NLU 4.0.0 NLU 4.0 for OCR Overview On the OCR side, we now support extracting tables from PDF/DOC(X)/PPT files into structured pandas dataframe, making it easier than ever before to analyze bulks of files visually! Checkout the OCR Tutorial for extracting Tables from Image/PDF/DOC(X) files to see this in action These models grab all Table data from the files detected and return a list of Pandas DataFrames, containing Pandas DataFrame for every table detected NLU Spell Transformer Class nlu.load(pdf2table) PdfToTextTable nlu.load(ppt2table) PptToTextTable nlu.load(doc2table) DocToTextTable This is powerd by John Snow Labs Spark OCR Annotataors for PdfToTextTable, DocToTextTable, PptToTextTable NLU 4.0 Core Overview On the NLU core side we have over 1000+ new state-of-the-art models in over 30 languages for modern extractive transformer-based Question Answering problems powerd by the ALBERT/BERT/DistilBERT/DeBERTa/RoBERTa/Longformer Spark NLP Annotators trained on various SQUAD-like QA datasets for domains like Twitter, Tech, News, Biomedical COVID-19 and in various model subflavors like sci_bert, electra, mini_lm, covid_bert, bio_bert, indo_bert, muril, sapbert, bioformer, link_bert, mac_bert Additionally up to 700% speedup transformer-based Word Embeddings on GPU and up to 97% speedup on CPU for tensorflow operations, support for Apple M1 chips, Pyspark 3.2 and 3.3 support. Ontop of this, we are now supporting Apple M1 based architectures and every Pyspark 3.X version, while deprecating support for Pyspark 2.X. Finally, NLU-Core features various new helper methods for working with Spark NLP and embellishes now the entire universe of Annotators defined by Spark NLP and Spark NLP for healthcare. NLU 4.0 for Healthcare Overview On the healthcare side NLU features 20 Biomedical models for over 8 languages (English, French, Italian, Portuguese, Romanian, Catalan and Galician) detect entities like HUMAN and SPECIES based on LivingNER corpus Romanian models for Deidentification and extracting Medical entities like Measurements, Form, Symptom, Route, Procedure, Disease_Syndrome_Disorder, Score, Drug_Ingredient, Pulse, Frequency, Date, Body_Part, Drug_Brand_Name, Time, Direction, Dosage, Medical_Device, Imaging_Technique, Test, Imaging_Findings, Imaging_Test, Test_Result, Weight, Clinical_Dept and Units with SPELL and SPELL respectively English NER models for parsing entities in Clinical Trial Abstracts like Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value using en.med_ner.clinical_trials_abstracts.pipe and also Pathogen NER models for Pathogen, MedicalCondition, Medicine with en.med_ner.pathogen and GENE_PROTEIN with en.med_ner.biomedical_bc2gm.pipeline  First Public Health Model for Emotional Stress classification It is a PHS-BERT-based model and trained with the Dreaddit dataset using en.classify.stress 50 + new Entity Mappers for problems like : Extract section headers in scientific articles and normalize them with en.map_entity.section_headers_normalized Map medical abbreviates to their definitions with en.map_entity.abbreviation_to_definition Map drugs to action and treatments with en.map_entity.drug_to_action_treatment Map drug brand to their National Drug Code (NDC) with en.map_entity.drug_brand_to_ndc Convert between terminologies using en.&lt;START_TERMINOLOGY&gt;_to_&lt;TARGET_TERMINOLOGY&gt; This works for the terminologies rxnorm, ndc, umls, icd10cm, icdo, umls, snomed, mesh snomed_to_icdo snomed_to_icd10cm rxnorm_to_umls powerd by Spark NLP for Healthcares ChunkMapper Annotator Extract Tables from PDF files as Pandas DataFrames Sample PDF: nlu.load(&#39;pdf2table&#39;).predict(&#39;/path/to/sample.pdf&#39;) Output of PDF Table OCR : mpg cyl disp hp drat wt qsec vs am gear 21 6 160 110 3.9 2.62 16.46 0 1 4 21 6 160 110 3.9 2.875 17.02 0 1 4 22.8 4 108 93 3.85 2.32 18.61 1 1 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 18.7 8 360 175 3.15 3.44 17.02 0 0 3 13.3 8 350 245 3.73 3.84 15.41 0 0 3 19.2 8 400 175 3.08 3.845 17.05 0 0 3 27.3 4 79 66 4.08 1.935 18.9 1 1 4 26 4 120.3 91 4.43 2.14 16.7 0 1 5 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 15.8 8 351 264 4.22 3.17 14.5 0 1 5 19.7 6 145 175 3.62 2.77 15.5 0 1 5 15 8 301 335 3.54 3.57 14.6 0 1 5 21.4 4 121 109 4.11 2.78 18.6 1 1 4 Extract Tables from DOC/DOCX files as Pandas DataFrames Sample DOCX: nlu.load(&#39;doc2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of DOCX Table OCR : Screen Reader Responses Share JAWS 853 49% NVDA 238 14% Window-Eyes 214 12% System Access 181 10% VoiceOver 159 9% Extract Tables from PPT files as Pandas DataFrame Sample PPT with two tables: nlu.load(&#39;ppt2table&#39;).predict(&#39;/path/to/sample.docx&#39;) Output of PPT Table OCR : Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa and Sepal.Length Sepal.Width Petal.Length Petal.Width Species 6.7 3.3 5.7 2.5 virginica 6.7 3 5.2 2.3 virginica 6.3 2.5 5 1.9 virginica 6.5 3 5.2 2 virginica 6.2 3.4 5.4 2.3 virginica 5.9 3 5.1 1.8 virginica Span Classifiers for question answering Albert, Bert, DeBerta, DistilBert, LongFormer, RoBerta, XlmRoBerta based Transformer Architectures are now avaiable for question answering with almost 1000 models avaiable for 35 unique languages powerd by their corrosponding Spark NLP XXXForQuestionAnswering Annotator Classes and in various tuning and dataset flavours. &lt;lang&gt;.answer_question.&lt;domain&gt;.&lt;datasets&gt;.&lt;annotator_class&gt;&lt;tune info&gt;.by_&lt;username&gt; If multiple datasets or tune parameters are defined , they are connected with a _ . These substrings define up the &lt;domain&gt; part of the NLU reference Legal cuad COVID 19 Biomedical biosaq Biomedical Literature pubmed Twitter tweet Wikipedia wiki News news Tech tech These substrings define up the &lt;dataset&gt; part of the NLU reference Arabic SQUAD ARCD Turkish TQUAD German GermanQuad Indonesian AQG Korean KLUE, KORQUAD HindiCHAI Multi-LingualMLQA Multi-Lingualtydiqa Multi-Lingualxquad These substrings define up the &lt;dataset&gt; part of the NLU reference Alternative Eval method reqa Synthetic Data synqa Benchmark / Eval Method ABSA-Bench roberta_absa Arabic architecture type soqaol These substrings define the &lt;annotator_class&gt; substring, if it does not map to a sparknlp annotator sci_bert electra mini_lm covid_bert bio_bert indo_bert muril sapbert bioformer link_bert mac_bert These substrings define the &lt;tune_info&gt; substring, if it does not map to a sparknlp annotator Train tweaks : multilingual,mini_lm,xtremedistiled,distilled,xtreme,augmented,zero_shot Size tweaks xl, xxl, large, base, medium, base, small, tiny, cased, uncased Dimension tweaks : 1024d,768d,512d,256d,128d,64d,32d QA DataFormat You need to use one of the Data formats below to pass context and question correctly to the model. # use ||| to seperate question||context data = &#39;What is my name?|||My name is Clara and I live in Berkeley&#39; # pass a tuple (question,context) data = (&#39;What is my name?&#39;,&#39;My name is Clara and I live in Berkeley&#39;) # use pandas Dataframe, one column = question, one column=context data = pd.DataFrame({ &#39;question&#39;: [&#39;What is my name?&#39;], &#39;context&#39;: [&quot;My name is Clara and I live in Berkely&quot;] }) # Get your answers with any of above formats nlu.load(&quot;en.answer_question.squadv2.deberta&quot;).predict(data) returns : answer answer_confidence context question Clara 0.994931 My name is Clara and I live in Berkely What is my name? New NLU helper Methods You can see all features showcased in the notebook or on the new docs page for Spark NLP utils nlu.viz(pipe,data) Visualize input data with an already configured Spark NLP pipeline, for Algorithms of type (Ner,Assertion, Relation, Resolution, Dependency) using Spark NLP Display Automatically infers applicable viz type and output columns to use for visualization. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu.viz(ade_pipeline, text) returns: If a pipeline has multiple models candidates that can be used for a viz, the first Annotator that is vizzable will be used to create viz. You can specify which type of viz to create with the viz_type parameter Output columns to use for the viz are automatically deducted from the pipeline, by using the first annotator that provides the correct output type for a specific viz. You can specify which columns to use for a viz by using the corresponding ner_col, pos_col, dep_untyped_col, dep_typed_col, resolution_col, relation_col, assertion_col, parameters. nlu.autocomplete_pipeline(pipe) Auto-Complete a pipeline or single annotator into a runnable pipeline by harnessing NLU’s DAG Autocompletion algorithm and returns it as NLU pipeline. The standard Spark pipeline is avaiable on the .vanilla_transformer_pipe attribute of the returned nlu pipe Every Annotator and Pipeline of Annotators defines a DAG of tasks, with various dependencies that must be satisfied in topoligical order. NLU enables the completion of an incomplete DAG by finding or creating a path between the very first input node which is almost always is DocumentAssembler/MultiDocumentAssembler and the very last node(s), which is given by the topoligical sorting the iterable annotators parameter. Paths are created by resolving input features of annotators to the corrrosponding providers with matching storage references. Example: # Lets autocomplete the pipeline for a RelationExtractionModel, which as many input columns and sub-dependencies. from sparknlp_jsl.annotator import RelationExtractionModel re_model = RelationExtractionModel().pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;).setOutputCol(&#39;relation&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlu.autocomplete_pipeline(re_model) nlu_pipe.predict(text) returns : relation relation_confidence relation_entity1 relation_entity2 relation_entity2_class 1 1 allergic reaction vancomycin Drug_Ingredient 1 1 skin itchy Symptom 1 0.99998 skin sore throat/burning/itchy Symptom 1 0.956225 skin numbness Symptom 1 0.999092 skin tongue External_body_part_or_region 0 0.942927 skin gums External_body_part_or_region 1 0.806327 itchy sore throat/burning/itchy Symptom 1 0.526163 itchy numbness Symptom 1 0.999947 itchy tongue External_body_part_or_region 0 0.994618 itchy gums External_body_part_or_region 0 0.994162 sore throat/burning/itchy numbness Symptom 1 0.989304 sore throat/burning/itchy tongue External_body_part_or_region 0 0.999969 sore throat/burning/itchy gums External_body_part_or_region 1 1 numbness tongue External_body_part_or_region 1 1 numbness gums External_body_part_or_region 1 1 tongue gums External_body_part_or_region nlu.to_pretty_df(pipe,data) Annotates a Pandas Dataframe/Pandas Series/Numpy Array/Spark DataFrame/Python List strings /Python String with given Spark NLP pipeline, which is assumed to be complete and runnable and returns it in a pythonic pandas dataframe format. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; # output is same as nlu.autocomplete_pipeline(re_model).nlu_pipe.predict(text) nlu.to_pretty_df(ade_pipeline,text) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 Annotators are grouped internally by NLU into output levels token,sentence, document,chunk and relation Same level annotators output columns are zipped and exploded together to create the final output df. Additionally, most keys from the metadata dictionary in the result annotations will be collected and expanded into their own columns in the resulting Dataframe, with special handling for Annotators that encode multiple metadata fields inside of one, seperated by strings like ||| or :::. Some columns are omitted from metadata to reduce total amount of output columns, these can be re-enabled by setting metadata=True For a given pipeline output level is automatically set to the last anntators output level by default. This can be changed by defining to_preddty_df(pipe,text,output_level=&#39;my_level&#39; for levels token,sentence, document,chunk and relation . nlu.to_nlu_pipe(pipe) Convert a pipeline or list of annotators into a NLU pipeline making .predict() and .viz() avaiable for every Spark NLP pipeline. Assumes the pipeline is already runnable. # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlu.to_nlu_pipe(ade_pipeline) # Same output as nlu.to_pretty_df(pipe,text) nlu_pipe.predict(text) # same output as nlu.viz(pipe,text) nlu_pipe.viz(text) # Acces auto-completed Spark NLP big data pipeline, nlu_pipe.vanilla_transformer_pipe.transform(spark_df) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 and 4 new Demo Notebooks These notebooks showcase some of latest classifier models for Banking Queries, Intents in Text, Question and new s classification Notebook for Classification of Banking Queries Notebook for Classification of Intent in Texts Notebook for classification of Similar Questions Notebook for Classification of Questions vs Statements Notebook for Classification of News into 4 classes NLU captures every Annotator of Spark NLP and Spark NLP for healthcare The entire universe of Annotators in Spark NLP and Spark-NLP for healthcare is now embellished by NLU Components by using generalizable annotation extractors methods and configs internally to support enable the new NLU util methods. The following annotator classes are newly captured: AssertionFilterer ChunkConverter ChunkKeyPhraseExtraction ChunkSentenceSplitter ChunkFiltererApproach ChunkFilterer ChunkMapperApproach ChunkMapperFilterer DocumentLogRegClassifierApproach DocumentLogRegClassifierModel ContextualParserApproach ReIdentification NerDisambiguator NerDisambiguatorModel AverageEmbeddings EntityChunkEmbeddings ChunkMergeApproach ChunkMergeApproach IOBTagger NerChunker NerConverterInternalModel DateNormalizer PosologyREModel RENerChunksFilter ResolverMerger AnnotationMerger Router Word2VecApproach WordEmbeddings EntityRulerApproach EntityRulerModel TextMatcherModel BigTextMatcher BigTextMatcherModel DateMatcher MultiDateMatcher RegexMatcher TextMatcher NerApproach NerCrfApproach NerOverwriter DependencyParserApproach TypedDependencyParserApproach SentenceDetectorDLApproach SentimentDetector ViveknSentimentApproach ContextSpellCheckerApproach NorvigSweetingApproach SymmetricDeleteApproach ChunkTokenizer ChunkTokenizerModel RecursiveTokenizer RecursiveTokenizerModel Token2Chunk WordSegmenterApproach GraphExtraction Lemmatizer Normalizer All NLU 4.0 for Healthcare Models Some examples: en.rxnorm.umls.mapping Code: nlu.load(&#39;en.rxnorm.umls.mapping&#39;).predict(&#39;1161611 315677&#39;) mapped_entity_umls_code_origin_entity mapped_entity_umls_code 1161611 C3215948 315677 C0984912 en.ner.clinical_trials_abstracts Code: nlu.load(&#39;en.ner.clinical_trials_abstracts&#39;).predict(&#39;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&#39;) Results:   entities_clinical_trials_abstracts entities_clinical_trials_abstracts_class entities_clinical_trials_abstracts_confidence 0 randomised CTDesign 0.9996 0 multicentre CTDesign 0.9998 0 insulin glargine Drug 0.99135 0 NPH insulin Drug 0.96875 0 type 2 diabetes DisorderOrSyndrome 0.999933 Code: nlu.load(&#39;en.ner.clinical_trials_abstracts&#39;).viz(&#39;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&#39;) Results: en.med_ner.pathogen Code: nlu.load(&#39;en.med_ner.pathogen&#39;).predict(&#39;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&#39;) Results:   entities_pathogen entities_pathogen_class entities_pathogen_confidence 0 Racecadotril Medicine 0.9468 0 loperamide Medicine 0.9987 0 Diarrhea MedicalCondition 0.9848 0 dehydration MedicalCondition 0.6307 0 rabies virus Pathogen 0.95685 0 Lyssavirus Pathogen 0.9694 0 Ephemerovirus Pathogen 0.6917 Code: nlu.load(&#39;en.med_ner.pathogen&#39;).viz(&#39;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&#39;) Results: es.med_ner.living_species.roberta Code: nlu.load(&#39;es.med_ner.living_species.roberta&#39;).predict(&#39;Lactante varón de dos años. Antecedentes familiares sin interés. Antecedentes personales: Embarazo, parto y periodo neonatal normal. En seguimiento por alergia a legumbres, diagnosticado con diez meses por reacción urticarial generalizada con lentejas y garbanzos, con dieta de exclusión a legumbres desde entonces. En ésta visita la madre describe episodios de eritema en zona maxilar derecha con afectación ocular ipsilateral que se resuelve en horas tras la administración de corticoides. Le ha ocurrido en 5-6 ocasiones, en relación con la ingesta de alimentos previamente tolerados. Exploración complementaria: Cacahuete, ac(ige)19.2 Ku.arb/l. Resultados: Ante la sospecha clínica de Síndrome de Frey, se tranquiliza a los padres, explicándoles la naturaleza del cuadro y se cita para revisión anual.&#39;) Results:   entities_living_species entities_living_species_class entities_living_species_confidence 0 Lactante varón HUMAN 0.93175 0 familiares HUMAN 1 0 personales HUMAN 1 0 neonatal HUMAN 0.9997 0 legumbres SPECIES 0.9962 0 lentejas SPECIES 0.9988 0 garbanzos SPECIES 0.9901 0 legumbres SPECIES 0.9976 0 madre HUMAN 1 0 Cacahuete SPECIES 0.998 0 padres HUMAN 1 Code: nlu.load(&#39;es.med_ner.living_species.roberta&#39;).viz(&#39;Lactante varón de dos años. Antecedentes familiares sin interés. Antecedentes personales: Embarazo, parto y periodo neonatal normal. En seguimiento por alergia a legumbres, diagnosticado con diez meses por reacción urticarial generalizada con lentejas y garbanzos, con dieta de exclusión a legumbres desde entonces. En ésta visita la madre describe episodios de eritema en zona maxilar derecha con afectación ocular ipsilateral que se resuelve en horas tras la administración de corticoides. Le ha ocurrido en 5-6 ocasiones, en relación con la ingesta de alimentos previamente tolerados. Exploración complementaria: Cacahuete, ac(ige)19.2 Ku.arb/l. Resultados: Ante la sospecha clínica de Síndrome de Frey, se tranquiliza a los padres, explicándoles la naturaleza del cuadro y se cita para revisión anual.&#39;) Results: All healthcare models added in NLU 4.0 : Language NLU Reference Spark NLP Reference Task Annotator Class model_id en en.map_entity.abbreviation_to_definition abbreviation_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.abbreviation_to_definition en en.map_entity.abbreviation_to_definition abbreviation_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.abbreviation_to_definition en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_to_action_treatment drug_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_to_action_treatment en en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_brand_to_ndc en en.map_entity.drug_brand_to_ndc drug_brandname_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.drug_brand_to_ndc en en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_snomed en en.map_entity.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_umls en en.map_entity.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icdo_to_snomed en en.map_entity.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.mesh_to_umls en en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_action_treatment en en.map_entity.rxnorm_to_action_treatment rxnorm_action_treatment_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_action_treatment en en.map_entity.rxnorm_resolver rxnorm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_resolver en en.map_entity.rxnorm_resolver rxnorm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_resolver en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_ndc rxnorm_ndc_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_ndc en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icd10cm en en.map_entity.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icdo en en.map_entity.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_umls en en.map_entity.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icd10cm en en.map_entity.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_snomed en en.map_entity.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_icdo en en.map_entity.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icdo_to_snomed en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.rxnorm_to_umls en en.map_entity.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.icd10cm_to_umls en en.map_entity.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.mesh_to_umls en en.map_entity.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.map_entity.snomed_to_umls en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.map_entity.section_headers_normalized normalized_section_header_mapper Chunk Mapping PretrainedPipeline Chunk Mappingen.map_entity.section_headers_normalized en en.icd10cm_to_snomed icd10cm_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icd10cm_to_snomed en en.icd10cm_to_umls icd10cm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icd10cm_to_umls en en.icdo_to_snomed icdo_snomed_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.icdo_to_snomed en en.mesh_to_umls mesh_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.mesh_to_umls en en.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.rxnorm_to_umls en en.rxnorm_to_umls rxnorm_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.rxnorm_to_umls en en.snomed_to_icd10cm snomed_icd10cm_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_icd10cm en en.snomed_to_icdo snomed_icdo_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_icdo en en.snomed_to_umls snomed_umls_mapper Chunk Mapping ChunkMapperModel Chunk Mappingen.snomed_to_umls en en.map_entity.icd10cm_to_snomed.pipe icd10cm_snomed_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.icd10cm_to_snomed.pipe en en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icd10cm.pipe en en.map_entity.snomed_to_icd10cm.pipe snomed_icd10cm_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icd10cm.pipe en en.map_entity.icdo_to_snomed.pipe icdo_snomed_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.icdo_to_snomed.pipe en en.map_entity.snomed_to_icdo.pipe snomed_icdo_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.snomed_to_icdo.pipe en en.map_entity.rxnorm_to_ndc.pipe rxnorm_ndc_mapping Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.map_entity.rxnorm_to_ndc.pipe en en.med_ner.pathogen.pipeline ner_pathogen_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.pathogen.pipeline en en.med_ner.biomedical_bc2gm.pipeline ner_biomedical_bc2gm_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.biomedical_bc2gm.pipeline ro ro.deid.clinical clinical_deidentification Pipeline Healthcare MedicalNerModel Pipeline Healthcarero.deid.clinical en en.med_ner.clinical_trials_abstracts.pipe ner_clinical_trials_abstracts_pipeline Pipeline Healthcare PretrainedPipeline Pipeline Healthcareen.med_ner.clinical_trials_abstracts.pipe en en.ner.clinical_trials_abstracts ner_clinical_trials_abstracts Named Entity Recognition MedicalNerModel Named Entity Recognitionen.ner.clinical_trials_abstracts en en.med_ner.clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionen.med_ner.clinical_trials_abstracts en en.med_ner.pathogen ner_pathogen Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.pathogen en en.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionen.med_ner.living_species.token_bert en en.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.living_species en en.med_ner.living_species.biobert ner_living_species_biobert Named Entity Recognition MedicalNerModel Named Entity Recognitionen.med_ner.living_species.biobert en en.classify.stress bert_sequence_classifier_stress Text Classification MedicalBertForSequenceClassification Text Classificationen.classify.stress es es.embed.scielo300d embeddings_scielo_300d Embeddings WordEmbeddingsModel Embeddingses.embed.scielo300d es es.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species es es.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.bert es es.med_ner.living_species.roberta ner_living_species_roberta Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.roberta es es.med_ner.living_species.300 ner_living_species_300 Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species.300 es es.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiones.med_ner.living_species fr fr.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionfr.med_ner.living_species fr fr.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionfr.med_ner.living_species.bert pt pt.med_ner.living_species.token_bert bert_token_classifier_ner_living_species Named Entity Recognition MedicalBertForTokenClassifier Named Entity Recognitionpt.med_ner.living_species.token_bert pt pt.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species pt pt.med_ner.living_species.roberta ner_living_species_roberta Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species.roberta pt pt.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionpt.med_ner.living_species.bert it it.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species it it.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species.bert it it.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionit.med_ner.living_species ca ca.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitionca.med_ner.living_species gl gl.med_ner.living_species ner_living_species Named Entity Recognition MedicalNerModel Named Entity Recognitiongl.med_ner.living_species ro ro.med_ner.living_species.bert ner_living_species_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.living_species.bert ro ro.med_ner.clinical ner_clinical Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.clinical ro ro.embed.clinical.bert.base_cased ner_clinical_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.embed.clinical.bert.base_cased ro ro.med_ner.deid.subentity ner_deid_subentity Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.deid.subentity ro ro.med_ner.deid.subentity.bert ner_deid_subentity_bert Named Entity Recognition MedicalNerModel Named Entity Recognitionro.med_ner.deid.subentity.bert All NLU 4.0 Core Models All core models added in NLU 4.0 : Can be found on the NLU website because of Github Limitations NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class bn.answer_question.tydiqa.multi_lingual_bert bert_qa_mbert_bengali_tydiqa_qa Question Answering Bengali BertForQuestionAnswering es.answer_question.squadv2.electra.small electra_qa_biomedtra_small_es_squad2 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad_sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac_finetuned_squad Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.base_cased.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_squad2_es_MMG Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.base_cased.by_mrm8488 bert_qa_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_mrm8488 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2.bert.distilled_base_cased bert_qa_distill_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_mrm8488 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad.ruperta.base.by_mrm8488 roberta_qa_RuPERTa_base_finetuned_squadv1 Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2.roberta.base roberta_qa_roberta_base_bne_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased_spa.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_spa_squad2_es_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2_bio_medical.roberta.base roberta_qa_roberta_base_biomedical_es_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_clinical_bio_medical.roberta.base roberta_qa_roberta_base_biomedical_clinical_es_squad2_hackathon_pln Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac_finetuned_squad2_es_MMG Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squadv2_sqac.bert.base_cased_v2.by_MMG bert_qa_bert_base_spanish_wwm_cased_finetuned_squad2_es_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_spanish Question Answering Castilian, Spanish XlmRoBertaForQuestionAnswering es.answer_question.xlm_roberta.multilingual_large xlm_roberta_qa_xlm_roberta_large_qa_multilingual_finedtuned_ru_ru_AlexKay Question Answering Castilian, Spanish XlmRoBertaForQuestionAnswering es.answer_question.squad.roberta.large.by_stevemobs roberta_qa_roberta_large_fine_tuned_squad_es_stevemobs Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squadv2.roberta.base_v2 roberta_qa_RuPERTa_base_finetuned_squadv2 Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.large.by_jamarju roberta_qa_roberta_large_bne_squad_2.0_es_jamarju Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_BSC-TeMU roberta_qa_BSC_TeMU_roberta_large_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.base.by_jamarju roberta_qa_roberta_base_bne_squad_2.0_es_jamarju Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.roberta.base_4096.by_mrm8488 roberta_qa_longformer_base_4096_spanish_finetuned_squad Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_tar Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.mlqa.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_mlqa Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.sqac.bert.base bert_qa_beto_base_spanish_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.sqac.distil_bert.base_uncased distilbert_qa_distillbert_base_spanish_uncased_finetuned_qa_sqac Question Answering Castilian, Spanish DistilBertForQuestionAnswering es.answer_question.sqac.roberta.base.by_BSC-TeMU roberta_qa_BSC_TeMU_roberta_base_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_IIC roberta_qa_roberta_base_spanish_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_sqac Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.sqac.roberta.base.by_mrm8488 roberta_qa_mrm8488_roberta_base_bne_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_nlp-en-es roberta_qa_nlp_en_es_roberta_base_bne_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_PlanTL-GOB-ES roberta_qa_PlanTL_GOB_ES_roberta_large_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.large.by_nlp-en-es roberta_qa_bertin_large_finetuned_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.squad.electra.small electra_qa_electricidad_small_finetuned_squadv1 Question Answering Castilian, Spanish BertForQuestionAnswering es.answer_question.squad.roberta.base.by_IIC roberta_qa_roberta_base_spanish_squades Question Answering Castilian, Spanish RoBertaForQuestionAnswering es.answer_question.sqac.roberta.base.by_PlanTL-GOB-ES roberta_qa_PlanTL_GOB_ES_roberta_base_bne_sqac Question Answering Castilian, Spanish RoBertaForQuestionAnswering ch.answer_question.xlm_roberta xlm_roberta_qa_ADDI_CH_XLM_R Question Answering Chamorro XlmRoBertaForQuestionAnswering da.answer_question.squad.bert bert_qa_danish_bert_botxo_qa_squad Question Answering Danish BertForQuestionAnswering da.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_da_da_saattrupdan Question Answering Danish XlmRoBertaForQuestionAnswering nl.answer_question.squadv2.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_dutch_squad2 Question Answering Dutch, Flemish BertForQuestionAnswering en.answer_question.squad.roberta.large.by_csarron roberta_qa_roberta_large_squad_v1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.large.by_rahulchakwate roberta_qa_roberta_large_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.scibert.by_amoux bert_qa_scibert_nli_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.scibert.by_ixa-ehu bert_qa_SciBERT_SQuAD_QuAC Question Answering English BertForQuestionAnswering en.answer_question.squad.scibert.uncased bert_qa_scibert_scivocab_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert bert_qa_spanbert_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_128d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_128_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_256d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_256_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.distilled_base roberta_qa_distilroberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_1024d_seed_42 bert_qa_spanbert_base_cased_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.distilled roberta_qa_distilroberta_finetuned_squadv1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_sq.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_5_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_sunitha roberta_qa_Roberta_Custom_Squad_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_6 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_8 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_deletion_10.by_huxxx657 roberta_qa_roberta_base_finetuned_deletion_squad_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_deletion_15.by_huxxx657 roberta_qa_roberta_base_finetuned_deletion_squad_15 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_sae.by_jgammack roberta_qa_SAE_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_10.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_10_new.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_10_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_15.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_15 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_15_v2.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_15_new Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_scrambled_5.by_huxxx657 roberta_qa_roberta_base_finetuned_scrambled_squad_5 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_vuiseng9 roberta_qa_roberta_l_squadv1.1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_32d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_32_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_seed_10 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_2 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_4 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_42 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_6 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_8 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v1.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v2.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_v3.by_huxxx657 roberta_qa_roberta_base_finetuned_squad_3 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.by_cgou roberta_qa_fin_RoBERTa_v1_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_seed_0 roberta_qa_roberta_base_few_shot_k_16_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.bert.cased.by_batterydata bert_qa_batterybert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_replydotai albert_qa_xxlarge_v1_finetuned_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_sultan albert_qa_BioM_xxlarge_SQuAD2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl_512d albert_qa_xxlargev1_squad2_512 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xxl_v2 albert_qa_xxlarge_v2_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.bert.base bert_qa_bert_base_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_deepset bert_base_cased_qa_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_vumichien bert_qa_tf_bert_base_cased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_cased.by_ydshieh bert_qa_ydshieh_bert_base_cased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_Vasanth bert_qa_bert_base_uncased_qa_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_deepset bert_qa_deepset_bert_base_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased.by_twmkn9 bert_qa_twmkn9_bert_base_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_uncased_v2 bert_qa_bert_base_uncased_finetuned_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_v2.by_mrm8488 bert_qa_bert_mini_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.base_v2_5.by_mrm8488 bert_qa_bert_mini_5_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_augustoortiz bert_qa_bert_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_maroo93 bert_qa_squad2.0 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.by_pinecone bert_qa_bert_reader_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.distilled bert_qa_xdistil_l12_h384_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.distilled_medium bert_qa_bert_medium_squad2_distilled Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large.by_Sindhu bert_qa_muril_large_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large.by_phiyodr bert_qa_bert_large_finetuned_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.xxl.by_elgeish albert_qa_cs224n_squad2.0_xxlarge_v1 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.xl_v2 albert_qa_xlarge_v2_squad_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.large_v2 albert_qa_cs224n_squad2.0_large_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2.albert.base_v2.by_vumichien albert_qa_vumichien_base_v2_squad2 Question Answering English AlbertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_8 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_8 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_0 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_2 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_4 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_4 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_64d_seed_6 bert_qa_spanbert_base_cased_few_shot_k_64_finetuned_squad_seed_6 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_seed_42 bert_qa_spanbert_base_cased_few_shot_k_16_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.xlm_roberta.by_jakobwes xlm_roberta_qa_xlm_roberta_squad_v1.1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad.xlm_roberta.by_meghana xlm_roberta_qa_hitalmqa_finetuned_squad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad_battery.bert.base_uncased bert_qa_batterydata_bert_base_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.span_bert.base_cased_512d_seed_10 bert_qa_spanbert_base_cased_few_shot_k_512_finetuned_squad_seed_10 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_4 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad_battery.bert.uncased.by_batterydata bert_qa_batterybert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.bert.uncased_only_bert.by_batterydata bert_qa_batteryonlybert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.scibert.cased bert_qa_batteryscibert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_battery.scibert.uncased bert_qa_batteryscibert_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad_ben_tel.bert.by_krinal214 bert_qa_bert_all_squad_ben_tel_context Question Answering English BertForQuestionAnswering en.answer_question.squad_covid.bert bert_qa_covid_squad Question Answering English BertForQuestionAnswering en.answer_question.squad_pubmed.biobert bert_qa_biobert_v1.1_pubmed_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad_translated.bert.by_krinal214 bert_qa_bert_all_squad_all_translated Question Answering English BertForQuestionAnswering en.answer_question.squad_translated.bert.que.by_krinal214 bert_qa_bert_all_squad_que_translated Question Answering English BertForQuestionAnswering en.answer_question.squadv2.albert.base_v2.by_elgeish albert_qa_cs224n_squad2.0_base_v2 Question Answering English AlbertForQuestionAnswering en.answer_question.squad_battery.bert.cased_only_bert.by_batterydata bert_qa_batteryonlybert_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_2 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_10 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_0 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_mtl.by_jgammack distilbert_qa_MTL_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_sae.by_jgammack distilbert_qa_SAE_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_arvalinno distilbert_qa_base_uncased_finetuned_indosquad_v2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_ericRosello distilbert_qa_base_uncased_finetuned_squad_frozen_v2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_holtin distilbert_qa_holtin_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v2.by_huxxx657 distilbert_qa_base_uncased_finetuned_jumbling_squad_15 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_v3.by_anurag0077 distilbert_qa_anurag0077_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_AyushPJ distilbert_qa_test_squad_trained_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_ZYW distilbert_qa_test_squad_trained Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_abhilash1910 distilbert_qa_squadv1 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_rowan1224 distilbert_qa_squad_slp Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_sunitha distilbert_qa_AQG_CV_Squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.by_tabo distilbert_qa_checkpoint_500_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra electra_qa_squad_slp Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_Palak electra_qa_google_base_discriminator_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_mrm8488 electra_qa_base_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_usami electra_qa_base_discriminator_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.base.by_valhalla electra_qa_base_discriminator_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.large.by_howey electra_qa_large_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.small.by_Palak electra_qa_google_small_discriminator_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.electra.small.by_bdickson electra_qa_small_discriminator_finetuned_squad_1 Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_full.by_holtin distilbert_qa_base_uncased_holtin_finetuned_full_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased_colab.by_Adrian distilbert_qa_base_uncased_finetuned_squad_colab Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vkrishnamoorthy distilbert_qa_vkrishnamoorthy_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vkmr distilbert_qa_vkmr_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_gokulkarthik distilbert_qa_gokulkarthik_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_graviraja distilbert_qa_graviraja_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_guhuawuli distilbert_qa_guhuawuli_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hark99 distilbert_qa_hark99_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hcy11 distilbert_qa_hcy11_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_hiiii23 distilbert_qa_hiiii23_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_holtin distilbert_qa_base_uncased_holtin_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_huggingfaceepita distilbert_qa_huggingfaceepita_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_huxxx657 distilbert_qa_huxxx657_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jgammack distilbert_qa_jgammack_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra.small.by_hankzhong electra_qa_hankzhong_small_discriminator_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jhoonk distilbert_qa_jhoonk_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_kaggleodin distilbert_qa_kaggleodin_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_lewtun distilbert_qa_base_uncased_finetuned_squad_v1 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_machine2049 distilbert_qa_base_uncased_finetuned_squad_ Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_manudotc distilbert_qa_transformers_base_uncased_finetuneQA_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_sunitha distilbert_qa_base_uncased_3feb_2022_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_tli8hf distilbert_qa_unqover_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_tucan9389 distilbert_qa_tucan9389_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_uploaded by huggingface distilbert_qa_base_uncased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_usami distilbert_qa_usami_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_vitusya distilbert_qa_vitusya_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_jsunster distilbert_qa_jsunster_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.roberta.base_64d_seed_10 roberta_qa_roberta_base_few_shot_k_64_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.electra.small.by_mrm8488 electra_qa_small_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.ixam_bert.by_MarcBrun bert_qa_ixambert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_42 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_6 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_8 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_0 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_10 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_2 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_4 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_6 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_256d_seed_8 roberta_qa_roberta_base_few_shot_k_256_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_0 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.bert.large_tiny_768d.by_MichelBartels bert_qa_tinybert_6l_768d_squad2_large_teacher_finetuned Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_2 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_4 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_6 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_32d_seed_8 roberta_qa_roberta_base_few_shot_k_32_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_0 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_10 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_2 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_4 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_6 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_512d_seed_8 roberta_qa_roberta_base_few_shot_k_512_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_4 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_2 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_10 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_128d_seed_0 roberta_qa_roberta_base_few_shot_k_128_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.ixam_bert.eu_en_tunedby_MarcBrun bert_qa_ixambert_finetuned_squad_eu_en_MarcBrun Question Answering English BertForQuestionAnswering en.answer_question.squad.ixam_bert.eu_tuned.by_MarcBrun bert_qa_ixambert_finetuned_squad_eu_MarcBrun Question Answering English BertForQuestionAnswering en.answer_question.squad.link_bert.large bert_qa_linkbert_large_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.by_ZYW bert_qa_squad_mbert_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.en_de_es.by_ZYW bert_qa_squad_mbert_en_de_es_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.en_de_es_vi_zh.by_ZYW bert_qa_squad_mbert_en_de_es_vi_zh_model Question Answering English BertForQuestionAnswering en.answer_question.squad.multi_lingual_bert.v2.by_ZYW bert_qa_squad_mbert_model_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base.by_Firat roberta_qa_Firat_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_ahmedattia143 roberta_qa_roberta_squadv1_base Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_csarron roberta_qa_roberta_base_squad_v1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.electra.small_v2.by_bdickson electra_qa_small_discriminator_finetuned_squad_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.roberta.base.by_huxxx657 roberta_qa_huxxx657_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_mrm8488 roberta_qa_roberta_base_1B_1_finetuned_squadv1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_rahulchakwate roberta_qa_rahulchakwate_roberta_base_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_tli8hf roberta_qa_unqover_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_0 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_10 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_10 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_2 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_4 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_42 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_6 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_6 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base_1024d_seed_8 roberta_qa_roberta_base_few_shot_k_1024_finetuned_squad_seed_8 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.roberta.base.by_jgammack roberta_qa_roberta_base_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.bert.large_tiny_768d_v2.by_MichelBartels bert_qa_tinybert_6l_768d_squad2_large_teacher_finetuned_step1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_768d bert_qa_tinybert_6l_768d_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_mit_restaurant_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_6l_128d_a2a_128d bert_qa_bert_uncased_L_6_H_128_A_2_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.distil_bert.base_uncased distilbert_qa_base_uncased_squad2_covid_qa_deepset Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_covid.electra.base electra_qa_base_squad2_covid_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.roberta.base.by_armageddon roberta_qa_roberta_base_squad2_covid_qa_deepset Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid.roberta.base.by_deepset roberta_qa_roberta_base_squad2_covid Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid.roberta.large roberta_qa_roberta_large_squad2_covid_qa_deepset Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid_cord19.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_cord19_200616_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.bert.v2 bert_qa_pubmed_bert_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.biobert.v2 bert_qa_biobert_v1.1_pubmed_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_pubmed.sapbert bert_qa_sapbert_from_pubmedbert_squad2 Question Answering English BertForQuestionAnswering en.answer_question.synqa.electra.large electra_qa_large_synqa Question Answering English BertForQuestionAnswering en.answer_question.synqa.roberta.large.by_mbartolo roberta_qa_roberta_large_synqa Question Answering English RoBertaForQuestionAnswering en.answer_question.synqa_ext.roberta.large.by_mbartolo roberta_qa_roberta_large_synqa_ext Question Answering English RoBertaForQuestionAnswering en.answer_question.tquad.bert.xtremedistiled_uncased bert_qa_xtremedistil_l6_h256_uncased_TQUAD_finetuned_lr_2e_05_epochs_9 Question Answering English BertForQuestionAnswering en.answer_question.trial.bert.by_sunitha bert_qa_Trial_3_Results Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_squad2_covid_qna Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.large_uncased bert_qa_bert_large_uncased_squad2_covid_qa_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.bert.base_uncased bert_qa_bert_base_uncased_squad2_covid_qa_deepset Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.distilled_base xlm_roberta_qa_xlm_roberta_base_squad2_distilled Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_squad2 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_bioasq8b.electra.base electra_qa_BioM_Base_SQuAD2_BioASQ8B Question Answering English BertForQuestionAnswering en.answer_question.squadv2_bioasq8b.electra.large electra_qa_BioM_Large_SQuAD2_BioASQ8B Question Answering English BertForQuestionAnswering en.answer_question.squadv2_chaii.xlm_roberta.distilled_base xlm_roberta_qa_xlm_roberta_base_squad2_distilled_finetuned_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_chaii.xlm_roberta.distilled_base_small xlm_roberta_qa_xlm_roberta_base_squad2_distilled_finetuned_chaii_small Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2_chemical.bert.uncased bert_qa_chemical_bert_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased_pistherea.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_Pistherea_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.squadv2_conll.bert.large_uncased_pwhatisthe.by_andi611 bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_Pwhatisthe_conll2003_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.trivia.albert.xxl albert_qa_xxlarge_tweetqa Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased.by_andi611 distilbert_qa_base_uncased_squad2_with_ner Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_multi.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_multi Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_multi_with_repeat.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_multi_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg_with_repeat.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2_cord19.bert.small bert_qa_bert_small_cord19_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_cord19.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_cord19_200616_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2_covid.albert.xxl_v2 albert_qa_xxlarge_v2_squad2_covid_deepset Question Answering English AlbertForQuestionAnswering en.answer_question.squadv2_conll.distil_bert.base_uncased_with_neg.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_with_neg Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_v2 xlm_roberta_qa_squadv2_xlm_roberta_base Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.trivia.bert.base_1024d bert_qa_bert_base_1024_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.base_4096.by_MrAnderson bert_qa_bert_base_4096_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265898 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265898 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265899 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265899 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265900 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265900 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265901 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265901 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265902 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265902 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265903 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265903 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265904 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265904 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265905 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265905 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265906 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265906 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265907 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265907 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265908 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265908 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265909 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265909 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265910 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265910 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265911 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265911 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.fr_tuned.by_Gantenbein roberta_qa_ADDI_FR_XLM_R Question Answering English RoBertaForQuestionAnswering en.answer_question.xlmr_roberta xlm_roberta_qa_XLMr_ENIS_QA_IsQ_EnA Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad.bert.multilingual_base bert_qa_bert_base_multilingual_xquad Question Answering English BertForQuestionAnswering en.answer_question.xquad.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_xquad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_xquad Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xquad_chaii.bert.cased bert_qa_bert_multi_cased_finedtuned_xquad_chaii Question Answering English BertForQuestionAnswering en.answer_question.xquad_squad.bert.cased bert_qa_bert_multi_cased_finetuned_xquadv1_finetuned_squad_colab Question Answering English BertForQuestionAnswering en.answer_question.xlm_roberta.fine_tune_24465520_26265897 xlm_roberta_qa_autonlp_more_fine_tune_24465520_26265897 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_ncthuan xlm_roberta_qa_xlm_l_uetqa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_laifuchicago xlm_roberta_qa_farm2tran Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_jeew xlm_roberta_qa_xlm_roberta_ckpt_95000 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.trivia.bert.base_512d bert_qa_bert_base_512_full_trivia Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.by_Danastos bert_qa_triviaqa_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.by_Kutay bert_qa_fine_tuned_tweetqa_aip Question Answering English BertForQuestionAnswering en.answer_question.trivia.distil_bert.base_uncased distilbert_qa_base_uncased_finetuned_triviaqa Question Answering English DistilBertForQuestionAnswering en.answer_question.trivia.longformer.large longformer_qa_large_4096_finetuned_triviaqa Question Answering English LongformerForQuestionAnswering en.answer_question.trivia.roberta roberta_qa_roberta_fine_tuned_tweet_sentiment_extractor Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.roberta.base roberta_qa_roberta_base_tweetqa_model Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.roberta.large roberta_qa_roberta_large_tweetqa Question Answering English RoBertaForQuestionAnswering en.answer_question.trivia.xlmr_roberta.large xlm_roberta_qa_xlmroberta_large_tweetqa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.bert bert_qa_bert_all Question Answering English BertForQuestionAnswering en.answer_question.trivia.bert.base_2048.by_MrAnderson bert_qa_bert_base_2048_full_trivia_copied_embeddings Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.bert.multilingual bert_qa_Part_2_BERT_Multilingual_Dutch_Model_E1 Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.multi_lingual_bert bert_qa_Part_2_mBERT_Model_E2 Question Answering English BertForQuestionAnswering en.answer_question.tydiqa.roberta roberta_qa_roberta_tydiqa Question Answering English RoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.3lang xlm_roberta_qa_xlm_3lang Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.by_horsbug98 xlm_roberta_qa_Part_1_XLM_Model_E1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.by_krinal214 xlm_roberta_qa_xlm_all Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.xlm_roberta.v2.by_horsbug98 xlm_roberta_qa_Part_2_XLM_Model_E1 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_finetune_qa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_Dongjae xlm_roberta_qa_mrc2reader Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_Srini99 xlm_roberta_qa_TQA Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.xlm_roberta.by_anukaver xlm_roberta_qa_xlm_roberta_est_qa Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.tydiqa.distil_bert distilbert_qa_multi_finetuned_for_xqua_on_tydiqa Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_Salesforce bert_qa_qaconv_bert_large_uncased_whole_word_masking_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465525.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465525 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465523.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465523 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_andi611 distilbert_qa_base_uncased_squad2_with_ner_mit_restaurant_with_neg_with_repeat Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_anurag0077 distilbert_qa_anurag0077_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_mvonwyl distilbert_qa_mvonwyl_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_tabo distilbert_qa_tabo_base_uncased_finetuned_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base_uncased.by_twmkn9 distilbert_qa_base_uncased_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.by_threem distilbert_qa_mysquadv2_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.v2.by_threem distilbert_qa_mysquadv2_8Jan22_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.electra.base.by_PremalMatalia electra_qa_base_best_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base.by_navteca electra_qa_base_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base.by_sultan electra_qa_BioM_Base_SQuAD2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.base_v2 electra_qa_base_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large.by_sultan electra_qa_BioM_Large_SQuAD2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large.by_superspray electra_qa_large_discriminator_squad2_custom_dataset Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.large_512d electra_qa_large_discriminator_squad2_512 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.electra.small_v2 electra_qa_small_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.longformer.base longformer_base_base_qa_squad2 Question Answering English LongformerForQuestionAnswering en.answer_question.squadv2.longformer.base_v2 longformer_qa_base_4096_finetuned_squadv2 Question Answering English LongformerForQuestionAnswering en.answer_question.squadv2.roberta.base.by_21iridescent roberta_qa_RoBERTa_base_finetuned_squad2_lwt Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_AnonymousSub roberta_qa_roberta_base_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_PremalMatalia roberta_qa_roberta_base_best_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_Shappey roberta_qa_roberta_base_QnA_squad2_trained Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.distil_bert.base_cased distilbert_base_cased_qa_squad2 Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.distil_bert.base distilbert_qa_base_squad2_custom_dataset Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.deberta deberta_v3_xsmall_qa_squad2 Question Answering English DeBertaForQuestionAnswering en.answer_question.squadv2.biobert.cased.by_ptnv-s bert_qa_biobert_squad2_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased.by_deepset bert_qa_bert_large_uncased_whole_word_masking_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2.by_madlag bert_qa_bert_large_uncased_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2_x2.15_f83.2_d25_hybrid.by_madlag bert_qa_bert_large_uncased_wwm_squadv2_x2.15_f83.2_d25_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_v2_x2.63_f82.6_d16_hybrid.by_madlag bert_qa_bert_large_uncased_wwm_squadv2_x2.63_f82.6_d16_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.large_uncased_whole_word_masking_v2.by_madlag bert_qa_bert_large_uncased_whole_word_masking_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.medium_v2 bert_qa_bert_medium_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.mini_lm_base_uncased bert_qa_minilm_uncased_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.small.by_mrm8488 bert_qa_bert_small_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.small_v2.by_mrm8488 bert_qa_bert_small_2_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_.by_mrm8488 bert_qa_bert_tiny_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.roberta.base.by_Teepika roberta_qa_roberta_base_squad2_finetuned_selqa Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_fadhilarkan distilbert_qa_fadhilarkan_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v3.by_mrm8488 bert_qa_bert_tiny_3_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v4.by_mrm8488 bert_qa_bert_tiny_4_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v5.by_mrm8488 bert_qa_bert_tiny_5_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_10l_512d_a8a_512d bert_qa_bert_uncased_L_10_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_2l_512d_a8a_512d bert_qa_bert_uncased_L_2_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_256d_a4a_256d bert_qa_bert_uncased_L_4_H_256_A_4_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_512d_a8a_512d bert_qa_bert_uncased_L_4_H_512_A_8_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_4l_768d_a12a_768d bert_qa_bert_uncased_L_4_H_768_A_12_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.uncased_6l_128d_a2a_128d bert_qa_bert_uncased_L_6_H_128_A_2_squad2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.biobert.cased.by_clagator bert_qa_biobert_squad2_cased Question Answering English BertForQuestionAnswering en.answer_question.squadv2.bert.tiny_v2.by_mrm8488 bert_qa_bert_tiny_2_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465524.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465524 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_avioo1 roberta_qa_avioo1_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_deepset roberta_base_qa_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base_128d_32d_v2 roberta_qa_distilrobert_base_squadv2_328seq_128stride_test Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base_v2 roberta_qa_distilroberta_base_squad_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.emanuals.by_AnonymousSub roberta_qa_EManuals_RoBERTa_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_Salesforce roberta_qa_qaconv_roberta_large_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_deepset roberta_qa_roberta_large_squad2_hp Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_navteca roberta_qa_roberta_large_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.large.by_phiyodr roberta_qa_roberta_large_finetuned_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.tiny.by_deepset roberta_qa_tinyroberta_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.tiny.v2.by_deepset roberta_qa_tinyroberta_squad2_step1 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.scibert.uncased_v2 bert_qa_scibert_scivocab_uncased_squad_v2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.span_bert.v2 bert_qa_spanbert_finetuned_squadv2 Question Answering English BertForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base.by_deepset xlm_roberta_base_qa_squad2 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465514.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465514 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465515.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465515 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465516.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465516 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465517.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465517 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465518.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465518 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465519.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465519 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465520.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465520 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465521.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465521 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.xlm_roberta.base_24465522.by_teacookies xlm_roberta_qa_autonlp_roberta_base_squad2_24465522 Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_twmkn9 roberta_qa_distilroberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_deepset roberta_qa_roberta_base_squad2_distilled Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.distilled_base.by_21iridescent roberta_qa_distilroberta_base_finetuned_squad2_lwt Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.declutr.by_AnonymousSub roberta_qa_declutr_model_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_mvonwyl roberta_qa_roberta_base_finetuned_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_navteca roberta_qa_navteca_roberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_nlpconnect roberta_qa_roberta_base_squad2_nq Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_prk roberta_qa_prk_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_shahrukhx01 roberta_qa_roberta_base_squad2_boolq_baseline Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_sumba roberta_qa_sumba_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_ydshieh roberta_qa_ydshieh_roberta_base_squad2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_quadruplet_0.1_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_quadruplet_0.1_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_triplet_0.1_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_triplet_0.1_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base.by_deepakvk roberta_qa_deepakvk_roberta_base_squad2_finetuned_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_hier_triplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_hier_triplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_only_classfn_twostage_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_only_classfn_twostage_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_bert_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostage_quadruplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostage_quadruplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagequadruplet_hier_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagequadruplet_hier_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagetriplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagetriplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_twostagetriplet_hier_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_twostagetriplet_hier_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_ruletriplet_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_bert_triplet_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_v2.by_AyushPJ roberta_qa_ai_club_inductions_21_nlp_roBERTa_base_squad_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_v2.by_mrm8488 roberta_qa_roberta_base_1B_1_finetuned_squadv2 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.cline.by_AnonymousSub roberta_qa_cline_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squadv2.roberta.base_rule_based_only_classfn_epochs_1_shard_1.by_AnonymousSub roberta_qa_rule_based_roberta_only_classfn_epochs_1_shard_1_squad2.0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_en distilbert_qa_en_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.electra.large.by_mrm8488 electra_qa_large_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_deepakvk distilbert_qa_base_uncased_distilled_squad_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.single_label_n_max.by_mcurmei distilbert_qa_single_label_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.single_label_n_max_long_training.by_mcurmei distilbert_qa_single_label_N_max_long_training Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.unique_n_max.by_mcurmei distilbert_qa_unique_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.electra.by_Andranik electra_qa_TestQA2 Question Answering English BertForQuestionAnswering en.answer_question.electra.by_carlosserquen electra_qa_elctrafp Question Answering English BertForQuestionAnswering en.answer_question.electra.by_rowan1224 electra_qa_slp Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_1 electra_qa_DSPFirst_Finetuning_1 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_2 electra_qa_DSPFirst_Finetuning_2 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_3 electra_qa_DSPFirst_Finetuning_3 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_4 electra_qa_DSPFirst_Finetuning_4 Question Answering English BertForQuestionAnswering en.answer_question.electra.finetuning_5 electra_qa_DSPFirst_Finetuning_5 Question Answering English BertForQuestionAnswering en.answer_question.klue.bert bert_qa_Klue_CommonSense_model Question Answering English BertForQuestionAnswering en.answer_question.klue.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_klue Question Answering English BertForQuestionAnswering en.answer_question.klue.xlm_roberta.base xlm_roberta_qa_klue_mrc_roberta_base Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_emre distilbert_qa_emre_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.korquad.bert.multilingual_base_cased.by_sangrimlee bert_qa_bert_base_multilingual_cased_korquad Question Answering English BertForQuestionAnswering en.answer_question.korquad.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_korquad_mask Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.longformer.by_Nomi97 longformer_qa_Chatbot Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.by_manishiitg longformer_qa_recruit Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.by_ponmari longformer_qa_ponmari Question Answering English LongformerForQuestionAnswering en.answer_question.longformer.large longformer_qa_recruit_large Question Answering English LongformerForQuestionAnswering en.answer_question.distil_bert.log_parser_winlogbeat.by_Slavka distilbert_qa_distil_bert_finetuned_log_parser_winlogbeat Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.log_parser.by_Slavka distilbert_qa_distil_bert_finetuned_log_parser_1 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.flat_n_max.by_mcurmei distilbert_qa_flat_N_max Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom5.by_aszidon distilbert_qa_custom5 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_cased.by_adamlin distilbert_qa_base_cased_sgd_qa_step5000 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config1.by_nlpunibo distilbert_qa_base_config1 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config2.by_nlpunibo distilbert_qa_base_config2 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_config3.by_nlpunibo distilbert_qa_base_config3 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_T-qualizer distilbert_qa_base_uncased_finetuned_advers Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_charlieoneill distilbert_qa_base_uncased_gradient_clinic Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_datarpit distilbert_qa_base_uncased_finetuned_natural_questions Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_machine2049 distilbert_qa_base_uncased_finetuned_duorc_ Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_uncased.by_tiennvcs distilbert_qa_base_uncased_finetuned_infovqa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Ifenna distilbert_qa_dbert_3epoch Question Answering English DistilBertForQuestionAnswering en.answer_question.longformer.v2 longformer_qa_recruit_v2 Question Answering English LongformerForQuestionAnswering en.answer_question.distil_bert.by_LucasS distilbert_qa_distilBertABSA Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Sounak distilbert_qa_finetuned Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_ajaypyatha distilbert_qa_sdsqna Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_alinemati distilbert_qa_BERT Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_keras-io distilbert_qa_transformers_qa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_minhdang241 distilbert_qa_robustqa_tapt Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_pakupoko distilbert_qa_bizlin_distil_model Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_poom-sci distilbert_qa_qa Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom.by_aszidon distilbert_qa_custom Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom3.by_aszidon distilbert_qa_custom3 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.custom4.by_aszidon distilbert_qa_custom4 Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.by_Sarmad distilbert_qa_projectmodel_bert Question Answering English DistilBertForQuestionAnswering en.answer_question.distil_bert.base_cased.by_Slavka distilbert_qa_bert_base_cased_finetuned_log_parser_winlogbeat Question Answering English DistilBertForQuestionAnswering en.answer_question.mitmovie_squad.roberta.by_thatdramebaazguy roberta_qa_movie_roberta_MITmovie_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.mlqa.bert.base_uncased bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_mlqa Question Answering English BertForQuestionAnswering en.answer_question.news.roberta.qa_ft.by_AnonymousSub roberta_qa_news_pretrain_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_ft_new.by_AnonymousSub roberta_qa_news_pretrain_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_roberta_ft_newsqa.by_AnonymousSub roberta_qa_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.output_files.bert.by_sunitha bert_qa_output_files Question Answering English BertForQuestionAnswering en.answer_question.pubmed.bert.base_uncased.by_Shushant bert_qa_Shushant_BiomedNLP_PubMedBERT_base_uncased_abstract_fulltext_ContaminationQAmodel_PubmedBERT Question Answering English BertForQuestionAnswering en.answer_question.roberta.756523213.by_AlirezaBaneshi roberta_qa_autotrain_test2_756523213 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.756523214.by_AlirezaBaneshi roberta_qa_autotrain_test2_756523214 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.augmented roberta_qa_roberta_unaugmentedv3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_123tarunanand roberta_qa_roberta_base_finetuned Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_eAsyle roberta_qa_roberta_base_custom_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_emr-se-miniproject roberta_qa_roberta_base_emr Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_nlpconnect roberta_qa_dpr_nq_reader_roberta_base Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base.by_rsvp-ai roberta_qa_bertserini_roberta_base Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.base_v2 roberta_qa_dpr_nq_reader_roberta_base_v2 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_AmazonScience roberta_qa_qanlu Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_Andranik roberta_qa_TestQaV1 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_AyushPJ roberta_qa_ai_club_inductions_21_nlp_roBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_Beri roberta_qa_legal_qa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_CNT-UPenn roberta_qa_RoBERTa_for_seizureFrequency_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_triplet_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_triplet_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_triplet_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_fpdm_triplet_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_hier_roberta_ft_newsqa.by_AnonymousSub roberta_qa_fpdm_hier_roberta_FT_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squad.roberta.base roberta_qa_roberta_base_MITmovie_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squad.roberta.by_thatdramebaazguy roberta_qa_movie_roberta_squad Question Answering English RoBertaForQuestionAnswering en.answer_question.movie_squadv2.bert.large_uncased bert_qa_bert_large_uncased_whole_word_masking_squad2_with_ner_mit_movie_with_neg_with_repeat Question Answering English BertForQuestionAnswering en.answer_question.multi_lingual_bert.by_horsbug98 bert_qa_Part_1_mBERT_Model_E2 Question Answering English BertForQuestionAnswering en.answer_question.multi_lingual_bert.by_krinal214 bert_qa_mBERT_all_ty_SQen_SQ20_1 Question Answering English BertForQuestionAnswering en.answer_question.news.bert.base_uncased.by_mirbostani bert_qa_bert_base_uncased_finetuned_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.base_uncased.by_tli8hf bert_qa_unqover_bert_base_uncased_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.by_AnonymousSub bert_qa_news_pretrain_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.by_Danastos bert_qa_newsqa_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_ft.by_AnonymousSub bert_qa_fpdm_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.mlqa.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_mlqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_ft_new.by_AnonymousSub bert_qa_fpdm_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.fpdm_hier_ft_by_AnonymousSub bert_qa_fpdm_hier_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.ft.by_AnonymousSub bert_qa_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.ft_new.by_AnonymousSub bert_qa_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.new.by_AnonymousSub bert_qa_news_pretrain_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.qa_fpdm_triplet_ft.by_AnonymousSub bert_qa_fpdm_triplet_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.bert.qa_fpdm_triplet_ft_new.by_AnonymousSub bert_qa_fpdm_triplet_bert_FT_new_newsqa Question Answering English BertForQuestionAnswering en.answer_question.news.distil_bert.base_uncased distilbert_qa_unqover_base_uncased_newsqa Question Answering English DistilBertForQuestionAnswering en.answer_question.news.roberta.base roberta_qa_unqover_roberta_base_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.large roberta_qa_unqover_roberta_large_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.roberta.qa_fpdm_hier_roberta_ft_new_newsqa.by_AnonymousSub roberta_qa_fpdm_hier_roberta_FT_new_newsqa Question Answering English RoBertaForQuestionAnswering en.answer_question.news.bert.fpdm_hier_ft.by_AnonymousSub bert_qa_fpdm_hier_bert_FT_newsqa Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Ching roberta_qa_negation_detector Question Answering English RoBertaForQuestionAnswering en.answer_question.distil_bert.base.by_minhdang241 distilbert_qa_robustqa_baseline_01 Question Answering English DistilBertForQuestionAnswering en.answer_question.cuad_gam.roberta.base.by_Gam roberta_qa_roberta_base_finetuned_cuad_gam Question Answering English RoBertaForQuestionAnswering en.answer_question.bert.by_SanayCo bert_qa_model_output Question Answering English BertForQuestionAnswering en.answer_question.bert.by_aymanm419 bert_qa_araSpeedest Question Answering English BertForQuestionAnswering en.answer_question.bert.by_ericRosello bert_qa_results Question Answering English BertForQuestionAnswering en.answer_question.bert.by_internetoftim bert_qa_demo Question Answering English BertForQuestionAnswering en.answer_question.bert.by_jackh1995 bert_qa_bert_finetuned_jackh1995 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_krinal214 bert_qa_bert_all_translated Question Answering English BertForQuestionAnswering en.answer_question.bert.by_manav bert_qa_causal_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.by_mezes bert_qa_eauction_section_parsing_from_pretrained Question Answering English BertForQuestionAnswering en.answer_question.bert.by_motiondew bert_qa_bert_finetuned_lr2_e5_b16_ep2 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_mrm8488 bert_qa_ManuERT_for_xqua Question Answering English BertForQuestionAnswering en.answer_question.bert.by_nlpunibo bert_qa_bert Question Answering English BertForQuestionAnswering en.answer_question.bert.by_nvkha bert_qa_bert_qa_vi_nvkha Question Answering English BertForQuestionAnswering en.answer_question.bert.by_piEsposito bert_qa_braquad_bert_qna Question Answering English BertForQuestionAnswering en.answer_question.bert.by_voidful bert_qa_question_answering_zh_voidful Question Answering English BertForQuestionAnswering en.answer_question.bert.by_z-uo bert_qa_bert_qasper Question Answering English BertForQuestionAnswering en.answer_question.bert.distilled_base_uncased bert_qa_distilbert_base_uncased_finetuned_custom Question Answering English BertForQuestionAnswering en.answer_question.bert.docvqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_docvqa Question Answering English BertForQuestionAnswering en.answer_question.bert.infovqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_infovqa Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_Sounak bert_qa_bert_large_finetuned Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_atharvamundada99 bert_qa_bert_large_question_answering_finetuned_legal Question Answering English BertForQuestionAnswering en.answer_question.bert.large.by_ricardo-filho bert_qa_bert_large_faquad Question Answering English BertForQuestionAnswering en.answer_question.bert.by_Rocketknight1 bert_qa_bert_finetuned_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.by_LenaSchmidt bert_qa_no_need_to_name_this Question Answering English BertForQuestionAnswering en.answer_question.bert.by_HankyStyle bert_qa_Multi_ling_BERT Question Answering English BertForQuestionAnswering en.answer_question.bert.by_ForutanRad bert_qa_bert_fa_QA_v1 Question Answering English BertForQuestionAnswering en.answer_qu estion.mqa_cls.bert.by_xraychen bert_qa_mqa_cls Question Answering English BertForQuestionAnswering en.answer_question.albert.by_AyushPJ albert_qa_ai_club_inductions_21_nlp Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_SalmanMo albert_qa_QA_1e Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_nlpunibo albert_qa_nlpunibo Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_rowan1224 albert_qa_slp Question Answering English AlbertForQuestionAnswering en.answer_question.albert.by_saburbutt albert_qa_generic Question Answering English AlbertForQuestionAnswering en.answer_question.albert.xl albert_qa_xlarge_finetuned Question Answering English AlbertForQuestionAnswering en.answer_question.bert.32d bert_qa_bert_set_date_1_lr_2e_5_bs_32_ep_4 Question Answering English BertForQuestionAnswering en.answer_question.bert.augmented bert_qa_augmented Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_peggyhuang bert_qa_finetune_bert_base_v1 Question Answering English BertForQuestionAnswering en.answer_question.bert.large_cased bert_qa_muril_large_cased_hita_qa Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_ricardo-filho bert_qa_bert_base_faquad Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_CenIA bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_tar Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_husnu bert_qa_bert_base_turkish_cased_finetuned_lr_2e_05_epochs_3 Question Answering English BertForQuestionAnswering en.answer_question.bert.base_cased.by_nntadotzip bert_qa_bert_base_cased_IUChatbot_ontologyDts Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_CenIA bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_tar Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_machine2049 bert_qa_bert_base_uncased_finetuned_duorc_bert Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_peggyhuang bert_qa_bert_base_uncased_coqa Question Answering English BertForQuestionAnswering en.answer_question.bert.base_uncased.by_vanadhi bert_qa_bert_base_uncased_fiqa_flm_sq_flit Question Answering English BertForQuestionAnswering en.answer_question.bert.base_v2 bert_qa_finetune_bert_base_v2 Question Answering English BertForQuestionAnswering en.answer_question.bert.base_v3.by_peggyhuang bert_qa_finetune_bert_base_v3 Question Answering English BertForQuestionAnswering en.answer_question.bert.by_Danastos bert_qa_nq_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.bert.base.by_xraychen bert_qa_mqa_baseline Question Answering English BertForQuestionAnswering en.answer_question.distil_bert.base.by_leemii18 distilbert_qa_robustqa_baseline_02 Question Answering English DistilBertForQuestionAnswering en.answer_question.bert.large_uncased bert_qa_bert_large_uncased_finetuned_docvqa Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_english_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_english Question Answering English BertForQuestionAnswering en.answer_question.chaii.xlm_roberta.base.by_SauravMaheshkar xlm_roberta_qa_xlm_roberta_base_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.base.by_tyqiangz xlm_roberta_qa_xlm_roberta_base_finetuned_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.large.by_SauravMaheshkar xlm_roberta_qa_xlm_roberta_large_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.chaii.xlm_roberta.large_multi.by_SauravMaheshkar xlm_roberta_qa_xlm_multi_roberta_large_chaii Question Answering English XlmRoBertaForQuestionAnswering en.answer_question.clinical.distil_bert distilbert_qa_BERT_ClinicalQA Question Answering English DistilBertForQuestionAnswering en.answer_question.conll.distil_bert.base_uncased distilbert_qa_base_uncased_qa_with_ner Question Answering English DistilBertForQuestionAnswering en.answer_question.cord19.bert.by_JAlexis bert_qa_Bertv1_fine Question Answering English BertForQuestionAnswering en.answer_question.cord19.bert.small bert_qa_bert_small_cord19qa Question Answering English BertForQuestionAnswering en.answer_question.cord19.prueba_bert.by_JAlexis bert_qa_PruebaBert Question Answering English BertForQuestionAnswering en.answer_question.covid.distil_bert.a.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTa Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.distil_bert.b.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTb Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.distil_bert.c.by_rahulkuruvilla distilbert_qa_COVID_DistilBERTc Question Answering English DistilBertForQuestionAnswering en.answer_question.covid.longformer longformer_qa_covid Question Answering English LongformerForQuestionAnswering en.answer_question.covid_bert.a.by_rahulkuruvilla bert_qa_COVID_BERTa Question Answering English BertForQuestionAnswering en.answer_question.covid_bert.b.by_rahulkuruvilla bert_qa_COVID_BERTb Question Answering English BertForQuestionAnswering en.answer_question.covid_bert.c.by_rahulkuruvilla bert_qa_COVID_BERTc Question Answering English BertForQuestionAnswering en.answer_question.cuad.roberta.base.by_Gam roberta_qa_roberta_base_finetuned_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_Rakib roberta_qa_roberta_base_on_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_akdeniz27 roberta_qa_akdeniz27_roberta_base_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.base.by_marshmellow77 roberta_qa_marshmellow77_roberta_base_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.cuad.roberta.large roberta_qa_roberta_large_cuad Question Answering English RoBertaForQuestionAnswering en.answer_question.chaii.roberta.base roberta_qa_roberta_base_chaii Question Answering English RoBertaForQuestionAnswering en.answer_question.chaii.electra.base electra_qa_base_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.distil_bert.base_uncased distilbert_qa_base_uncased_distilled_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.chaii.distil_bert.base_cased distilbert_qa_base_cased_distilled_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.bert.multilingual_german_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_german Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_hindi_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_hindi Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_spanish_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_spanish Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_vietnamese_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_vietnamese Question Answering English BertForQuestionAnswering en.answer_question.bert.sim.by_xraychen bert_qa_mqa_sim Question Answering English BertForQuestionAnswering en.answer_question.bert.unsupsim.by_xraychen bert_qa_mqa_unsupsim Question Answering English BertForQuestionAnswering en.answer_question.bert.vi_infovqa.base_uncased.by_tiennvcs bert_qa_bert_base_uncased_finetuned_vi_infovqa Question Answering English BertForQuestionAnswering en.answer_question.bert.xtremedistiled_uncased_lr_2e_05_epochs_3.by_husnu bert_qa_xtremedistil_l6_h256_uncased_finetuned_lr_2e_05_epochs_3 Question Answering English BertForQuestionAnswering en.answer_question.bert.xtremedistiled_uncased_lr_2e_05_epochs_6.by_husnu bert_qa_xtremedistil_l6_h256_uncased_finetuned_lr_2e_05_epochs_6 Question Answering English BertForQuestionAnswering en.answer_question.bert.zero_shot.by_fractalego bert_qa_fewrel_zero_shot Question Answering English BertForQuestionAnswering en.answer_question.bert.multilingual_arabic_tuned_base_cased.by_bhavikardeshna bert_qa_multilingual_bert_base_cased_arabic Question Answering English BertForQuestionAnswering en.answer_question.bert.zero_shot.by_krinal214 bert_qa_zero_shot Question Answering English BertForQuestionAnswering en.answer_question.bio_medical.bert.base bert_qa_biomedical_slot_filling_reader_base Question Answering English BertForQuestionAnswering en.answer_question.bio_medical.bert.large bert_qa_biomedical_slot_filling_reader_large Question Answering English BertForQuestionAnswering en.answer_question.biobert bert_qa_biobert_bioasq Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.base_cased bert_qa_bert_base_cased_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.cased bert_qa_bert_multi_cased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.large_uncased_uncased_whole_word_masking.by_SauravMaheshkar bert_qa_bert_large_uncased_whole_word_masking_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.large_uncased_uncased_whole_word_masking_finetuned.by_SauravMaheshkar bert_qa_bert_large_uncased_whole_word_masking_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.bert.uncased bert_qa_bert_multi_uncased_finetuned_chaii Question Answering English BertForQuestionAnswering en.answer_question.chaii.distil_bert distilbert_qa_multi_finetuned_for_xqua_on_chaii Question Answering English DistilBertForQuestionAnswering en.answer_question.bio_clinical.bert bert_qa_sagemaker_BioclinicalBERT_ADR Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_LucasS roberta_qa_robertaBaseABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.korquad.bert.multilingual_base_cased.by_eliza-dukim bert_qa_bert_base_multilingual_cased_korquad_v1 Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Nakul24 roberta_qa_RoBERTa_emotion_extraction Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.large.by_rsvp-ai bert_qa_bertserini_bert_large_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large.by_ruselkomp bert_qa_sbert_large_nlu_ru_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_cased bert_qa_bert_large_cased_whole_word_masking_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_Graphcore bert_qa_Graphcore_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_haddadalwi bert_qa_bert_large_uncased_whole_word_masking_finetuned_squad_finetuned_islamic_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_howey bert_qa_howey_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_internetoftim bert_qa_internetoftim_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_ofirzaf bert_qa_ofirzaf_bert_large_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased.by_uploaded by huggingface bert_qa_bert_large_uncased_whole_word_masking_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased_sparse_80_1x4_block_pruneofa.by_Intel bert_qa_bert_large_uncased_squadv1.1_sparse_80_1x4_block_pruneofa Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.large_uncased_sparse_90_unstructured.by_Intel bert_qa_bert_large_uncased_squadv1.1_sparse_90_unstructured Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium.by_anas-awadalla bert_qa_bert_medium_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium.by_mrm8488 bert_qa_bert_medium_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.medium_finetuned.by_anas-awadalla bert_qa_bert_medium_pretrained_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.mini_lm_base_uncased bert_qa_MiniLM_L12_H384_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.ms_tuned.base.by_zhufy bert_qa_squad_ms_bert_base Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_Paul-Vinh bert_qa_Paul_Vinh_bert_base_multilingual_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_salti bert_qa_salti_bert_base_multilingual_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_cased.by_vanichandna bert_qa_bert_base_multilingual_cased_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.multilingual_base_uncased bert_qa_bert_base_multilingual_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.sl256.by_vuiseng9 bert_qa_bert_l_squadv1.1_sl256 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_kamilali bert_qa_kamilali_distilbert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_juliusco bert_qa_juliusco_distilbert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.distilled_base_uncased.by_huggingface bert_qa_prunebert_base_uncased_6_finepruned_w_distil_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.cased bert_qa_bert_multi_cased_squad_sv_marbogusz Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Ghost1 bert_qa_bert_finetuned_squad1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Harsit bert_qa_Harsit_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_KevinChoi bert_qa_KevinChoi_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Kutay bert_qa_fine_tuned_squad_aip Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Laikokwei bert_qa_Laikokwei_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Neulvo bert_qa_Neulvo_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_andresestevez bert_qa_andresestevez_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ankitkupadhyay bert_qa_ankitkupadhyay_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_datauma bert_qa_datauma_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_hendrixcosta bert_qa_bertimbau_squad1.1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.sl384.by_vuiseng9 bert_qa_bert_l_squadv1.1_sl384 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_huggingface-course bert_qa_huggingface_course_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_maroo93 bert_qa_squad1.1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_mrbalazs5 bert_qa_mrbalazs5_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_mrp bert_qa_mrp_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_nickmuchi bert_qa_nickmuchi_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_peterhsu bert_qa_tf_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ruselkomp bert_qa_tests_finetuned_squad_test_bert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_spacemanidol bert_qa_neuralmagic_bert_squad_12layer_0sparse Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_stevemobs bert_qa_bert_finetuned_squad_pytorch Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_vanichandna bert_qa_muril_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_youngjae bert_qa_youngjae_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_jatinshah bert_qa_jatinshah_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_FardinSaboori bert_qa_FardinSaboori_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small.by_anas-awadalla bert_qa_bert_small_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small_finetuned.by_anas-awadalla bert_qa_bert_small_pretrained_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_ParulChaudhari distilbert_qa_ParulChaudhari_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Plimpton distilbert_qa_Plimpton_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Raphaelg9 distilbert_qa_Raphaelg9_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Rocketknight1 distilbert_qa_Rocketknight1_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_SEISHIN distilbert_qa_SEISHIN_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Shashidhar distilbert_qa_Shashidhar_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Sourabh714 distilbert_qa_Sourabh714_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_SupriyaArun distilbert_qa_SupriyaArun_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Thitaree distilbert_qa_Thitaree_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Tianle distilbert_qa_Tianle_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_V3RX2000 distilbert_qa_V3RX2000_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Wiam distilbert_qa_Wiam_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_aaraki distilbert_qa_aaraki_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_abhinavkulkarni distilbert_qa_abhinavkulkarni_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_akr distilbert_qa_akr_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_andi611 distilbert_qa_andi611_base_uncased_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_anurag0077 distilbert_qa_base_uncased_finetuned_squad3 Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_arvalinno distilbert_qa_arvalinno_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_avioo1 distilbert_qa_avioo1_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_bdickson distilbert_qa_bdickson_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_caiosantillo distilbert_qa_caiosantillo_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Nadhiya distilbert_qa_Nadhiya_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_MYX4567 distilbert_qa_MYX4567_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_HomayounSadri distilbert_qa_HomayounSadri_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Hoang distilbert_qa_Hoang_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.bert.tiny bert_qa_bert_tiny_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v1.1.by_maroo93 bert_qa_squad1.1_1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v1.by_vanichandna bert_qa_muril_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v2.by_peterhsu bert_qa_peterhsu_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.v2.by_ruselkomp bert_qa_tests_finetuned_squad_test_bert_2 Question Answering English BertForQuestionAnswering en.answer_question.squad.biobert.base_cased.by_dmis-lab bert_qa_biobert_base_cased_v1.1_squad Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_Mr-Wick roberta_qa_Roberta Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bioformer.cased bert_qa_bioformer_cased_v1.0_squad1 Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_bert bert_qa_covidbert_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_biobert.base_cased bert_qa_biobert_base_cased_v1.1_squad_finetuned_covbiobert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.small.by_mrm8488 bert_qa_bert_small_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.covid_roberta.base_cased bert_qa_biobert_base_cased_v1.1_squad_finetuned_covdrobert Question Answering English BertForQuestionAnswering en.answer_question.squad.distil_bert.base_cased.by_ncduy distilbert_qa_base_cased_distilled_squad_finetuned_squad_test Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_cased.by_uploaded by huggingface distilbert_qa_base_cased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_small_cased distilbert_qa_base_cased_distilled_squad_finetuned_squad_small Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_tiny_cased distilbert_qa_tiny_base_cased_distilled_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_21iridescent distilbert_qa_21iridescent_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Adrian distilbert_qa_Adrian_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Ayoola distilbert_qa_Ayoola_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_FOFer distilbert_qa_FOFer_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Firat distilbert_qa_Firat_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base_uncased.by_Gayathri distilbert_qa_Gayathri_base_uncased_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.distil_bert.base distilbert_qa_base_finetuned_squad Question Answering English DistilBertForQuestionAnswering en.answer_question.squad.bert.by_Danastos bert_qa_squad_bert_el_Danastos Question Answering English BertForQuestionAnswering en.answer_question.squad.biobert.base_cased.by_juliusco bert_qa_biobert_base_cased_v1.1_squad_finetuned_biobert Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_ArpanZS bert_qa_debug_squad Question Answering English BertForQuestionAnswering en.answer_question.roberta.techqa_cline_emanuals.by_AnonymousSub roberta_qa_cline_emanuals_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.techqa_declutr.by_AnonymousSub roberta_qa_declutr_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.techqa_declutr_emanuals.by_AnonymousSub roberta_qa_declutr_emanuals_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.testabsa.by_eAsyle roberta_qa_testABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.testabsa3.by_eAsyle roberta_qa_testABSA3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.tiny_768d roberta_qa_tinyroberta_6l_768d Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.unaugv3.by_comacrae roberta_qa_roberta_unaugv3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta_absa roberta_qa_robertaABSA Question Answering English RoBertaForQuestionAnswering en.answer_question.scibert.v2 bert_qa_nolog_SciBert_v2 Question Answering English BertForQuestionAnswering en.answer_question.span_bert.by_Nakul24 bert_qa_Spanbert_emotion_extraction Question Answering English BertForQuestionAnswering en.answer_question.span_bert.by_manishiitg bert_qa_spanbert_recruit_qa Question Answering English BertForQuestionAnswering en.answer_question.span_bert.large bert_qa_spanbert_large_recruit_qa Question Answering English BertForQuestionAnswering en.answer_question.sqac.bert.base_cased bert_qa_bert_base_spanish_wwm_cased_finetuned_qa_sqac Question Answering English BertForQuestionAnswering en.answer_question.sqac.bert.base_uncased bert_qa_bert_base_spanish_wwm_uncased_finetuned_qa_sqac Question Answering English BertForQuestionAnswering en.answer_question.squad.albert.base_v2 albert_qa_base_v2_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.by_SS8 albert_qa_squad_2.0 Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.xl albert_qa_xlarge_finetuned_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.albert.xxl albert_qa_xxlarge_finetuned_squad Question Answering English AlbertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_KevinChoi bert_qa_KevinChoi_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_huggingface-course bert_qa_huggingface_course_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.accelerate.by_peterhsu bert_qa_peterhsu_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.roberta.techqa_cline.by_AnonymousSub roberta_qa_cline_techqa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.paraphrasev3.by_comacrae roberta_qa_roberta_paraphrasev3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_seed_4 roberta_qa_roberta_large_data_seed_4 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_seed_0.by_anas-awadalla roberta_qa_roberta_large_data_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.by_DaisyMak bert_qa_bert_finetuned_squad_accelerate_10epoch_transformerfrozen Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_aravind-812 roberta_qa_roberta_train_json Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_arjunth2001 roberta_qa_priv_qna Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_billfrench roberta_qa_cyberlandr_door Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_nlpunibo roberta_qa_nlpunibo_roberta Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_pierrerappolt roberta_qa_cart Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_shmuelamar roberta_qa_REQA_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_stevemobs roberta_qa_quales_iberlef Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_sunitha roberta_qa_roberta_customds_finetune Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_veronica320 roberta_qa_QA_for_Event_Extraction Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.accelerate.by_youngjae bert_qa_youngjae_bert_finetuned_squad_accelerate Question Answering English BertForQuestionAnswering en.answer_question.roberta.by_vesteinn roberta_qa_IceBERT_QA Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.ch_tuned.by_Gantenbein roberta_qa_ADDI_CH_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.cv_custom_ds.by_sunitha roberta_qa_CV_Custom_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.cv_merge_ds.by_sunitha roberta_qa_CV_Merge_DS Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.de_tuned.by_Gantenbein roberta_qa_ADDI_DE_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.eda_and_parav3.by_comacrae roberta_qa_roberta_eda_and_parav3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.edav3.by_comacrae roberta_qa_roberta_edav3 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.fi_tuned.by_Gantenbein roberta_qa_ADDI_FI_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.fr_tuned.by_Gantenbein roberta_qa_ADDI_FR_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.it_tuned.by_Gantenbein roberta_qa_ADDI_IT_RoBERTa Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.large_init_large_seed_0.by_anas-awadalla roberta_qa_roberta_large_initialization_seed_0 Question Answering English RoBertaForQuestionAnswering en.answer_question.roberta.by_z-uo roberta_qa_roberta_qasper Question Answering English RoBertaForQuestionAnswering en.answer_question.squad.bert.augmented bert_qa_augmented_Squad_Translated Question Answering English BertForQuestionAnswering en.answer_question.squad.albert.by_rowan1224 albert_qa_squad_slp Question Answering English AlbertForQuestionAnswering en.answer_question.squad.bert.base.by_rsvp-ai bert_qa_bertserini_bert_base_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_vuiseng9 bert_qa_vuiseng9_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.x1.16_f88.1_d8_unstruct.by_madlag bert_qa_bert_base_uncased_squadv1_x1.16_f88.1_d8_unstruct_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1024d_seed_42 bert_qa_bert_base_uncased_few_shot_k_1024_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_128d_seed_0 bert_qa_bert_base_uncased_few_shot_k_128_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_mrm8488 bert_qa_bert_mini_wrslb_finetuned_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1_block_sparse_0.20_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.13_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_256d_seed_0 bert_qa_bert_base_uncased_few_shot_k_256_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_32d_seed_0 bert_qa_bert_base_uncased_few_shot_k_32_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_512d_seed_0 bert_qa_bert_base_uncased_few_shot_k_512_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_64d_seed_0 bert_qa_bert_base_uncased_few_shot_k_64_finetuned_squad_seed_0 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_victoraavila bert_qa_victoraavila_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_l3.by_howey bert_qa_bert_base_uncased_squad_L3 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_seed_42 bert_qa_bert_base_uncased_few_shot_k_16_finetuned_squad_seed_42 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_v2.by_ericRosello bert_qa_bert_base_uncased_finetuned_squad_frozen_v2 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_v2.by_madlag bert_qa_bert_base_uncased_squad1.1_pruned_x3.2_v2 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.16_f88.1_d8_unstruct_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.20_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.84_f88.7_d36_hybrid_filled_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x1.96_f88.3_d27_hybrid_filled_opt_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x1.96_f88.3_d27_hybrid_filled_opt_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.01_f89.2_d30_hybrid_rewind_opt_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.01_f89.2_d30_hybrid_rewind_opt_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.32_f86.6_d15_hybrid_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.32_f86.6_d15_hybrid_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x2.44_f87.7_d26_hybrid_filled_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_x2.44_f87.7_d26_hybrid_filled_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.07_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.by_Alexander-Learn bert_qa_Alexander_Learn_bert_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_l6.by_howey bert_qa_bert_base_uncased_squad_L6 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_tli8hf bert_qa_unqover_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased_1_block_sparse_0.13_v1.by_madlag bert_qa_bert_base_uncased_squadv1_x1.84_f88.7_d36_hybrid_filled_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_madlag bert_qa_bert_base_uncased_squad_v1_sparse0.25 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_vuiseng9 bert_qa_bert_base_squadv1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_xraychen bert_qa_squad_baseline Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base.by_zhufy bert_qa_squad_en_bert_base Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_srmukundb bert_qa_srmukundb_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_Seongkyu bert_qa_Seongkyu_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_SreyanG-NVIDIA bert_qa_SreyanG_NVIDIA_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_andresestevez bert_qa_andresestevez_bert_base_cased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_batterydata bert_qa_bert_base_cased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_ncduy bert_qa_bert_base_cased_finetuned_squad_test Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.1.1_block_sparse_0.32_v1.by_madlag bert_qa_bert_base_uncased_squad1.1_block_sparse_0.32_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_cased.by_KB bert_qa_bert_base_swedish_cased_squad_experimental Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_Intel bert_qa_bert_base_uncased_squadv1.1_sparse_80_1x4_block_pruneofa Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_lewtun bert_qa_bert_base_uncased_finetuned_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_HomayounSadri bert_qa_HomayounSadri_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_kaporter bert_qa_kaporter_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_jgammack bert_qa_MTL_bert_base_uncased_ww_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_csarron bert_qa_csarron_bert_base_uncased_squad_v1 Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_jimypbr bert_qa_jimypbr_bert_base_uncased_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_bdickson bert_qa_bdickson_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_Tianle bert_qa_Tianle_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_SupriyaArun bert_qa_SupriyaArun_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering en.answer_question.squad.bert.base_uncased.by_SreyanG-NVIDIA bert_qa_SreyanG_NVIDIA_bert_base_uncased_finetuned_squad Question Answering English BertForQuestionAnswering fi.answer_question.xlm_roberta xlm_roberta_qa_ADDI_FI_XLM_R Question Answering Finnish XlmRoBertaForQuestionAnswering fr.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_fr_fr_saattrupdan Question Answering French XlmRoBertaForQuestionAnswering de.answer_question.squad_spanish_tuned.xlmr_roberta.base.by_saattrupdan xlm_roberta_qa_xlmr_base_texas_squad_es_es_saattrupdan Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_german Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.squadv2.electra.base electra_qa_base_squad2 Question Answering German BertForQuestionAnswering de.answer_question.squadv2.bert bert_qa_bert_multi_english_german_squad2 Question Answering German BertForQuestionAnswering de.answer_question.squad_de_tuned.xlmr_roberta.base.by_saattrupdan xlm_roberta_qa_xlmr_base_texas_squad_de_de_saattrupdan Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.xlm_roberta xlm_roberta_qa_ADDI_DE_XLM_R Question Answering German XlmRoBertaForQuestionAnswering de.answer_question.electra.distilled_base electra_qa_g_base_germanquad_distilled Question Answering German BertForQuestionAnswering de.answer_question.electra.base electra_qa_g_base_germanquad Question Answering German BertForQuestionAnswering de.answer_question.electra electra_qa_German_question_answer Question Answering German BertForQuestionAnswering de.answer_question.bert bert_qa_GBERTQnA Question Answering German BertForQuestionAnswering de.answer_question.electra.large electra_qa_g_large_germanquad Question Answering German BertForQuestionAnswering he.answer_question.squad.bert bert_qa_hebert_finetuned_hebrew_squad Question Answering Hebrew BertForQuestionAnswering hi.answer_question.xlm_roberta xlm_roberta_qa_autonlp_hindi_question_answering_23865268 Question Answering Hindi XlmRoBertaForQuestionAnswering hi.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_hindi Question Answering Hindi XlmRoBertaForQuestionAnswering hu.answer_question.squad.bert bert_qa_huBert_fine_tuned_hungarian_squadv1 Question Answering Hungarian BertForQuestionAnswering is.answer_question.squad.roberta roberta_qa_icebert_texas_squad_is_saattrupdan Question Answering Icelandic RoBertaForQuestionAnswering is.answer_question.squad.xlmr_roberta.base xlm_roberta_qa_xlmr_base_texas_squad_is_is_saattrupdan Question Answering Icelandic XlmRoBertaForQuestionAnswering is.answer_question.xlmr_roberta xlm_roberta_qa_XLMr_ENIS_QA_Is Question Answering Icelandic XlmRoBertaForQuestionAnswering id.answer_question.indo_bert bert_qa_Indobert_QA Question Answering Indonesian BertForQuestionAnswering it.answer_question.squad.bert bert_qa_bert_italian_finedtuned_squadv1_it_alfa Question Answering Italian BertForQuestionAnswering it.answer_question.squad.bert.base_uncased bert_qa_bert_base_italian_uncased_squad_it_antoniocappiello Question Answering Italian BertForQuestionAnswering it.answer_question.squad.bert.xxl_cased bert_qa_squad_xxl_cased_hub1 Question Answering Italian BertForQuestionAnswering it.answer_question.xlm_roberta xlm_roberta_qa_ADDI_IT_XLM_R Question Answering Italian XlmRoBertaForQuestionAnswering ja.answer_question.wikipedia.bert.base bert_qa_base_japanese_wikipedia_ud_head Question Answering Japanese BertForQuestionAnswering ja.answer_question.wikipedia.bert.large bert_qa_large_japanese_wikipedia_ud_head Question Answering Japanese BertForQuestionAnswering ko.answer_question.korquad.electra.small electra_qa_small_v3_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base_v2_384.by_monologg electra_qa_base_v2_finetuned_korquad_384 Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base_v2.by_monologg electra_qa_base_v2_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.korquad.electra.base electra_qa_base_v3_finetuned_korquad Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.electra.base.by_seongju electra_qa_klue_mrc_base Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base.by_bespin-global bert_qa_bespin_global_klue_bert_base_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base_aihub.by_bespin-global bert_qa_klue_bert_base_aihub_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.bert.base.by_ainize bert_qa_ainize_klue_bert_base_mrc Question Answering Korean BertForQuestionAnswering ko.answer_question.electra electra_qa_long Question Answering Korean BertForQuestionAnswering ko.answer_question.klue.electra.base.by_obokkkk electra_qa_base_v3_discriminator_finetuned_klue_v4 Question Answering Korean BertForQuestionAnswering el.answer_question.bert bert_qa_qacombination_bert_el_Danastos Question Answering Modern Greek (1453-) BertForQuestionAnswering pl.answer_question.squad.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_polish_squad1 Question Answering Polish BertForQuestionAnswering pl.answer_question.squadv2.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetuned_polish_squad2 Question Answering Polish BertForQuestionAnswering pt.answer_question.squad.distil_bert distilbert_qa_multi_finedtuned_squad Question Answering Portuguese DistilBertForQuestionAnswering pt.answer_question.squad.bert.large_cased bert_qa_bert_large_cased_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.biobert bert_qa_bioBERTpt_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.bert.base_cased.by_mrm8488 bert_qa_bert_base_portuguese_cased_finetuned_squad_v1_pt_mrm8488 Question Answering Portuguese BertForQuestionAnswering pt.answer_question.squad.bert.base_cased.by_pierreguillou bert_qa_bert_base_cased_squad_v1.1_portuguese Question Answering Portuguese BertForQuestionAnswering ru.answer_question.distil_bert distilbert_qa_model_QA_5_epoch_RU Question Answering Russian DistilBertForQuestionAnswering si.answer_question.bert.base bert_qa_bert_base_sinhala_qa Question Answering Sinhala, Sinhalese BertForQuestionAnswering sv.answer_question.squadv2.bert.base bert_qa_bert_base_swedish_squad2 Question Answering Swedish BertForQuestionAnswering sv.answer_question.xlmr_roberta.large xlm_roberta_qa_xlmr_large_qa_sv_sv_m3hrdadfi Question Answering Swedish XlmRoBertaForQuestionAnswering ta.answer_question.squad.xlm_roberta xlm_roberta_qa_xlm_roberta_squad_tamil Question Answering Tamil XlmRoBertaForQuestionAnswering th.answer_question.xquad_squad.bert.cased bert_qa_thai_bert_multi_cased_finetuned_xquadv1_finetuned_squad Question Answering Thai BertForQuestionAnswering th.answer_question.xquad.multi_lingual_bert.base bert_qa_xquad_th_mbert_base Question Answering Thai BertForQuestionAnswering th.answer_question.bert.multilingual_base_cased bert_qa_bert_base_multilingual_cased_finetune_qa Question Answering Thai BertForQuestionAnswering th.answer_question.squadv2.xlm_roberta.base xlm_roberta_qa_thai_xlm_roberta_base_squad2 Question Answering Thai XlmRoBertaForQuestionAnswering tr.answer_question.squad.electra electra_qa_enelpi_squad Question Answering Turkish BertForQuestionAnswering tr.answer_question.xlm_roberta xlm_roberta_qa_XLM_Turkish Question Answering Turkish XlmRoBertaForQuestionAnswering tr.answer_question.squadv2.electra.base_v2 electra_qa_base_discriminator_finetuned_squadv2 Question Answering Turkish BertForQuestionAnswering tr.answer_question.squad.electra.base electra_qa_base_discriminator_finetuned_squadv1 Question Answering Turkish BertForQuestionAnswering tr.answer_question.squad.bert.base bert_qa_bert_base_turkish_squad Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.base_uncased bert_qa_loodos_bert_base_uncased_QA_fine_tuned Question Answering Turkish BertForQuestionAnswering tr.answer_question.electra electra_qa_turkish Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.distilled bert_qa_distilbert_tr_q_a Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.by_yunusemreemik bert_qa_logo_qna_model Question Answering Turkish BertForQuestionAnswering tr.answer_question.bert.by_lserinol bert_qa_bert_turkish_question_answering Question Answering Turkish BertForQuestionAnswering tr.answer_question.electra.small_uncased electra_qa_small_turkish_uncased_discriminator_finetuned Question Answering Turkish BertForQuestionAnswering uk.answer_question.xlmr_roberta xlmroberta_qa_ukrainian Question Answering Ukrainian XlmRoBertaForQuestionAnswering vi.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_vi_qa Question Answering Vietnamese XlmRoBertaForQuestionAnswering ar.answer_question.bert bert_qa_arap_qa_bert Question Answering Arabic BertForQuestionAnswering ar.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_arabic Question Answering Arabic XlmRoBertaForQuestionAnswering ar.answer_question.tydiqa.electra.base electra_qa_ara_base_artydiqa Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra.base electra_qa_AraElectra_base_finetuned_ARCD Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra.768d electra_qa_araElectra_SQUAD_ARCD_768 Question Answering Arabic BertForQuestionAnswering ar.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_arabic_qa Question Answering Arabic XlmRoBertaForQuestionAnswering ar.answer_question.electra electra_qa_AraELECTRA_discriminator_SOQAL Question Answering Arabic BertForQuestionAnswering ar.answer_question.bert.v2 bert_qa_arap_qa_bert_v2 Question Answering Arabic BertForQuestionAnswering ar.answer_question.bert.large_v2 bert_qa_arap_qa_bert_large_v2 Question Answering Arabic BertForQuestionAnswering ar.answer_question.squad_arcd.electra electra_qa_araElectra_SQUAD_ARCD Question Answering Arabic BertForQuestionAnswering zh.answer_question.mac_bert.large bert_qa_chinese_pretrain_mrc_macbert_large Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.multilingual_base_cased bert_qa_multilingual_bert_base_cased_chinese Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_qalover bert_qa_chinese_pert_large_open_domain_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_luhua bert_qa_chinese_pretrain_mrc_roberta_wwm_ext_large Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.large.by_hfl bert_qa_chinese_pert_large_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_uer bert_qa_roberta_base_chinese_extractive_qa Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.by_jackh1995 bert_qa_bert_chinese_finetuned Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_liam168 bert_qa_qa_roberta_base_chinese_extractive Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_jackh1995 bert_qa_roberta_base_chinese_extractive_qa_scratch Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.base.by_hfl bert_qa_chinese_pert_base_mrc Question Answering Chinese BertForQuestionAnswering zh.answer_question.squad.bert.base bert_qa_bert_base_chinese_finetuned_squad_colab Question Answering Chinese BertForQuestionAnswering zh.answer_question.bert.by_yechen bert_qa_question_answering_chinese Question Answering Chinese BertForQuestionAnswering zh.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_chinese Question Answering Chinese XlmRoBertaForQuestionAnswering fa.answer_question.bert.base bert_qa_bert_base_fa_qa Question Answering Persian BertForQuestionAnswering fa.answer_question.xlm_roberta.large xlm_roberta_qa_xlm_roberta_large_fa_qa Question Answering Persian XlmRoBertaForQuestionAnswering fa.answer_question.xlmr_roberta.large xlmroberta_qa_xlmr_large Question Answering Persian XlmRoBertaForQuestionAnswering sw.answer_question.tydiqa.xlm_roberta.base xlm_roberta_qa_afriberta_base_finetuned_tydiqa Question Answering Swahili (macrolanguage) XlmRoBertaForQuestionAnswering vn.answer_question.xlm_roberta.base xlm_roberta_qa_xlm_roberta_base_vietnamese Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.chaii.xlm_roberta xlm_roberta_qa_xlm_roberta_qa_chaii Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.xquad.bert.uncased bert_qa_bert_multi_uncased_finetuned_xquadv1 Question Answering nan BertForQuestionAnswering xx.answer_question.xquad.bert.cased bert_qa_bert_multi_cased_finetuned_xquadv1 Question Answering nan BertForQuestionAnswering xx.answer_question.xlm_roberta.distilled xlm_roberta_qa_distill_xlm_mrc Question Answering nan XlmRoBertaForQuestionAnswering xx.answer_question.tydiqa.multi_lingual_bert bert_qa_Part_1_mBERT_Model_E1 Question Answering nan BertForQuestionAnswering xx.answer_question.tydiqa.bert bert_qa_telugu_bertu_tydiqa Question Answering nan BertForQuestionAnswering xx.answer_question.xquad_tydiqa.bert.cased bert_qa_bert_multi_cased_finedtuned_xquad_tydiqa_goldp Question Answering nan BertForQuestionAnswering xx.answer_question.squad.distil_bert._en_de_es_vi_zh_tuned.by_ZYW distilbert_qa_squad_en_de_es_vi_zh_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.roberta roberta_qa_ft_lr_cu_leolin12345 Question Answering nan RoBertaForQuestionAnswering xx.answer_question.distil_bert.vi_zh_es_tuned.by_ZYW distilbert_qa_en_de_vi_zh_es_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.distil_bert.en_de_tuned.by_ZYW distilbert_qa_en_de_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.distil_bert.en_de_es_tuned.by_ZYW distilbert_qa_en_de_es_model Question Answering nan DistilBertForQuestionAnswering xx.answer_question.squad.distil_bert.en_de_es_tuned.by_ZYW distilbert_qa_squad_en_de_es_model Question Answering nan DistilBertForQuestionAnswering Minor Improvements IOB Schema Detection for Tokenclassifiers and adding NER Converting in those cases Tweaks in column name generation of most annotators Bug Fixes fixed bug in multi lang parsing fixed bug for Normalizers fixed bug in fetching metadata for resolvers fixed bug in deducting outputlevel and inferring output columns fixed broken nlp_refs NLU Version 3.4.4 600 new models with over 75 new languages including Ancient,Dead and Extinct languages, 155 languages total covered, 400% Tokenizer Speedup, 18x USE-Embeddings GPU speedup in John Snow Labs NLU 3.4.4 We are very excited to announce NLU 3.4.4 has been released with over 600 new model, over 75 new languages and 155 languages covered in total, 400% speedup for tokenizers and 18x speedup of UniversalSentenceEncoder on GPU. On the general NLP side we have transformer based Embeddings and Token Classifiers powered by state of the art CamemBertEmbeddings and DeBertaForTokenClassification based architectures as well as various new models for Historical, Ancient,Dead, Extinct, Genetic and Constructed languages like Old Church Slavonic, Latin, Sanskrit, Esperanto, Volapük, Coptic, Nahuatl, Ancient Greek (to 1453), Old Russian. On the healthcare side we have Portuguese De-identification Models, have NER models for Gene detection and finally RxNorm Sentence resolution model for mapping and extracting pharmaceutical actions (e.g. analgesic, hypoglycemic) as well as treatments (e.g. backache, diabetes). General NLP Models All general NLP models First time language models covered The languages for these models are covered for the very first time ever by NLU. Number Language Name(s) NLU Reference Spark NLP Reference Task Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Scope Language Type 0 Sanskrit sa.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sa san san Individual Ancient 1 Sanskrit sa.lemma lemma_vedic Lemmatization LemmatizerModel sa san san Individual Ancient 2 Sanskrit sa.pos pos_vedic Part of Speech Tagging PerceptronModel sa san san Individual Ancient 3 Sanskrit sa.stopwords stopwords_iso Stop Words Removal StopWordsCleaner sa san san Individual Ancient 4 Volapük vo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel vo vol vol Individual Constructed 5 Nahuatl languages nah.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nah nan Collective Genetic 6 Aragonese an.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel an arg arg Individual Living 7 Assamese as.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel as asm asm Individual Living 8 Asturian, Asturleonese, Bable, Leonese ast.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan ast ast Individual Living 9 Bashkir ba.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ba bak bak Individual Living 10 Bavarian bar.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bar Individual Living 11 Bishnupriya bpy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bpy Individual Living 12 Burmese my.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel my 639-2/T: mya639-2/B: bur mya Individual Living 13 Cebuano ceb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan ceb ceb Individual Living 14 Central Bikol bcl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan bcl Individual Living 15 Chechen ce.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ce che che Individual Living 16 Chuvash cv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel cv chv chv Individual Living 17 Corsican co.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel co cos cos Individual Living 18 Dhivehi, Divehi, Maldivian dv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel dv div div Individual Living 19 Egyptian Arabic arz.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan arz Individual Living 20 Emiliano-Romagnolo eml.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel eml nan nan Individual Living 21 Erzya myv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan myv myv Individual Living 22 Georgian ka.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ka 639-2/T: kat639-2/B: geo kat Individual Living 23 Goan Konkani gom.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan gom Individual Living 24 Javanese jv.embed.distilbert distilbert_embeddings_javanese_distilbert_small Embeddings DistilBertEmbeddings jv jav jav Individual Living 25 Javanese jv.embed.javanese_distilbert_small_imdb distilbert_embeddings_javanese_distilbert_small_imdb Embeddings DistilBertEmbeddings jv jav jav Individual Living 26 Javanese jv.embed.javanese_roberta_small roberta_embeddings_javanese_roberta_small Embeddings RoBertaEmbeddings jv jav jav Individual Living 27 Javanese jv.embed.javanese_roberta_small_imdb roberta_embeddings_javanese_roberta_small_imdb Embeddings RoBertaEmbeddings jv jav jav Individual Living 28 Javanese jv.embed.javanese_bert_small_imdb bert_embeddings_javanese_bert_small_imdb Embeddings BertEmbeddings jv jav jav Individual Living 29 Javanese jv.embed.javanese_bert_small bert_embeddings_javanese_bert_small Embeddings BertEmbeddings jv jav jav Individual Living 30 Kirghiz, Kyrgyz ky.stopwords stopwords_iso Stop Words Removal StopWordsCleaner ky kir kir Individual Living 31 Letzeburgesch, Luxembourgish lb.stopwords stopwords_iso Stop Words Removal StopWordsCleaner lb ltz ltz Individual Living 32 Letzeburgesch, Luxembourgish lb.lemma lemma_spacylookup Lemmatization LemmatizerModel lb ltz ltz Individual Living 33 Letzeburgesch, Luxembourgish lb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel lb ltz ltz Individual Living 34 Ligurian lij.stopwords stopwords_iso Stop Words Removal StopWordsCleaner nan nan lij Individual Living 35 Lombard lmo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan lmo Individual Living 36 Low German, Low Saxon nds.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nds nds Individual Living 37 Macedonian mk.stopwords stopwords_iso Stop Words Removal StopWordsCleaner mk 639-2/T: mkd639-2/B: mac mkd Individual Living 38 Macedonian mk.lemma lemma_spacylookup Lemmatization LemmatizerModel mk 639-2/T: mkd639-2/B: mac mkd Individual Living 39 Macedonian mk.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mk 639-2/T: mkd639-2/B: mac mkd Individual Living 40 Maithili mai.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan mai mai Individual Living 41 Manx gv.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel gv glv glv Individual Living 42 Mazanderani mzn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan mzn Individual Living 43 Minangkabau min.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan min min Individual Living 44 Mingrelian xmf.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan xmf Individual Living 45 Mirandese mwl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan mwl mwl Individual Living 46 Neapolitan nap.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nap nap Individual Living 47 Nepal Bhasa, Newari new.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan new new Individual Living 48 Northern Frisian frr.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan frr frr Individual Living 49 Northern Sami sme.lemma lemma_giella Lemmatization LemmatizerModel se sme sme Individual Living 50 Northern Sami sme.pos pos_giella Part of Speech Tagging PerceptronModel se sme sme Individual Living 51 Northern Sotho, Pedi, Sepedi nso.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nso nso Individual Living 52 Occitan (post 1500) oc.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel oc oci oci Individual Living 53 Ossetian, Ossetic os.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel os oss oss Individual Living 54 Pfaelzisch pfl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pfl Individual Living 55 Piemontese pms.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pms Individual Living 56 Romansh rm.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel rm roh roh Individual Living 57 Scots sco.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan sco sco Individual Living 58 Sicilian scn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan scn scn Individual Living 59 Sinhala, Sinhalese si.stopwords stopwords_iso Stop Words Removal StopWordsCleaner si sin sin Individual Living 60 Sinhala, Sinhalese si.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel si sin sin Individual Living 61 Sundanese su.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel su sun sun Individual Living 62 Sundanese su.embed.sundanese_roberta_base roberta_embeddings_sundanese_roberta_base Embeddings RoBertaEmbeddings su sun sun Individual Living 63 Tagalog tl.lemma lemma_spacylookup Lemmatization LemmatizerModel tl tgl tgl Individual Living 64 Tagalog tl.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tl tgl tgl Individual Living 65 Tagalog tl.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tl tgl tgl Individual Living 66 Tagalog tl.embed.roberta_tagalog_large roberta_embeddings_roberta_tagalog_large Embeddings RoBertaEmbeddings tl tgl tgl Individual Living 67 Tagalog tl.embed.roberta_tagalog_base roberta_embeddings_roberta_tagalog_base Embeddings RoBertaEmbeddings tl tgl tgl Individual Living 68 Tajik tg.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tg tgk tgk Individual Living 69 Tatar tt.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tt tat tat Individual Living 70 Tatar tt.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tt tat tat Individual Living 71 Tigrinya ti.stopwords stopwords_iso Stop Words Removal StopWordsCleaner ti tir tir Individual Living 72 Tosk Albanian als.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan als Individual Living 73 Tswana tn.stopwords stopwords_iso Stop Words Removal StopWordsCleaner tn tsn tsn Individual Living 74 Turkmen tk.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel tk tuk tuk Individual Living 75 Upper Sorbian hsb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan hsb hsb Individual Living 76 Venetian vec.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan vec Individual Living 77 Vlaams vls.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan vls Individual Living 78 Walloon wa.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel wa wln wln Individual Living 79 Waray (Philippines) war.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan war war Individual Living 80 Western Armenian hyw.pos pos_armtdp Part of Speech Tagging PerceptronModel nan nan hyw Individual Living 81 Western Armenian hyw.lemma lemma_armtdp Lemmatization LemmatizerModel nan nan hyw Individual Living 82 Western Frisian fy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel fy fry fry Individual Living 83 Western Panjabi pnb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan pnb Individual Living 84 Yakut sah.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan sah sah Individual Living 85 Zeeuws zea.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel nan nan zea Individual Living 86 Albanian sq.stopwords stopwords_iso Stop Words Removal StopWordsCleaner sq 639-2/T: sqi639-2/B: alb sqi Macrolanguage Living 87 Albanian sq.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sq 639-2/T: sqi639-2/B: alb sqi Macrolanguage Living 88 Azerbaijani az.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel az aze aze Macrolanguage Living 89 Azerbaijani az.stopwords stopwords_iso Stop Words Removal StopWordsCleaner az aze aze Macrolanguage Living 90 Malagasy mg.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mg mlg mlg Macrolanguage Living 91 Malay (macrolanguage) ms.embed.albert albert_embeddings_albert_large_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 92 Malay (macrolanguage) ms.embed.distilbert distilbert_embeddings_malaysian_distilbert_small Embeddings DistilBertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 93 Malay (macrolanguage) ms.embed.albert_tiny_bahasa_cased albert_embeddings_albert_tiny_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 94 Malay (macrolanguage) ms.embed.albert_base_bahasa_cased albert_embeddings_albert_base_bahasa_cased Embeddings AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 95 Malay (macrolanguage) ms.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ms 639-2/T: msa639-2/B: may msa Macrolanguage Living 96 Mongolian mn.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel mn mon mon Macrolanguage Living 97 Oriya (macrolanguage) or.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel or ori ori Macrolanguage Living 98 Pashto, Pushto ps.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel ps pus pus Macrolanguage Living 99 Quechua qu.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel qu que que Macrolanguage Living 100 Sardinian sc.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sc srd srd Macrolanguage Living 101 Serbo-Croatian sh.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel sh nan nan Macrolanguage Living 102 Uzbek uz.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel uz uzb uzb Macrolanguage Living All general NLP models Powered by the incredible Spark NLP 3.4.4 and previous releases. Number NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Language Type Scope 0 cu.pos pos_proiel Part of Speech Tagging Church Slavic, Church Slavonic, Old Bulgarian, Old Church Slavonic, Old Slavonic PerceptronModel cu chu chu Ancient Individual 1 la.lemma lemma_proiel Lemmatization Latin LemmatizerModel la lat lat Ancient Individual 2 la.lemma lemma_proiel Lemmatization Latin LemmatizerModel la lat lat Ancient Individual 3 la.pos pos_perseus Part of Speech Tagging Latin PerceptronModel la lat lat Ancient Individual 4 la.pos pos_perseus Part of Speech Tagging Latin PerceptronModel la lat lat Ancient Individual 5 sa.embed.w2v_cc_300d w2v_cc_300d Embeddings Sanskrit WordEmbeddingsModel sa san san Ancient Individual 6 sa.lemma lemma_vedic Lemmatization Sanskrit LemmatizerModel sa san san Ancient Individual 7 sa.pos pos_vedic Part of Speech Tagging Sanskrit PerceptronModel sa san san Ancient Individual 8 sa.stopwords stopwords_iso Stop Words Removal Sanskrit StopWordsCleaner sa san san Ancient Individual 9 eo.embed.w2v_cc_300d w2v_cc_300d Embeddings Esperanto WordEmbeddingsModel eo epo epo Constructed Individual 10 vo.embed.w2v_cc_300d w2v_cc_300d Embeddings Volapük WordEmbeddingsModel vo vol vol Constructed Individual 11 cop.pos pos_scriptorium Part of Speech Tagging Coptic PerceptronModel nan cop cop Extinct Individual 12 nah.embed.w2v_cc_300d w2v_cc_300d Embeddings Nahuatl languages WordEmbeddingsModel nan nah nan Genetic Collective 13 grc.lemma lemma_proiel Lemmatization Ancient Greek (to 1453) LemmatizerModel nan grc grc Historical Individual 14 grc.stopwords stopwords_iso Stop Words Removal Ancient Greek (to 1453) StopWordsCleaner nan grc grc Historical Individual 15 grc.lemma lemma_proiel Lemmatization Ancient Greek (to 1453) LemmatizerModel nan grc grc Historical Individual 16 grc.pos pos_proiel Part of Speech Tagging Ancient Greek (to 1453) PerceptronModel nan grc grc Historical Individual 17 orv.lemma lemma_torot Lemmatization Old Russian LemmatizerModel nan nan orv Historical Individual 18 af.embed.w2v_cc_300d w2v_cc_300d Embeddings Afrikaans WordEmbeddingsModel af afr afr Living Individual 19 af.stopwords stopwords_iso Stop Words Removal Afrikaans StopWordsCleaner af afr afr Living Individual 20 am.embed.w2v_cc_300d w2v_cc_300d Embeddings Amharic WordEmbeddingsModel am amh amh Living Individual 21 am.embed.am_roberta roberta_embeddings_am_roberta Embeddings Amharic RoBertaEmbeddings am amh amh Living Individual 22 am.stopwords stopwords_iso Stop Words Removal Amharic StopWordsCleaner am amh amh Living Individual 23 an.embed.w2v_cc_300d w2v_cc_300d Embeddings Aragonese WordEmbeddingsModel an arg arg Living Individual 24 hy.stopwords stopwords_iso Stop Words Removal Armenian StopWordsCleaner hy 639-2/T: hye639-2/B: arm hye Living Individual 25 hy.lemma lemma_armtdp Lemmatization Armenian LemmatizerModel hy 639-2/T: hye639-2/B: arm hye Living Individual 26 hy.embed.w2v_cc_300d w2v_cc_300d Embeddings Armenian WordEmbeddingsModel hy 639-2/T: hye639-2/B: arm hye Living Individual 27 as.embed.w2v_cc_300d w2v_cc_300d Embeddings Assamese WordEmbeddingsModel as asm asm Living Individual 28 ast.embed.w2v_cc_300d w2v_cc_300d Embeddings Asturian, Asturleonese, Bable, Leonese WordEmbeddingsModel nan ast ast Living Individual 29 ba.embed.w2v_cc_300d w2v_cc_300d Embeddings Bashkir WordEmbeddingsModel ba bak bak Living Individual 30 eu.stopwords stopwords_iso Stop Words Removal Basque StopWordsCleaner eu 639-2/T: eus639-2/B: baq eus Living Individual 31 eu.embed.w2v_cc_300d w2v_cc_300d Embeddings Basque WordEmbeddingsModel eu 639-2/T: eus639-2/B: baq eus Living Individual 32 eu.lemma lemma_bdt Lemmatization Basque LemmatizerModel eu 639-2/T: eus639-2/B: baq eus Living Individual 33 bar.embed.w2v_cc_300d w2v_cc_300d Embeddings Bavarian WordEmbeddingsModel nan nan bar Living Individual 34 be.embed.w2v_cc_300d w2v_cc_300d Embeddings Belarusian WordEmbeddingsModel be bel bel Living Individual 35 be.lemma lemma_hse Lemmatization Belarusian LemmatizerModel be bel bel Living Individual 36 bn.embed.indic_transformers_bn_distilbert distilbert_embeddings_indic_transformers_bn_distilbert Embeddings Bengali DistilBertEmbeddings bn ben ben Living Individual 37 bn.embed.w2v_cc_300d w2v_cc_300d Embeddings Bengali WordEmbeddingsModel bn ben ben Living Individual 38 bn.embed.indic_transformers_bn_bert bert_embeddings_indic_transformers_bn_bert Embeddings Bengali BertEmbeddings bn ben ben Living Individual 39 bn.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Bengali BertEmbeddings bn ben ben Living Individual 40 bn.embed.bangla_bert bert_embeddings_bangla_bert Embeddings Bengali BertEmbeddings bn ben ben Living Individual 41 bn.stopwords stopwords_iso Stop Words Removal Bengali StopWordsCleaner bn ben ben Living Individual 42 bh.embed.w2v_cc_300d w2v_cc_300d Embeddings Bihari language group, also known ash bih in ISO 639-2/5 WordEmbeddingsModel bh nan nan Living Individual 43 bpy.embed.w2v_cc_300d w2v_cc_300d Embeddings Bishnupriya WordEmbeddingsModel nan nan bpy Living Individual 44 bs.embed.w2v_cc_300d w2v_cc_300d Embeddings Bosnian WordEmbeddingsModel bs bos bos Living Individual 45 br.embed.w2v_cc_300d w2v_cc_300d Embeddings Breton WordEmbeddingsModel br bre bre Living Individual 46 bg.embed.w2v_cc_300d w2v_cc_300d Embeddings Bulgarian WordEmbeddingsModel bg bul bul Living Individual 47 bg.stopwords stopwords_iso Stop Words Removal Bulgarian StopWordsCleaner bg bul bul Living Individual 48 my.embed.w2v_cc_300d w2v_cc_300d Embeddings Burmese WordEmbeddingsModel my 639-2/T: mya639-2/B: bur mya Living Individual 49 es.embed.distilbert_base_es_multilingual_cased distilbert_embeddings_distilbert_base_es_multilingual_cased Embeddings Castilian, Spanish DistilBertEmbeddings es spa spa Living Individual 50 es.embed.distilbert_base_es_cased distilbert_embeddings_distilbert_base_es_cased Embeddings Castilian, Spanish DistilBertEmbeddings es spa spa Living Individual 51 es.embed.bertin_base_gaussian roberta_embeddings_bertin_base_gaussian Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 52 es.embed.bertin_roberta_base_spanish roberta_embeddings_bertin_roberta_base_spanish Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 53 es.embed.bertin_roberta_large_spanish roberta_embeddings_bertin_roberta_large_spanish Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 54 es.embed.bertin_base_stepwise roberta_embeddings_bertin_base_stepwise Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 55 es.embed.dpr_spanish_passage_encoder_allqa_base bert_embeddings_dpr_spanish_passage_encoder_allqa_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 56 es.embed.dpr_spanish_question_encoder_allqa_base bert_embeddings_dpr_spanish_question_encoder_allqa_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 57 es.embed.beto_gn_base_cased bert_embeddings_beto_gn_base_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 58 es.embed.dpr_spanish_passage_encoder_squades_base bert_embeddings_dpr_spanish_passage_encoder_squades_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 59 es.embed.dpr_spanish_question_encoder_squades_base bert_embeddings_dpr_spanish_question_encoder_squades_base Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 60 es.embed.bert_base_es_cased bert_embeddings_bert_base_es_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 61 es.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 62 es.embed.alberti_bert_base_multilingual_cased bert_embeddings_alberti_bert_base_multilingual_cased Embeddings Castilian, Spanish BertEmbeddings es spa spa Living Individual 63 es.embed.roberta_base_bne roberta_embeddings_roberta_base_bne Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 64 es.embed.jurisbert roberta_embeddings_jurisbert Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 65 es.embed.mlm_spanish_roberta_base roberta_embeddings_mlm_spanish_roberta_base Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 66 es.embed.roberta_large_bne roberta_embeddings_roberta_large_bne Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 67 es.pos pos_ancora Part of Speech Tagging Castilian, Spanish PerceptronModel es spa spa Living Individual 68 es.embed.bertin_base_random_exp_512seqlen roberta_embeddings_bertin_base_random_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 69 es.embed.bertin_base_gaussian_exp_512seqlen roberta_embeddings_bertin_base_gaussian_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 70 es.ner.roberta_base_bne_capitel_ner_plus roberta_ner_roberta_base_bne_capitel_ner_plus Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 71 es.ner.roberta_base_bne_capitel_ner roberta_ner_roberta_base_bne_capitel_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 72 es.ner.RuPERTa_base_finetuned_ner roberta_ner_RuPERTa_base_finetuned_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 73 es.pos.roberta_base_bne_capitel_pos roberta_pos_roberta_base_bne_capitel_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 74 es.ner.NER_LAW_MONEY4 roberta_ner_NER_LAW_MONEY4 Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 75 es.pos.roberta_large_bne_capitel_pos roberta_pos_roberta_large_bne_capitel_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 76 es.ner.bsc_bio_ehr_es_pharmaconer roberta_ner_bsc_bio_ehr_es_pharmaconer Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 77 es.embed.RoBERTalex roberta_embeddings_RoBERTalex Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 78 es.ner.roberta_large_bne_capitel_ner roberta_ner_roberta_large_bne_capitel_ner Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 79 es.embed.RuPERTa_base roberta_embeddings_RuPERTa_base Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 80 es.embed.bertin_base_random roberta_embeddings_bertin_base_random Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 81 es.lemma lemma_spacylookup Lemmatization Castilian, Spanish LemmatizerModel es spa spa Living Individual 82 es.stopwords stopwords_iso Stop Words Removal Castilian, Spanish StopWordsCleaner es spa spa Living Individual 83 es.pos.RuPERTa_base_finetuned_pos roberta_pos_RuPERTa_base_finetuned_pos Part of Speech Tagging Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 84 es.embed.bertin_base_stepwise_exp_512seqlen roberta_embeddings_bertin_base_stepwise_exp_512seqlen Embeddings Castilian, Spanish RoBertaEmbeddings es spa spa Living Individual 85 es.ner.bsc_bio_ehr_es_cantemist roberta_ner_bsc_bio_ehr_es_cantemist Named Entity Recognition Castilian, Spanish RoBertaForTokenClassification es spa spa Living Individual 86 ca.lemma lemma_spacylookup Lemmatization Catalan, Valencian LemmatizerModel ca cat cat Living Individual 87 ca.embed.w2v_cc_300d w2v_cc_300d Embeddings Catalan, Valencian WordEmbeddingsModel ca cat cat Living Individual 88 ca.stopwords stopwords_iso Stop Words Removal Catalan, Valencian StopWordsCleaner ca cat cat Living Individual 89 ceb.embed.w2v_cc_300d w2v_cc_300d Embeddings Cebuano WordEmbeddingsModel nan ceb ceb Living Individual 90 bcl.embed.w2v_cc_300d w2v_cc_300d Embeddings Central Bikol WordEmbeddingsModel nan nan bcl Living Individual 91 ce.embed.w2v_cc_300d w2v_cc_300d Embeddings Chechen WordEmbeddingsModel ce che che Living Individual 92 cv.embed.w2v_cc_300d w2v_cc_300d Embeddings Chuvash WordEmbeddingsModel cv chv chv Living Individual 93 co.embed.w2v_cc_300d w2v_cc_300d Embeddings Corsican WordEmbeddingsModel co cos cos Living Individual 94 hr.embed.w2v_cc_300d w2v_cc_300d Embeddings Croatian WordEmbeddingsModel hr hrv hrv Living Individual 95 hr.stopwords stopwords_iso Stop Words Removal Croatian StopWordsCleaner hr hrv hrv Living Individual 96 hr.lemma lemma_spacylookup Lemmatization Croatian LemmatizerModel hr hrv hrv Living Individual 97 cs.stopwords stopwords_iso Stop Words Removal Czech StopWordsCleaner cs 639-2/T: ces639-2/B: cze ces Living Individual 98 cs.embed.w2v_cc_300d w2v_cc_300d Embeddings Czech WordEmbeddingsModel cs 639-2/T: ces639-2/B: cze ces Living Individual 99 cs.pos pos_fictree Part of Speech Tagging Czech PerceptronModel cs 639-2/T: ces639-2/B: cze ces Living Individual 100 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 101 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 102 cs.lemma lemma_cltt Lemmatization Czech LemmatizerModel cs 639-2/T: ces639-2/B: cze ces Living Individual 103 da.embed.w2v_cc_300d w2v_cc_300d Embeddings Danish WordEmbeddingsModel da dan dan Living Individual 104 da.lemma lemma_spacylookup Lemmatization Danish LemmatizerModel da dan dan Living Individual 105 da.stopwords stopwords_iso Stop Words Removal Danish StopWordsCleaner da dan dan Living Individual 106 dv.embed.w2v_cc_300d w2v_cc_300d Embeddings Dhivehi, Divehi, Maldivian WordEmbeddingsModel dv div div Living Individual 107 nl.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_nl_cased Embeddings Dutch, Flemish DistilBertEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 108 nl.pos.fullstop_dutch_punctuation_prediction roberta_pos_fullstop_dutch_punctuation_prediction Part of Speech Tagging Dutch, Flemish RoBertaForTokenClassification nl 639-2/T: nld639-2/B: dut nld Living Individual 109 nl.stopwords stopwords_iso Stop Words Removal Dutch, Flemish StopWordsCleaner nl 639-2/T: nld639-2/B: dut nld Living Individual 110 nl.embed.robbert_v2_dutch_base roberta_embeddings_robbert_v2_dutch_base Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 111 nl.embed.robbertje_1_gb_bort roberta_embeddings_robbertje_1_gb_bort Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 112 nl.embed.robbertje_1_gb_shuffled roberta_embeddings_robbertje_1_gb_shuffled Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 113 nl.embed.robbertje_1_gb_non_shuffled roberta_embeddings_robbertje_1_gb_non_shuffled Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 114 nl.embed.robbertje_1_gb_merged roberta_embeddings_robbertje_1_gb_merged Embeddings Dutch, Flemish RoBertaEmbeddings nl 639-2/T: nld639-2/B: dut nld Living Individual 115 nl.embed.w2v_cc_300d w2v_cc_300d Embeddings Dutch, Flemish WordEmbeddingsModel nl 639-2/T: nld639-2/B: dut nld Living Individual 116 nl.lemma lemma_spacylookup Lemmatization Dutch, Flemish LemmatizerModel nl 639-2/T: nld639-2/B: dut nld Living Individual 117 arz.embed.w2v_cc_300d w2v_cc_300d Embeddings Egyptian Arabic WordEmbeddingsModel nan nan arz Living Individual 118 eml.embed.w2v_cc_300d w2v_cc_300d Embeddings Emiliano-Romagnolo WordEmbeddingsModel eml nan nan Living Individual 119 en.ner.debertav3_large.conll03 deberta_v3_large_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 120 en.ner.debertav3_base.conll03 deberta_v3_base_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 121 en.ner.debertav3_small.conll03 deberta_v3_small_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 122 en.ner.debertav3_xsmall.conll03 deberta_v3_xsmall_token_classifier_conll03 Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 123 en.ner.debertav3_large.ontonotes deberta_v3_large_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 124 en.ner.debertav3_base.ontonotes deberta_v3_base_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 125 en.ner.debertav3_small.ontonotes deberta_v3_small_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 126 en.ner.debertav3_xsmall.ontonotes deberta_v3_xsmall_token_classifier_ontonotes Named Entity Recognition English DeBertaForTokenClassification en eng eng Living Individual 127 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 128 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 129 en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment Entity Resolution English SentenceEntityResolverModel en eng eng Living Individual 130 en.embed.albert_xlarge_v1 albert_embeddings_albert_xlarge_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 131 en.embed.albert_base_v1 albert_embeddings_albert_base_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 132 en.embed.albert_xxlarge_v1 albert_embeddings_albert_xxlarge_v1 Embeddings English AlbertEmbeddings en eng eng Living Individual 133 en.embed.distilbert_base_en_cased distilbert_embeddings_distilbert_base_en_cased Embeddings English DistilBertEmbeddings en eng eng Living Individual 134 en.embed.distilbert_base_uncased_sparse_90_unstructured_pruneofa distilbert_embeddings_distilbert_base_uncased_sparse_90_unstructured_pruneofa Embeddings English DistilBertEmbeddings en eng eng Living Individual 135 en.embed.distilbert_base_uncased_sparse_85_unstructured_pruneofa distilbert_embeddings_distilbert_base_uncased_sparse_85_unstructured_pruneofa Embeddings English DistilBertEmbeddings en eng eng Living Individual 136 en.classify.questionpair classifierdl_electra_questionpair Text Classification English ClassifierDLModel en eng eng Living Individual 137 en.classify.question_vs_statement bert_sequence_classifier_question_statement Text Classification English BertForSequenceClassification en eng eng Living Individual 138 en.classify.song_lyrics bert_sequence_classifier_song_lyrics Text Classification English BertForSequenceClassification en eng eng Living Individual 139 en.embed.muppet_roberta_base roberta_embeddings_muppet_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 140 en.embed.muppet_roberta_large roberta_embeddings_muppet_roberta_large Embeddings English RoBertaEmbeddings en eng eng Living Individual 141 en.embed.fairlex_ecthr_minilm roberta_embeddings_fairlex_ecthr_minilm Embeddings English RoBertaEmbeddings en eng eng Living Individual 142 en.embed.distilroberta_base_finetuned_jira_qt_issue_titles_and_bodies roberta_embeddings_distilroberta_base_finetuned_jira_qt_issue_titles_and_bodies Embeddings English RoBertaEmbeddings en eng eng Living Individual 143 en.embed.legal_roberta_base roberta_embeddings_legal_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 144 en.embed.distilroberta_base roberta_embeddings_distilroberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 145 en.embed.pmc_med_bio_mlm_roberta_large roberta_embeddings_pmc_med_bio_mlm_roberta_large Embeddings English RoBertaEmbeddings en eng eng Living Individual 146 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 147 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 148 en.lemma lemma_lines Lemmatization English LemmatizerModel en eng eng Living Individual 149 en.embed.roberta_pubmed roberta_embeddings_roberta_pubmed Embeddings English RoBertaEmbeddings en eng eng Living Individual 150 en.embed.fairlex_scotus_minilm roberta_embeddings_fairlex_scotus_minilm Embeddings English RoBertaEmbeddings en eng eng Living Individual 151 en.embed.distilroberta_base_finetuned_jira_qt_issue_title roberta_embeddings_distilroberta_base_finetuned_jira_qt_issue_title Embeddings English RoBertaEmbeddings en eng eng Living Individual 152 en.embed.chEMBL26_smiles_v2 roberta_embeddings_chEMBL26_smiles_v2 Embeddings English RoBertaEmbeddings en eng eng Living Individual 153 en.embed.SecRoBERTa roberta_embeddings_SecRoBERTa Embeddings English RoBertaEmbeddings en eng eng Living Individual 154 en.embed.distilroberta_base_climate_d_s roberta_embeddings_distilroberta_base_climate_d_s Embeddings English RoBertaEmbeddings en eng eng Living Individual 155 en.embed.chEMBL_smiles_v1 roberta_embeddings_chEMBL_smiles_v1 Embeddings English RoBertaEmbeddings en eng eng Living Individual 156 en.embed.distilroberta_base_climate_f roberta_embeddings_distilroberta_base_climate_f Embeddings English RoBertaEmbeddings en eng eng Living Individual 157 en.embed.distilroberta_base_climate_d roberta_embeddings_distilroberta_base_climate_d Embeddings English RoBertaEmbeddings en eng eng Living Individual 158 en.embed.Bible_roberta_base roberta_embeddings_Bible_roberta_base Embeddings English RoBertaEmbeddings en eng eng Living Individual 159 en.embed.w2v_cc_300d w2v_cc_300d Embeddings English WordEmbeddingsModel en eng eng Living Individual 160 en.pos pos_atis Part of Speech Tagging English PerceptronModel en eng eng Living Individual 161 en.ner.ner_chemical_bionlp_bc5cdr_pubmed roberta_ner_ner_chemical_bionlp_bc5cdr_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 162 en.pos.roberta_large_english_upos roberta_pos_roberta_large_english_upos Part of Speech Tagging English RoBertaForTokenClassification en eng eng Living Individual 163 en.ner.roberta_ticker roberta_ner_roberta_ticker Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 164 en.embed.bert_political_election2020_twitter_mlm bert_embeddings_bert_political_election2020_twitter_mlm Embeddings English BertEmbeddings en eng eng Living Individual 165 en.embed.bert_base_uncased_mnli_sparse_70_unstructured_no_classifier bert_embeddings_bert_base_uncased_mnli_sparse_70_unstructured_no_classifier Embeddings English BertEmbeddings en eng eng Living Individual 166 en.embed.crosloengual_bert bert_embeddings_crosloengual_bert Embeddings English BertEmbeddings en eng eng Living Individual 167 en.embed.chemical_bert_uncased bert_embeddings_chemical_bert_uncased Embeddings English BertEmbeddings en eng eng Living Individual 168 en.embed.deberta_base_uncased bert_embeddings_deberta_base_uncased Embeddings English BertEmbeddings en eng eng Living Individual 169 en.embed.bert_base_en_cased bert_embeddings_bert_base_en_cased Embeddings English BertEmbeddings en eng eng Living Individual 170 en.embed.bert_for_patents bert_embeddings_bert_for_patents Embeddings English BertEmbeddings en eng eng Living Individual 171 en.embed.SecBERT bert_embeddings_SecBERT Embeddings English BertEmbeddings en eng eng Living Individual 172 en.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings English BertEmbeddings en eng eng Living Individual 173 en.embed.DiLBERT bert_embeddings_DiLBERT Embeddings English BertEmbeddings en eng eng Living Individual 174 en.embed.FinancialBERT bert_embeddings_FinancialBERT Embeddings English BertEmbeddings en eng eng Living Individual 175 en.embed.false_positives_scancode_bert_base_uncased_L8_1 bert_embeddings_false_positives_scancode_bert_base_uncased_L8_1 Embeddings English BertEmbeddings en eng eng Living Individual 176 en.embed.legal_bert_small_uncased bert_embeddings_legal_bert_small_uncased Embeddings English BertEmbeddings en eng eng Living Individual 177 en.embed.legal_bert_base_uncased bert_embeddings_legal_bert_base_uncased Embeddings English BertEmbeddings en eng eng Living Individual 178 en.embed.COVID_SciBERT bert_embeddings_COVID_SciBERT Embeddings English BertEmbeddings en eng eng Living Individual 179 en.embed.e bert_biolink_base Embeddings English BertEmbeddings en eng eng Living Individual 180 en.embed.danbert_small_cased bert_embeddings_danbert_small_cased Embeddings English BertEmbeddings en eng eng Living Individual 181 en.embed.bert_base_uncased_dstc9 bert_embeddings_bert_base_uncased_dstc9 Embeddings English BertEmbeddings en eng eng Living Individual 182 en.embed.hateBERT bert_embeddings_hateBERT Embeddings English BertEmbeddings en eng eng Living Individual 183 en.embed.childes_bert bert_embeddings_childes_bert Embeddings English BertEmbeddings en eng eng Living Individual 184 en.embed.clinical_pubmed_bert_base_512 bert_embeddings_clinical_pubmed_bert_base_512 Embeddings English BertEmbeddings en eng eng Living Individual 185 en.embed.netbert bert_embeddings_netbert Embeddings English BertEmbeddings en eng eng Living Individual 186 en.embed.psych_search bert_embeddings_psych_search Embeddings English BertEmbeddings en eng eng Living Individual 187 en.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings English BertEmbeddings en eng eng Living Individual 188 en.embed.finbert_pretrain_yiyanghkust bert_embeddings_finbert_pretrain_yiyanghkust Embeddings English BertEmbeddings en eng eng Living Individual 189 en.embed.lic_class_scancode_bert_base_cased_L32_1 bert_embeddings_lic_class_scancode_bert_base_cased_L32_1 Embeddings English BertEmbeddings en eng eng Living Individual 190 en.embed.sec_bert_sh bert_embeddings_sec_bert_sh Embeddings English BertEmbeddings en eng eng Living Individual 191 en.embed.sec_bert_num bert_embeddings_sec_bert_num Embeddings English BertEmbeddings en eng eng Living Individual 192 en.embed.finest_bert bert_embeddings_finest_bert Embeddings English BertEmbeddings en eng eng Living Individual 193 en.embed.bert_large_cased_whole_word_masking bert_embeddings_bert_large_cased_whole_word_masking Embeddings English BertEmbeddings en eng eng Living Individual 194 en.embed.clinical_pubmed_bert_base_128 bert_embeddings_clinical_pubmed_bert_base_128 Embeddings English BertEmbeddings en eng eng Living Individual 195 en.embed.bert_base_uncased_sparse_70_unstructured bert_embeddings_bert_base_uncased_sparse_70_unstructured Embeddings English BertEmbeddings en eng eng Living Individual 196 en.embed.sec_bert_base bert_embeddings_sec_bert_base Embeddings English BertEmbeddings en eng eng Living Individual 197 en.stopwords stopwords_iso Stop Words Removal English StopWordsCleaner en eng eng Living Individual 198 en.embed.agriculture_bert_uncased bert_embeddings_agriculture_bert_uncased Embeddings English BertEmbeddings en eng eng Living Individual 199 en.embed.bert_large_uncased_whole_word_masking bert_embeddings_bert_large_uncased_whole_word_masking Embeddings English BertEmbeddings en eng eng Living Individual 200 en.embed.ge bert_biolink_large Embeddings English BertEmbeddings en eng eng Living Individual 201 en.ner.roberta_large_finetuned_abbr roberta_ner_roberta_large_finetuned_abbr Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 202 en.ner.roberta_classics_ner roberta_ner_roberta_classics_ner Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 203 en.pos.roberta_base_english_upos roberta_pos_roberta_base_english_upos Part of Speech Tagging English RoBertaForTokenClassification en eng eng Living Individual 204 en.ner.roberta_large_ner_english roberta_ner_roberta_large_ner_english Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 205 en.ner.ner_gene_dna_rna_jnlpba_pubmed roberta_ner_ner_gene_dna_rna_jnlpba_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 206 en.ner.ner_disease_ncbi_bionlp_bc5cdr_pubmed roberta_ner_ner_disease_ncbi_bionlp_bc5cdr_pubmed Named Entity Recognition English RoBertaForTokenClassification en eng eng Living Individual 207 myv.embed.w2v_cc_300d w2v_cc_300d Embeddings Erzya WordEmbeddingsModel nan myv myv Living Individual 208 fo.pos pos_farpahc Part of Speech Tagging Faroese PerceptronModel fo fao fao Living Individual 209 fi.embed.w2v_cc_300d w2v_cc_300d Embeddings Finnish WordEmbeddingsModel fi fin fin Living Individual 210 fi.pos pos_tdt Part of Speech Tagging Finnish PerceptronModel fi fin fin Living Individual 211 fi.lemma lemma_tdt Lemmatization Finnish LemmatizerModel fi fin fin Living Individual 212 fi.stopwords stopwords_iso Stop Words Removal Finnish StopWordsCleaner fi fin fin Living Individual 213 fi.lemma lemma_tdt Lemmatization Finnish LemmatizerModel fi fin fin Living Individual 214 fr.embed.camembert_large camembert_large Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 215 fr.embed.camembert_base camembert_base Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 216 fr.embed.camembert_ccnet4g camembert_base_ccnet_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 217 fr.embed.camembert_base_ccnet camembert_base_ccnet Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 218 fr.embed.camembert_oscar_4g camembert_base_oscar_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 219 fr.embed.camembert_wiki_4g camembert_base_wikipedia_4gb Embeddings French CamemBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 220 fr.embed.albert albert_embeddings_fralbert_base Embeddings French AlbertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 221 fr.embed.distilbert distilbert_embeddings_distilbert_base_fr_cased Embeddings French DistilBertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 222 fr.embed.bert_base_fr_cased bert_embeddings_bert_base_fr_cased Embeddings French BertEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 223 fr.pos pos_sequoia Part of Speech Tagging French PerceptronModel fr 639-2/T: fra639-2/B: fre fra Living Individual 224 fr.pos pos_sequoia Part of Speech Tagging French PerceptronModel fr 639-2/T: fra639-2/B: fre fra Living Individual 225 fr.embed.french_roberta roberta_embeddings_french_roberta Embeddings French RoBertaEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 226 fr.lemma lemma_ftb Lemmatization French LemmatizerModel fr 639-2/T: fra639-2/B: fre fra Living Individual 227 fr.lemma lemma_ftb Lemmatization French LemmatizerModel fr 639-2/T: fra639-2/B: fre fra Living Individual 228 fr.stopwords stopwords_iso Stop Words Removal French StopWordsCleaner fr 639-2/T: fra639-2/B: fre fra Living Individual 229 fr.embed.roberta_base_wechsel_french roberta_embeddings_roberta_base_wechsel_french Embeddings French RoBertaEmbeddings fr 639-2/T: fra639-2/B: fre fra Living Individual 230 gd.embed.w2v_cc_300d w2v_cc_300d Embeddings Gaelic, Scottish Gaelic WordEmbeddingsModel gd gla gla Living Individual 231 gl.embed.w2v_cc_300d w2v_cc_300d Embeddings Galician WordEmbeddingsModel gl glg glg Living Individual 232 gl.lemma lemma_treegal Lemmatization Galician LemmatizerModel gl glg glg Living Individual 233 ka.embed.w2v_cc_300d w2v_cc_300d Embeddings Georgian WordEmbeddingsModel ka 639-2/T: kat639-2/B: geo kat Living Individual 234 de.embed.distilbert_base_de_cased distilbert_embeddings_distilbert_base_de_cased Embeddings German DistilBertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 235 de.embed.distilbert_base_german_cased distilbert_embeddings_distilbert_base_german_cased Embeddings German DistilBertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 236 de.embed.albert_german_ner albert_embeddings_albert_german_ner Embeddings German AlbertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 237 de.embed.bert_base_historical_german_rw_cased bert_embeddings_bert_base_historical_german_rw_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 238 de.embed.gbert_base bert_embeddings_gbert_base Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 239 de.embed.german_financial_statements_bert bert_embeddings_german_financial_statements_bert Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 240 de.stopwords stopwords_iso Stop Words Removal German StopWordsCleaner de 639-2/T: deu639-2/B: ger deu Living Individual 241 de.lemma lemma_spacylookup Lemmatization German LemmatizerModel de 639-2/T: deu639-2/B: ger deu Living Individual 242 de.embed.bert_base_german_dbmdz_uncased bert_embeddings_bert_base_german_dbmdz_uncased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 243 de.embed.roberta_base_wechsel_german roberta_embeddings_roberta_base_wechsel_german Embeddings German RoBertaEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 244 de.embed.gbert_large bert_embeddings_gbert_large Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 245 de.embed.bert_base_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 246 de.embed.bert_base_german_cased_oldvocab bert_embeddings_bert_base_german_cased_oldvocab Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 247 de.embed.bert_base_de_cased bert_embeddings_bert_base_de_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 248 de.embed.bert_base_german_uncased bert_embeddings_bert_base_german_uncased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 249 de.embed.bert_base_german_dbmdz_cased bert_embeddings_bert_base_german_dbmdz_cased Embeddings German BertEmbeddings de 639-2/T: deu639-2/B: ger deu Living Individual 250 gom.embed.w2v_cc_300d w2v_cc_300d Embeddings Goan Konkani WordEmbeddingsModel nan nan gom Living Individual 251 gu.embed.RoBERTa_hindi_guj_san roberta_embeddings_RoBERTa_hindi_guj_san Embeddings Gujarati RoBertaEmbeddings gu guj guj Living Individual 252 gu.stopwords stopwords_iso Stop Words Removal Gujarati StopWordsCleaner gu guj guj Living Individual 253 he.stopwords stopwords_iso Stop Words Removal Hebrew StopWordsCleaner he heb heb Living Individual 254 hi.embed.distilbert_base_hi_cased distilbert_embeddings_distilbert_base_hi_cased Embeddings Hindi DistilBertEmbeddings hi hin hin Living Individual 255 hi.embed.indic_transformers_hi_distilbert distilbert_embeddings_indic_transformers_hi_distilbert Embeddings Hindi DistilBertEmbeddings hi hin hin Living Individual 256 hi.stopwords stopwords_iso Stop Words Removal Hindi StopWordsCleaner hi hin hin Living Individual 257 hi.embed.RoBERTa_hindi_guj_san roberta_embeddings_RoBERTa_hindi_guj_san Embeddings Hindi RoBertaEmbeddings hi hin hin Living Individual 258 hi.embed.indic_transformers_hi_roberta roberta_embeddings_indic_transformers_hi_roberta Embeddings Hindi RoBertaEmbeddings hi hin hin Living Individual 259 hi.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Hindi BertEmbeddings hi hin hin Living Individual 260 hi.embed.indic_transformers_hi_bert bert_embeddings_indic_transformers_hi_bert Embeddings Hindi BertEmbeddings hi hin hin Living Individual 261 hu.lemma lemma_spacylookup Lemmatization Hungarian LemmatizerModel hu hun hun Living Individual 262 hu.stopwords stopwords_iso Stop Words Removal Hungarian StopWordsCleaner hu hun hun Living Individual 263 is.lemma lemma_icepahc Lemmatization Icelandic LemmatizerModel is 639-2/T: isl639-2/B: ice isl Living Individual 264 is.stopwords stopwords_iso Stop Words Removal Icelandic StopWordsCleaner is 639-2/T: isl639-2/B: ice isl Living Individual 265 id.embed.distilbert distilbert_embeddings_distilbert_base_indonesian Embeddings Indonesian DistilBertEmbeddings id ind ind Living Individual 266 id.pos pos_csui Part of Speech Tagging Indonesian PerceptronModel id ind ind Living Individual 267 id.embed.indo_roberta_small roberta_embeddings_indo_roberta_small Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 268 id.embed.indonesian_roberta_base roberta_embeddings_indonesian_roberta_base Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 269 id.pos.indonesian_roberta_base_posp_tagger roberta_pos_indonesian_roberta_base_posp_tagger Part of Speech Tagging Indonesian RoBertaForTokenClassification id ind ind Living Individual 270 id.lemma lemma_gsd Lemmatization Indonesian LemmatizerModel id ind ind Living Individual 271 id.lemma lemma_gsd Lemmatization Indonesian LemmatizerModel id ind ind Living Individual 272 id.embed.roberta_base_indonesian_522M roberta_embeddings_roberta_base_indonesian_522M Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 273 id.stopwords stopwords_iso Stop Words Removal Indonesian StopWordsCleaner id ind ind Living Individual 274 id.embed.indonesian_roberta_large roberta_embeddings_indonesian_roberta_large Embeddings Indonesian RoBertaEmbeddings id ind ind Living Individual 275 ga.pos pos_idt Part of Speech Tagging Irish PerceptronModel ga gle gle Living Individual 276 ga.stopwords stopwords_iso Stop Words Removal Irish StopWordsCleaner ga gle gle Living Individual 277 it.embed.distilbert_base_it_cased distilbert_embeddings_distilbert_base_it_cased Embeddings Italian DistilBertEmbeddings it ita ita Living Individual 278 it.embed.BERTino distilbert_embeddings_BERTino Embeddings Italian DistilBertEmbeddings it ita ita Living Individual 279 it.stopwords stopwords_iso Stop Words Removal Italian StopWordsCleaner it ita ita Living Individual 280 it.pos pos_partut Part of Speech Tagging Italian PerceptronModel it ita ita Living Individual 281 it.embed.bert_base_italian_xxl_cased bert_embeddings_bert_base_italian_xxl_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 282 it.embed.bert_base_italian_xxl_uncased bert_embeddings_bert_base_italian_xxl_uncased Embeddings Italian BertEmbeddings it ita ita Living Individual 283 it.embed.chefberto_italian_cased bert_embeddings_chefberto_italian_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 284 it.embed.hseBert_it_cased bert_embeddings_hseBert_it_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 285 it.embed.wineberto_italian_cased bert_embeddings_wineberto_italian_cased Embeddings Italian BertEmbeddings it ita ita Living Individual 286 it.pos pos_partut Part of Speech Tagging Italian PerceptronModel it ita ita Living Individual 287 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 288 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 289 it.lemma lemma_twittiro Lemmatization Italian LemmatizerModel it ita ita Living Individual 290 ja.embed.distilbert_base_ja_cased distilbert_embeddings_distilbert_base_ja_cased Embeddings Japanese DistilBertEmbeddings ja jpn jpn Living Individual 291 ja.embed.albert_base_japanese_v1 albert_embeddings_albert_base_japanese_v1 Embeddings Japanese AlbertEmbeddings ja jpn jpn Living Individual 292 ja.embed.bert_base_ja_cased bert_embeddings_bert_base_ja_cased Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 293 ja.embed.bert_base_japanese_char_v2 bert_embeddings_bert_base_japanese_char_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 294 ja.embed.bert_base_japanese_char_extended bert_embeddings_bert_base_japanese_char_extended Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 295 ja.embed.bert_large_japanese_char bert_embeddings_bert_large_japanese_char Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 296 ja.embed.bert_large_japanese bert_embeddings_bert_large_japanese Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 297 ja.embed.bert_small_japanese bert_embeddings_bert_small_japanese Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 298 ja.embed.bert_large_japanese_char_extended bert_embeddings_bert_large_japanese_char_extended Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 299 ja.pos pos_gsd Part of Speech Tagging Japanese PerceptronModel ja jpn jpn Living Individual 300 ja.embed.bert_small_japanese_fin bert_embeddings_bert_small_japanese_fin Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 301 ja.embed.bert_base_japanese_basic_char_v2 bert_embeddings_bert_base_japanese_basic_char_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 302 ja.stopwords stopwords_iso Stop Words Removal Japanese StopWordsCleaner ja jpn jpn Living Individual 303 ja.embed.bert_base_japanese_char_whole_word_masking bert_embeddings_bert_base_japanese_char_whole_word_masking Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 304 ja.embed.bert_base_japanese_char bert_embeddings_bert_base_japanese_char Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 305 ja.embed.bert_base_japanese_whole_word_masking bert_embeddings_bert_base_japanese_whole_word_masking Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 306 ja.embed.bert_base_japanese_v2 bert_embeddings_bert_base_japanese_v2 Embeddings Japanese BertEmbeddings ja jpn jpn Living Individual 307 jv.embed.distilbert distilbert_embeddings_javanese_distilbert_small Embeddings Javanese DistilBertEmbeddings jv jav jav Living Individual 308 jv.embed.javanese_distilbert_small_imdb distilbert_embeddings_javanese_distilbert_small_imdb Embeddings Javanese DistilBertEmbeddings jv jav jav Living Individual 309 jv.embed.javanese_roberta_small roberta_embeddings_javanese_roberta_small Embeddings Javanese RoBertaEmbeddings jv jav jav Living Individual 310 jv.embed.javanese_roberta_small_imdb roberta_embeddings_javanese_roberta_small_imdb Embeddings Javanese RoBertaEmbeddings jv jav jav Living Individual 311 jv.embed.javanese_bert_small_imdb bert_embeddings_javanese_bert_small_imdb Embeddings Javanese BertEmbeddings jv jav jav Living Individual 312 jv.embed.javanese_bert_small bert_embeddings_javanese_bert_small Embeddings Javanese BertEmbeddings jv jav jav Living Individual 313 kn.embed.KNUBert roberta_embeddings_KNUBert Embeddings Kannada RoBertaEmbeddings kn kan kan Living Individual 314 kn.embed.KanBERTo roberta_embeddings_KanBERTo Embeddings Kannada RoBertaEmbeddings kn kan kan Living Individual 315 kn.stopwords stopwords_iso Stop Words Removal Kannada StopWordsCleaner kn kan kan Living Individual 316 ky.stopwords stopwords_iso Stop Words Removal Kirghiz, Kyrgyz StopWordsCleaner ky kir kir Living Individual 317 ko.lemma lemma_gsd Lemmatization Korean LemmatizerModel ko kor kor Living Individual 318 ko.stopwords stopwords_iso Stop Words Removal Korean StopWordsCleaner ko kor kor Living Individual 319 ko.embed.roberta_ko_small roberta_embeddings_roberta_ko_small Embeddings Korean RoBertaEmbeddings ko kor kor Living Individual 320 ko.pos pos_gsd Part of Speech Tagging Korean PerceptronModel ko kor kor Living Individual 321 ko.embed.bert_kor_base bert_embeddings_bert_kor_base Embeddings Korean BertEmbeddings ko kor kor Living Individual 322 ko.embed.dbert bert_embeddings_dbert Embeddings Korean BertEmbeddings ko kor kor Living Individual 323 ko.embed.KR_FinBert bert_embeddings_KR_FinBert Embeddings Korean BertEmbeddings ko kor kor Living Individual 324 ko.embed.bert_base_v1_sports bert_embeddings_bert_base_v1_sports Embeddings Korean BertEmbeddings ko kor kor Living Individual 325 ko.lemma lemma_gsd Lemmatization Korean LemmatizerModel ko kor kor Living Individual 326 lb.stopwords stopwords_iso Stop Words Removal Letzeburgesch, Luxembourgish StopWordsCleaner lb ltz ltz Living Individual 327 lb.lemma lemma_spacylookup Lemmatization Letzeburgesch, Luxembourgish LemmatizerModel lb ltz ltz Living Individual 328 lb.embed.w2v_cc_300d w2v_cc_300d Embeddings Letzeburgesch, Luxembourgish WordEmbeddingsModel lb ltz ltz Living Individual 329 lij.stopwords stopwords_iso Stop Words Removal Ligurian StopWordsCleaner nan nan lij Living Individual 330 lt.embed.w2v_cc_300d w2v_cc_300d Embeddings Lithuanian WordEmbeddingsModel lt lit lit Living Individual 331 lt.lemma lemma_spacylookup Lemmatization Lithuanian LemmatizerModel lt lit lit Living Individual 332 lt.stopwords stopwords_iso Stop Words Removal Lithuanian StopWordsCleaner lt lit lit Living Individual 333 lmo.embed.w2v_cc_300d w2v_cc_300d Embeddings Lombard WordEmbeddingsModel nan nan lmo Living Individual 334 nds.embed.w2v_cc_300d w2v_cc_300d Embeddings Low German, Low Saxon WordEmbeddingsModel nan nds nds Living Individual 335 mk.stopwords stopwords_iso Stop Words Removal Macedonian StopWordsCleaner mk 639-2/T: mkd639-2/B: mac mkd Living Individual 336 mk.lemma lemma_spacylookup Lemmatization Macedonian LemmatizerModel mk 639-2/T: mkd639-2/B: mac mkd Living Individual 337 mk.embed.w2v_cc_300d w2v_cc_300d Embeddings Macedonian WordEmbeddingsModel mk 639-2/T: mkd639-2/B: mac mkd Living Individual 338 mai.embed.w2v_cc_300d w2v_cc_300d Embeddings Maithili WordEmbeddingsModel nan mai mai Living Individual 339 ml.stopwords stopwords_iso Stop Words Removal Malayalam StopWordsCleaner ml mal mal Living Individual 340 ml.embed.w2v_cc_300d w2v_cc_300d Embeddings Malayalam WordEmbeddingsModel ml mal mal Living Individual 341 mt.lemma lemma_mudt Lemmatization Maltese LemmatizerModel mt mlt mlt Living Individual 342 mt.pos pos_mudt Part of Speech Tagging Maltese PerceptronModel mt mlt mlt Living Individual 343 mt.embed.w2v_cc_300d w2v_cc_300d Embeddings Maltese WordEmbeddingsModel mt mlt mlt Living Individual 344 gv.embed.w2v_cc_300d w2v_cc_300d Embeddings Manx WordEmbeddingsModel gv glv glv Living Individual 345 mr.embed.distilbert distilbert_embeddings_marathi_distilbert Embeddings Marathi DistilBertEmbeddings mr mar mar Living Individual 346 mr.embed.albert albert_embeddings_marathi_albert Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 347 mr.embed.albert albert_embeddings_marathi_albert Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 348 mr.embed.albert_v2 albert_embeddings_marathi_albert_v2 Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 349 mr.embed.albert_v2 albert_embeddings_marathi_albert_v2 Embeddings Marathi AlbertEmbeddings mr mar mar Living Individual 350 mr.lemma lemma_ufal Lemmatization Marathi LemmatizerModel mr mar mar Living Individual 351 mr.stopwords stopwords_iso Stop Words Removal Marathi StopWordsCleaner mr mar mar Living Individual 352 mr.embed.marathi_bert bert_embeddings_marathi_bert Embeddings Marathi BertEmbeddings mr mar mar Living Individual 353 mr.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Marathi BertEmbeddings mr mar mar Living Individual 354 mr.pos pos_ufal Part of Speech Tagging Marathi PerceptronModel mr mar mar Living Individual 355 mzn.embed.w2v_cc_300d w2v_cc_300d Embeddings Mazanderani WordEmbeddingsModel nan nan mzn Living Individual 356 min.embed.w2v_cc_300d w2v_cc_300d Embeddings Minangkabau WordEmbeddingsModel nan min min Living Individual 357 xmf.embed.w2v_cc_300d w2v_cc_300d Embeddings Mingrelian WordEmbeddingsModel nan nan xmf Living Individual 358 mwl.embed.w2v_cc_300d w2v_cc_300d Embeddings Mirandese WordEmbeddingsModel nan mwl mwl Living Individual 359 el.stopwords stopwords_iso Stop Words Removal Modern Greek (1453-) StopWordsCleaner el 639-2/T: ell639-2/B: gre ell Living Individual 360 ro.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ro_cased Embeddings Moldavian, Moldovan, Romanian DistilBertEmbeddings ro 639-2/T: ron639-2/B: rum ron Living Individual 361 ro.embed.ALR_BERT albert_embeddings_ALR_BERT Embeddings Moldavian, Moldovan, Romanian AlbertEmbeddings ro 639-2/T: ron639-2/B: rum ron Living Individual 362 ro.embed.w2v_cc_300d w2v_cc_300d Embeddings Moldavian, Moldovan, Romanian WordEmbeddingsModel ro 639-2/T: ron639-2/B: rum ron Living Individual 363 ro.stopwords stopwords_iso Stop Words Removal Moldavian, Moldovan, Romanian StopWordsCleaner ro 639-2/T: ron639-2/B: rum ron Living Individual 364 ro.pos pos_nonstandard Part of Speech Tagging Moldavian, Moldovan, Romanian PerceptronModel ro 639-2/T: ron639-2/B: rum ron Living Individual 365 ro.lemma lemma_spacylookup Lemmatization Moldavian, Moldovan, Romanian LemmatizerModel ro 639-2/T: ron639-2/B: rum ron Living Individual 366 nap.embed.w2v_cc_300d w2v_cc_300d Embeddings Neapolitan WordEmbeddingsModel nan nap nap Living Individual 367 new.embed.w2v_cc_300d w2v_cc_300d Embeddings Nepal Bhasa, Newari WordEmbeddingsModel nan new new Living Individual 368 frr.embed.w2v_cc_300d w2v_cc_300d Embeddings Northern Frisian WordEmbeddingsModel nan frr frr Living Individual 369 sme.lemma lemma_giella Lemmatization Northern Sami LemmatizerModel se sme sme Living Individual 370 sme.pos pos_giella Part of Speech Tagging Northern Sami PerceptronModel se sme sme Living Individual 371 nso.embed.w2v_cc_300d w2v_cc_300d Embeddings Northern Sotho, Pedi, Sepedi WordEmbeddingsModel nan nso nso Living Individual 372 nb.stopwords stopwords_iso Stop Words Removal Norwegian Bokmål StopWordsCleaner nb nob nob Living Individual 373 nb.lemma lemma_spacylookup Lemmatization Norwegian Bokmål LemmatizerModel nb nob nob Living Individual 374 nn.embed.w2v_cc_300d w2v_cc_300d Embeddings Norwegian Nynorsk WordEmbeddingsModel nn nno nno Living Individual 375 oc.embed.w2v_cc_300d w2v_cc_300d Embeddings Occitan (post 1500) WordEmbeddingsModel oc oci oci Living Individual 376 os.embed.w2v_cc_300d w2v_cc_300d Embeddings Ossetian, Ossetic WordEmbeddingsModel os oss oss Living Individual 377 pa.embed.w2v_cc_300d w2v_cc_300d Embeddings Panjabi, Punjabi WordEmbeddingsModel pa pan pan Living Individual 378 pa.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Panjabi, Punjabi BertEmbeddings pa pan pan Living Individual 379 pfl.embed.w2v_cc_300d w2v_cc_300d Embeddings Pfaelzisch WordEmbeddingsModel nan nan pfl Living Individual 380 pms.embed.w2v_cc_300d w2v_cc_300d Embeddings Piemontese WordEmbeddingsModel nan nan pms Living Individual 381 pl.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_pl_cased Embeddings Polish DistilBertEmbeddings pl pol pol Living Individual 382 pl.stopwords stopwords_iso Stop Words Removal Polish StopWordsCleaner pl pol pol Living Individual 383 pl.embed.w2v_cc_300d w2v_cc_300d Embeddings Polish WordEmbeddingsModel pl pol pol Living Individual 384 pl.lemma lemma_lfg Lemmatization Polish LemmatizerModel pl pol pol Living Individual 385 pt.med_ner.deid.subentity ner_deid_subentity De-identification Portuguese MedicalNerModel pt por por Living Individual 386 pt.med_ner.deid.generic ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 387 pt.med_ner.deid ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 388 pt.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_pt_cased Embeddings Portuguese DistilBertEmbeddings pt por por Living Individual 389 pt.embed.BR_BERTo roberta_embeddings_BR_BERTo Embeddings Portuguese RoBertaEmbeddings pt por por Living Individual 390 pt.embed.gs_all biobert_embeddings_all Embeddings Portuguese BertEmbeddings pt por por Living Individual 391 pt.stopwords stopwords_iso Stop Words Removal Portuguese StopWordsCleaner pt por por Living Individual 392 pt.embed.gs_clinical biobert_embeddings_clinical Embeddings Portuguese BertEmbeddings pt por por Living Individual 393 pt.embed.gs_biomedical biobert_embeddings_biomedical Embeddings Portuguese BertEmbeddings pt por por Living Individual 394 pt.lemma lemma_bosque Lemmatization Portuguese LemmatizerModel pt por por Living Individual 395 pt.lemma lemma_bosque Lemmatization Portuguese LemmatizerModel pt por por Living Individual 396 pt.embed.bert_base_portuguese_cased_finetuned_tcu_acordaos bert_embeddings_bert_base_portuguese_cased_finetuned_tcu_acordaos Embeddings Portuguese BertEmbeddings pt por por Living Individual 397 pt.ner.satellite_instrument_roberta_NER roberta_ner_satellite_instrument_roberta_NER Named Entity Recognition Portuguese RoBertaForTokenClassification pt por por Living Individual 398 pt.embed.bert_small_gl_cased bert_embeddings_bert_small_gl_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 399 pt.embed.bert_large_cased_pt_lenerbr bert_embeddings_bert_large_cased_pt_lenerbr Embeddings Portuguese BertEmbeddings pt por por Living Individual 400 pt.embed.bert_large_portuguese_cased bert_embeddings_bert_large_portuguese_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 401 pt.embed.bert_base_cased_pt_lenerbr bert_embeddings_bert_base_cased_pt_lenerbr Embeddings Portuguese BertEmbeddings pt por por Living Individual 402 pt.embed.bert_base_portuguese_cased_finetuned_peticoes bert_embeddings_bert_base_portuguese_cased_finetuned_peticoes Embeddings Portuguese BertEmbeddings pt por por Living Individual 403 pt.embed.bert_base_portuguese_cased bert_embeddings_bert_base_portuguese_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 404 pt.embed.bert_base_pt_cased bert_embeddings_bert_base_pt_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 405 pt.embed.bert_base_gl_cased bert_embeddings_bert_base_gl_cased Embeddings Portuguese BertEmbeddings pt por por Living Individual 406 rm.embed.w2v_cc_300d w2v_cc_300d Embeddings Romansh WordEmbeddingsModel rm roh roh Living Individual 407 ru.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ru_cased Embeddings Russian DistilBertEmbeddings ru rus rus Living Individual 408 ru.pos pos_syntagrus Part of Speech Tagging Russian PerceptronModel ru rus rus Living Individual 409 ru.lemma lemma_gsd Lemmatization Russian LemmatizerModel ru rus rus Living Individual 410 ru.lemma lemma_gsd Lemmatization Russian LemmatizerModel ru rus rus Living Individual 411 ru.embed.ruRoberta_large roberta_embeddings_ruRoberta_large Embeddings Russian RoBertaEmbeddings ru rus rus Living Individual 412 ru.pos pos_syntagrus Part of Speech Tagging Russian PerceptronModel ru rus rus Living Individual 413 ru.stopwords stopwords_iso Stop Words Removal Russian StopWordsCleaner ru rus rus Living Individual 414 ru.embed.roberta_base_russian_v0 roberta_embeddings_roberta_base_russian_v0 Embeddings Russian RoBertaEmbeddings ru rus rus Living Individual 415 ru.embed.bert_base_ru_cased bert_embeddings_bert_base_ru_cased Embeddings Russian BertEmbeddings ru rus rus Living Individual 416 ru.embed.w2v_cc_300d w2v_cc_300d Embeddings Russian WordEmbeddingsModel ru rus rus Living Individual 417 sco.embed.w2v_cc_300d w2v_cc_300d Embeddings Scots WordEmbeddingsModel nan sco sco Living Individual 418 sr.lemma lemma_spacylookup Lemmatization Serbian LemmatizerModel sr srp srp Living Individual 419 sr.embed.w2v_cc_300d w2v_cc_300d Embeddings Serbian WordEmbeddingsModel sr srp srp Living Individual 420 sr.lemma lemma_spacylookup Lemmatization Serbian LemmatizerModel sr srp srp Living Individual 421 sr.stopwords stopwords_iso Stop Words Removal Serbian StopWordsCleaner sr srp srp Living Individual 422 scn.embed.w2v_cc_300d w2v_cc_300d Embeddings Sicilian WordEmbeddingsModel nan scn scn Living Individual 423 sd.embed.w2v_cc_300d w2v_cc_300d Embeddings Sindhi WordEmbeddingsModel sd snd snd Living Individual 424 si.stopwords stopwords_iso Stop Words Removal Sinhala, Sinhalese StopWordsCleaner si sin sin Living Individual 425 si.embed.w2v_cc_300d w2v_cc_300d Embeddings Sinhala, Sinhalese WordEmbeddingsModel si sin sin Living Individual 426 sk.stopwords stopwords_iso Stop Words Removal Slovak StopWordsCleaner sk 639-2/T: slk639-2/B: slo slk Living Individual 427 sk.lemma lemma_snk Lemmatization Slovak LemmatizerModel sk 639-2/T: slk639-2/B: slo slk Living Individual 428 sk.embed.w2v_cc_300d w2v_cc_300d Embeddings Slovak WordEmbeddingsModel sk 639-2/T: slk639-2/B: slo slk Living Individual 429 sl.lemma lemma_sst Lemmatization Slovenian LemmatizerModel sl slv slv Living Individual 430 sl.stopwords stopwords_iso Stop Words Removal Slovenian StopWordsCleaner sl slv slv Living Individual 431 sl.pos pos_sst Part of Speech Tagging Slovenian PerceptronModel sl slv slv Living Individual 432 sl.embed.w2v_cc_300d w2v_cc_300d Embeddings Slovenian WordEmbeddingsModel sl slv slv Living Individual 433 so.embed.w2v_cc_300d w2v_cc_300d Embeddings Somali WordEmbeddingsModel so som som Living Individual 434 su.embed.w2v_cc_300d w2v_cc_300d Embeddings Sundanese WordEmbeddingsModel su sun sun Living Individual 435 su.embed.sundanese_roberta_base roberta_embeddings_sundanese_roberta_base Embeddings Sundanese RoBertaEmbeddings su sun sun Living Individual 436 sv.stopwords stopwords_iso Stop Words Removal Swedish StopWordsCleaner sv swe swe Living Individual 437 sv.embed.w2v_cc_300d w2v_cc_300d Embeddings Swedish WordEmbeddingsModel sv swe swe Living Individual 438 sv.lemma lemma_lines Lemmatization Swedish LemmatizerModel sv swe swe Living Individual 439 sv.lemma lemma_lines Lemmatization Swedish LemmatizerModel sv swe swe Living Individual 440 tl.lemma lemma_spacylookup Lemmatization Tagalog LemmatizerModel tl tgl tgl Living Individual 441 tl.embed.w2v_cc_300d w2v_cc_300d Embeddings Tagalog WordEmbeddingsModel tl tgl tgl Living Individual 442 tl.stopwords stopwords_iso Stop Words Removal Tagalog StopWordsCleaner tl tgl tgl Living Individual 443 tl.embed.roberta_tagalog_large roberta_embeddings_roberta_tagalog_large Embeddings Tagalog RoBertaEmbeddings tl tgl tgl Living Individual 444 tl.embed.roberta_tagalog_base roberta_embeddings_roberta_tagalog_base Embeddings Tagalog RoBertaEmbeddings tl tgl tgl Living Individual 445 tg.embed.w2v_cc_300d w2v_cc_300d Embeddings Tajik WordEmbeddingsModel tg tgk tgk Living Individual 446 ta.stopwords stopwords_iso Stop Words Removal Tamil StopWordsCleaner ta tam tam Living Individual 447 ta.embed.w2v_cc_300d w2v_cc_300d Embeddings Tamil WordEmbeddingsModel ta tam tam Living Individual 448 ta.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Tamil BertEmbeddings ta tam tam Living Individual 449 tt.stopwords stopwords_iso Stop Words Removal Tatar StopWordsCleaner tt tat tat Living Individual 450 tt.embed.w2v_cc_300d w2v_cc_300d Embeddings Tatar WordEmbeddingsModel tt tat tat Living Individual 451 te.embed.indic_transformers_te_bert bert_embeddings_indic_transformers_te_bert Embeddings Telugu BertEmbeddings te tel tel Living Individual 452 te.embed.telugu_bertu bert_embeddings_telugu_bertu Embeddings Telugu BertEmbeddings te tel tel Living Individual 453 te.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Telugu BertEmbeddings te tel tel Living Individual 454 te.embed.indic_transformers_te_roberta roberta_embeddings_indic_transformers_te_roberta Embeddings Telugu RoBertaEmbeddings te tel tel Living Individual 455 te.stopwords stopwords_iso Stop Words Removal Telugu StopWordsCleaner te tel tel Living Individual 456 te.lemma lemma_mtg Lemmatization Telugu LemmatizerModel te tel tel Living Individual 457 te.embed.w2v_cc_300d w2v_cc_300d Embeddings Telugu WordEmbeddingsModel te tel tel Living Individual 458 th.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_th_cased Embeddings Thai DistilBertEmbeddings th tha tha Living Individual 459 th.stopwords stopwords_iso Stop Words Removal Thai StopWordsCleaner th tha tha Living Individual 460 th.embed.w2v_cc_300d w2v_cc_300d Embeddings Thai WordEmbeddingsModel th tha tha Living Individual 461 ti.stopwords stopwords_iso Stop Words Removal Tigrinya StopWordsCleaner ti tir tir Living Individual 462 als.embed.w2v_cc_300d w2v_cc_300d Embeddings Tosk Albanian WordEmbeddingsModel nan nan als Living Individual 463 tn.stopwords stopwords_iso Stop Words Removal Tswana StopWordsCleaner tn tsn tsn Living Individual 464 tr.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_tr_cased Embeddings Turkish DistilBertEmbeddings tr tur tur Living Individual 465 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 466 tr.stopwords stopwords_iso Stop Words Removal Turkish StopWordsCleaner tr tur tur Living Individual 467 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 468 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 469 tr.embed.w2v_cc_300d w2v_cc_300d Embeddings Turkish WordEmbeddingsModel tr tur tur Living Individual 470 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 471 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 472 tr.pos pos_boun Part of Speech Tagging Turkish PerceptronModel tr tur tur Living Individual 473 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 474 tr.lemma lemma_penn Lemmatization Turkish LemmatizerModel tr tur tur Living Individual 475 tk.embed.w2v_cc_300d w2v_cc_300d Embeddings Turkmen WordEmbeddingsModel tk tuk tuk Living Individual 476 ug.embed.w2v_cc_300d w2v_cc_300d Embeddings Uighur, Uyghur WordEmbeddingsModel ug uig uig Living Individual 477 uk.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_uk_cased Embeddings Ukrainian DistilBertEmbeddings uk ukr ukr Living Individual 478 uk.embed.ukr_roberta_base roberta_embeddings_ukr_roberta_base Embeddings Ukrainian RoBertaEmbeddings uk ukr ukr Living Individual 479 uk.stopwords stopwords_iso Stop Words Removal Ukrainian StopWordsCleaner uk ukr ukr Living Individual 480 uk.embed.w2v_cc_300d w2v_cc_300d Embeddings Ukrainian WordEmbeddingsModel uk ukr ukr Living Individual 481 uk.pos.bert_large_slavic_cyrillic_upos bert_pos_bert_large_slavic_cyrillic_upos Part of Speech Tagging Ukrainian BertForTokenClassification uk ukr ukr Living Individual 482 uk.pos.bert_base_slavic_cyrillic_upos bert_pos_bert_base_slavic_cyrillic_upos Part of Speech Tagging Ukrainian BertForTokenClassification uk ukr ukr Living Individual 483 hsb.embed.w2v_cc_300d w2v_cc_300d Embeddings Upper Sorbian WordEmbeddingsModel nan hsb hsb Living Individual 484 ur.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_ur_cased Embeddings Urdu DistilBertEmbeddings ur urd urd Living Individual 485 ur.embed.muril_adapted_local bert_embeddings_muril_adapted_local Embeddings Urdu BertEmbeddings ur urd urd Living Individual 486 ur.embed.roberta_urdu_small roberta_embeddings_roberta_urdu_small Embeddings Urdu RoBertaEmbeddings ur urd urd Living Individual 487 ur.lemma lemma_udtb Lemmatization Urdu LemmatizerModel ur urd urd Living Individual 488 ur.lemma lemma_udtb Lemmatization Urdu LemmatizerModel ur urd urd Living Individual 489 ur.pos pos_udtb Part of Speech Tagging Urdu PerceptronModel ur urd urd Living Individual 490 ur.embed.w2v_cc_300d w2v_cc_300d Embeddings Urdu WordEmbeddingsModel ur urd urd Living Individual 491 ur.stopwords stopwords_iso Stop Words Removal Urdu StopWordsCleaner ur urd urd Living Individual 492 vec.embed.w2v_cc_300d w2v_cc_300d Embeddings Venetian WordEmbeddingsModel nan nan vec Living Individual 493 vi.stopwords stopwords_iso Stop Words Removal Vietnamese StopWordsCleaner vi vie vie Living Individual 494 vi.embed.w2v_cc_300d w2v_cc_300d Embeddings Vietnamese WordEmbeddingsModel vi vie vie Living Individual 495 vls.embed.w2v_cc_300d w2v_cc_300d Embeddings Vlaams WordEmbeddingsModel nan nan vls Living Individual 496 wa.embed.w2v_cc_300d w2v_cc_300d Embeddings Walloon WordEmbeddingsModel wa wln wln Living Individual 497 war.embed.w2v_cc_300d w2v_cc_300d Embeddings Waray (Philippines) WordEmbeddingsModel nan war war Living Individual 498 hyw.pos pos_armtdp Part of Speech Tagging Western Armenian PerceptronModel nan nan hyw Living Individual 499 hyw.lemma lemma_armtdp Lemmatization Western Armenian LemmatizerModel nan nan hyw Living Individual 500 fy.embed.w2v_cc_300d w2v_cc_300d Embeddings Western Frisian WordEmbeddingsModel fy fry fry Living Individual 501 pnb.embed.w2v_cc_300d w2v_cc_300d Embeddings Western Panjabi WordEmbeddingsModel nan nan pnb Living Individual 502 wo.pos pos_wtb Part of Speech Tagging Wolof PerceptronModel wo wol wol Living Individual 503 sah.embed.w2v_cc_300d w2v_cc_300d Embeddings Yakut WordEmbeddingsModel nan sah sah Living Individual 504 yo.embed.w2v_cc_300d w2v_cc_300d Embeddings Yoruba WordEmbeddingsModel yo yor yor Living Individual 505 zea.embed.w2v_cc_300d w2v_cc_300d Embeddings Zeeuws WordEmbeddingsModel nan nan zea Living Individual 506 sq.stopwords stopwords_iso Stop Words Removal Albanian StopWordsCleaner sq 639-2/T: sqi639-2/B: alb sqi Living Macrolanguage 507 sq.embed.w2v_cc_300d w2v_cc_300d Embeddings Albanian WordEmbeddingsModel sq 639-2/T: sqi639-2/B: alb sqi Living Macrolanguage 508 ar.embed.distilbert distilbert_embeddings_distilbert_base_ar_cased Embeddings Arabic DistilBertEmbeddings ar ara ara Living Macrolanguage 509 ar.embed.albert albert_embeddings_albert_base_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 510 ar.embed.albert_xlarge_arabic albert_embeddings_albert_xlarge_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 511 ar.embed.albert_large_arabic albert_embeddings_albert_large_arabic Embeddings Arabic AlbertEmbeddings ar ara ara Living Macrolanguage 512 ar.pos.arabic_camelbert_msa_pos_msa bert_pos_bert_base_arabic_camelbert_msa_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 513 ar.pos.arabic_camelbert_mix_pos_egy bert_pos_bert_base_arabic_camelbert_mix_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 514 ar.pos.arabic_camelbert_da_pos_glf bert_pos_bert_base_arabic_camelbert_da_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 515 ar.pos.arabic_camelbert_ca_pos_glf bert_pos_bert_base_arabic_camelbert_ca_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 516 ar.pos.arabic_camelbert_msa_pos_egy bert_pos_bert_base_arabic_camelbert_msa_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 517 ar.pos.arabic_camelbert_ca_pos_egy bert_pos_bert_base_arabic_camelbert_ca_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 518 ar.pos.arabic_camelbert_msa_pos_glf bert_pos_bert_base_arabic_camelbert_msa_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 519 ar.pos.arabic_camelbert_mix_pos_glf bert_pos_bert_base_arabic_camelbert_mix_pos_glf Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 520 ar.pos.arabic_camelbert_da_pos_egy bert_pos_bert_base_arabic_camelbert_da_pos_egy Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 521 ar.stopwords stopwords_iso Stop Words Removal Arabic StopWordsCleaner ar ara ara Living Macrolanguage 522 ar.embed.multi_dialect_bert_base_arabic bert_embeddings_multi_dialect_bert_base_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 523 ar.ner.arabic_camelbert_da_ner bert_ner_bert_base_arabic_camelbert_da_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 524 ar.ner.arabic_camelbert_mix_ner bert_ner_bert_base_arabic_camelbert_mix_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 525 ar.pos pos_padt Part of Speech Tagging Arabic PerceptronModel ar ara ara Living Macrolanguage 526 ar.ner.multilingual_cased_ner_hrl bert_ner_bert_base_multilingual_cased_ner_hrl Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 527 ar.ner.arabic_camelbert_msa_ner bert_ner_bert_base_arabic_camelbert_msa_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 528 ar.ner.ANER bert_ner_ANER Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 529 ar.ner.arabert_ner bert_ner_arabert_ner Named Entity Recognition Arabic BertForTokenClassification ar ara ara Living Macrolanguage 530 ar.lemma lemma_padt Lemmatization Arabic LemmatizerModel ar ara ara Living Macrolanguage 531 ar.pos.arabic_camelbert_mix_pos_msa bert_pos_bert_base_arabic_camelbert_mix_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 532 ar.embed.mbert_ar_c19 bert_embeddings_mbert_ar_c19 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 533 ar.embed.bert_base_arabic_camelbert_msa_half bert_embeddings_bert_base_arabic_camelbert_msa_half Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 534 ar.embed.bert_large_arabertv02 bert_embeddings_bert_large_arabertv02 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 535 ar.embed.AraBertMo_base_V1 bert_embeddings_AraBertMo_base_V1 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 536 ar.embed.DarijaBERT bert_embeddings_DarijaBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 537 ar.embed.bert_base_arabertv02 bert_embeddings_bert_base_arabertv02 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 538 ar.embed.arabert_c19 bert_embeddings_arabert_c19 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 539 ar.embed.bert_base_arabic_camelbert_msa bert_embeddings_bert_base_arabic_camelbert_msa Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 540 ar.embed.bert_base_arabertv2 bert_embeddings_bert_base_arabertv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 541 ar.embed.bert_base_arabic bert_embeddings_bert_base_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 542 ar.embed.Ara_DialectBERT bert_embeddings_Ara_DialectBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 543 ar.embed.MARBERT bert_embeddings_MARBERT Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 544 ar.embed.bert_base_arabic_camelbert_msa_eighth bert_embeddings_bert_base_arabic_camelbert_msa_eighth Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 545 ar.embed.MARBERTv2 bert_embeddings_MARBERTv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 546 ar.embed.bert_large_arabertv2 bert_embeddings_bert_large_arabertv2 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 547 ar.embed.bert_base_arabert bert_embeddings_bert_base_arabert Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 548 ar.embed.bert_base_arabertv01 bert_embeddings_bert_base_arabertv01 Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 549 ar.embed.bert_mini_arabic bert_embeddings_bert_mini_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 550 ar.embed.bert_large_arabic bert_embeddings_bert_large_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 551 ar.embed.bert_large_arabertv02_twitter bert_embeddings_bert_large_arabertv02_twitter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 552 ar.embed.dziribert bert_embeddings_dziribert Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 553 ar.embed.bert_base_arabertv02_twitter bert_embeddings_bert_base_arabertv02_twitter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 554 ar.embed.bert_medium_arabic bert_embeddings_bert_medium_arabic Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 555 ar.pos.arabic_camelbert_da_pos_msa bert_pos_bert_base_arabic_camelbert_da_pos_msa Part of Speech Tagging Arabic BertForTokenClassification ar ara ara Living Macrolanguage 556 ar.embed.bert_base_qarib bert_embeddings_bert_base_qarib Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 557 ar.embed.bert_base_qarib60_860k bert_embeddings_bert_base_qarib60_860k Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 558 ar.embed.bert_base_qarib60_1790k bert_embeddings_bert_base_qarib60_1790k Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 559 ar.embed.bert_base_arabic_camelbert_msa_sixteenth bert_embeddings_bert_base_arabic_camelbert_msa_sixteenth Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 560 ar.embed.bert_base_arabic_camelbert_mix bert_embeddings_bert_base_arabic_camelbert_mix Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 561 ar.embed.bert_base_arabic_camelbert_msa_quarter bert_embeddings_bert_base_arabic_camelbert_msa_quarter Embeddings Arabic BertEmbeddings ar ara ara Living Macrolanguage 562 az.embed.w2v_cc_300d w2v_cc_300d Embeddings Azerbaijani WordEmbeddingsModel az aze aze Living Macrolanguage 563 az.stopwords stopwords_iso Stop Words Removal Azerbaijani StopWordsCleaner az aze aze Living Macrolanguage 564 zh.embed.distilbert_base_cased distilbert_embeddings_distilbert_base_zh_cased Embeddings Chinese DistilBertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 565 zh.embed.wobert_chinese_plus_base bert_embeddings_wobert_chinese_plus_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 566 zh.embed.bert_base_chinese_jinyong bert_embeddings_bert_base_chinese_jinyong Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 567 zh.embed.rbt3 bert_embeddings_rbt3 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 568 zh.embed.jdt_fin_roberta_wwm bert_embeddings_jdt_fin_roberta_wwm Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 569 zh.embed.mengzi_oscar_base bert_embeddings_mengzi_oscar_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 570 zh.embed.roberta_base_wechsel_chinese roberta_embeddings_roberta_base_wechsel_chinese Embeddings Chinese RoBertaEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 571 zh.embed.sikubert bert_embeddings_sikubert Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 572 zh.embed.jdt_fin_roberta_wwm_large bert_embeddings_jdt_fin_roberta_wwm_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 573 zh.embed.rbtl3 bert_embeddings_rbtl3 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 574 zh.embed.macbert4csc_base_chinese bert_embeddings_macbert4csc_base_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 575 zh.pos.chinese_roberta_large_upos bert_pos_chinese_roberta_large_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 576 zh.pos.chinese_roberta_base_upos bert_pos_chinese_roberta_base_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 577 zh.pos.chinese_bert_wwm_ext_upos bert_pos_chinese_bert_wwm_ext_upos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 578 zh.pos pos_gsdsimp Part of Speech Tagging Chinese PerceptronModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 579 zh.pos pos_gsdsimp Part of Speech Tagging Chinese PerceptronModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 580 zh.stopwords stopwords_iso Stop Words Removal Chinese StopWordsCleaner zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 581 zh.pos.bert_base_chinese_pos bert_pos_bert_base_chinese_pos Part of Speech Tagging Chinese BertForTokenClassification zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 582 zh.embed.rbt6 bert_embeddings_rbt6 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 583 zh.embed.sikuroberta bert_embeddings_sikuroberta Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 584 zh.embed.uer_large bert_embeddings_uer_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 585 zh.embed.env_bert_chinese bert_embeddings_env_bert_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 586 zh.embed.chinese_roberta_wwm_ext bert_embeddings_chinese_roberta_wwm_ext Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 587 zh.embed.chinese_macbert_base bert_embeddings_chinese_macbert_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 588 zh.embed.bert_base_zh_cased bert_embeddings_bert_base_zh_cased Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 589 zh.embed.bert_large_chinese bert_embeddings_bert_large_chinese Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 590 zh.embed.chinese_roberta_wwm_large_ext_fix_mlm bert_embeddings_chinese_roberta_wwm_large_ext_fix_mlm Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 591 zh.embed.chinese_roberta_wwm_ext_large bert_embeddings_chinese_roberta_wwm_ext_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 592 zh.embed.chinese_bert_wwm_ext bert_embeddings_chinese_bert_wwm_ext Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 593 zh.embed.chinese_macbert_large bert_embeddings_chinese_macbert_large Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 594 zh.embed.mengzi_oscar_base_retrieval bert_embeddings_mengzi_oscar_base_retrieval Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 595 zh.embed.mengzi_bert_base_fin bert_embeddings_mengzi_bert_base_fin Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 596 zh.embed.wobert_chinese_base bert_embeddings_wobert_chinese_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 597 zh.embed.wobert_chinese_plus bert_embeddings_wobert_chinese_plus Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 598 zh.embed.rbt4 bert_embeddings_rbt4 Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 599 zh.embed.mengzi_oscar_base_caption bert_embeddings_mengzi_oscar_base_caption Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 600 zh.embed.mengzi_bert_base bert_embeddings_mengzi_bert_base Embeddings Chinese BertEmbeddings zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 601 zh.embed.w2v_cc_300d w2v_cc_300d Embeddings Chinese WordEmbeddingsModel zh 639-2/T: zho639-2/B: chi zho Living Macrolanguage 602 et.stopwords stopwords_iso Stop Words Removal Estonian StopWordsCleaner et est est Living Macrolanguage 603 et.pos pos_edt Part of Speech Tagging Estonian PerceptronModel et est est Living Macrolanguage 604 et.embed.w2v_cc_300d w2v_cc_300d Embeddings Estonian WordEmbeddingsModel et est est Living Macrolanguage 605 et.lemma lemma_ewt Lemmatization Estonian LemmatizerModel et est est Living Macrolanguage 606 et.lemma lemma_ewt Lemmatization Estonian LemmatizerModel et est est Living Macrolanguage 607 lv.stopwords stopwords_iso Stop Words Removal Latvian StopWordsCleaner lv lav lav Living Macrolanguage 608 lv.pos pos_lvtb Part of Speech Tagging Latvian PerceptronModel lv lav lav Living Macrolanguage 609 mg.embed.w2v_cc_300d w2v_cc_300d Embeddings Malagasy WordEmbeddingsModel mg mlg mlg Living Macrolanguage 610 ms.embed.albert albert_embeddings_albert_large_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 611 ms.embed.distilbert distilbert_embeddings_malaysian_distilbert_small Embeddings Malay (macrolanguage) DistilBertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 612 ms.embed.albert_tiny_bahasa_cased albert_embeddings_albert_tiny_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 613 ms.embed.albert_base_bahasa_cased albert_embeddings_albert_base_bahasa_cased Embeddings Malay (macrolanguage) AlbertEmbeddings ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 614 ms.embed.w2v_cc_300d w2v_cc_300d Embeddings Malay (macrolanguage) WordEmbeddingsModel ms 639-2/T: msa639-2/B: may msa Living Macrolanguage 615 mn.embed.w2v_cc_300d w2v_cc_300d Embeddings Mongolian WordEmbeddingsModel mn mon mon Living Macrolanguage 616 ne.embed.w2v_cc_300d w2v_cc_300d Embeddings Nepali (macrolanguage) WordEmbeddingsModel ne nep nep Living Macrolanguage 617 ne.stopwords stopwords_iso Stop Words Removal Nepali (macrolanguage) StopWordsCleaner ne nep nep Living Macrolanguage 618 no.lemma lemma_nynorsk Lemmatization Norwegian LemmatizerModel no nor nor Living Macrolanguage 619 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 620 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 621 no.pos pos_bokmaal Part of Speech Tagging Norwegian PerceptronModel no nor nor Living Macrolanguage 622 no.embed.w2v_cc_300d w2v_cc_300d Embeddings Norwegian WordEmbeddingsModel no nor nor Living Macrolanguage 623 no.lemma lemma_nynorsk Lemmatization Norwegian LemmatizerModel no nor nor Living Macrolanguage 624 or.embed.w2v_cc_300d w2v_cc_300d Embeddings Oriya (macrolanguage) WordEmbeddingsModel or ori ori Living Macrolanguage 625 ps.embed.w2v_cc_300d w2v_cc_300d Embeddings Pashto, Pushto WordEmbeddingsModel ps pus pus Living Macrolanguage 626 fa.embed.albert albert_embeddings_albert_fa_base_v2 Embeddings Persian AlbertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 627 fa.embed.distilbert_fa_zwnj_base distilbert_embeddings_distilbert_fa_zwnj_base Embeddings Persian DistilBertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 628 fa.embed.albert_fa_zwnj_base_v2 albert_embeddings_albert_fa_zwnj_base_v2 Embeddings Persian AlbertEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 629 fa.embed.roberta_fa_zwnj_base roberta_embeddings_roberta_fa_zwnj_base Embeddings Persian RoBertaEmbeddings fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 630 fa.ner.roberta_fa_zwnj_base_ner roberta_ner_roberta_fa_zwnj_base_ner Named Entity Recognition Persian RoBertaForTokenClassification fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 631 fa.pos pos_perdt Part of Speech Tagging Persian PerceptronModel fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 632 fa.stopwords stopwords_iso Stop Words Removal Persian StopWordsCleaner fa 639-2/T: fas639-2/B: per fas Living Macrolanguage 633 qu.embed.w2v_cc_300d w2v_cc_300d Embeddings Quechua WordEmbeddingsModel qu que que Living Macrolanguage 634 sc.embed.w2v_cc_300d w2v_cc_300d Embeddings Sardinian WordEmbeddingsModel sc srd srd Living Macrolanguage 635 sh.embed.w2v_cc_300d w2v_cc_300d Embeddings Serbo-Croatian WordEmbeddingsModel sh nan nan Living Macrolanguage 636 sw.embed.w2v_cc_300d w2v_cc_300d Embeddings Swahili (macrolanguage) WordEmbeddingsModel sw swa swa Living Macrolanguage 637 uz.embed.w2v_cc_300d w2v_cc_300d Embeddings Uzbek WordEmbeddingsModel uz uzb uzb Living Macrolanguage 638 yi.embed.w2v_cc_300d w2v_cc_300d Embeddings Yiddish WordEmbeddingsModel yi yid yid Living Macrolanguage 639 qhe.lemma lemma_hiencs Lemmatization Reserved for local use LemmatizerModel nan qhe qhe nan Local 640 qtd.pos pos_sagt Part of Speech Tagging Reserved for local use PerceptronModel nan qtd qtd nan Local All Healthcare Powered by the amazing Spark NLP for Healthcare 3.5.2 and Spark NLP for Healthcare 3.5.1 releases. Number NLU Reference Spark NLP Reference Task Language Name(s) Annotator Class ISO-639-1 ISO-639-2/639-5 ISO-639-3 Language Type Scope 0 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 1 en.med_ner.biomedical_bc2gm ner_biomedical_bc2gm Named Entity Recognition English MedicalNerModel en eng eng Living Individual 2 en.resolve.rxnorm_action_treatment sbiobertresolve_rxnorm_action_treatment Entity Resolution English SentenceEntityResolverModel en eng eng Living Individual 3 en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition English MedicalBertForTokenClassifier en eng eng Living Individual 4 en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition English MedicalBertForTokenClassifier en eng eng Living Individual 5 pt.med_ner.deid.subentity ner_deid_subentity De-identification Portuguese MedicalNerModel pt por por Living Individual 6 pt.med_ner.deid.generic ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual 7 pt.med_ner.deid ner_deid_generic De-identification Portuguese MedicalNerModel pt por por Living Individual NLU Version 3.4.3 Zero-Shot-Relation-Extraction, DeBERTa for Sequence Classification, 150+ new models, 60+ Languages in John Snow Labs NLU 3.4.3 We are very excited to announce NLU 3.4.3 has been released! This release features new models for Zero-Shot-Relation-Extraction, DeBERTa for Sequence Classification, Deidentification in French and Italian and Lemmatizers, Parts of Speech Taggers, and Word2Vec Embeddings for over 66 languages, with 20 languages being covered for the first time by NLU, including ancient and exotic languages like Ancient Greek, Old Russian, Old French and much more. Once again we would like to thank our community to make this release possible. NLU for Healthcare On the healthcare NLP side, a new ZeroShotRelationExtractionModel is available, which can extract relations between clinical entities in an unsupervised fashion, no training required! Additionally, New French and Italian Deidentification models are available for clinical and healthcare domains. Powerd by the fantastic Spark NLP for helathcare 3.5.0 release Zero-Shot Relation Extraction Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset import nlu pipe = nlu.load(&#39;med_ner.clinical relation.zeroshot_biobert&#39;) # Configure relations to extract pipe[&#39;zero_shot_relation_extraction&#39;].setRelationalCategories({ &quot;CURE&quot;: [&quot; cures .&quot;], &quot;IMPROVE&quot;: [&quot; improves .&quot;, &quot; cures .&quot;], &quot;REVEAL&quot;: [&quot; reveals .&quot;]}) .setMultiLabel(False) df = pipe.predict(&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;) df[ &#39;relation&#39;, &#39;relation_confidence&#39;, &#39;relation_entity1&#39;, &#39;relation_entity1_class&#39;, &#39;relation_entity2&#39;, &#39;relation_entity2_class&#39;,] # Results in following table : relation relation_confidence relation_entity1 relation_entity1_class relation_entity2 relation_entity2_class REVEAL 0.976004 An MRI test TEST cancer PROBLEM IMPROVE 0.988195 Paracetamol TREATMENT sickness PROBLEM IMPROVE 0.992962 Paracetamol TREATMENT headache PROBLEM New Healthcare Models overview Language NLU Reference Spark NLP Reference Task Annotator Class en en.relation.zeroshot_biobert re_zeroshot_biobert Relation Extraction ZeroShotRelationExtractionModel fr fr.med_ner.deid_generic ner_deid_generic De-identification MedicalNerModel fr fr.med_ner.deid_subentity ner_deid_subentity De-identification MedicalNerModel it it.med_ner.deid_generic ner_deid_generic Named Entity Recognition MedicalNerModel it it.med_ner.deid_subentity ner_deid_subentity Named Entity Recognition MedicalNerModel NLU general On the general NLP side we have new transformer based DeBERTa v3 sequence classifiers models fine-tuned in Urdu, French and English for Sentiment and News classification. Additionally, 100+ Part Of Speech Taggers and Lemmatizers for 66 Languages and for 7 languages new word2vec embeddings, including hi,azb,bo,diq,cy,es,it, powered by the amazing Spark NLP 3.4.3 release New Languages covered: First time languages covered by NLU are : South Azerbaijani, Tibetan, Dimli, Central Kurdish, Southern Altai, Scottish Gaelic,Faroese,Literary Chinese,Ancient Greek, Gothic, Old Russian, Church Slavic, Old French,Uighur,Coptic,Croatian, Belarusian, Serbian and their respective ISO-639-3 and ISO 630-2 codes are : azb,bo,diq,ckb, lt gd, fo,lzh,grc,got,orv,cu,fro,qtd,ug,cop,hr,be,qhe,sr New NLP Models Overview Language NLU Reference Spark NLP Reference Task Annotator Class en en.classify.sentiment.imdb.deberta deberta_v3_xsmall_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.small deberta_v3_small_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.base deberta_v3_base_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.sentiment.imdb.deberta.large deberta_v3_large_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification en en.classify.news.deberta deberta_v3_xsmall_sequence_classifier_ag_news Text Classification DeBertaForSequenceClassification en en.classify.news.deberta.small deberta_v3_small_sequence_classifier_ag_news Text Classification DeBertaForSequenceClassification ur ur.classify.sentiment.imdb mdeberta_v3_base_sequence_classifier_imdb Text Classification DeBertaForSequenceClassification fr fr.classify.allocine mdeberta_v3_base_sequence_classifier_allocine Text Classification DeBertaForSequenceClassification ur ur.embed.bert_cased bert_embeddings_bert_base_ur_cased Embeddings BertEmbeddings fr fr.embed.bert_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings BertEmbeddings de de.embed.medbert bert_embeddings_German_MedBERT Embeddings BertEmbeddings ar ar.embed.arbert bert_embeddings_ARBERT Embeddings BertEmbeddings bn bn.embed.bangala_bert bert_embeddings_bangla_bert_base Embeddings BertEmbeddings zh zh.embed.bert_5lang_cased bert_embeddings_bert_base_5lang_cased Embeddings BertEmbeddings hi hi.embed.bert_hi_cased bert_embeddings_bert_base_hi_cased Embeddings BertEmbeddings it it.embed.bert_it_cased bert_embeddings_bert_base_it_cased Embeddings BertEmbeddings ko ko.embed.bert bert_embeddings_bert_base Embeddings BertEmbeddings tr tr.embed.bert_cased bert_embeddings_bert_base_tr_cased Embeddings BertEmbeddings vi vi.embed.bert_cased bert_embeddings_bert_base_vi_cased Embeddings BertEmbeddings hif hif.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel azb azb.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel bo bo.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel diq diq.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel cy cy.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel es es.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel it it.embed.word2vec w2v_cc_300d Embeddings WordEmbeddingsModel af af.lemma lemma Lemmatization LemmatizerModel lt lt.lemma lemma_alksnis Lemmatization LemmatizerModel nl nl.lemma lemma Lemmatization LemmatizerModel gd gd.lemma lemma_arcosg Lemmatization LemmatizerModel es es.lemma lemma Lemmatization LemmatizerModel ca ca.lemma lemma Lemmatization LemmatizerModel el el.lemma.gdt lemma_gdt Lemmatization LemmatizerModel en en.lemma.atis lemma_atis Lemmatization LemmatizerModel tr tr.lemma.boun lemma_boun Lemmatization LemmatizerModel da da.lemma.ddt lemma_ddt Lemmatization LemmatizerModel cs cs.lemma.cac lemma_cac Lemmatization LemmatizerModel en en.lemma.esl lemma_esl Lemmatization LemmatizerModel bg bg.lemma.btb lemma_btb Lemmatization LemmatizerModel id id.lemma.csui lemma_csui Lemmatization LemmatizerModel gl gl.lemma.ctg lemma_ctg Lemmatization LemmatizerModel cy cy.lemma.ccg lemma_ccg Lemmatization LemmatizerModel fo fo.lemma.farpahc lemma_farpahc Lemmatization LemmatizerModel tr tr.lemma.atis lemma_atis Lemmatization LemmatizerModel ga ga.lemma.idt lemma_idt Lemmatization LemmatizerModel ja ja.lemma.gsdluw lemma_gsdluw Lemmatization LemmatizerModel es es.lemma.gsd lemma_gsd Lemmatization LemmatizerModel en en.lemma.gum lemma_gum Lemmatization LemmatizerModel zh zh.lemma.gsd lemma_gsd Lemmatization LemmatizerModel lv lv.lemma.lvtb lemma_lvtb Lemmatization LemmatizerModel hi hi.lemma.hdtb lemma_hdtb Lemmatization LemmatizerModel pt pt.lemma.gsd lemma_gsd Lemmatization LemmatizerModel de de.lemma.gsd lemma_gsd Lemmatization LemmatizerModel nl nl.lemma.lassysmall lemma_lassysmall Lemmatization LemmatizerModel lzh lzh.lemma.kyoto lemma_kyoto Lemmatization LemmatizerModel zh zh.lemma.gsdsimp lemma_gsdsimp Lemmatization LemmatizerModel he he.lemma.htb lemma_htb Lemmatization LemmatizerModel fr fr.lemma.gsd lemma_gsd Lemmatization LemmatizerModel ro ro.lemma.nonstandard lemma_nonstandard Lemmatization LemmatizerModel ja ja.lemma.gsd lemma_gsd Lemmatization LemmatizerModel it it.lemma.isdt lemma_isdt Lemmatization LemmatizerModel de de.lemma.hdt lemma_hdt Lemmatization LemmatizerModel is is.lemma.modern lemma_modern Lemmatization LemmatizerModel la la.lemma.ittb lemma_ittb Lemmatization LemmatizerModel fr fr.lemma.partut lemma_partut Lemmatization LemmatizerModel pcm pcm.lemma.nsc lemma_nsc Lemmatization LemmatizerModel pl pl.lemma.pdb lemma_pdb Lemmatization LemmatizerModel grc grc.lemma.perseus lemma_perseus Lemmatization LemmatizerModel cs cs.lemma.pdt lemma_pdt Lemmatization LemmatizerModel fa fa.lemma.perdt lemma_perdt Lemmatization LemmatizerModel got got.lemma.proiel lemma_proiel Lemmatization LemmatizerModel fr fr.lemma.rhapsodie lemma_rhapsodie Lemmatization LemmatizerModel it it.lemma.partut lemma_partut Lemmatization LemmatizerModel en en.lemma.partut lemma_partut Lemmatization LemmatizerModel no no.lemma.nynorsklia lemma_nynorsklia Lemmatization LemmatizerModel orv orv.lemma.rnc lemma_rnc Lemmatization LemmatizerModel cu cu.lemma.proiel lemma_proiel Lemmatization LemmatizerModel la la.lemma.perseus lemma_perseus Lemmatization LemmatizerModel fr fr.lemma.parisstories lemma_parisstories Lemmatization LemmatizerModel fro fro.lemma.srcmf lemma_srcmf Lemmatization LemmatizerModel vi vi.lemma.vtb lemma_vtb Lemmatization LemmatizerModel qtd qtd.lemma.sagt lemma_sagt Lemmatization LemmatizerModel ro ro.lemma.rrt lemma_rrt Lemmatization LemmatizerModel hu hu.lemma.szeged lemma_szeged Lemmatization LemmatizerModel ug ug.lemma.udt lemma_udt Lemmatization LemmatizerModel wo wo.lemma.wtb lemma_wtb Lemmatization LemmatizerModel cop cop.lemma.scriptorium lemma_scriptorium Lemmatization LemmatizerModel ru ru.lemma.syntagrus lemma_syntagrus Lemmatization LemmatizerModel ru ru.lemma.taiga lemma_taiga Lemmatization LemmatizerModel fr fr.lemma.sequoia lemma_sequoia Lemmatization LemmatizerModel la la.lemma.udante lemma_udante Lemmatization LemmatizerModel ro ro.lemma.simonero lemma_simonero Lemmatization LemmatizerModel it it.lemma.vit lemma_vit Lemmatization LemmatizerModel hr hr.lemma.set lemma_set Lemmatization LemmatizerModel fa fa.lemma.seraji lemma_seraji Lemmatization LemmatizerModel tr tr.lemma.tourism lemma_tourism Lemmatization LemmatizerModel ta ta.lemma.ttb lemma_ttb Lemmatization LemmatizerModel sl sl.lemma.ssj lemma_ssj Lemmatization LemmatizerModel sv sv.lemma.talbanken lemma_talbanken Lemmatization LemmatizerModel uk uk.lemma.iu lemma_iu Lemmatization LemmatizerModel te te.pos pos_mtg Part of Speech Tagging PerceptronModel te te.pos pos_mtg Part of Speech Tagging PerceptronModel ta ta.pos pos_ttb Part of Speech Tagging PerceptronModel ta ta.pos pos_ttb Part of Speech Tagging PerceptronModel cs cs.pos pos_ud_pdt Part of Speech Tagging PerceptronModel cs cs.pos pos_ud_pdt Part of Speech Tagging PerceptronModel bg bg.pos pos_btb Part of Speech Tagging PerceptronModel bg bg.pos pos_btb Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel af af.pos pos_afribooms Part of Speech Tagging PerceptronModel es es.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel en en.pos.ewt pos_ewt Part of Speech Tagging PerceptronModel gd gd.pos.arcosg pos_arcosg Part of Speech Tagging PerceptronModel el el.pos.gdt pos_gdt Part of Speech Tagging PerceptronModel hy hy.pos.armtdp pos_armtdp Part of Speech Tagging PerceptronModel pt pt.pos.bosque pos_bosque Part of Speech Tagging PerceptronModel tr tr.pos.framenet pos_framenet Part of Speech Tagging PerceptronModel cs cs.pos.cltt pos_cltt Part of Speech Tagging PerceptronModel eu eu.pos.bdt pos_bdt Part of Speech Tagging PerceptronModel et et.pos.ewt pos_ewt Part of Speech Tagging PerceptronModel da da.pos.ddt pos_ddt Part of Speech Tagging PerceptronModel cy cy.pos.ccg pos_ccg Part of Speech Tagging PerceptronModel lt lt.pos.alksnis pos_alksnis Part of Speech Tagging PerceptronModel nl nl.pos.alpino pos_alpino Part of Speech Tagging PerceptronModel fi fi.pos.ftb pos_ftb Part of Speech Tagging PerceptronModel tr tr.pos.atis pos_atis Part of Speech Tagging PerceptronModel ca ca.pos.ancora pos_ancora Part of Speech Tagging PerceptronModel gl gl.pos.ctg pos_ctg Part of Speech Tagging PerceptronModel de de.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel fr fr.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel ja ja.pos.gsdluw pos_gsdluw Part of Speech Tagging PerceptronModel it it.pos.isdt pos_isdt Part of Speech Tagging PerceptronModel be be.pos.hse pos_hse Part of Speech Tagging PerceptronModel nl nl.pos.lassysmall pos_lassysmall Part of Speech Tagging PerceptronModel sv sv.pos.lines pos_lines Part of Speech Tagging PerceptronModel uk uk.pos.iu pos_iu Part of Speech Tagging PerceptronModel fr fr.pos.parisstories pos_parisstories Part of Speech Tagging PerceptronModel en en.pos.partut pos_partut Part of Speech Tagging PerceptronModel la la.pos.ittb pos_ittb Part of Speech Tagging PerceptronModel lzh lzh.pos.kyoto pos_kyoto Part of Speech Tagging PerceptronModel id id.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel he he.pos.htb pos_htb Part of Speech Tagging PerceptronModel tr tr.pos.kenet pos_kenet Part of Speech Tagging PerceptronModel de de.pos.hdt pos_hdt Part of Speech Tagging PerceptronModel qhe qhe.pos.hiencs pos_hiencs Part of Speech Tagging PerceptronModel la la.pos.llct pos_llct Part of Speech Tagging PerceptronModel en en.pos.lines pos_lines Part of Speech Tagging PerceptronModel pcm pcm.pos.nsc pos_nsc Part of Speech Tagging PerceptronModel ko ko.pos.kaist pos_kaist Part of Speech Tagging PerceptronModel pt pt.pos.gsd pos_gsd Part of Speech Tagging PerceptronModel hi hi.pos.hdtb pos_hdtb Part of Speech Tagging PerceptronModel is is.pos.modern pos_modern Part of Speech Tagging PerceptronModel en en.pos.gum pos_gum Part of Speech Tagging PerceptronModel fro fro.pos.srcmf pos_srcmf Part of Speech Tagging PerceptronModel sl sl.pos.ssj pos_ssj Part of Speech Tagging PerceptronModel ru ru.pos.taiga pos_taiga Part of Speech Tagging PerceptronModel grc grc.pos.perseus pos_perseus Part of Speech Tagging PerceptronModel sr sr.pos.set pos_set Part of Speech Tagging PerceptronModel orv orv.pos.rnc pos_rnc Part of Speech Tagging PerceptronModel ug ug.pos.udt pos_udt Part of Speech Tagging PerceptronModel got got.pos.proiel pos_proiel Part of Speech Tagging PerceptronModel sv sv.pos.talbanken pos_talbanken Part of Speech Tagging PerceptronModel sv sv.pos.talbanken pos_talbanken Part of Speech Tagging PerceptronModel pl pl.pos.pdb pos_pdb Part of Speech Tagging PerceptronModel fa fa.pos.seraji pos_seraji Part of Speech Tagging PerceptronModel tr tr.pos.penn pos_penn Part of Speech Tagging PerceptronModel hu hu.pos.szeged pos_szeged Part of Speech Tagging PerceptronModel sk sk.pos.snk pos_snk Part of Speech Tagging PerceptronModel sk sk.pos.snk pos_snk Part of Speech Tagging PerceptronModel ro ro.pos.simonero pos_simonero Part of Speech Tagging PerceptronModel it it.pos.postwita pos_postwita Part of Speech Tagging PerceptronModel gl gl.pos.treegal pos_treegal Part of Speech Tagging PerceptronModel cs cs.pos.pdt pos_pdt Part of Speech Tagging PerceptronModel ro ro.pos.rrt pos_rrt Part of Speech Tagging PerceptronModel orv orv.pos.torot pos_torot Part of Speech Tagging PerceptronModel hr hr.pos.set pos_set Part of Speech Tagging PerceptronModel la la.pos.proiel pos_proiel Part of Speech Tagging PerceptronModel fr fr.pos.partut pos_partut Part of Speech Tagging PerceptronModel it it.pos.vit pos_vit Part of Speech Tagging PerceptronModel Bugfixes Improved Error Messages and integrated detection and stopping of endless loops which could occur during construction of nlu pipelines Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.2 Multilingual DeBERTa Transformer Embeddings for 100+ Languages, Spanish Deidentification and NER for Randomized Clinical Trials - John Snow Labs NLU 3.4.2 We are very excited NLU 3.4.2 has been released. On the open source side we have 5 new DeBERTa Transformer models for English and Multi-Lingual for 100+ languages. DeBERTa improves over BERT and RoBERTa by introducing two novel techniques. For the healthcare side we have new NER models for randomized clinical trials (RCT) which can detect entities of type BACKGROUND, CONCLUSIONS, METHODS, OBJECTIVE, RESULTS from clinical text. Additionally, new Spanish Deidentification NER models for entities like STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL and many more. New Open Source Models Integrates models from Spark NLP 3.4.2 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.embed.deberta_v3_xsmall deberta_v3_xsmall Embeddings DeBertaEmbeddings en en.embed.deberta_v3_small deberta_v3_small Embeddings DeBertaEmbeddings en en.embed.deberta_v3_base deberta_v3_base Embeddings DeBertaEmbeddings en en.embed.deberta_v3_large deberta_v3_large Embeddings DeBertaEmbeddings xx xx.embed.mdeberta_v3_base mdeberta_v3_base Embeddings DeBertaEmbeddings New Healthcare Models Integrates models from Spark NLP For Healthcare 3.4.2 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.med_ner.clinical_trials bert_sequence_classifier_rct_biobert Text Classification MedicalBertForSequenceClassification es es.med_ner.deid.generic.roberta ner_deid_generic_roberta_augmented De-identification MedicalNerModel es es.med_ner.deid.subentity.roberta ner_deid_subentity_roberta_augmented De-identification MedicalNerModel en en.med_ner.deid.generic_augmented ner_deid_generic_augmented [‘Named Entity Recognition’, ‘De-identification’] MedicalNerModel en en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented [‘Named Entity Recognition’, ‘De-identification’] MedicalNerModel Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.1 22 New models for 23 languages including various African and Indian languages, Medical Spanish models and more in NLU 3.4.1 We are very excited to announce the release of NLU 3.4.1 which features 22 new models for 23 languages where the The open-source side covers new Embeddings for Vietnamese and English Clinical domains and Multilingual Embeddings for 12 Indian and 9 African Languages. Additionally, there are new Sequence classifiers for Multilingual NER for 9 African languages, German Sentiment Classifiers and English Emotion and Typo Classifiers. The healthcare side covers Medical Spanish models, Classifiers for Drugs, Gender, the Pico Framework, and Relation Extractors for Adverse Drug events and Temporality. Finally, Spark 3.2.X is now supported and bugs related to Databricks environments have been fixed. General NLU Improvements Support for Spark 3.2.x New Open Source Models Based on the amazing 3.4.1 Spark NLP Release integrates new Multilingual embeddings for 12 Major Indian languages, embeddings for Vietnamese, French, and English Clinical domains. Additionally new Multilingual NER model for 9 African languages, English 6 Class Emotion classifier and Typo detectors. New Embeddings Multilingual ALBERT - IndicBert model pretrained exclusively on 12 major Indian languages with size smaller and performance on par or better than competing models. Languages covered are Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. Available with xx.embed.albert.indic Fine tuned Vietnamese DistilBERT Base cased embeddings. Available with vi.embed.distilbert.cased Clinical Longformer Embeddings which consistently out-performs ClinicalBERT for various downstream tasks and on datasets. Available with en.embed.longformer.clinical Fine tuned Static French Word2Vec Embeddings in 3 sizes, 200d, 300d and 100d. Available with fr.embed.word2vec_wiki_1000, fr.embed.word2vec_wac_200 and fr.embed.w2v_cc_300d New Transformer based Token and Sequence Classifiers Multilingual NER Distilbert model which detects entities DATE, LOC, ORG, PER for the languages 9 African languages (Hausa, Igbo, Kinyarwanda, Luganda, Nigerian, Pidgin, Swahili, Wolof, and Yorùbá). Available with xx.ner.masakhaner.distilbert German News Sentiment Classifier available with de.classify.news_sentiment.bert English Emotion Classifier for 6 Classes available with en.classify.emotion.bert **English Typo Detector **: available with en.classify.typos.distilbert Language NLU Reference Spark NLP Reference Task Annotator Class xx xx.embed.albert.indic albert_indic Embeddings AlbertEmbeddings xx xx.ner.masakhaner.distilbert xlm_roberta_large_token_classifier_masakhaner Named Entity Recognition DistilBertForTokenClassification en en.embed.longformer.clinical clinical_longformer Embeddings LongformerEmbeddings en en.classify.emotion.bert bert_sequence_classifier_emotion Text Classification BertForSequenceClassification de de.classify.news_sentiment.bert bert_sequence_classifier_news_sentiment Sentiment Analysis BertForSequenceClassification en en.classify.typos.distilbert distilbert_token_classifier_typo_detector Named Entity Recognition DistilBertForTokenClassification fr fr.embed.word2vec_wiki_1000 word2vec_wiki_1000 Embeddings WordEmbeddingsModel fr fr.embed.word2vec_wac_200 word2vec_wac_200 Embeddings WordEmbeddingsModel fr fr.embed.w2v_cc_300d w2v_cc_300d Embeddings WordEmbeddingsModel vi vi.embed.distilbert.cased distilbert_base_cased Embeddings DistilBertEmbeddings New Healthcare Models Integrated from the amazing 3.4.1 Spark NLP For Healthcare Release. which makes 2 new Annotator Classes available, MedicalBertForSequenceClassification and MedicalDistilBertForSequenceClassification, various medical Spanish models, RxNorm Resolvers, Transformer based sequence classifiers for Drugs, Gender and the PICO framework, and Relation extractors for Temporality and Causality of Drugs and Adverse Events. New Medical Spanish Models Spanish Word2Vec Embeddings available with es.embed.sciwiki_300d Spanish PHI Deidentification NER models with two different subsets of entities extracted, available with ner_deid_generic and ner_deid_subentity New Resolvers RxNorm resolvers with augmented concept data available with en.med_ner.supplement_clinical New Transformer based Sequence Classifiers Adverse Drug Event Classifier Biobert based available with en.classify.ade.seq_biobert Patient Gender Classifier Biobert and Distilbert based available with en.classify.gender.seq_biobert and available with en.classify.ade.seq_distilbert PiCO Framework Classifier available with en.classify.pico.seq_biobert New Relation Extractors Temporal Relation Extractor available with en.relation.temporal_events_clinical Adverse Drug Event Relation Extractors one version Biobert Embeddings and one non-DL version available with en.relation.adverse_drug_events.clinical available with en.relation.adverse_drug_events.clinical.biobert Language NLU Reference Spark NLP Reference Task Annotator Class es es.embed.sciwiki_300d embeddings_sciwiki_300d Embeddings WordEmbeddingsModel es es.med_ner.deid.generic ner_deid_generic De-identification MedicalNerModel es es.med_ner.deid.subentity ner_deid_subentity De-identification MedicalNerModel en en.med_ner.supplement_clinical ner_supplement_clinical Named Entity Recognition MedicalNerModel en en.resolve.rxnorm.augmented_re sbiobertresolve_rxnorm_augmented_re Entity Resolution SentenceEntityResolverModel en en.classify.ade.seq_biobert bert_sequence_classifier_ade Text Classification MedicalBertForSequenceClassification en en.classify.gender.seq_biobert bert_sequence_classifier_gender_biobert Text Classification MedicalBertForSequenceClassification en en.classify.pico.seq_biobert bert_sequence_classifier_pico_biobert Text Classification MedicalBertForSequenceClassification en en.classify.ade.seq_distilbert distilbert_sequence_classifier_ade Text Classification MedicalDistilBertForSequenceClassification en en.relation.temporal_events_clinical re_temporal_events_clinical Relation Extraction RelationExtractionModel en en.relation.adverse_drug_events.clinical re_ade_clinical Relation Extraction RelationExtractionModel en en.relation.adverse_drug_events.clinical.biobert redl_ade_biobert Relation Extraction RelationExtractionDLModel Bugfixes Fixed bug that caused non-default output level of components to be sentence Fixed a bug that caused nlu references pointing to pretrained pipelines in spark nlp to crash in Databricks environments Additional NLU resources 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.4.0 1 line to OCR for images, PDFS and DOCX, Text Generation with GPT2 and new T5 models, Sequence Classification with XlmRoBerta, RoBerta, Xlnet, Longformer and Albert, Transformer based medical NER with MedicalBertForTokenClassifier, 80 new models, 20+ new languages including various African and Scandinavian and much more in John Snow Labs NLU 3.4.0 ! We are incredibly excited to announce John Snow Labs NLU 3.4.0 has been released! This release features 11 new annotator classes and 80 new models, including 3 OCR Transformers which enable you to extract text from various file types, support for GPT2 and new pretrained T5 models for Text Generation and dozens more of new transformer based models for Token and Sequence Classification. This includes 8 new Sequence classifier models which can be pretrained in Huggingface and imported into Spark NLP and NLU. Finally, the NLU tutorial page of the 140+ notebooks has been updated New NLU OCR Features 3 new OCR based spells are supported, which enable extracting text from files of type JPEG, PNG, BMP, WBMP, GIF, JPG, TIFF, DOCX, PDF in just 1 line of code. You need a Spark OCR license for using these, which is available for free here and refer to the new OCR tutorial notebook Find more details on the NLU OCR documentation page New NLU Healthcare Features The healthcare side features a new MedicalBertForTokenClassifier annotator which is a Bert based model for token classification problems like Named Entity Recognition, Parts of Speech and much more. Overall there are 28 new models which include German De-Identification models, English NER models for extracting Drug Development Trials, Clinical Abbreviations and Acronyms, NER models for chemical compounds/drugs and genes/proteins, updated MedicalBertForTokenClassifier NER models for the medical domains Adverse drug Events, Anatomy, Chemicals, Genes,Proteins, Cellular/Molecular Biology, Drugs, Bacteria, De-Identification and general Medical and Clinical Named Entities. For Entity Relation Extraction between entity pairs new models for interaction between Drugs and Proteins. For Entity Resolution new models for resolving Clinical Abbreviations and Acronyms to their full length names and also a model for resolving Drug Substance Entities to the categories Clinical Drug, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance and new resolvers for LOINC and SNOMED terminologies. New NLU Open source Features On the open source side we have new support for Open Ai’s GPT2 for various text sequence to sequence problems and additionally the following new Transformer models are supported : RoBertaForSequenceClassification, XlmRoBertaForSequenceClassification, LongformerForSequenceClassification, AlbertForSequenceClassification, XlnetForSequenceClassification, Word2Vec with various pre-trained weights for various problems! New GPT2 models for generating text conditioned on some input, New T5 style transfer models for active to passive, formal to informal, informal to formal, passive to active sequence to sequence generation. Additionally, a new T5 model for generating SQL code from natural language input is provided. On top of this dozens new Transformer based Sequence Classifiers and Token Classifiers have been released, this is includes for Token Classifier the following models : Multi-Lingual general NER models for 10 African Languages (Amharic, Hausa, Igbo, Kinyarwanda, Luganda, Nigerian, Pidgin, Swahilu, Wolof, and Yorùbá), 10 high resourced languages (10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese), 6 Scandinavian languages (Danish, Norwegian-Bokmål, Norwegian-Nynorsk, Swedish, Icelandic, Faroese) , Uni-Lingual NER models for general entites in the language Chinese, Hindi, Islandic, Indonesian and finally English NER models for extracting entities related to Stocks Ticker Symbols, Restaurants, Time. For Sequence Classification new models for classifying Toxicity in Russian text and English models for Movie Reviews, News Categorization, Sentimental Tone and General Sentiment New NLU OCR Models The following Transformers have been integrated from Spark OCR NLU Spell Transformer Class nlu.load(img2text) ImageToText nlu.load(pdf2text) PdfToText nlu.load(doc2text) DocToText New Open Source Models Integration for the 49 new models from the colossal Spark NLP 3.4.0 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.gpt2.distilled gpt2_distilled Text Generation GPT2Transformer en en.gpt2 gpt2 Text Generation GPT2Transformer en en.gpt2.medium gpt2_medium Text Generation GPT2Transformer en en.gpt2.large gpt_large Text Generation GPT2Transformer en en.t5.active_to_passive_styletransfer t5_active_to_passive_styletransfer Text Generation T5Transformer en en.t5.formal_to_informal_styletransfer t5_formal_to_informal_styletransfer Text Generation T5Transformer en en.t5.grammar_error_corrector t5_grammar_error_corrector Text Generation T5Transformer en en.t5.informal_to_formal_styletransfer t5_informal_to_formal_styletransfer Text Generation T5Transformer en en.t5.passive_to_active_styletransfer t5_passive_to_active_styletransfer Text Generation T5Transformer en en.t5.wikiSQL t5_small_wikiSQL Text Generation T5Transformer xx xx.ner.masakhaner xlm_roberta_large_token_classifier_masakhaner Named Entity Recognition XlmRoBertaForTokenClassification xx xx.ner.high_resourced_lang xlm_roberta_large_token_classifier_hrl Named Entity Recognition XlmRoBertaForTokenClassification xx xx.ner.scandinavian bert_token_classifier_scandi_ner Named Entity Recognition BertForTokenClassification en en.embed.electra.medical electra_medal_acronym Embeddings BertEmbeddings en en.ner.restaurant nerdl_restaurant_100d Named Entity Recognition NerDLModel en en.embed.word2vec.gigaword_wiki word2vec_gigaword_wiki_300 Embeddings Word2VecModel en en.embed.word2vec.gigaword word2vec_gigaword_300 Embeddings Word2VecModel en en.classify.xlm_roberta.imdb xlm_roberta_base_sequence_classifier_imdb Text Classification XlmRoBertaForSequenceClassification en en.classify.xlm_roberta.ag_news xlm_roberta_base_sequence_classifier_ag_news Text Classification XlmRoBertaForSequenceClassification en en.classify.roberta.imdb roberta_base_sequence_classifier_imdb Text Classification RoBertaForSequenceClassification en en.classify.roberta.ag_news roberta_base_sequence_classifier_ag_news Text Classification RoBertaForSequenceClassification en en.classify.albert.ag_news albert_base_sequence_classifier_ag_news Text Classification AlbertForSequenceClassification en en.classify.albert.imdb albert_base_sequence_classifier_imdb Text Classification AlbertForSequenceClassification en en.classify.ag_news.longformer longformer_base_sequence_classifier_ag_news Text Classification LongformerForSequenceClassification en en.classify.imdb.xlnet xlnet_base_sequence_classifier_imdb Text Classification XlnetForSequenceClassification en en.classify.finance_sentiment bert_sequence_classifier_finbert_tone Sentiment Analysis BertForSequenceClassification en en.classify.imdb.longformer longformer_base_sequence_classifier_imdb Text Classification LongformerForSequenceClassification en en.classify.ag_news.longformer longformer_base_sequence_classifier_ag_news Text Classification LongformerForSequenceClassification en en.ner.time roberta_token_classifier_timex_semeval Named Entity Recognition RoBertaForTokenClassification en en.ner.stocks_ticker roberta_token_classifier_ticker Named Entity Recognition RoBertaForTokenClassification ru ru.classify.toxic bert_sequence_classifier_toxicity Text Classification BertForSequenceClassification it it.classify.sentiment bert_sequence_classifier_sentiment Sentiment Analysis BertForSequenceClassification es es.ner wikiner_6B_100 Named Entity Recognition NerDLModel is is.ner roberta_token_classifier_icelandic_ner Named Entity Recognition RoBertaForTokenClassification id id.pos roberta_token_classifier_pos_tagger Part of Speech Tagging RoBertaForTokenClassification tr tr.ner turkish_ner_840B_300 Named Entity Recognition NerDLModel id id.ner xlm_roberta_large_token_classification_ner Named Entity Recognition XlmRoBertaForTokenClassification de de.ner xlm_roberta_large_token_classifier_conll03 Named Entity Recognition XlmRoBertaForTokenClassification hi hi.ner bert_token_classifier_hi_en_ner Named Entity Recognition BertForTokenClassification nl nl.ner wikiner_6B_100 Named Entity Recognition NerDLModel zh zh.ner bert_token_classifier_chinese_ner Named Entity Recognition BertForTokenClassification fr fr.classify.xlm_roberta.allocine xlm_roberta_base_sequence_classifier_allocine Text Classification XlmRoBertaForSequenceClassification ur ur.classify.fakenews classifierdl_urduvec_fakenews Text Classification ClassifierDLModel ur ur.classify.news classifierdl_bert_news Text Classification ClassifierDLModel fi fi.embed_sentence.bert.uncased bert_base_finnish_uncased Embeddings BertSentenceEmbeddings fi fi.embed_sentence.bert bert_base_finnish_uncased Embeddings BertSentenceEmbeddings fi fi.embed_sentence.bert.cased bert_base_finnish_cased Embeddings BertSentenceEmbeddings te te.embed.distilbert distilbert_uncased Embeddings DistilBertEmbeddings sw sw.embed.xlm_roberta xlm_roberta_base_finetuned_swahili Embeddings XlmRoBertaEmbeddings New Healthcare Models Integration for the 28 new models from the amazing Spark NLP for healthcare 3.4.0 release Language NLU Reference Spark NLP Reference Task Annotator Class en en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot Named Entity Recognition MedicalBertForTokenClassifier en en.med_ner.chemprot.bert bert_token_classifier_ner_chemprot Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_clinical bert_token_classifier_ner_clinical Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_jsl bert_token_classifier_ner_jsl Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition MedicalBertForTokenClassifier en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition MedicalBertForTokenClassifier en en.med_ner.abbreviation_clinical ner_abbreviation_clinical Named Entity Recognition MedicalNerModel en en.med_ner.drugprot_clinical ner_drugprot_clinical Named Entity Recognition MedicalNerModel en en.ner.drug_development_trials bert_token_classifier_drug_development_trials Named Entity Recognition BertForTokenClassification en en.med_ner.chemprot ner_chemprot_biobert Named Entity Recognition MedicalNerModel en en.relation.drugprot redl_drugprot_biobert Relation Extraction RelationExtractionDLModel en en.relation.drugprot.clinical re_drugprot_clinical Relation Extraction RelationExtractionModel en en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym Entity Resolution SentenceEntityResolverModel en en.resolve.clinical_abbreviation_acronym sbiobertresolve_clinical_abbreviation_acronym Entity Resolution SentenceEntityResolverModel en en.resolve.umls_drug_substance sbiobertresolve_umls_drug_substance Entity Resolution SentenceEntityResolverModel en en.resolve.loinc_cased sbiobertresolve_loinc_cased Entity Resolution SentenceEntityResolverModel en en.resolve.loinc_uncased sbluebertresolve_loinc_uncased Entity Resolution SentenceEntityResolverModel en en.embed_sentence.biobert.rxnorm sbiobert_jsl_rxnorm_cased Entity Resolution BertSentenceEmbeddings en en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased Embeddings BertSentenceEmbeddings en en.embed_sentence.bert_uncased.rxnorm sbert_jsl_medium_rxnorm_uncased Embeddings BertSentenceEmbeddings en en.resolve.snomed_drug sbiobertresolve_snomed_drug Entity Resolution SentenceEntityResolverModel de de.med_ner.deid_subentity ner_deid_subentity Named Entity Recognition MedicalNerModel de de.med_ner.deid_generic ner_deid_generic Named Entity Recognition MedicalNerModel de de.embed.w2v w2v_cc_300d Embeddings WordEmbeddingsModel Additional NLU resources NLU OCR tutorial notebook 140+ NLU Tutorials NLU in Action Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.3.1 48 new Transformer based models in 9 new languages, including NER for Finance, Industry, Politcal Policies, COVID and Chemical Trials, various clinical and medical domains in Spanish and English and much more in NLU 3.3.1 We are incredibly excited to announce NLU 3.3.1 has been released with 48 new models in 9 languages! It comes with 2 new types of state-of-the-art models,distilBERT and BERT for sequence classification with various pre-trained weights, state-of-the-art bert based classifiers for problems in the domains of Finance, Sentiment Classification, Industry, News, and much more. On the healthcare side, NLU features 22 new models in for English and Spanish with with entity Resolver Models for LOINC, MeSH, NDC and SNOMED and UMLS Diseases, NER models for Biomarkers, NIHSS-Guidelines, COVID Trials , Chemical Trials, Bert based Token Classifier models for biological, genetical,cancer, cellular terms, Bert for Sequence Classification models for clinical question vs statement classification and finally Spanish Clinical NER and Resolver Models Once again, we would like to thank our community for making another amazing release possible! New Open Source Models and Features Integrates the amazing Spark NLP 3.3.3 and 3.3.2 releases, featuring: New state-of-the-art fine-tuned BERT models for Sequence Classification in English, French, German, Spanish, Japanese, Turkish, Russian, and multilingual languages. DistilBertForSequenceClassification models in English, French and Urdu Word2Vec models. classify.distilbert_sequence.banking77 : Banking NER model trained on BANKING77 dataset, which provides a very fine-grained set of intents in a banking domain. It comprises 13,083 customer service queries labeled with 77 intents. It focuses on fine-grained single-domain intent detection. Can extract entities like activate_my_card, age_limit, apple_pay_or_google_pay, atm_support, automatic_top_up, balance_not_updated_after_bank_transfer, balance_not_updated_after_cheque_or_cash_deposit, beneficiary_not_allowed, cancel_transfer, card_about_to_expire, card_acceptance, card_arrival, card_delivery_estimate, card_linking, card_not_working, card_payment_fee_charged, card_payment_not_recognised, card_payment_wrong_exchange_rate, card_swallowed, cash_withdrawal_charge, cash_withdrawal_not_recognised, change_pin, compromised_card, contactless_not_working, country_support, declined_card_payment, declined_cash_withdrawal, declined_transfer, direct_debit_payment_not_recognised, disposable_card_limits, edit_personal_details, exchange_charge, exchange_rate, exchange_via_app, extra_charge_on_statement, failed_transfer, fiat_currency_support, get_disposable_virtual_card, get_physical_card, getting_spare_card, getting_virtual_card, lost_or_stolen_card, lost_or_stolen_phone, order_physical_card, passcode_forgotten, pending_card_payment, pending_cash_withdrawal, pending_top_up, pending_transfer, pin_blocked, receiving_money, classify.distilbert_sequence.industry : Industry NER model which can extract entities like Advertising, Aerospace &amp; Defense, Apparel Retail, Apparel, Accessories &amp; Luxury Goods, Application Software, Asset Management &amp; Custody Banks, Auto Parts &amp; Equipment, Biotechnology, Building Products, Casinos &amp; Gaming, Commodity Chemicals, Communications Equipment, Construction &amp; Engineering, Construction Machinery &amp; Heavy Trucks, Consumer Finance, Data Processing &amp; Outsourced Services, Diversified Metals &amp; Mining, Diversified Support Services, Electric Utilities, Electrical Components &amp; Equipment, Electronic Equipment &amp; Instruments, Environmental &amp; Facilities Services, Gold, Health Care Equipment, Health Care Facilities, Health Care Services. xx.classify.bert_sequence.sentiment : Multi-Lingual Sentiment Classifier This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5). This model is intended for direct use as a sentiment analysis model for product reviews in any of the six languages above, or for further finetuning on related sentiment analysis tasks. distilbert_sequence.policy : Policy Classifier This model was trained on 129.669 manually annotated sentences to classify text into one of seven political categories: ‘Economy’, ‘External Relations’, ‘Fabric of Society’, ‘Freedom and Democracy’, ‘Political System’, ‘Welfare and Quality of Life’ or ‘Social Groups’. classify.bert_sequence.dehatebert_mono : Hate Speech Classifier This model was trained on 129.669 manually annotated sentences to classify text into one of seven political categories: ‘Economy’, ‘External Relations’, ‘Fabric of Society’, ‘Freedom and Democracy’, ‘Political System’, ‘Welfare and Quality of Life’ or ‘Social Groups’. Complete List of Open Source Models : | Language | NLU Reference | Spark NLP Reference | Task | |:———–|:——————————————————————————————————————————————————-|:————————————————————————————————————————————————————-|:——————–| | en | en.classify.bert_sequence.imdb_large | bert_large_sequence_classifier_imdb | Text Classification | | en | en.classify.bert_sequence.imdb | bert_base_sequence_classifier_imdb | Text Classification | | en | en.classify.bert_sequence.ag_news | bert_base_sequence_classifier_ag_news | Text Classification | | en | en.classify.bert_sequence.dbpedia_14 | bert_base_sequence_classifier_dbpedia_14 | Text Classification | | en | en.classify.bert_sequence.finbert | bert_sequence_classifier_finbert | Text Classification | | en | en.classify.bert_sequence.dehatebert_mono | bert_sequence_classifier_dehatebert_mono | Text Classification | | tr | tr.classify.bert_sequence.sentiment | bert_sequence_classifier_turkish_sentiment | Text Classification | | de | de.classify.bert_sequence.sentiment | bert_sequence_classifier_sentiment | Text Classification | | ru | ru.classify.bert_sequence.sentiment | bert_sequence_classifier_rubert_sentiment | Text Classification | | ja | ja.classify.bert_sequence.sentiment | bert_sequence_classifier_japanese_sentiment | Text Classification | | es | es.classify.bert_sequence.sentiment | bert_sequence_classifier_beto_sentiment_analysis | Text Classification | | es | es.classify.bert_sequence.emotion | bert_sequence_classifier_beto_emotion_analysis | Text Classification | | xx | xx.classify.bert_sequence.sentiment | bert_sequence_classifier_multilingual_sentiment | Text Classification | | en | en.classify.distilbert_sequence.sst2 | distilbert_sequence_classifier_sst2 | Text Classification | | en | en.classify.distilbert_sequence.policy | distilbert_sequence_classifier_policy | Text Classification | | en | en.classify.distilbert_sequence.industry | distilbert_sequence_classifier_industry | Text Classification | | en | en.classify.distilbert_sequence.emotion | distilbert_sequence_classifier_emotion | Text Classification | | en | en.classify.distilbert_sequence.banking77 | distilbert_sequence_classifier_banking77 | Text Classification | | en | en.classify.distilbert_sequence.imdb | distilbert_base_sequence_classifier_imdb | Text Classification | | en | en.classify.distilbert_sequence.amazon_polarity | distilbert_base_sequence_classifier_amazon_polarity | Text Classification | | en | en.classify.distilbert_sequence.ag_news | distilbert_base_sequence_classifier_ag_news | Text Classification | | fr | fr.classify.distilbert_sequence.allocine | distilbert_multilingual_sequence_classifier_allocine | Text Classification | | ur | ur.classify.distilbert_sequence.imdb | distilbert_base_sequence_classifier_imdb | Text Classification | | en | en.embed_sentence.doc2vec | doc2vec_gigaword_300 | Embeddings | | en | en.embed_sentence.doc2vec.gigaword_300 | doc2vec_gigaword_300 | Embeddings | | en | en.embed_sentence.doc2vec.gigaword_wiki_300 | doc2vec_gigaword_wiki_300 | Embeddings | New Healthcare models and Features Integrates the incredible Spark NLP for Healthcare releases 3.3.4, 3.3.2 and 3.3.1, featuring: New Clinical NER Models for protected health information(PHI), ner_biomarker for extracting extract biomarkers, therapies, oncological, and other general concepts Oncogenes, Tumor_Finding, UnspecificTherapy, Ethnicity, Age, ResponseToTreatment, Biomarker, HormonalTherapy, Staging, Drug, CancerDx, Radiotherapy, CancerSurgery, TargetedTherapy, PerformanceStatus, CancerModifier, Radiological_Test_Result, Biomarker_Measurement, Metastasis, Radiological_Test, Chemotherapy, Test, Dosage, Test_Result, Immunotherapy, Date, Gender, Prognostic_Biomarkers, Duration, Predictive_Biomarkers ner_nihss : NER model that can identify entities according to NIHSS guidelines for clinical stroke assessment to evaluate neurological status in acute stroke patients 11_ExtinctionInattention, 6b_RightLeg, 1c_LOCCommands, 10_Dysarthria, NIHSS, 5_Motor, 8_Sensory, 4_FacialPalsy, 6_Motor, 2_BestGaze, Measurement, 6a_LeftLeg, 5b_RightArm, 5a_LeftArm, 1b_LOCQuestions, 3_Visual, 9_BestLanguage, 7_LimbAtaxia, 1a_LOC . redl_nihss_biobert : relation extraction model that can relate scale items and their measurements according to NIHSS guidelines. es.med_ner.roberta_ner_diag_proc : New Spanish Clinical NER Models for extracting the entities DIAGNOSTICO, PROCEDIMIENTO es.resolve.snomed: New Spanish SNOMED Entity Resolvers bert_sequence_classifier_question_statement_clinical:New Clinical Question vs Statement for BertForSequenceClassification model med_ner.covid_trials : This model is trained to extract covid-specific medical entities in clinical trials. It supports the following entities ranging from virus type to trial design: Stage, Severity, Virus, Trial_Design, Trial_Phase, N_Patients, Institution, Statistical_Indicator, Section_Header, Cell_Type, Cellular_component, Viral_components, Physiological_reaction, Biological_molecules, Admission_Discharge, Age, BMI, Cerebrovascular_Disease, Date, Death_Entity, Diabetes, Disease_Syndrome_Disorder, Dosage, Drug_Ingredient, Employment, Frequency, Gender, Heart_Disease, Hypertension, Obesity, Pulse, Race_Ethnicity, Respiration, Route, Smoking, Time, Total_Cholesterol, Treatment, VS_Finding, Vaccine . med_ner.chemd : This model extract the names of chemical compounds and drugs in medical texts. The entities that can be detected are as follows : SYSTEMATIC, IDENTIFIERS, FORMULA, TRIVIAL, ABBREVIATION, FAMILY, MULTIPLE . For reference click here . https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331685/ bert_token_classifier_ner_bionlp : This model is BERT-based version of ner_bionlp model and can detect biological and genetics terms in cancer-related texts. (Amino_acid, Anatomical_system, Cancer, Cell, Cellular_component, Developing_anatomical_Structure, Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism, Organism_subdivision, Simple_chemical, Tissue bert_token_classifier_ner_cellular : This model is BERT-based version of ner_cellular model and can detect molecular biology-related terms (DNA, Cell_type, Cell_line, RNA, Protein) in medical texts. We have updated med_ner.jsl.enriched model by enriching the training data using clinical trials data to make it more robust. This model is capable of predicting up to 87 different entities and is based on ner_jsl model. Here are the entities this model can detect; Social_History_Header, Oncology_Therapy, Blood_Pressure, Respiration, Performance_Status, Family_History_Header, Dosage, Clinical_Dept, Diet, Procedure, HDL, Weight, Admission_Discharge, LDL, Kidney_Disease, Oncological, Route, Imaging_Technique, Puerperium, Overweight, Temperature, Diabetes, Vaccine, Age, Test_Result, Employment, Time, Obesity, EKG_Findings, Pregnancy, Communicable_Disease, BMI, Strength, Tumor_Finding, Section_Header, RelativeDate, ImagingFindings, Death_Entity, Date, Cerebrovascular_Disease, Treatment, Labour_Delivery, Pregnancy_Delivery_Puerperium, Direction, Internal_organ_or_component, Psychological_Condition, Form, Medical_Device, Test, Symptom, Disease_Syndrome_Disorder, Staging, Birth_Entity, Hyperlipidemia, O2_Saturation, Frequency, External_body_part_or_region, Drug_Ingredient, Vital_Signs_Header, Substance_Quantity, Race_Ethnicity, VS_Finding, Injury_or_Poisoning, Medical_History_Header, Alcohol, Triglycerides, Total_Cholesterol, Sexually_Active_or_Sexual_Orientation, Female_Reproductive_Status, Relationship_Status, Drug_BrandName, RelativeTime, Duration, Hypertension, Metastasis, Gender, Oxygen_Therapy, Pulse, Heart_Disease, Modifier, Allergen, Smoking, Substance, Cancer_Modifier, Fetus_NewBorn, Height classify.bert_sequence.question_statement_clinical : This model classifies sentences into one of these two classes: question (interrogative sentence) or statement (declarative sentence) and trained with BertForSequenceClassification. This model is at first trained on SQuAD and SPAADIA dataset and then fine tuned on the clinical visit documents and MIMIC-III dataset annotated in-house. Using this model, you can find the question statements and exclude &amp; utilize in the downstream tasks such as NER and relation extraction models. classify.token_bert.ner_chemical : This model is BERT-based version of ner_chemicals model and can detect chemical compounds (CHEM) in the medical texts. resolve.umls_disease_syndrome : This model is trained on the Disease or Syndrome category using sbiobert_base_cased_mli embeddings. Complete List of Healthcare Models : Language NLU Reference Spark NLP Reference Task en en.med_ner.deid_subentity_augmented_i2b2 ner_deid_subentity_augmented_i2b2 Named Entity Recognition en en.med_ner.biomarker ner_biomarker Named Entity Recognition en en.med_ner.nihss ner_nihss Named Entity Recognition en en.extract_relation.nihss redl_nihss_biobert Relation Extraction en en.resolve.mesh sbiobertresolve_mesh Entity Resolution en en.resolve.mli sbiobert_base_cased_mli Embeddings en en.resolve.ndc sbiobertresolve_ndc Entity Resolution en en.resolve.loinc.augmented sbiobertresolve_loinc_augmented Entity Resolution en en.resolve.clinical_snomed_procedures_measurements sbiobertresolve_clinical_snomed_procedures_measurements Entity Resolution es es.embed.roberta_base_biomedical roberta_base_biomedical Embeddings es es.med_ner.roberta_ner_diag_proc roberta_ner_diag_proc Named Entity Recognition es es.resolve.snomed robertaresolve_snomed Entity Resolution en en.med_ner.covid_trials ner_covid_trials Named Entity Recognition en en.classify.token_bert.bionlp bert_token_classifier_ner_bionlp Named Entity Recognition en en.classify.token_bert.cellular bert_token_classifier_ner_cellular Named Entity Recognition en en.classify.token_bert.chemicals bert_token_classifier_ner_chemicals Named Entity Recognition en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.rxnorm_augmented sbiobertresolve_rxnorm_augmented Entity Resolution en en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome Entity Resolution en en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs Entity Resolution en en.classify.bert_sequence.question_statement_clinical bert_sequence_classifier_question_statement_clinical Text Classification NLU Version 3.3.0 2000%+ Speedup on small data, 63 new models for 100+ Languages with 6 new supported Transformer classes including BERT, XLM-RoBERTa, alBERT, Longformer, XLnet based models, 48 NER profiling helathcare pipelines and much more in John Snow Labs NLU 3.3.0 We are incredibly excited to announce NLU 3.3.0 has been released! It comes with a up to 2000%+ speedup on small datasets, 6 new Types of Deep Learning transformer models, including RoBertaForTokenClassification,XlmRoBertaForTokenClassification,AlbertForTokenClassification,LongformerForTokenClassification,XlnetForTokenClassification,XlmRoBertaSentenceEmbeddings. In total there are 63 NLP Models 6 New Languages Supported which are Igbo, Ganda, Dholuo, Naija, Wolof,Kinyarwanda with their corresponding ISO codes ig, lg, lou, pcm, wo,rw with New SOTA XLM-RoBERTa models in Luganda, Kinyarwanda, Igbo, Hausa, and Amharic languages and 2 new Multilingual Embeddings with 100+ supported languages via XLM-Roberta are available. On the healthcare NLP side we are glad to announce 18 new NLP for Healthcare models including NER Profiling pretrained pipelines to run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text New BERT-Based Deidentification NER Model, Sentence Entity Resolver Models For German Language New Spell Checker Model For Drugs , 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) ,Radiology NER Model Trained On cheXpert Datasetand New UMLS Sentence Entity Resolver Models Additionally 2 new tutorials are avaiable, NLU &amp; Streamlit Crashcourse and NLU for Healthcare Crashcourse of every of the 50 + healthcare Domains and 200+ healthcare models New Features and Improvements 2000%+ Speedup prediction for small datasets NLU pipelines now predict up to 2000% faster by optimizing integration with Spark NLP’s light pipelines. NLU will configure usage of this automatically, but it can be turned off as well via multithread=False 50x faster saving of NLU Pipelines Up to 50x faster saving Spark NLP/ NLU models and pipelines! We have improved the way we package TensorFlow SavedModel while saving Spark NLP models &amp; pipelines. For instance, it used to take up to 10 minutes to save the xlm_roberta_base model before Spark NLP 3.3.0, and now it only takes up to 15 seconds! New Annotator Classes Integrated The following new transformer classes are available with various pretrained weights in 1 line of code : RoBertaForTokenClassification XlmRoBertaForTokenClassification AlbertForTokenClassification LongformerForTokenClassification XlnetForTokenClassification XlmRoBertaSentenceEmbeddings New Transformer Models The following models are available from the amazing Spark NLP 3.3.0 and 3.3.1 releases which includes NLP models for Yiddish, Ukrainian, Telugu, Tamil, Somali, Sindhi, Russian, Punjabi, Nepali, Marathi, Malayalam, Kannada, Indonesian, Gujrati, Bosnian, Igbo, Ganda, Dholuo, Naija, Wolof,Kinyarwanda Language NLU Reference Spark NLP Reference Task   ig ig.embed.xlm_roberta xlm_roberta_base_finetuned_igbo Embeddings   ig ig.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_igbo Embeddings   lg lg.embed.xlm_roberta xlm_roberta_base_finetuned_luganda Embeddings   lg lg.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_luganda Embeddings   wo wo.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_wolof Embeddings   wo wo.embed.xlm_roberta xlm_roberta_base_finetuned_wolof Embeddings   rw rw.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_kinyarwanda Embeddings   rw rw.embed.xlm_roberta xlm_roberta_base_finetuned_kinyarwanda Embeddings   sw sw.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_swahili Embeddings   sw sw.embed.xlm_roberta xlm_roberta_base_finetuned_swahili Embeddings   ha ha.embed.xlm_roberta xlm_roberta_base_finetuned_hausa Embeddings   ha ha.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_hausa Embeddings   am am.embed.xlm_roberta xlm_roberta_base_finetuned_amharic Embeddings   am am.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_amharic Embeddings   yo yo.embed_sentence.xlm_roberta sent_xlm_roberta_base_finetuned_yoruba Embeddings   yo yo.embed.xlm_roberta xlm_roberta_base_finetuned_yoruba Embeddings   fa fa.classify.token_roberta_token_classifier_zwnj_base_ner roberta_token_classifier_zwnj_base_ner Named Entity Recognition   yi detect_sentence sentence_detector_dl Sentence Detection   uk detect_sentence sentence_detector_dl Sentence Detection   te detect_sentence sentence_detector_dl Sentence Detection   ta detect_sentence sentence_detector_dl Sentence Detection   so detect_sentence sentence_detector_dl Sentence Detection   sd detect_sentence sentence_detector_dl Sentence Detection   ru detect_sentence sentence_detector_dl Sentence Detection   pa detect_sentence sentence_detector_dl Sentence Detection   ne detect_sentence sentence_detector_dl Sentence Detection   mr detect_sentence sentence_detector_dl Sentence Detection   ml detect_sentence sentence_detector_dl Sentence Detection   kn detect_sentence sentence_detector_dl Sentence Detection   id detect_sentence sentence_detector_dl Sentence Detection   gu detect_sentence sentence_detector_dl Sentence Detection   bs detect_sentence sentence_detector_dl Sentence Detection   en en.classify.token_roberta_large_token_classifier_conll03 roberta_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_roberta_base_token_classifier_ontonotes roberta_base_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_roberta_base_token_classifier_conll03 roberta_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_distilroberta_base_token_classifier_ontonotes distilroberta_base_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_albert_large_token_classifier_conll03 albert_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_albert_base_token_classifier_conll03 albert_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_xlnet_base_token_classifier_conll03 xlnet_base_token_classifier_conll03 Named Entity Recognition   en en.classify.token_roberta.large_token_classifier_ontonotes roberta_large_token_classifier_ontonotes Named Entity Recognition   en en.classify.token_albert.xlarge_token_classifier_conll03 albert_xlarge_token_classifier_conll03 Named Entity Recognition   en en.classify.token_xlnet.large_token_classifier_conll03 xlnet_large_token_classifier_conll03 Named Entity Recognition   en en.classify.token_longformer.base_token_classifier_conll03 longformer_base_token_classifier_conll03 Named Entity Recognition   xx xx.classify.token_xlm_roberta.token_classifier_ner_40_lang xlm_roberta_token_classifier_ner_40_lang Named Entity Recognition   xx xx.embed.xlm_roberta_large xlm_roberta_large Embeddings   New Healthcare models The following models are available from the amazing Spark NLP for Healthcare releases 3.3.0, 3.2.3, 3.3.1, which includes 48 Multi-NER tuning pipelines, BERT-based DEidentification, German NER resolvers, Spell Checkers for Drugs, 5 ner NER models trained via BErtForTokenClassification, NER models for Radiology CID10CM, RxNORM NDC and HCPCSS models and UMLS sentence resolver models Language NLU Reference Spark NLP Reference Task de de.resolve.snomed sbertresolve_snomed Entity Resolution de de.resolve.icd10gm sbertresolve_icd10gm Entity Resolution en en.med_ner.profiling_clinical ner_profiling_clinical Pipeline Healthcare en en.med_ner.profiling_biobert ner_profiling_biobert Pipeline Healthcare en en.med_ner.chexpert ner_chexpert Named Entity Recognition en en.classify.token_bert.ner_bacteria bert_token_classifier_ner_bacteria Named Entity Recognition en en.classify.token_bert.ner_anatomy bert_token_classifier_ner_anatomy Named Entity Recognition en en.classify.token_bert.ner_drugs bert_token_classifier_ner_drugs Named Entity Recognition en en.classify.token_bert.ner_jsl_slim bert_token_classifier_ner_jsl_slim Named Entity Recognition en en.classify.token_bert.ner_ade bert_token_classifier_ner_ade Named Entity Recognition en en.resolve.rxnorm_ndc sbiobertresolve_rxnorm_ndc Entity Resolution en en.resolve.icd10cm_generalised sbiobertresolve_icd10cm_generalised Entity Resolution en en.resolve.hcpcs sbiobertresolve_hcpcs Entity Resolution en en.spell.drug_norvig spellcheck_drug_norvig Spell Check en en.classify.token_bert.ner_deid bert_token_classifier_ner_deid Named Entity Recognition en en.classify.token_bert.ner_chemical bert_token_classifier_ner_chemicals Named Entity Recognition en en.resolve.umls_disease_syndrome sbiobertresolve_umls_disease_syndrome Entity Resolution en en.resolve.umls_clinical_drugs sbiobertresolve_umls_clinical_drugs Entity Resolution Updated Model Names The nlu model references have been updated to better reflect their use-cases. en.classify.token_bert.conll03 en.classify.token_bert.large_conll03 en.classify.token_bert.ontonote en.classify.token_bert.large_ontonote en.classify.token_bert.few_nerd en.classify.token_bert.classifier_ner_btc es.classify.token_bert.spanish_ner ja.classify.token_bert.classifier_ner_ud_gsd fa.classify.token_bert.parsbert_armanner fa.classify.token_bert.parsbert_ner fa.classify.token_bert.parsbert_peymaner sv.classify.token_bert.swedish_ner tr.classify.token_bert.turkish_ner en.classify.token_bert.ner_clinical en.classify.token_bert.ner_jsl New Tutorial Videos NLU &amp; Streamlit Crashcourse NLU for Healthcare Crashcourse of every of the 50 + healthcare Domains and 200+ healthcare models Optional get_embeddings parameter for pipelines NLU pipelines can now be forced to not return embeddings via get_embeddings parameter. Updated Compatibility Docs Added documentation section regarding compatibility of NLU, Spark NLP and Spark NLP for healthcare Bugfixes Fixed a bug with Pyspark versions 3.0 and below that caused failure of predicting with pipeline Fixed a bug that caused the results of TokenClassifier Models to not be properly extracted Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.2.1 27 new models in 7 Languages, including Japanese NER, resolution models for SNOMED, ICDO, CPT and RxNorm codes and much more in NLU 3.2.1 We are very excited to announce NLU 3.2.1! This release comes with models 27 new models for 7 languages which are transformer based. New NER-Classifiers, BertSentenceEmbeddings, BertEmbeddings and BertForTokenClassificationEmbeddings for Japanese, German, Dutch, Swedish, Spanish, French and English. For healthcare there are new Entity Resolvers and MedicalNerModels for Snomed Conditions, Cpt Measurements, Icd0, Rxnorm Dispositions, Posology and Deidentification. Finally, a new tutorial notebook and a webinar are available, which showcase almost every feature of NLU for the over 50 Domains in Healthcare/Clinical/Biomedical/etc.. New Transformer Models Models in Japanese, German, Dutch, Swedish, Spanish, French and English from the great Spark NLP 3.2.3 release nlu.load() Refrence Spark NLP Refrence Annotater class Language en.embed.bert.base_uncased_legal bert_base_uncased_legal BertEmbeddings en en.embed_sentence.bert.base_uncased_legal sent_bert_base_uncased_legal BertSentenceEmbeddings en en.embed.token_bert.classifier_ner_btc bert_token_classifier_ner_btc BertForTokenClassification en es.embed.bert.base_uncased bert_base_uncased BertEmbeddings es es.embed.bert.base_cased bert_base_cased BertEmbeddings es es.embed_sentence.bert.base_uncased sent_bert_base_uncased BertSentenceEmbeddings es es.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings es el.embed.bert.base_uncased bert_base_uncased BertEmbeddings el el.embed_sentence.bert.base_uncased sent_bert_base_uncased BertSentenceEmbeddings el sv.embed.bert.base_cased bert_base_cased BertEmbeddings sv sv.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings sv nl.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings nl nl.embed.bert.base_cased bert_base_cased BertEmbeddings nl fr.classify.sentiment.bert classifierdl_bert_sentiment ClassifierDLModel fr ja.embed.glove.cc_300d japanese_cc_300d WordEmbeddingsModel ja ja.ner.ud_gsd_cc_300d ner_ud_gsd_cc_300d NerDLModel ja ja.ner.ud_gsd_xlm_roberta_base ner_ud_gsd_xlm_roberta_base NerDLModel ja ja.embed.token_bert.classifier_ner_ud_gsd bert_token_classifier_ner_ud_gsd BertForTokenClassification ja de.embed_sentence.bert.base_cased sent_bert_base_cased BertSentenceEmbeddings de de.classify.sentiment.bert classifierdl_bert_sentiment ClassifierDLModel de New Healthcare Transformer Models Models for Snomed Conditions, Cpt Measurements, Icd0, Rxnorm Dispositions, Posology and Deidentification from the amazing Spark NLP 3.2.2 for Healthcare Release nlu.load() Refrences Spark NLP Refrence Annotater class Language en.resolve.snomed_conditions sbertresolve_snomed_conditions SentenceEntityResolverModel en en.resolve.cpt.procedures_measurements sbiobertresolve_cpt_procedures_measurements_augmented SentenceEntityResolverModel en en.resolve.icdo.base sbiobertresolve_icdo_base SentenceEntityResolverModel en en.resolve.rxnorm.disposition.sbert sbertresolve_rxnorm_disposition SentenceEntityResolverModel en en.resolve.rxnorm_disposition.sbert sbertresolve_rxnorm_disposition SentenceEntityResolverModel en en.med_ner.posology.experimental ner_posology_experimental MedicalNerModel en en.med_ner.deid.subentity_augmented ner_deid_subentity_augmented MedicalNerModel en New Notebooks NLU Healthcare Overview and Crashcourse Enhancements Columns of the Pandas DataFrame returned by NLU will now be sorted alphabetically Bugfixes Fixed a bug that caused output levels no beeing inferred properly Fixed a bug that caused SentenceResolver visualizations not to appear. NLU Version 3.2.0 100+ Transformers Models in 40+ languages, 3-D Streamlit Entity-Embedding-Manifold visualizations, Multi-Lingual NER, Longformers, TokenDistilBERT, Trainable Sentence Resolvers, 7% less memory usage and much more in NLU 3.2.0 We are extremely excited to announce the release of NLU 3.2.0 which marks the 1-year anniversary of the birth of this magical library. This release packs features and improvements in every division of NLU’s aspects, 89 new NLP models with new Models including Longformer, TokenBert, TokenDistilBert and Multi-Lingual NER for 40+ Languages. 12 new Healthcare models with trainable sentence resolvers and models Adverse Drug Relations, Clinical Token Bert Models, NER Models for Radiology, Drugs, Posology, Administration Cycles, RXNorm, and new Medical Assertion models. New Streamlit visualizations enable you to see Entities in 3-D, 2-D, and 1-D Manifolds which are applicable to Entities and their Embeddings, Detected by Named-Entity-Recognizer models. Finally, a ~7% decrease in Memory consumption in NLU’s core which benefits every computation, achieved by leveraging Pyarrow. We are incredibly thankful to our community, which helped us come this far, and are looking forward to another magical year of NLU! Streamlit Entity Manifold visualization function pipe.viz_streamlit_entity_embed_manifold Visualize recognized entities by NER models via their Entity Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 10+ Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. You can pick additional NER models and compare them via the GUI dropdown on the left. Reduces Dimensionality of high dimensional Entity Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 330+ Named Entity Recognizer models Gemerates NUM-DIMENSIONS * NUM-NER-MODELS * NUM-DIMENSION-REDUCTION-ALGOS plots nlu.load(&#39;ner&#39;).viz_streamlit_sentence_embed_manifold([&#39;Hello From John Snow Labs&#39;, &#39;Peter loves to visit New York&#39;]) or just run streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/09_entity_embedding_manifolds.py function parameters pipe.viz_streamlit_sentence_embed_manifold | Argument | Type | Default |Description | |—————————-|————|———————————————————–|———————————————————| |default_texts| List[str] |”Donald Trump likes to visit New York”, “Angela Merkel likes to visit Berlin!”, ‘Peter hates visiting Paris’)| List of strings to apply classifiers, embeddings, and manifolds to. | | title | str | &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; | Title of the Streamlit app |sub_title| Optional[str] | “Apply any of the 10+ Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Entity Embeddings to 1-D, 2-D and 3-D “ | Sub title of the Streamlit app | |default_algos_to_apply| List[str] | [&quot;TSNE&quot;, &quot;PCA&quot;] | A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;, | |target_dimensions| List[int] | (1,2,3) | Defines the target dimension embeddings will be reduced to | |show_algo_select| bool | True | Show selector for Manifold and Matrix Decomposition Algorithms | | set_wide_layout_CSS | bool | True | Whether to inject custom CSS or not.| |num_cols | int | 2 | How many columns should for the layout in streamlit when rendering the similarity matrixes.| | key | str | &quot;NLU_streamlit&quot; | Key for the Streamlit elements drawn | | show_logo | bool | True | Show logo | | display_infos | bool | False | Display additonal information about ISO codes and the NLU namespace structure.| | n_jobs | Optional[int] | 3| False | How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. | Sentence Entity Resolver Training Sentence Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labeled with classes. These classes and strings are still ambiguous though and it is not possible to group semantically identically entities without any definition of terminology. With the Sentence Resolver you can train a state-of-the-art deep learning architecture to map entities to their unique terminological representation. Train a Sentence resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd import nlu dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;], &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlu.load(&#39;train.resolve_sentence&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;])   sentence_resolution_resolve_sentence_confidence sentence_resolution_resolve_sentence_code sentence_resolution_resolve_sentence sentence 0 ‘1.0000’ ‘23’ ‘TESLA’ ‘The Tesla company is good to invest is’ 1 ‘1.0000’ ‘23’ ‘TESLA’ ‘TSLA is good to invest’ 2 ‘1.0000’ ‘23’ ‘TESLA’ ‘TESLA INC. we should buy’ 3 ‘1.0000’ ‘23’ ‘TESLA’ ‘PUT ALL MONEY IN TSLA inc!!’ Alternatively you can also use non-default healthcare embeddings. trainable_pipe = nlu.load(&#39;en.embed.glove.biovec train.resolve_sentence&#39;) Transformer Models New models from the spectacular Spark NLP 3.2.0 + releases are integrated. 89 new models in total, with new LongFormer, TokenBert, TokenDistilBert and Multi-Lingual NER for 40+ languages. The supported languages with their ISO 639-1 code are : af, ar, bg, bn, de, el, en, es, et, eu, fa, fi, fr, he, hi, hu, id, it, ja, jv, ka, kk, ko, ml, mr, ms, my, nl, pt, ru, sw, ta, te, th, tl, tr, ur, vi, yo, and zh nlu.load() Refrence Spark NLP Refrence Annotator Class language en.embed.longformer longformer_base_4096 LongformerEmbeddings en en.embed.longformer.large longformer_large_4096 LongformerEmbeddings en en.ner.ontonotes_roberta_base ner_ontonotes_roberta_base NerDLModel en en.ner.ontonotes_roberta_large ner_ontonotes_roberta_large NerDLModel en en.ner.ontonotes_distilbert_base_cased ner_ontonotes_distilbert_base_cased NerDLModel en en.ner.conll_bert_base_cased ner_conll_bert_base_cased NerDLModel en en.ner.conll_distilbert_base_cased ner_conll_distilbert_base_cased NerDLModel en en.ner.conll_roberta_base ner_conll_roberta_base NerDLModel en en.ner.conll_roberta_large ner_conll_roberta_large NerDLModel en en.ner.conll_xlm_roberta_base ner_conll_xlm_roberta_base NerDLModel en en.ner.conll_longformer_large_4096 ner_conll_longformer_large_4096 NerDLModel en en.embed.token_bert.conll03 bert_base_token_classifier_conll03 NerDLModel en en.embed.token_bert.large_conll03 bert_large_token_classifier_conll03 NerDLModel en en.embed.token_bert.ontonote bert_base_token_classifier_ontonote NerDLModel en en.embed.token_bert.large_ontonote bert_large_token_classifier_ontonote NerDLModel en en.embed.token_bert.few_nerd bert_base_token_classifier_few_nerd NerDLModel en fa.embed.token_bert.parsbert_armanner bert_token_classifier_parsbert_armanner NerDLModel fa fa.embed.token_bert.parsbert_ner bert_token_classifier_parsbert_ner NerDLModel fa fa.embed.token_bert.parsbert_peymaner bert_token_classifier_parsbert_peymaner NerDLModel fa tr.embed.token_bert.turkish_ner bert_token_classifier_turkish_ner NerDLModel tr es.embed.token_bert.spanish_ner bert_token_classifier_spanish_ner NerDLModel es sv.embed.token_bert.swedish_ner bert_token_classifier_swedish_ner NerDLModel sv en.ner.fewnerd nerdl_fewnerd_100d NerDLModel en en.ner.fewnerd_subentity nerdl_fewnerd_subentity_100d NerDLModel en en.ner.movie ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.movie_complex ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.movie_simple ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.mit_movie_complex_bert ner_mit_movie_complex_bert_base_cased NerDLModel en en.ner.mit_movie_complex_distilbert ner_mit_movie_complex_distilbert_base_cased NerDLModel en en.ner.mit_movie_simple ner_mit_movie_simple_distilbert_base_cased NerDLModel en en.embed_sentence.bert_use_cmlm_en_base sent_bert_use_cmlm_en_base BertSentenceEmbeddings en en.embed_sentence.bert_use_cmlm_en_large sent_bert_use_cmlm_en_large BertSentenceEmbeddings en xx.ner.xtreme_glove_840B_300 ner_xtreme_glove_840B_300 NerDLModel xx xx.ner.xtreme_xlm_roberta_xtreme_base ner_xtreme_xlm_roberta_xtreme_base NerDLModel xx xx.ner.wikiner_glove_840B_300 ner_wikiner_glove_840B_300 NerDLModel xx xx.ner.wikiner_xlm_roberta_base ner_wikiner_xlm_roberta_base NerDLModel xx xx.embed_sentence.bert_use_cmlm_multi_base_br sent_bert_use_cmlm_multi_base_br BertSentenceEmbeddings xx xx.embed_sentence.bert_use_cmlm_multi_base sent_bert_use_cmlm_multi_base BertSentenceEmbeddings xx xx.embed.xlm_roberta_xtreme_base xlm_roberta_xtreme_base XlmRoBertaEmbeddings xx xx.embed.bert_base_multilingual_cased bert_base_multilingual_cased Embeddings xx xx.embed.bert_base_multilingual_uncased bert_base_multilingual_uncased Embeddings xx xx.af.translate_to.ru opus_tatoeba_af_ru Translation xx xx.he.translate_to.fr opus_tatoeba_he_fr Translation xx xx.it.translate_to.he opus_tatoeba_it_he Translation xx xx.cs.translate_to.sv opus_mt_cs_sv Translation xx tr.classify.cyberbullying classifierdl_berturk_cyberbullying Pipelines tr zh.embed.xlnet chinese_xlnet_base Embeddings zh de.classify.news classifierdl_bert_news Pipelines de tr.classify.berturk_cyberbullying classifierdl_berturk_cyberbullying_pipeline Pipelines tr de.classify.bert_news classifierdl_bert_news_pipeline Pipelines de en.classify.electra_questionpair classifierdl_electra_questionpair_pipeline Pipelines en tr.classify.bert_news classifierdl_bert_news_pipeline Pipelines tr en.ner.conll_elmo ner_conll_elmo NerDLModel en en.ner.conll_albert_base_uncased ner_conll_albert_base_uncased NerDLModel en en.ner.conll_albert_large_uncased ner_conll_albert_large_uncased NerDLModel en en.ner.conll_xlnet_base_cased ner_conll_xlnet_base_cased NerDLModel en xx.embed.bert.muril bert_muril BertEmbeddings xx en.embed.bert.wiki_books_sst2 bert_wiki_books_sst2 BertEmbeddings en en.embed.bert.wiki_books_squad2 bert_wiki_books_squad2 BertEmbeddings en en.embed.bert.wiki_books_qqp bert_wiki_books_qqp BertEmbeddings en en.embed.bert.wiki_books_qnli bert_wiki_books_qnli BertEmbeddings en en.embed.bert.wiki_books_mnli bert_wiki_books_mnli BertEmbeddings en en.embed.bert.wiki_books bert_wiki_books BertEmbeddings en en.embed.bert.pubmed_squad2 bert_pubmed_squad2 BertEmbeddings en en.embed.bert.pubmed bert_pubmed BertEmbeddings en en.embed_sentence.bert.wiki_books_sst2 sent_bert_wiki_books_sst2 BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_squad2 sent_bert_wiki_books_squad2 BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_qqp sent_bert_wiki_books_qqp BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_qnli sent_bert_wiki_books_qnli BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books_mnli sent_bert_wiki_books_mnli BertSentenceEmbeddings en en.embed_sentence.bert.wiki_books sent_bert_wiki_books BertSentenceEmbeddings en en.embed_sentence.bert.pubmed_squad2 sent_bert_pubmed_squad2 BertSentenceEmbeddings en en.embed_sentence.bert.pubmed sent_bert_pubmed BertSentenceEmbeddings en xx.embed_sentence.bert.muril sent_bert_muril BertSentenceEmbeddings xx yi.detect_sentence sentence_detector_dl SentenceDetectorDLModel yi uk.detect_sentence sentence_detector_dl SentenceDetectorDLModel uk te.detect_sentence sentence_detector_dl SentenceDetectorDLModel te ta.detect_sentence sentence_detector_dl SentenceDetectorDLModel ta so.detect_sentence sentence_detector_dl SentenceDetectorDLModel so sd.detect_sentence sentence_detector_dl SentenceDetectorDLModel sd ru.detect_sentence sentence_detector_dl SentenceDetectorDLModel ru pa.detect_sentence sentence_detector_dl SentenceDetectorDLModel pa ne.detect_sentence sentence_detector_dl SentenceDetectorDLModel ne mr.detect_sentence sentence_detector_dl SentenceDetectorDLModel mr ml.detect_sentence sentence_detector_dl SentenceDetectorDLModel ml kn.detect_sentence sentence_detector_dl SentenceDetectorDLModel kn bs.detect_sentence sentence_detector_dl SentenceDetectorDLModel bs id.detect_sentence sentence_detector_dl SentenceDetectorDLModel id gu.detect_sentence sentence_detector_dl SentenceDetectorDLModel gu New Healthcare Transformer Models 12 new models from the amazing Spark NLP for Healthcare 3.2.0+ releases, including models for genetic variants, radiology, assertion, rxnorm, adverse drugs and new clinical tokenbert models that improves accuracy by 4% compared to the previous models. nlu.load() Refrence Spark NLP Refrence Annotator Class en.med_ner.radiology.wip_greedy_biobert jsl_rd_ner_wip_greedy_biobert MedicalNerModel en.med_ner.genetic_variants ner_genetic_variants MedicalNerModel en.med_ner.jsl_slim ner_jsl_slim MedicalNerModel en.med_ner.jsl_greedy_biobert ner_jsl_greedy_biobert MedicalNerModel en.embed.token_bert.ner_clinical bert_token_classifier_ner_clinical MedicalNerModel en.embed.token_bert.ner_jsl bert_token_classifier_ner_jsl MedicalNerModel en.relation.ade redl_ade_biobert RelationExtractionDLModel en.relation.ade_clinical re_ade_clinical RelationExtractionDLModel en.relation.ade_biobert re_ade_biobert RelationExtractionDLModel en.resolve.rxnorm_disposition sbiobertresolve_rxnorm_disposition SentenceEntityResolverModel en.assert.jsl assertion_jsl AssertionDLModel en.assert.jsl_large assertion_jsl_large AssertionDLModel PyArrow Memory Optimizations Optimized integration with Pyarrow to share memory between the Python Virtual Machine and Java Virtual Machine which yields around 7% less memory consumption on average in all computations. This improvement will take effect for everyone using the default pyspark installation, which comes with a compatible Pyarrow Version. If you manually install or upgrade Pyarrow, please refer to the official Spark docs and make sure you have a Pyarrow version installed that works with your Pyspark version. New Notebooks Sentence Resolution Training Notebook Benchmark Notebook Bugfixes Fixed a bug that caused the similarity matrix calculations to generate NaNs and crash Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark streamlit==0.80.0` NLU Version 3.1.1 Sentence Embedding Visualizations, 20+ New Models, 2 New Trainable Models, Drug Normalizer and more in John Snow Labs NLU 3.1.1 We are very excited to announce NLU 3.1.1 has been released! It features a new Sentence Embedding visualization component for Streamlit which supports all 10+ previous dimension reduction techniques. Additionally, all embedding visualizations now support Latent Dirichlet Allocation for dimension reduction. Finally, 2 new trainable models for NER and chunk resolution are supported, a new drug normalizer algorithm has been added, 20+ new pre-trained models including Multi-Lingual, German, various healthcare models and improved NER defaults when using licensed models that have NER dependencies. Streamlit Sentence Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_sentence_embed_manifold Visualize Sentence Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 12 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlu references in the additional_classifiers_for_coloring parameter. You can also select additional classifiers via the GUI. Reduces Dimensionality of high dimensional Sentence Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Sentence Embedding models Color points by classifying with any of the 100+ Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots text= &quot;&quot;&quot;You can visualize any of the 100 + Sentence Embeddings with 10+ dimension reduction algorithms and view the results in 3D, 2D, and 1D which can be colored by various classifier labels! &quot;&quot;&quot; nlu.load(&#39;embed_sentence.bert&#39;).viz_streamlit_sentence_embed_manifold(text) function parameters pipe.viz_streamlit_sentence_embed_manifold | Argument | Type | Default |Description | |—————————-|————|———————————————————–|———————————————————| |default_texts| List[str] | (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) | List of strings to apply classifiers, embeddings, and manifolds to. | | text | Optional[str] | &#39;Billy likes to swim&#39; | Text to predict classes for. | |sub_title| Optional[str] | “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Sentence Embeddings to 1-D, 2-D and 3-D “ | Sub title of the Streamlit app | |default_algos_to_apply| List[str] | [&quot;TSNE&quot;, &quot;PCA&quot;] | A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;, | |target_dimensions| List[int] | (1,2,3) | Defines the target dimension embeddings will be reduced to | |show_algo_select| bool | True | Show selector for Manifold and Matrix Decomposition Algorithms | |show_embed_select| bool | True | Show selector for Embedding Selection | |show_color_select| bool | True | Show selector for coloring plots | |display_embed_information | bool | True | Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.| | set_wide_layout_CSS | bool | True | Whether to inject custom CSS or not.| |num_cols | int | 2 | How many columns should for the layout in streamlit when rendering the similarity matrixes.| | key | str | &quot;NLU_streamlit&quot; | Key for the Streamlit elements drawn | |additional_classifiers_for_coloring | List[str]|[&#39;sentiment.imdb&#39;] | List of additional NLU references to load for generting hue colors | | show_model_select | bool | True | Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click | | model_select_position | str | &#39;side&#39; | Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info | | show_logo | bool | True | Show logo | | display_infos | bool | False | Display additonal information about ISO codes and the NLU namespace structure.| | n_jobs | Optional[int] | 3| False | How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. | General Streamlit enhancements Support for Latent Dirichlet Allocation The Latent Dirichlet Allocation algorithm is now supported for the Word Embedding Visualizations and the Sentence Embedding Visualizations Normalization of Vectors before calculating sentence similarity. WordEmbedding vectors will now be normalized before calculating similarity scores, which bounds each similarity between 0 and 1 Control order of plots You can now control the order in Which visualizations appear in the main GUI Sentence Embedding Visualization Chunk Entity Resolver Training Chunk Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labeled with classes. These classes and strings are still ambigous though and it is not possible to group semantically identically entities without any definition of terminology. With the Chunk Resolver you can train a state-of-the-art deep learning architecture to map entities to their unique terminological representation. Train a chunk resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;] &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlu.load(&#39;train.resolve_chunks&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;]) entity_resolution_confidence entity_resolution_code entity_resolution document ‘1.0000’ ‘23’ ‘TESLA’ Peter told me to buy Tesla ‘1.0000’ ‘23’ ‘TESLA’ I have money to loose, is TSLA a good option? Train with default glove embeddings untrained_chunk_resolver = nlu.load(&#39;train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Train with custom embeddings # Use BIo GLove untrained_chunk_resolver = nlu.load(&#39;en.embed.glove.biovec train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule-based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with the following columns the possible matches. import nlu import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlu.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Drug Normalizer Drug Normalizer tutorial notebook Normalize raw text from clinical documents, e.g. scraped web pages or xml documents. Removes all dirty characters from text following one or more input regex patterns. Can apply unwanted character removal which a specific policy. Can apply lower case normalization. Parameters are lowercase: whether to convert strings to lowercase. Default is False. policy: rule to remove patterns from text. Valid policy values are: all abbreviations, dosages Defaults is all. abbreviation policy used to expend common drugs abbreviations, dosages policy used to convert drugs dosages and values to the standard form (see examples below). data = [&quot;Agnogenic one half cup&quot;,&quot;adalimumab 54.5 + 43.2 gm&quot;,&quot;aspirin 10 meq/ 5 ml oral sol&quot;,&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec&quot;,&quot;Sodium Chloride/Potassium Chloride 13bag&quot;] nlu.load(&#39;norm_drugs&#39;).predict(data) drug_norm text Agnogenic 0.5 oral solution Agnogenic one half cup adalimumab 97700 mg adalimumab 54.5 + 43.2 gm aspirin 2 meq/ml oral solution aspirin 10 meq/ 5 ml oral sol interferon alfa - 2b 10000000 unt ( 1 ml ) injection interferon alfa-2b 10 million unit ( 1 ml ) injec Sodium Chloride / Potassium Chloride 13 bag Sodium Chloride/Potassium Chloride 13bag New NLU Spells These new magical 1-liners which get new the folowing models Open Source NLU Spells NLU Spell Spark NLP Model nlu.load(‘de.ner.wikiner.6B_100’) wikiner_6B_100 nlu.load(‘xx.embed.glove.glove_6B_100’) glove_6B_100 Healthcare NLU spells NLU Spell Spark NLP Model nlu.load(‘en.resolve.snomed_body_structure_med’) sbertresolve_snomed_bodyStructure_med nlu.load(‘en.resolve.snomed_body_structure’) sbiobertresolve_snomed_bodyStructure nlu.load(‘en.resolve.icdo_augmented’) sbiobertresolve_icdo_augmented nlu.load(‘en.embed_sentence.biobert.jsl_cased’) sbiobert_jsl_cased nlu.load(‘en.embed_sentence.biobert.jsl_umls_cased’) sbiobert_jsl_umls_cased nlu.load(‘en.embed_sentence.bert.jsl_medium_uncased’) sbert_jsl_medium_uncased nlu.load(‘en.embed_sentence.bert.jsl_medium_umls_uncased’) sbert_jsl_medium_umls_uncased nlu.load(‘en.embed_sentence.bert.jsl_mini_uncased’) sbert_jsl_mini_uncased nlu.load(‘en.embed_sentence.bert.jsl_mini_umlsuncased’) sbert_jsl_mini_umls_uncasedjsl_tiny_uncased nlu.load(‘en.embed_sentence.bert.jsl_tiny_uncased’) sbert_jsl_tiny_uncased nlu.load(‘en.embed_sentence.bert.jsl_tiny_umls_uncased’) sbert_jsl_tiny_umls_uncased nlu.load(‘en.resolve.icd10cm.slim_billable_hcc’) sbiobertresolve_icd10cm_slim_billable_hcc nlu.load(‘en.resolve.icd10cm.slim_billable_hcc_med’) sbertresolve_icd10cm_slim_billable_hcc_med nlu.load(‘med_ner.deid.generic_augmented’) ner_deid_generic_augmented nlu.load(‘med_ner.deid.subentity_augmented’) ner_deid_subentity_augmented nlu.load(‘en.assert.radiology’) assertion_dl_radiology nlu.load(‘en.relation.test_result_date’) re_test_result_date nlu.load(‘en.med_ner.admission_events’) ner_events_admission_clinical nlu.load(‘en.classify.ade.clinicalbert’) classifierdl_ade_clinicalbert nlu.load(‘en.recognize_entities.posology’) recognize_entities_posology nlu.load(‘en.embed_sentence.bluebert_cased_mli’) spark_name Improved NER defaults When loading licensed models that require a NER features like Assertion, Relation, Resolution, nlu will now use the en.med_ner model which maps to the Spark NLP model jsl_ner_wip_clinical as default. See https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html for more infos on this model. New Notebooks Rule based NER with context matching tutorial notebook Drug Normalizer tutorial notebook Generic Deep Learning Tensorflow Classifier Additional NLU ressources 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 4000+ models &amp; pipelines in 200+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 NLU Version 3.1.0 2600+ New Models for 200+ Languages and 10+ Dimension Reduction Algorithms for Streamlit Word-Embedding visualizations in 3-D We are extremely excited to announce the release of NLU 3.1 ! This is our biggest release so far and it comes with over 2600+ new models in 200+ languages, including DistilBERT, RoBERTa, and XLM-RoBERTa and Huggingface based Embeddings from the incredible Spark-NLP 3.1.0 release, new Streamlit Visualizations for visualizing Word Embeddings in 3-D, 2-D, and 1-D, New Healthcare pipelines for healthcare code mappings and finally confidence extraction for open source NER models. Additionally, the NLU Namespace has been renamed to the NLU Spellbook, to reflect the magicalness of each 1-liners represented by them! Streamlit Word Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_word_embed_manifold Visualize Word Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 11 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms. Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlu references in the additional_classifiers_for_coloring parameter. Reduces Dimensionality of high dimensional Word Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Word Embedding models Color points by classifying with any of the 100+ Parts of Speech Classifiers or Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlu.load(&#39;bert&#39;,verbose=True).viz_streamlit_word_embed_manifold(default_texts=THE_MATRIX_ARCHITECT_SCRIPT.split(&#39; n&#39;),default_algos_to_apply=[&#39;TSNE&#39;],MAX_DISPLAY_NUM=5) function parameters pipe.viz_streamlit_word_embed_manifold Argument Type Default Description default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to. text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for. sub_title Optional[str] Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Word Embeddings to 1-D, 2-D and 3-D Sub title of the Streamlit app default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39; target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms show_embed_select bool True Show selector for Embedding Selection show_color_select bool True Show selector for coloring plots MAX_DISPLAY_NUM int 100 Cap maximum number of Tokens displayed display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. set_wide_layout_CSS bool True Whether to inject custom CSS or not. num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn additional_classifiers_for_coloring List[str] [&#39;pos&#39;, &#39;sentiment.imdb&#39;] List of additional NLU references to load for generting hue colors show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. n_jobs Optional[int] False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Larger Example showcasing more dimension reduction techniques on a larger corpus : Supported Manifold Algorithms TSNE ISOMAP LLE Spectral Embedding MDS Supported Matrix Decomposition Algorithms PCA Truncated SVD aka LSA DictionaryLearning FactorAnalysis FastICA KernelPCA New Healthcare Pipelines Five new healthcare code mapping pipelines: nlu.load(en.resolve.icd10cm.umls): This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;icd10cm&#39;: [&#39;M89.50&#39;, &#39;R82.2&#39;, &#39;R09.01&#39;],&#39;umls&#39;: [&#39;C4721411&#39;, &#39;C0159076&#39;, &#39;C0004044&#39;]} nlu.load(en.resolve.mesh.umls): This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;mesh&#39;: [&#39;C028491&#39;, &#39;D019326&#39;, &#39;C579867&#39;],&#39;umls&#39;: [&#39;C0970275&#39;, &#39;C0886627&#39;, &#39;C3696376&#39;]} nlu.load(en.resolve.rxnorm.umls): This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1161611&#39;, &#39;315677&#39;, &#39;343663&#39;],&#39;umls&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;, &#39;C1146501&#39;]} nlu.load(en.resolve.rxnorm.mesh): This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1191&#39;, &#39;6809&#39;, &#39;47613&#39;],&#39;mesh&#39;: [&#39;D001241&#39;, &#39;D008687&#39;, &#39;D019355&#39;]} nlu.load(en.resolve.snomed.umls): This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;snomed&#39;: [&#39;733187009&#39;, &#39;449433008&#39;, &#39;51264003&#39;],&#39;umls&#39;: [&#39;C4546029&#39;, &#39;C3164619&#39;, &#39;C0271267&#39;]} In the following table the NLU and Spark-NLP references are listed: NLU Reference Spark NLP Reference en.resolve.icd10cm.umls icd10cm_umls_mapping en.resolve.mesh.umls mesh_umls_mapping en.resolve.rxnorm.umls rxnorm_umls_mapping en.resolve.rxnorm.mesh rxnorm_mesh_mapping en.resolve.snomed.umls snomed_umls_mapping en.explain_doc.carp explain_clinical_doc_carp en.explain_doc.era explain_clinical_doc_era New Open Source Models and Pipelines nlu.load() Refrence Spark NLP Refrence en.embed.distilbert distilbert_base_cased en.embed.distilbert.base distilbert_base_cased en.embed.distilbert.base.uncased distilbert_base_uncased en.embed.distilroberta distilroberta_base en.embed.roberta roberta_base en.embed.roberta.base roberta_base en.embed.roberta.large roberta_large xx.marian opus_mt_en_fr xx.embed.distilbert. distilbert_base_multilingual_cased xx.embed.xlm xlm_roberta_base xx.embed.xlm.base xlm_roberta_base xx.embed.xlm.twitter twitter_xlm_roberta_base zh.embed.bert bert_base_chinese zh.embed.bert.wwm chinese_bert_wwm de.embed.bert bert_base_german_cased de.embed.bert.uncased bert_base_german_uncased nl.embed.bert bert_base_dutch_cased it.embed.bert bert_base_italian_cased tr.embed.bert bert_base_turkish_cased tr.embed.bert.uncased bert_base_turkish_uncased xx.fr.marian.translate_to.bcl opus_mt_bcl_fr xx.tr.marian.translate_to.ar opus_mt_ar_tr xx.sv.marian.translate_to.af opus_mt_af_sv xx.de.marian.translate_to.ar opus_mt_ar_de xx.fr.marian.translate_to.bi opus_mt_bi_fr xx.es.marian.translate_to.bi opus_mt_bi_es xx.fi.marian.translate_to.af opus_mt_af_fi xx.fi.marian.translate_to.crs opus_mt_crs_fi xx.fi.marian.translate_to.bem opus_mt_bem_fi xx.sv.marian.translate_to.bem opus_mt_bem_sv xx.it.marian.translate_to.ca opus_mt_ca_it xx.fr.marian.translate_to.ca opus_mt_ca_fr xx.es.marian.translate_to.bcl opus_mt_bcl_es xx.uk.marian.translate_to.ca opus_mt_ca_uk xx.fr.marian.translate_to.bem opus_mt_bem_fr xx.de.marian.translate_to.af opus_mt_af_de xx.nl.marian.translate_to.af opus_mt_af_nl xx.fr.marian.translate_to.ase opus_mt_ase_fr xx.es.marian.translate_to.az opus_mt_az_es xx.es.marian.translate_to.chk opus_mt_chk_es xx.sv.marian.translate_to.ceb opus_mt_ceb_sv xx.es.marian.translate_to.ceb opus_mt_ceb_es xx.es.marian.translate_to.aed opus_mt_aed_es xx.pl.marian.translate_to.ar opus_mt_ar_pl xx.es.marian.translate_to.bem opus_mt_bem_es xx.eo.marian.translate_to.af opus_mt_af_eo xx.fr.marian.translate_to.cs opus_mt_cs_fr xx.fi.marian.translate_to.bcl opus_mt_bcl_fi xx.es.marian.translate_to.crs opus_mt_crs_es xx.sv.marian.translate_to.bi opus_mt_bi_sv xx.de.marian.translate_to.bg opus_mt_bg_de xx.ru.marian.translate_to.ar opus_mt_ar_ru xx.es.marian.translate_to.bg opus_mt_bg_es xx.uk.marian.translate_to.cs opus_mt_cs_uk xx.sv.marian.translate_to.bzs opus_mt_bzs_sv xx.es.marian.translate_to.be opus_mt_be_es xx.es.marian.translate_to.bzs opus_mt_bzs_es xx.fr.marian.translate_to.af opus_mt_af_fr xx.pt.marian.translate_to.ca opus_mt_ca_pt xx.fr.marian.translate_to.chk opus_mt_chk_fr xx.de.marian.translate_to.ase opus_mt_ase_de xx.it.marian.translate_to.ar opus_mt_ar_it xx.fi.marian.translate_to.ceb opus_mt_ceb_fi xx.cpp.marian.translate_to.cpp opus_mt_cpp_cpp xx.fr.marian.translate_to.ber opus_mt_ber_fr xx.ru.marian.translate_to.bg opus_mt_bg_ru xx.es.marian.translate_to.ase opus_mt_ase_es xx.es.marian.translate_to.af opus_mt_af_es xx.it.marian.translate_to.bg opus_mt_bg_it xx.sv.marian.translate_to.am opus_mt_am_sv xx.eo.marian.translate_to.ar opus_mt_ar_eo xx.fr.marian.translate_to.ceb opus_mt_ceb_fr xx.es.marian.translate_to.ca opus_mt_ca_es xx.fi.marian.translate_to.bzs opus_mt_bzs_fi xx.de.marian.translate_to.crs opus_mt_crs_de xx.fi.marian.translate_to.cs opus_mt_cs_fi xx.afa.marian.translate_to.afa opus_mt_afa_afa xx.sv.marian.translate_to.bg opus_mt_bg_sv xx.tr.marian.translate_to.bg opus_mt_bg_tr xx.fr.marian.translate_to.crs opus_mt_crs_fr xx.sv.marian.translate_to.ase opus_mt_ase_sv xx.de.marian.translate_to.cs opus_mt_cs_de xx.eo.marian.translate_to.cs opus_mt_cs_eo xx.sv.marian.translate_to.chk opus_mt_chk_sv xx.sv.marian.translate_to.bcl opus_mt_bcl_sv xx.fr.marian.translate_to.ar opus_mt_ar_fr xx.ru.marian.translate_to.af opus_mt_af_ru xx.he.marian.translate_to.ar opus_mt_ar_he xx.fi.marian.translate_to.bg opus_mt_bg_fi xx.es.marian.translate_to.ber opus_mt_ber_es xx.es.marian.translate_to.ar opus_mt_ar_es xx.uk.marian.translate_to.bg opus_mt_bg_uk xx.fr.marian.translate_to.bzs opus_mt_bzs_fr xx.el.marian.translate_to.ar opus_mt_ar_el xx.nl.marian.translate_to.ca opus_mt_ca_nl xx.de.marian.translate_to.bcl opus_mt_bcl_de xx.eo.marian.translate_to.bg opus_mt_bg_eo xx.de.marian.translate_to.efi opus_mt_efi_de xx.bzs.marian.translate_to.de opus_mt_de_bzs xx.fj.marian.translate_to.de opus_mt_de_fj xx.fi.marian.translate_to.da opus_mt_da_fi xx.no.marian.translate_to.da opus_mt_da_no xx.cs.marian.translate_to.de opus_mt_de_cs xx.efi.marian.translate_to.de opus_mt_de_efi xx.gil.marian.translate_to.de opus_mt_de_gil xx.bcl.marian.translate_to.de opus_mt_de_bcl xx.pag.marian.translate_to.de opus_mt_de_pag xx.kg.marian.translate_to.de opus_mt_de_kg xx.fi.marian.translate_to.efi opus_mt_efi_fi xx.is.marian.translate_to.de opus_mt_de_is xx.fr.marian.translate_to.da opus_mt_da_fr xx.pl.marian.translate_to.de opus_mt_de_pl xx.ln.marian.translate_to.de opus_mt_de_ln xx.pap.marian.translate_to.de opus_mt_de_pap xx.vi.marian.translate_to.de opus_mt_de_vi xx.no.marian.translate_to.de opus_mt_de_no xx.eo.marian.translate_to.el opus_mt_el_eo xx.af.marian.translate_to.de opus_mt_de_af xx.es.marian.translate_to.ee opus_mt_ee_es xx.eo.marian.translate_to.de opus_mt_de_eo xx.bi.marian.translate_to.de opus_mt_de_bi xx.mt.marian.translate_to.de opus_mt_de_mt xx.lt.marian.translate_to.de opus_mt_de_lt xx.bg.marian.translate_to.de opus_mt_de_bg xx.hil.marian.translate_to.de opus_mt_de_hil xx.eu.marian.translate_to.de opus_mt_de_eu xx.da.marian.translate_to.de opus_mt_de_da xx.ms.marian.translate_to.de opus_mt_de_ms xx.he.marian.translate_to.de opus_mt_de_he xx.et.marian.translate_to.de opus_mt_de_et xx.es.marian.translate_to.de opus_mt_de_es xx.fr.marian.translate_to.el opus_mt_el_fr xx.fr.marian.translate_to.ee opus_mt_ee_fr xx.el.marian.translate_to.de opus_mt_de_el xx.sv.marian.translate_to.el opus_mt_el_sv xx.es.marian.translate_to.csn opus_mt_csn_es xx.tl.marian.translate_to.de opus_mt_de_tl xx.pon.marian.translate_to.de opus_mt_de_pon xx.fr.marian.translate_to.efi opus_mt_efi_fr xx.uk.marian.translate_to.de opus_mt_de_uk xx.ar.marian.translate_to.el opus_mt_el_ar xx.fi.marian.translate_to.el opus_mt_el_fi xx.ig.marian.translate_to.de opus_mt_de_ig xx.guw.marian.translate_to.de opus_mt_de_guw xx.iso.marian.translate_to.de opus_mt_de_iso xx.sv.marian.translate_to.efi opus_mt_efi_sv xx.ha.marian.translate_to.de opus_mt_de_ha xx.fr.marian.translate_to.de opus_mt_de_fr xx.gaa.marian.translate_to.de opus_mt_de_gaa xx.nso.marian.translate_to.de opus_mt_de_nso xx.ht.marian.translate_to.de opus_mt_de_ht xx.nl.marian.translate_to.de opus_mt_de_nl xx.sv.marian.translate_to.ee opus_mt_ee_sv xx.fi.marian.translate_to.ee opus_mt_ee_fi xx.de.marian.translate_to.ee opus_mt_ee_de xx.eo.marian.translate_to.da opus_mt_da_eo xx.es.marian.translate_to.csg opus_mt_csg_es xx.de.marian.translate_to.da opus_mt_da_de xx.ar.marian.translate_to.de opus_mt_de_ar xx.hu.marian.translate_to.de opus_mt_de_hu xx.ca.marian.translate_to.de opus_mt_de_ca xx.pis.marian.translate_to.de opus_mt_de_pis xx.ho.marian.translate_to.de opus_mt_de_ho xx.de.marian.translate_to.de opus_mt_de_de xx.lua.marian.translate_to.de opus_mt_de_lua xx.loz.marian.translate_to.de opus_mt_de_loz xx.crs.marian.translate_to.de opus_mt_de_crs xx.es.marian.translate_to.da opus_mt_da_es xx.ee.marian.translate_to.de opus_mt_de_ee xx.it.marian.translate_to.de opus_mt_de_it xx.ilo.marian.translate_to.de opus_mt_de_ilo xx.ny.marian.translate_to.de opus_mt_de_ny xx.fi.marian.translate_to.de opus_mt_de_fi xx.ase.marian.translate_to.de opus_mt_de_ase xx.hr.marian.translate_to.de opus_mt_de_hr xx.sl.marian.translate_to.fi opus_mt_fi_sl xx.sk.marian.translate_to.fi opus_mt_fi_sk xx.ru.marian.translate_to.es opus_mt_es_ru xx.sn.marian.translate_to.fi opus_mt_fi_sn xx.pl.marian.translate_to.eo opus_mt_eo_pl xx.cs.marian.translate_to.es opus_mt_es_cs xx.wls.marian.translate_to.fi opus_mt_fi_wls xx.gaa.marian.translate_to.fi opus_mt_fi_gaa xx.is.marian.translate_to.fi opus_mt_fi_is xx.ha.marian.translate_to.es opus_mt_es_ha xx.nl.marian.translate_to.es opus_mt_es_nl xx.ha.marian.translate_to.fi opus_mt_fi_ha xx.fj.marian.translate_to.fi opus_mt_fi_fj xx.ber.marian.translate_to.es opus_mt_es_ber xx.ho.marian.translate_to.fi opus_mt_fi_ho xx.ny.marian.translate_to.fi opus_mt_fi_ny xx.sl.marian.translate_to.es opus_mt_es_sl xx.ts.marian.translate_to.fi opus_mt_fi_ts xx.el.marian.translate_to.eo opus_mt_eo_el xx.war.marian.translate_to.fi opus_mt_fi_war xx.cs.marian.translate_to.fi opus_mt_fi_cs xx.loz.marian.translate_to.es opus_mt_es_loz xx.mk.marian.translate_to.fi opus_mt_fi_mk xx.bg.marian.translate_to.es opus_mt_es_bg xx.srn.marian.translate_to.fi opus_mt_fi_srn xx.is.marian.translate_to.es opus_mt_es_is xx.hu.marian.translate_to.eo opus_mt_eo_hu xx.tw.marian.translate_to.fi opus_mt_fi_tw xx.mt.marian.translate_to.fi opus_mt_fi_mt xx.fr.marian.translate_to.es opus_mt_es_fr xx.yo.marian.translate_to.es opus_mt_es_yo xx.xh.marian.translate_to.fi opus_mt_fi_xh xx.lv.marian.translate_to.fi opus_mt_fi_lv xx.de.marian.translate_to.fi opus_mt_fi_de xx.ve.marian.translate_to.es opus_mt_es_ve xx.es.marian.translate_to.fi opus_mt_fi_es xx.eo.marian.translate_to.es opus_mt_es_eo xx.cs.marian.translate_to.eo opus_mt_eo_cs xx.mt.marian.translate_to.es opus_mt_es_mt xx.el.marian.translate_to.es opus_mt_es_el xx.ee.marian.translate_to.es opus_mt_es_ee xx.de.marian.translate_to.eu opus_mt_eu_de xx.et.marian.translate_to.es opus_mt_es_et xx.fi.marian.translate_to.et opus_mt_et_fi xx.wls.marian.translate_to.es opus_mt_es_wls xx.mg.marian.translate_to.fi opus_mt_fi_mg xx.eu.marian.translate_to.es opus_mt_es_eu xx.lua.marian.translate_to.es opus_mt_es_lua xx.pon.marian.translate_to.es opus_mt_es_pon xx.mfe.marian.translate_to.fi opus_mt_fi_mfe xx.he.marian.translate_to.eo opus_mt_eo_he xx.id.marian.translate_to.es opus_mt_es_id xx.xh.marian.translate_to.es opus_mt_es_xh xx.ar.marian.translate_to.es opus_mt_es_ar xx.crs.marian.translate_to.es opus_mt_es_crs xx.es.marian.translate_to.eu opus_mt_eu_es xx.tpi.marian.translate_to.fi opus_mt_fi_tpi xx.pis.marian.translate_to.fi opus_mt_fi_pis xx.vi.marian.translate_to.es opus_mt_es_vi xx.es.marian.translate_to.et opus_mt_et_es xx.rw.marian.translate_to.fi opus_mt_fi_rw xx.gl.marian.translate_to.es opus_mt_es_gl xx.pt.marian.translate_to.eo opus_mt_eo_pt xx.he.marian.translate_to.fi opus_mt_fi_he xx.af.marian.translate_to.fi opus_mt_fi_af xx.ru.marian.translate_to.fi opus_mt_fi_ru xx.ve.marian.translate_to.fi opus_mt_fi_ve xx.ca.marian.translate_to.es opus_mt_es_ca xx.tr.marian.translate_to.fi opus_mt_fi_tr xx.ht.marian.translate_to.fi opus_mt_fi_ht xx.nl.marian.translate_to.fi opus_mt_fi_nl xx.iso.marian.translate_to.fi opus_mt_fi_iso xx.fi.marian.translate_to.es opus_mt_es_fi xx.da.marian.translate_to.eo opus_mt_eo_da xx.ln.marian.translate_to.es opus_mt_es_ln xx.csn.marian.translate_to.es opus_mt_es_csn xx.pon.marian.translate_to.fi opus_mt_fi_pon xx.af.marian.translate_to.eo opus_mt_eo_af xx.bzs.marian.translate_to.fi opus_mt_fi_bzs xx.no.marian.translate_to.es opus_mt_es_no xx.es.marian.translate_to.es opus_mt_es_es xx.lua.marian.translate_to.fi opus_mt_fi_lua xx.yua.marian.translate_to.es opus_mt_es_yua xx.ru.marian.translate_to.eu opus_mt_eu_ru xx.tpi.marian.translate_to.es opus_mt_es_tpi xx.lue.marian.translate_to.fi opus_mt_fi_lue xx.sv.marian.translate_to.eo opus_mt_eo_sv xx.niu.marian.translate_to.es opus_mt_es_niu xx.tiv.marian.translate_to.fi opus_mt_fi_tiv xx.pag.marian.translate_to.es opus_mt_es_pag xx.run.marian.translate_to.fi opus_mt_fi_run xx.ty.marian.translate_to.es opus_mt_es_ty xx.gil.marian.translate_to.es opus_mt_es_gil xx.ln.marian.translate_to.fi opus_mt_fi_ln xx.ty.marian.translate_to.fi opus_mt_fi_ty xx.prl.marian.translate_to.es opus_mt_es_prl xx.kg.marian.translate_to.es opus_mt_es_kg xx.rw.marian.translate_to.es opus_mt_es_rw xx.kqn.marian.translate_to.fi opus_mt_fi_kqn xx.sq.marian.translate_to.fi opus_mt_fi_sq xx.sw.marian.translate_to.fi opus_mt_fi_sw xx.csg.marian.translate_to.es opus_mt_es_csg xx.ro.marian.translate_to.es opus_mt_es_ro xx.ee.marian.translate_to.fi opus_mt_fi_ee xx.ilo.marian.translate_to.fi opus_mt_fi_ilo xx.eo.marian.translate_to.fi opus_mt_fi_eo xx.iso.marian.translate_to.es opus_mt_es_iso xx.bem.marian.translate_to.fi opus_mt_fi_bem xx.tn.marian.translate_to.fi opus_mt_fi_tn xx.da.marian.translate_to.es opus_mt_es_da xx.es.marian.translate_to.eo opus_mt_eo_es xx.ru.marian.translate_to.eo opus_mt_eo_ru xx.rn.marian.translate_to.es opus_mt_es_rn xx.lt.marian.translate_to.es opus_mt_es_lt xx.guw.marian.translate_to.es opus_mt_es_guw xx.tvl.marian.translate_to.es opus_mt_es_tvl xx.fr.marian.translate_to.et opus_mt_et_fr xx.ht.marian.translate_to.es opus_mt_es_ht xx.mos.marian.translate_to.fi opus_mt_fi_mos xx.ase.marian.translate_to.es opus_mt_es_ase xx.crs.marian.translate_to.fi opus_mt_fi_crs xx.bcl.marian.translate_to.fi opus_mt_fi_bcl xx.tvl.marian.translate_to.fi opus_mt_fi_tvl xx.lus.marian.translate_to.fi opus_mt_fi_lus xx.he.marian.translate_to.es opus_mt_es_he xx.pis.marian.translate_to.es opus_mt_es_pis xx.it.marian.translate_to.es opus_mt_es_it xx.fi.marian.translate_to.eo opus_mt_eo_fi xx.tw.marian.translate_to.es opus_mt_es_tw xx.aed.marian.translate_to.es opus_mt_es_aed xx.bzs.marian.translate_to.es opus_mt_es_bzs xx.nso.marian.translate_to.fi opus_mt_fi_nso xx.gaa.marian.translate_to.es opus_mt_es_gaa xx.zai.marian.translate_to.es opus_mt_es_zai xx.no.marian.translate_to.fi opus_mt_fi_no xx.uk.marian.translate_to.fi opus_mt_fi_uk xx.sg.marian.translate_to.es opus_mt_es_sg xx.ilo.marian.translate_to.es opus_mt_es_ilo xx.bg.marian.translate_to.eo opus_mt_eo_bg xx.pap.marian.translate_to.fi opus_mt_fi_pap xx.ho.marian.translate_to.es opus_mt_es_ho xx.toi.marian.translate_to.fi opus_mt_fi_toi xx.st.marian.translate_to.es opus_mt_es_st xx.to.marian.translate_to.fi opus_mt_fi_to xx.kg.marian.translate_to.fi opus_mt_fi_kg xx.sv.marian.translate_to.fi opus_mt_fi_sv xx.tll.marian.translate_to.fi opus_mt_fi_tll xx.ceb.marian.translate_to.es opus_mt_es_ceb xx.ig.marian.translate_to.es opus_mt_es_ig xx.sv.marian.translate_to.et opus_mt_et_sv xx.af.marian.translate_to.es opus_mt_es_af xx.pl.marian.translate_to.es opus_mt_es_pl xx.ro.marian.translate_to.eo opus_mt_eo_ro xx.tn.marian.translate_to.es opus_mt_es_tn xx.sm.marian.translate_to.fi opus_mt_fi_sm xx.mk.marian.translate_to.es opus_mt_es_mk xx.id.marian.translate_to.fi opus_mt_fi_id xx.hr.marian.translate_to.fi opus_mt_fi_hr xx.sg.marian.translate_to.fi opus_mt_fi_sg xx.hil.marian.translate_to.fi opus_mt_fi_hil xx.nl.marian.translate_to.eo opus_mt_eo_nl xx.pap.marian.translate_to.es opus_mt_es_pap xx.fr.marian.translate_to.fi opus_mt_fi_fr xx.bi.marian.translate_to.es opus_mt_es_bi xx.fi.marian.translate_to.fi opus_mt_fi_fi xx.nso.marian.translate_to.es opus_mt_es_nso xx.et.marian.translate_to.fi opus_mt_fi_et xx.uk.marian.translate_to.es opus_mt_es_uk xx.sh.marian.translate_to.eo opus_mt_eo_sh xx.lu.marian.translate_to.fi opus_mt_fi_lu xx.gil.marian.translate_to.fi opus_mt_fi_gil xx.ro.marian.translate_to.fi opus_mt_fi_ro xx.it.marian.translate_to.eo opus_mt_eo_it xx.hu.marian.translate_to.fi opus_mt_fi_hu xx.bcl.marian.translate_to.es opus_mt_es_bcl xx.fse.marian.translate_to.fi opus_mt_fi_fse xx.hil.marian.translate_to.es opus_mt_es_hil xx.ig.marian.translate_to.fi opus_mt_fi_ig xx.tl.marian.translate_to.es opus_mt_es_tl xx.pag.marian.translate_to.fi opus_mt_fi_pag xx.guw.marian.translate_to.fi opus_mt_fi_guw xx.swc.marian.translate_to.es opus_mt_es_swc xx.swc.marian.translate_to.fi opus_mt_fi_swc xx.lg.marian.translate_to.fi opus_mt_fi_lg xx.srn.marian.translate_to.es opus_mt_es_srn xx.hr.marian.translate_to.es opus_mt_es_hr xx.sm.marian.translate_to.es opus_mt_es_sm xx.de.marian.translate_to.es opus_mt_es_de xx.st.marian.translate_to.fi opus_mt_fi_st xx.fr.marian.translate_to.eo opus_mt_eo_fr xx.de.marian.translate_to.et opus_mt_et_de xx.niu.marian.translate_to.fi opus_mt_fi_niu xx.el.marian.translate_to.fi opus_mt_fi_el xx.efi.marian.translate_to.fi opus_mt_fi_efi xx.war.marian.translate_to.es opus_mt_es_war xx.mfs.marian.translate_to.es opus_mt_es_mfs xx.bg.marian.translate_to.fi opus_mt_fi_bg xx.lus.marian.translate_to.es opus_mt_es_lus xx.de.marian.translate_to.eo opus_mt_eo_de xx.it.marian.translate_to.fi opus_mt_fi_it xx.efi.marian.translate_to.es opus_mt_es_efi xx.ny.marian.translate_to.es opus_mt_es_ny xx.fj.marian.translate_to.es opus_mt_es_fj xx.ru.marian.translate_to.et opus_mt_et_ru xx.mh.marian.translate_to.fi opus_mt_fi_mh xx.es.marian.translate_to.ig opus_mt_ig_es xx.sv.marian.translate_to.hu opus_mt_hu_sv xx.lue.marian.translate_to.fr opus_mt_fr_lue xx.fi.marian.translate_to.ha opus_mt_ha_fi xx.ca.marian.translate_to.it opus_mt_it_ca xx.de.marian.translate_to.ilo opus_mt_ilo_de xx.it.marian.translate_to.he opus_tatoeba_it_he xx.loz.marian.translate_to.fr opus_mt_fr_loz xx.ms.marian.translate_to.fr opus_mt_fr_ms xx.uk.marian.translate_to.it opus_mt_it_uk xx.gaa.marian.translate_to.fr opus_mt_fr_gaa xx.pap.marian.translate_to.fr opus_mt_fr_pap xx.fi.marian.translate_to.ilo opus_mt_ilo_fi xx.lg.marian.translate_to.fr opus_mt_fr_lg xx.it.marian.translate_to.is opus_mt_is_it xx.ms.marian.translate_to.it opus_mt_it_ms xx.es.marian.translate_to.fr opus_mt_fr_es xx.ar.marian.translate_to.he opus_mt_he_ar xx.ro.marian.translate_to.fr opus_mt_fr_ro xx.ru.marian.translate_to.fr opus_mt_fr_ru xx.fi.marian.translate_to.ht opus_mt_ht_fi xx.bg.marian.translate_to.it opus_mt_it_bg xx.mh.marian.translate_to.fr opus_mt_fr_mh xx.to.marian.translate_to.fr opus_mt_fr_to xx.sl.marian.translate_to.fr opus_mt_fr_sl xx.fr.marian.translate_to.gil opus_mt_gil_fr xx.es.marian.translate_to.hr opus_mt_hr_es xx.ilo.marian.translate_to.fr opus_mt_fr_ilo xx.ee.marian.translate_to.fr opus_mt_fr_ee xx.sv.marian.translate_to.he opus_mt_he_sv xx.fr.marian.translate_to.ha opus_mt_ha_fr xx.gil.marian.translate_to.fr opus_mt_fr_gil xx.fi.marian.translate_to.id opus_mt_id_fi xx.iir.marian.translate_to.iir opus_mt_iir_iir xx.pl.marian.translate_to.fr opus_mt_fr_pl xx.tw.marian.translate_to.fr opus_mt_fr_tw xx.sv.marian.translate_to.gaa opus_mt_gaa_sv xx.ar.marian.translate_to.it opus_mt_it_ar xx.es.marian.translate_to.gil opus_mt_gil_es xx.ase.marian.translate_to.fr opus_mt_fr_ase xx.fr.marian.translate_to.gaa opus_mt_gaa_fr xx.lus.marian.translate_to.fr opus_mt_fr_lus xx.fr.marian.translate_to.iso opus_mt_iso_fr xx.sm.marian.translate_to.fr opus_mt_fr_sm xx.mfe.marian.translate_to.fr opus_mt_fr_mfe xx.af.marian.translate_to.fr opus_mt_fr_af xx.de.marian.translate_to.ig opus_mt_ig_de xx.es.marian.translate_to.id opus_mt_id_es xx.kqn.marian.translate_to.fr opus_mt_fr_kqn xx.zne.marian.translate_to.fi opus_mt_fi_zne xx.rw.marian.translate_to.fr opus_mt_fr_rw xx.ny.marian.translate_to.fr opus_mt_fr_ny xx.ig.marian.translate_to.fr opus_mt_fr_ig xx.ur.marian.translate_to.hi opus_mt_hi_ur xx.lt.marian.translate_to.it opus_mt_it_lt xx.srn.marian.translate_to.fr opus_mt_fr_srn xx.tiv.marian.translate_to.fr opus_mt_fr_tiv xx.war.marian.translate_to.fr opus_mt_fr_war xx.fr.marian.translate_to.is opus_mt_is_fr xx.de.marian.translate_to.gaa opus_mt_gaa_de xx.kwy.marian.translate_to.fr opus_mt_fr_kwy xx.sv.marian.translate_to.gil opus_mt_gil_sv xx.hr.marian.translate_to.fr opus_mt_fr_hr xx.fr.marian.translate_to.ig opus_mt_ig_fr xx.sv.marian.translate_to.ht opus_mt_ht_sv xx.de.marian.translate_to.fr opus_mt_fr_de xx.fiu.marian.translate_to.fiu opus_mt_fiu_fiu xx.wls.marian.translate_to.fr opus_mt_fr_wls xx.eo.marian.translate_to.hu opus_mt_hu_eo xx.guw.marian.translate_to.fr opus_mt_fr_guw xx.de.marian.translate_to.is opus_mt_is_de xx.tvl.marian.translate_to.fr opus_mt_fr_tvl xx.zne.marian.translate_to.fr opus_mt_fr_zne xx.ha.marian.translate_to.fr opus_mt_fr_ha xx.fi.marian.translate_to.guw opus_mt_guw_fi xx.es.marian.translate_to.is opus_mt_is_es xx.sv.marian.translate_to.it opus_mt_it_sv xx.uk.marian.translate_to.fr opus_mt_fr_uk xx.uk.marian.translate_to.hu opus_mt_hu_uk xx.mt.marian.translate_to.fr opus_mt_fr_mt xx.gem.marian.translate_to.gem opus_mt_gem_gem xx.fr.marian.translate_to.fj opus_mt_fj_fr xx.fi.marian.translate_to.gil opus_mt_gil_fi xx.fr.marian.translate_to.hu opus_mt_hu_fr xx.bcl.marian.translate_to.fr opus_mt_fr_bcl xx.gmq.marian.translate_to.gmq opus_mt_gmq_gmq xx.kg.marian.translate_to.fr opus_mt_fr_kg xx.sn.marian.translate_to.fr opus_mt_fr_sn xx.bg.marian.translate_to.fr opus_mt_fr_bg xx.fr.marian.translate_to.guw opus_mt_guw_fr xx.ts.marian.translate_to.fr opus_mt_fr_ts xx.pis.marian.translate_to.fr opus_mt_fr_pis xx.bi.marian.translate_to.fr opus_mt_fr_bi xx.ln.marian.translate_to.fr opus_mt_fr_ln xx.de.marian.translate_to.hil opus_mt_hil_de xx.nso.marian.translate_to.fr opus_mt_fr_nso xx.es.marian.translate_to.iso opus_mt_iso_es xx.crs.marian.translate_to.fr opus_mt_fr_crs xx.niu.marian.translate_to.fr opus_mt_fr_niu xx.fr.marian.translate_to.ht opus_mt_ht_fr xx.fi.marian.translate_to.he opus_mt_he_fi xx.gmw.marian.translate_to.gmw opus_mt_gmw_gmw xx.fr.marian.translate_to.hr opus_mt_hr_fr xx.sg.marian.translate_to.fr opus_mt_fr_sg xx.pon.marian.translate_to.fr opus_mt_fr_pon xx.fi.marian.translate_to.gaa opus_mt_gaa_fi xx.pag.marian.translate_to.fr opus_mt_fr_pag xx.fi.marian.translate_to.is opus_mt_is_fi xx.sk.marian.translate_to.fr opus_mt_fr_sk xx.yap.marian.translate_to.fr opus_mt_fr_yap xx.es.marian.translate_to.ha opus_mt_ha_es xx.no.marian.translate_to.fr opus_mt_fr_no xx.ine.marian.translate_to.ine opus_mt_ine_ine xx.fr.marian.translate_to.id opus_mt_id_fr xx.bzs.marian.translate_to.fr opus_mt_fr_bzs xx.he.marian.translate_to.fr opus_tatoeba_he_fr xx.sv.marian.translate_to.fr opus_mt_fr_sv xx.uk.marian.translate_to.he opus_mt_he_uk xx.fr.marian.translate_to.it opus_mt_it_fr xx.fi.marian.translate_to.ig opus_mt_ig_fi xx.vi.marian.translate_to.fr opus_mt_fr_vi xx.fi.marian.translate_to.fse opus_mt_fse_fi xx.es.marian.translate_to.guw opus_mt_guw_es xx.tll.marian.translate_to.fr opus_mt_fr_tll xx.lua.marian.translate_to.fr opus_mt_fr_lua xx.yap.marian.translate_to.fi opus_mt_fi_yap xx.es.marian.translate_to.gaa opus_mt_gaa_es xx.sv.marian.translate_to.ig opus_mt_ig_sv xx.ht.marian.translate_to.fr opus_mt_fr_ht xx.el.marian.translate_to.fr opus_mt_fr_el xx.inc.marian.translate_to.inc opus_mt_inc_inc xx.swc.marian.translate_to.fr opus_mt_fr_swc xx.ar.marian.translate_to.fr opus_mt_fr_ar xx.es.marian.translate_to.ilo opus_mt_ilo_es xx.fi.marian.translate_to.hr opus_mt_hr_fi xx.tpi.marian.translate_to.fr opus_mt_fr_tpi xx.ve.marian.translate_to.fr opus_mt_fr_ve xx.sv.marian.translate_to.guw opus_mt_guw_sv xx.sv.marian.translate_to.iso opus_mt_iso_sv xx.sv.marian.translate_to.is opus_mt_is_sv xx.tum.marian.translate_to.fr opus_mt_fr_tum xx.es.marian.translate_to.ht opus_mt_ht_es xx.ho.marian.translate_to.fr opus_mt_fr_ho xx.efi.marian.translate_to.fr opus_mt_fr_efi xx.es.marian.translate_to.gl opus_mt_gl_es xx.ru.marian.translate_to.he opus_mt_he_ru xx.fi.marian.translate_to.hil opus_mt_hil_fi xx.eo.marian.translate_to.he opus_mt_he_eo xx.lu.marian.translate_to.fr opus_mt_fr_lu xx.sv.marian.translate_to.ha opus_mt_ha_sv xx.rnd.marian.translate_to.fr opus_mt_fr_rnd xx.st.marian.translate_to.fr opus_mt_fr_st xx.tl.marian.translate_to.fr opus_mt_fr_tl xx.bem.marian.translate_to.fr opus_mt_fr_bem xx.eo.marian.translate_to.is opus_mt_is_eo xx.is.marian.translate_to.it opus_mt_it_is xx.hu.marian.translate_to.fr opus_mt_fr_hu xx.yo.marian.translate_to.fi opus_mt_fi_yo xx.iso.marian.translate_to.fr opus_mt_fr_iso xx.de.marian.translate_to.it opus_mt_it_de xx.ty.marian.translate_to.fr opus_mt_fr_ty xx.hil.marian.translate_to.fr opus_mt_fr_hil xx.eo.marian.translate_to.it opus_mt_it_eo xx.sv.marian.translate_to.hr opus_mt_hr_sv xx.ber.marian.translate_to.fr opus_mt_fr_ber xx.de.marian.translate_to.guw opus_mt_guw_de xx.fi.marian.translate_to.hu opus_mt_hu_fi xx.es.marian.translate_to.it opus_mt_it_es xx.de.marian.translate_to.hu opus_mt_hu_de xx.fj.marian.translate_to.fr opus_mt_fr_fj xx.sv.marian.translate_to.id opus_mt_id_sv xx.xh.marian.translate_to.fr opus_mt_fr_xh xx.yo.marian.translate_to.fr opus_mt_fr_yo xx.ca.marian.translate_to.fr opus_mt_fr_ca xx.es.marian.translate_to.he opus_mt_he_es xx.de.marian.translate_to.he opus_mt_he_de xx.pt.marian.translate_to.gl opus_mt_gl_pt xx.ru.marian.translate_to.hy opus_mt_hy_ru xx.mos.marian.translate_to.fr opus_mt_fr_mos xx.ceb.marian.translate_to.fr opus_mt_fr_ceb xx.sh.marian.translate_to.ja opus_mt_ja_sh xx.bg.marian.translate_to.ja opus_mt_ja_bg xx.sv.marian.translate_to.ja opus_mt_ja_sv xx.ru.marian.translate_to.lv opus_mt_lv_ru xx.fr.marian.translate_to.ms opus_mt_ms_fr xx.sv.marian.translate_to.mt opus_mt_mt_sv xx.da.marian.translate_to.ja opus_mt_ja_da xx.de.marian.translate_to.niu opus_mt_niu_de xx.es.marian.translate_to.niu opus_mt_niu_es xx.sv.marian.translate_to.lus opus_mt_lus_sv xx.sv.marian.translate_to.lg opus_mt_lg_sv xx.sv.marian.translate_to.pon opus_mt_pon_sv xx.ru.marian.translate_to.lt opus_mt_lt_ru xx.fi.marian.translate_to.lg opus_mt_lg_fi xx.sv.marian.translate_to.kg opus_mt_kg_sv xx.fr.marian.translate_to.nl opus_mt_nl_fr xx.ms.marian.translate_to.ms opus_mt_ms_ms xx.es.marian.translate_to.lg opus_mt_lg_es xx.fr.marian.translate_to.lu opus_mt_lu_fr xx.fr.marian.translate_to.loz opus_mt_loz_fr xx.ca.marian.translate_to.nl opus_mt_nl_ca xx.sv.marian.translate_to.lue opus_mt_lue_sv xx.vi.marian.translate_to.ja opus_mt_ja_vi xx.fr.marian.translate_to.ja opus_mt_ja_fr xx.fi.marian.translate_to.pap opus_mt_pap_fi xx.pl.marian.translate_to.lt opus_mt_lt_pl xx.de.marian.translate_to.ny opus_mt_ny_de xx.fr.marian.translate_to.lue opus_mt_lue_fr xx.gl.marian.translate_to.pt opus_mt_pt_gl xx.fr.marian.translate_to.pap opus_mt_pap_fr xx.uk.marian.translate_to.pl opus_mt_pl_uk xx.fi.marian.translate_to.niu opus_mt_niu_fi xx.ar.marian.translate_to.ja opus_mt_ja_ar xx.es.marian.translate_to.mh opus_mt_mh_es xx.ar.marian.translate_to.pl opus_mt_pl_ar xx.de.marian.translate_to.pag opus_mt_pag_de xx.es.marian.translate_to.no opus_mt_no_es xx.es.marian.translate_to.mfs opus_mt_mfs_es xx.fr.marian.translate_to.pis opus_mt_pis_fr xx.eo.marian.translate_to.pt opus_mt_pt_eo xx.de.marian.translate_to.lt opus_mt_lt_de xx.fr.marian.translate_to.ln opus_mt_ln_fr xx.es.marian.translate_to.pag opus_mt_pag_es xx.fi.marian.translate_to.nl opus_mt_nl_fi xx.vi.marian.translate_to.it opus_mt_it_vi xx.fi.marian.translate_to.ko opus_mt_ko_fi xx.de.marian.translate_to.nso opus_mt_nso_de xx.fr.marian.translate_to.niu opus_mt_niu_fr xx.ca.marian.translate_to.pt opus_mt_pt_ca xx.fr.marian.translate_to.kwy opus_mt_kwy_fr xx.ru.marian.translate_to.no opus_mt_no_ru xx.fi.marian.translate_to.pon opus_mt_pon_fi xx.fi.marian.translate_to.lu opus_mt_lu_fi xx.es.marian.translate_to.ko opus_mt_ko_es xx.es.marian.translate_to.ny opus_mt_ny_es xx.itc.marian.translate_to.itc opus_mt_itc_itc xx.es.marian.translate_to.ja opus_mt_ja_es xx.fr.marian.translate_to.mk opus_mt_mk_fr xx.it.marian.translate_to.ms opus_mt_ms_it xx.sv.marian.translate_to.lu opus_mt_lu_sv xx.fr.marian.translate_to.nso opus_mt_nso_fr xx.uk.marian.translate_to.pt opus_mt_pt_uk xx.no.marian.translate_to.no opus_mt_no_no xx.sv.marian.translate_to.lua opus_mt_lua_sv xx.es.marian.translate_to.pl opus_mt_pl_es xx.es.marian.translate_to.lu opus_mt_lu_es xx.fr.marian.translate_to.lus opus_mt_lus_fr xx.tr.marian.translate_to.ja opus_mt_ja_tr xx.fi.marian.translate_to.pag opus_mt_pag_fi xx.fr.marian.translate_to.kqn opus_mt_kqn_fr xx.fi.marian.translate_to.ja opus_mt_ja_fi xx.af.marian.translate_to.nl opus_mt_nl_af xx.sv.marian.translate_to.pag opus_mt_pag_sv xx.sv.marian.translate_to.nl opus_mt_nl_sv xx.uk.marian.translate_to.no opus_mt_no_uk xx.es.marian.translate_to.lua opus_mt_lua_es xx.fi.marian.translate_to.mt opus_mt_mt_fi xx.eo.marian.translate_to.lt opus_mt_lt_eo xx.de.marian.translate_to.no opus_mt_no_de xx.eo.marian.translate_to.pl opus_mt_pl_eo xx.es.marian.translate_to.loz opus_mt_loz_es xx.ru.marian.translate_to.ja opus_mt_ja_ru xx.sv.marian.translate_to.pl opus_mt_pl_sv xx.fi.marian.translate_to.mh opus_mt_mh_fi xx.hu.marian.translate_to.ja opus_mt_ja_hu xx.fi.marian.translate_to.mk opus_mt_mk_fi xx.es.marian.translate_to.lue opus_mt_lue_es xx.sv.marian.translate_to.lt opus_mt_lt_sv xx.fr.marian.translate_to.pon opus_mt_pon_fr xx.es.marian.translate_to.pap opus_mt_pap_es xx.es.marian.translate_to.ln opus_mt_ln_es xx.de.marian.translate_to.loz opus_mt_loz_de xx.ru.marian.translate_to.ka opus_mt_ka_ru xx.sv.marian.translate_to.kwy opus_mt_kwy_sv xx.fi.marian.translate_to.lv opus_mt_lv_fi xx.pl.marian.translate_to.ja opus_mt_ja_pl xx.hu.marian.translate_to.ko opus_mt_ko_hu xx.de.marian.translate_to.ja opus_mt_ja_de xx.de.marian.translate_to.ko opus_mt_ko_de xx.es.marian.translate_to.kg opus_mt_kg_es xx.de.marian.translate_to.pap opus_mt_pap_de xx.fi.marian.translate_to.no opus_mt_no_fi xx.fi.marian.translate_to.lue opus_mt_lue_fi xx.no.marian.translate_to.pl opus_mt_pl_no xx.fr.marian.translate_to.mt opus_mt_mt_fr xx.es.marian.translate_to.mg opus_mt_mg_es xx.es.marian.translate_to.pis opus_mt_pis_es xx.fr.marian.translate_to.pl opus_mt_pl_fr xx.sv.marian.translate_to.ko opus_mt_ko_sv xx.sv.marian.translate_to.loz opus_mt_loz_sv xx.fi.marian.translate_to.loz opus_mt_loz_fi xx.pl.marian.translate_to.no opus_mt_no_pl xx.nl.marian.translate_to.ja opus_mt_ja_nl xx.de.marian.translate_to.pl opus_mt_pl_de xx.lt.marian.translate_to.pl opus_mt_pl_lt xx.ru.marian.translate_to.ko opus_mt_ko_ru xx.fr.marian.translate_to.lv opus_mt_lv_fr xx.he.marian.translate_to.ja opus_mt_ja_he xx.sv.marian.translate_to.niu opus_mt_niu_sv xx.de.marian.translate_to.ms opus_mt_ms_de xx.es.marian.translate_to.lt opus_mt_lt_es xx.sv.marian.translate_to.no opus_mt_no_sv xx.nl.marian.translate_to.no opus_mt_no_nl xx.fi.marian.translate_to.lua opus_mt_lua_fi xx.fr.marian.translate_to.lt opus_mt_lt_fr xx.ms.marian.translate_to.ja opus_mt_ja_ms xx.es.marian.translate_to.kqn opus_mt_kqn_es xx.fr.marian.translate_to.lg opus_mt_lg_fr xx.es.marian.translate_to.mk opus_mt_mk_es xx.da.marian.translate_to.no opus_mt_no_da xx.it.marian.translate_to.lt opus_mt_lt_it xx.es.marian.translate_to.prl opus_mt_prl_es xx.fr.marian.translate_to.lua opus_mt_lua_fr xx.es.marian.translate_to.nso opus_mt_nso_es xx.sv.marian.translate_to.lv opus_mt_lv_sv xx.fi.marian.translate_to.pis opus_mt_pis_fi xx.es.marian.translate_to.pon opus_mt_pon_es xx.fr.marian.translate_to.ko opus_mt_ko_fr xx.de.marian.translate_to.ln opus_mt_ln_de xx.uk.marian.translate_to.nl opus_mt_nl_uk xx.eo.marian.translate_to.nl opus_mt_nl_eo xx.es.marian.translate_to.lv opus_mt_lv_es xx.tr.marian.translate_to.lt opus_mt_lt_tr xx.es.marian.translate_to.mt opus_mt_mt_es xx.fi.marian.translate_to.lus opus_mt_lus_fi xx.tl.marian.translate_to.pt opus_mt_pt_tl xx.no.marian.translate_to.nl opus_mt_nl_no xx.sv.marian.translate_to.kqn opus_mt_kqn_sv xx.pt.marian.translate_to.ja opus_mt_ja_pt xx.fi.marian.translate_to.nso opus_mt_nso_fi xx.fr.marian.translate_to.kg opus_mt_kg_fr xx.sv.marian.translate_to.pis opus_mt_pis_sv xx.is.marian.translate_to.sv opus_mt_sv_is xx.sla.marian.translate_to.sla opus_mt_sla_sla xx.sv.marian.translate_to.srn opus_mt_srn_sv xx.niu.marian.translate_to.sv opus_mt_sv_niu xx.to.marian.translate_to.sv opus_mt_sv_to xx.guw.marian.translate_to.sv opus_mt_sv_guw xx.sn.marian.translate_to.sv opus_mt_sv_sn xx.sv.marian.translate_to.rnd opus_mt_rnd_sv xx.tum.marian.translate_to.sv opus_mt_sv_tum xx.mos.marian.translate_to.sv opus_mt_sv_mos xx.srn.marian.translate_to.sv opus_mt_sv_srn xx.ht.marian.translate_to.sv opus_mt_sv_ht xx.no.marian.translate_to.ru opus_mt_ru_no xx.sl.marian.translate_to.sv opus_mt_sv_sl xx.fr.marian.translate_to.sv opus_mt_sv_fr xx.uk.marian.translate_to.ru opus_mt_ru_uk xx.tiv.marian.translate_to.sv opus_mt_sv_tiv xx.es.marian.translate_to.ru opus_mt_ru_es xx.pag.marian.translate_to.sv opus_mt_sv_pag xx.gaa.marian.translate_to.sv opus_mt_sv_gaa xx.kqn.marian.translate_to.sv opus_mt_sv_kqn xx.fr.marian.translate_to.sg opus_mt_sg_fr xx.st.marian.translate_to.sv opus_mt_sv_st xx.ase.marian.translate_to.sv opus_mt_sv_ase xx.es.marian.translate_to.rn opus_mt_rn_es xx.ru.marian.translate_to.sl opus_mt_sl_ru xx.lu.marian.translate_to.sv opus_mt_sv_lu xx.eu.marian.translate_to.ru opus_mt_ru_eu xx.no.marian.translate_to.sv opus_mt_sv_no xx.sq.marian.translate_to.sv opus_mt_sv_sq xx.da.marian.translate_to.ru opus_mt_ru_da xx.ny.marian.translate_to.sv opus_mt_sv_ny xx.kg.marian.translate_to.sv opus_mt_sv_kg xx.pis.marian.translate_to.sv opus_mt_sv_pis xx.sv.marian.translate_to.sk opus_mt_sk_sv xx.lus.marian.translate_to.sv opus_mt_sv_lus xx.fi.marian.translate_to.sl opus_mt_sl_fi xx.tn.marian.translate_to.sv opus_mt_sv_tn xx.fr.marian.translate_to.srn opus_mt_srn_fr xx.lv.marian.translate_to.sv opus_mt_sv_lv xx.uk.marian.translate_to.sl opus_mt_sl_uk xx.sg.marian.translate_to.sv opus_mt_sv_sg xx.he.marian.translate_to.sv opus_mt_sv_he xx.eo.marian.translate_to.ru opus_mt_ru_eo xx.fr.marian.translate_to.ru opus_mt_ru_fr xx.lv.marian.translate_to.ru opus_mt_ru_lv xx.lua.marian.translate_to.sv opus_mt_sv_lua xx.ar.marian.translate_to.ru opus_mt_ru_ar xx.tll.marian.translate_to.sv opus_mt_sv_tll xx.lue.marian.translate_to.sv opus_mt_sv_lue xx.bi.marian.translate_to.sv opus_mt_sv_bi xx.hu.marian.translate_to.sv opus_mt_sv_hu xx.bzs.marian.translate_to.sv opus_mt_sv_bzs xx.ru.marian.translate_to.sv opus_mt_sv_ru xx.eo.marian.translate_to.ro opus_mt_ro_eo xx.es.marian.translate_to.st opus_mt_st_es xx.mt.marian.translate_to.sv opus_mt_sv_mt xx.af.marian.translate_to.sv opus_mt_sv_af xx.ts.marian.translate_to.sv opus_mt_sv_ts xx.af.marian.translate_to.ru opus_tatoeba_af_ru xx.efi.marian.translate_to.sv opus_mt_sv_efi xx.es.marian.translate_to.sv opus_mt_sv_es xx.fi.marian.translate_to.sk opus_mt_sk_fi xx.fr.marian.translate_to.rw opus_mt_rw_fr xx.sv.marian.translate_to.run opus_mt_run_sv xx.th.marian.translate_to.sv opus_mt_sv_th xx.ln.marian.translate_to.sv opus_mt_sv_ln xx.es.marian.translate_to.sk opus_mt_sk_es xx.lt.marian.translate_to.ru opus_mt_ru_lt xx.mfe.marian.translate_to.sv opus_mt_sv_mfe xx.cs.marian.translate_to.sv opus_mt_sv_cs xx.vi.marian.translate_to.ru opus_mt_ru_vi xx.ee.marian.translate_to.sv opus_mt_sv_ee xx.bg.marian.translate_to.ru opus_mt_ru_bg xx.nso.marian.translate_to.sv opus_mt_sv_nso xx.mh.marian.translate_to.sv opus_mt_sv_mh xx.iso.marian.translate_to.sv opus_mt_sv_iso xx.fi.marian.translate_to.st opus_mt_st_fi xx.bg.marian.translate_to.sv opus_mt_sv_bg xx.sv.marian.translate_to.sq opus_mt_sq_sv xx.sv.marian.translate_to.sn opus_mt_sn_sv xx.de.marian.translate_to.rn opus_mt_rn_de xx.pon.marian.translate_to.sv opus_mt_sv_pon xx.ha.marian.translate_to.sv opus_mt_sv_ha xx.fi.marian.translate_to.ru opus_mt_ru_fi xx.sk.marian.translate_to.sv opus_mt_sv_sk xx.es.marian.translate_to.run opus_mt_run_es xx.et.marian.translate_to.ru opus_mt_ru_et xx.swc.marian.translate_to.sv opus_mt_sv_swc xx.hil.marian.translate_to.sv opus_mt_sv_hil xx.ro.marian.translate_to.sv opus_mt_sv_ro xx.fr.marian.translate_to.rnd opus_mt_rnd_fr xx.kwy.marian.translate_to.sv opus_mt_sv_kwy xx.uk.marian.translate_to.sh opus_mt_sh_uk xx.sm.marian.translate_to.sv opus_mt_sv_sm xx.sv.marian.translate_to.rw opus_mt_rw_sv xx.et.marian.translate_to.sv opus_mt_sv_et xx.eo.marian.translate_to.sv opus_mt_sv_eo xx.rnd.marian.translate_to.sv opus_mt_sv_rnd xx.eo.marian.translate_to.sh opus_mt_sh_eo xx.ru.marian.translate_to.rn opus_mt_rn_ru xx.rw.marian.translate_to.sv opus_mt_sv_rw xx.fr.marian.translate_to.sn opus_mt_sn_fr xx.ig.marian.translate_to.sv opus_mt_sv_ig xx.fj.marian.translate_to.sv opus_mt_sv_fj xx.sl.marian.translate_to.ru opus_mt_ru_sl xx.ho.marian.translate_to.sv opus_mt_sv_ho xx.sv.marian.translate_to.sl opus_mt_sl_sv xx.pap.marian.translate_to.sv opus_mt_sv_pap xx.fr.marian.translate_to.sl opus_mt_sl_fr xx.es.marian.translate_to.sl opus_mt_sl_es xx.run.marian.translate_to.sv opus_mt_sv_run xx.el.marian.translate_to.sv opus_mt_sv_el xx.gil.marian.translate_to.sv opus_mt_sv_gil xx.crs.marian.translate_to.sv opus_mt_sv_crs xx.fr.marian.translate_to.sk opus_mt_sk_fr xx.es.marian.translate_to.sq opus_mt_sq_es xx.sv.marian.translate_to.sg opus_mt_sg_sv xx.es.marian.translate_to.srn opus_mt_srn_es xx.fr.marian.translate_to.ro opus_mt_ro_fr xx.fr.marian.translate_to.rn opus_mt_rn_fr xx.fr.marian.translate_to.st opus_mt_st_fr xx.es.marian.translate_to.rw opus_mt_rw_es xx.hr.marian.translate_to.sv opus_mt_sv_hr xx.es.marian.translate_to.sm opus_mt_sm_es xx.es.marian.translate_to.ssp opus_mt_ssp_es xx.nl.marian.translate_to.sv opus_mt_sv_nl xx.bem.marian.translate_to.sv opus_mt_sv_bem xx.sem.marian.translate_to.sem opus_mt_sem_sem xx.sv.marian.translate_to.sv opus_mt_sv_sv xx.sv.marian.translate_to.st opus_mt_st_sv xx.lg.marian.translate_to.sv opus_mt_sv_lg xx.bcl.marian.translate_to.sv opus_mt_sv_bcl xx.toi.marian.translate_to.sv opus_mt_sv_toi xx.id.marian.translate_to.sv opus_mt_sv_id xx.he.marian.translate_to.ru opus_mt_ru_he xx.ceb.marian.translate_to.sv opus_mt_sv_ceb xx.tw.marian.translate_to.sv opus_mt_sv_tw xx.chk.marian.translate_to.sv opus_mt_sv_chk xx.fr.marian.translate_to.sm opus_mt_sm_fr xx.tvl.marian.translate_to.sv opus_mt_sv_tvl xx.es.marian.translate_to.sg opus_mt_sg_es xx.ilo.marian.translate_to.sv opus_mt_sv_ilo xx.sv.marian.translate_to.ro opus_mt_ro_sv xx.fi.marian.translate_to.sg opus_mt_sg_fi xx.hy.marian.translate_to.ru opus_mt_ru_hy xx.fi.marian.translate_to.ro opus_mt_ro_fi xx.tpi.marian.translate_to.sv opus_mt_sv_tpi xx.fi.marian.translate_to.sv opus_mt_sv_fi xx.sv.marian.translate_to.ru opus_mt_ru_sv xx.es.marian.translate_to.toi opus_mt_toi_es xx.no.marian.translate_to.uk opus_mt_uk_no xx.ar.marian.translate_to.tr opus_mt_tr_ar xx.he.marian.translate_to.uk opus_mt_uk_he xx.sv.marian.translate_to.tvl opus_mt_tvl_sv xx.uk.marian.translate_to.sv opus_mt_sv_uk xx.fr.marian.translate_to.tvl opus_mt_tvl_fr xx.bg.marian.translate_to.uk opus_mt_uk_bg xx.fi.marian.translate_to.toi opus_mt_toi_fi xx.ca.marian.translate_to.uk opus_mt_uk_ca xx.fr.marian.translate_to.uk opus_mt_uk_fr xx.eo.marian.translate_to.tr opus_mt_tr_eo xx.uk.marian.translate_to.tr opus_mt_tr_uk xx.es.marian.translate_to.tl opus_mt_tl_es xx.es.marian.translate_to.tr opus_mt_tr_es xx.it.marian.translate_to.uk opus_mt_uk_it xx.fi.marian.translate_to.uk opus_mt_uk_fi xx.lt.marian.translate_to.tr opus_mt_tr_lt xx.es.marian.translate_to.swc opus_mt_swc_es xx.umb.marian.translate_to.sv opus_mt_sv_umb xx.sv.marian.translate_to.tw opus_mt_tw_sv xx.urj.marian.translate_to.urj opus_mt_urj_urj xx.yap.marian.translate_to.sv opus_mt_sv_yap xx.fr.marian.translate_to.ty opus_mt_ty_fr xx.fr.marian.translate_to.swc opus_mt_swc_fr xx.pt.marian.translate_to.tl opus_mt_tl_pt xx.tr.marian.translate_to.uk opus_mt_uk_tr xx.sv.marian.translate_to.tr opus_mt_tr_sv xx.fi.marian.translate_to.tvl opus_mt_tvl_fi xx.es.marian.translate_to.tn opus_mt_tn_es xx.fi.marian.translate_to.swc opus_mt_swc_fi xx.fr.marian.translate_to.toi opus_mt_toi_fr xx.fi.marian.translate_to.ts opus_mt_ts_fi xx.de.marian.translate_to.uk opus_mt_uk_de xx.sv.marian.translate_to.uk opus_mt_uk_sv xx.fi.marian.translate_to.tw opus_mt_tw_fi xx.sv.marian.translate_to.to opus_mt_to_sv xx.sv.marian.translate_to.tll opus_mt_tll_sv xx.fr.marian.translate_to.th opus_mt_th_fr xx.es.marian.translate_to.ty opus_mt_ty_es xx.fr.marian.translate_to.tw opus_mt_tw_fr xx.fr.marian.translate_to.to opus_mt_to_fr xx.sl.marian.translate_to.uk opus_mt_uk_sl xx.xh.marian.translate_to.sv opus_mt_sv_xh xx.war.marian.translate_to.sv opus_mt_sv_war xx.hu.marian.translate_to.uk opus_mt_uk_hu xx.ru.marian.translate_to.uk opus_mt_uk_ru xx.sv.marian.translate_to.tn opus_mt_tn_sv xx.fr.marian.translate_to.tum opus_mt_tum_fr xx.sv.marian.translate_to.toi opus_mt_toi_sv xx.sv.marian.translate_to.ty opus_mt_ty_sv xx.fr.marian.translate_to.tr opus_mt_tr_fr xx.fr.marian.translate_to.tn opus_mt_tn_fr xx.cs.marian.translate_to.uk opus_mt_uk_cs xx.fr.marian.translate_to.ts opus_mt_ts_fr xx.sv.marian.translate_to.swc opus_mt_swc_sv xx.es.marian.translate_to.to opus_mt_to_es xx.es.marian.translate_to.uk opus_mt_uk_es xx.nl.marian.translate_to.uk opus_mt_uk_nl xx.zne.marian.translate_to.sv opus_mt_sv_zne xx.es.marian.translate_to.tvl opus_mt_tvl_es xx.pt.marian.translate_to.uk opus_mt_uk_pt xx.fr.marian.translate_to.tiv opus_mt_tiv_fr xx.fr.marian.translate_to.tll opus_mt_tll_fr xx.sh.marian.translate_to.uk opus_mt_uk_sh xx.wls.marian.translate_to.sv opus_mt_sv_wls xx.ve.marian.translate_to.sv opus_mt_sv_ve xx.es.marian.translate_to.tum opus_mt_tum_es xx.fi.marian.translate_to.tll opus_mt_tll_fi xx.es.marian.translate_to.tw opus_mt_tw_es xx.sv.marian.translate_to.tiv opus_mt_tiv_sv xx.fi.marian.translate_to.ty opus_mt_ty_fi xx.pl.marian.translate_to.uk opus_mt_uk_pl xx.sv.marian.translate_to.tpi opus_mt_tpi_sv xx.az.marian.translate_to.tr opus_mt_tr_az xx.es.marian.translate_to.tll opus_mt_tll_es xx.ty.marian.translate_to.sv opus_mt_sv_ty xx.tzo.marian.translate_to.es opus_mt_es_tzo xx.sv.marian.translate_to.crs opus_mt_crs_sv xx.es.marian.translate_to.zai opus_mt_zai_es xx.niu.marian.translate_to.de opus_mt_de_niu xx.sv.marian.translate_to.nso opus_mt_nso_sv xx.fr.marian.translate_to.bg opus_mt_bg_fr xx.es.marian.translate_to.lus opus_mt_lus_es xx.es.marian.translate_to.nl opus_mt_nl_es xx.fr.marian.translate_to.yo opus_mt_yo_fr xx.sv.marian.translate_to.ilo opus_mt_ilo_sv xx.es.marian.translate_to.ts opus_mt_ts_es xx.run.marian.translate_to.fr opus_mt_fr_run xx.to.marian.translate_to.es opus_mt_es_to xx.ceb.marian.translate_to.fi opus_mt_fi_ceb xx.it.marian.translate_to.ja opus_mt_ja_it xx.es.marian.translate_to.sn opus_mt_sn_es xx.yo.marian.translate_to.sv opus_mt_sv_yo xx.tr.marian.translate_to.az opus_mt_az_tr xx.fr.marian.translate_to.no opus_mt_no_fr xx.tn.marian.translate_to.fr opus_mt_fr_tn xx.id.marian.translate_to.fr opus_mt_fr_id xx.de.marian.translate_to.ca opus_mt_ca_de xx.sv.marian.translate_to.tum opus_mt_tum_sv xx.ru.marian.translate_to.da opus_mt_da_ru xx.de.marian.translate_to.tl opus_mt_tl_de xx.eo.marian.translate_to.fr opus_mt_fr_eo xx.vi.marian.translate_to.zh opus_mt_zh_vi xx.es.marian.translate_to.vi opus_mt_vi_es xx.es.marian.translate_to.mfe opus_mt_mfe_es xx.fi.marian.translate_to.iso opus_mt_iso_fi xx.es.marian.translate_to.tzo opus_mt_tzo_es xx.sn.marian.translate_to.es opus_mt_es_sn xx.es.marian.translate_to.xh opus_mt_xh_es xx.sv.marian.translate_to.zne opus_mt_zne_sv xx.sv.marian.translate_to.ts opus_mt_ts_sv xx.it.marian.translate_to.zh opus_mt_zh_it xx.uk.marian.translate_to.zh opus_mt_zh_uk xx.fi.marian.translate_to.yo opus_mt_yo_fi xx.sv.marian.translate_to.war opus_mt_war_sv xx.sv.marian.translate_to.yo opus_mt_yo_sv xx.tll.marian.translate_to.es opus_mt_es_tll xx.nl.marian.translate_to.zh opus_mt_zh_nl xx.fr.marian.translate_to.wls opus_mt_wls_fr xx.it.marian.translate_to.vi opus_mt_vi_it xx.bg.marian.translate_to.zh opus_mt_zh_bg xx.sv.marian.translate_to.xh opus_mt_xh_sv xx.es.marian.translate_to.zne opus_mt_zne_es xx.zlw.marian.translate_to.zlw opus_mt_zlw_zlw xx.sv.marian.translate_to.yap opus_mt_yap_sv xx.he.marian.translate_to.zh opus_mt_zh_he xx.fr.marian.translate_to.xh opus_mt_xh_fr xx.fi.marian.translate_to.war opus_mt_war_fi xx.sv.marian.translate_to.zh opus_mt_zh_sv xx.zls.marian.translate_to.zls opus_mt_zls_zls xx.fi.marian.translate_to.zne opus_mt_zne_fi xx.es.marian.translate_to.ve opus_mt_ve_es xx.de.marian.translate_to.vi opus_mt_vi_de xx.eo.marian.translate_to.vi opus_mt_vi_eo xx.sv.marian.translate_to.wls opus_mt_wls_sv xx.es.marian.translate_to.war opus_mt_war_es xx.ru.marian.translate_to.vi opus_mt_vi_ru xx.ms.marian.translate_to.zh opus_mt_zh_ms xx.fr.marian.translate_to.zne opus_mt_zne_fr xx.fr.marian.translate_to.yap opus_mt_yap_fr xx.de.marian.translate_to.zh opus_mt_zh_de xx.es.marian.translate_to.yo opus_mt_yo_es xx.es.marian.translate_to.vsl opus_mt_vsl_es xx.zle.marian.translate_to.zle opus_mt_zle_zle xx.fr.marian.translate_to.vi opus_mt_vi_fr xx.fr.marian.translate_to.war opus_mt_war_fr xx.fi.marian.translate_to.zh opus_mt_zh_fi xx.he.marian.translate_to.it opus_tatoeba_he_it xx.es.marian.translate_to.zh opus_tatoeba_es_zh xx.es.translate_to.af translate_af_es xx.nl.translate_to.af translate_af_nl xx.eo.translate_to.af translate_af_eo xx.afa.translate_to.afa translate_afa_afa xx.sv.translate_to.af translate_af_sv xx.es.translate_to.aed translate_aed_es xx.fr.translate_to.af translate_af_fr xx.fi.translate_to.af translate_af_fi xx.de.translate_to.af translate_af_de xx.ru.translate_to.af translate_af_ru xx.es.translate_to.az translate_az_es xx.de.translate_to.bcl translate_bcl_de xx.sv.translate_to.bem translate_bem_sv xx.tr.translate_to.az translate_az_tr xx.sv.translate_to.bcl translate_bcl_sv xx.es.translate_to.ar translate_ar_es xx.es.translate_to.bem translate_bem_es xx.ru.translate_to.ar translate_ar_ru xx.es.translate_to.be translate_be_es xx.fr.translate_to.bem translate_bem_fr xx.he.translate_to.ar translate_ar_he xx.es.translate_to.bcl translate_bcl_es xx.es.translate_to.ase translate_ase_es xx.de.translate_to.ar translate_ar_de xx.pl.translate_to.ar translate_ar_pl xx.tr.translate_to.ar translate_ar_tr xx.sv.translate_to.ase translate_ase_sv xx.fi.translate_to.bcl translate_bcl_fi xx.el.translate_to.ar translate_ar_el xx.fr.translate_to.bcl translate_bcl_fr xx.fi.translate_to.bem translate_bem_fi xx.fr.translate_to.ase translate_ase_fr xx.fr.translate_to.ar translate_ar_fr xx.eo.translate_to.ar translate_ar_eo xx.it.translate_to.ar translate_ar_it xx.sv.translate_to.am translate_am_sv xx.de.translate_to.ase translate_ase_de xx.uk.translate_to.bg translate_bg_uk xx.it.translate_to.bg translate_bg_it xx.sv.translate_to.bzs translate_bzs_sv xx.pt.translate_to.ca translate_ca_pt xx.es.translate_to.ber translate_ber_es xx.it.translate_to.ca translate_ca_it xx.eo.translate_to.bg translate_bg_eo xx.sv.translate_to.ceb translate_ceb_sv xx.fr.translate_to.bi translate_bi_fr xx.sv.translate_to.bg translate_bg_sv xx.fr.translate_to.ca translate_ca_fr xx.tr.translate_to.bg translate_bg_tr xx.es.translate_to.ceb translate_ceb_es xx.de.translate_to.ca translate_ca_de xx.fi.translate_to.ceb translate_ceb_fi xx.es.translate_to.ca translate_ca_es xx.es.translate_to.bg translate_bg_es xx.uk.translate_to.ca translate_ca_uk xx.sv.translate_to.bi translate_bi_sv xx.sv.translate_to.chk translate_chk_sv xx.fr.translate_to.ceb translate_ceb_fr xx.es.translate_to.bzs translate_bzs_es xx.de.translate_to.crs translate_crs_de xx.nl.translate_to.ca translate_ca_nl xx.es.translate_to.chk translate_chk_es xx.fr.translate_to.ber translate_ber_fr xx.fi.translate_to.bzs translate_bzs_fi xx.es.translate_to.crs translate_crs_es xx.fi.translate_to.bg translate_bg_fi xx.cpp.translate_to.cpp translate_cpp_cpp xx.de.translate_to.bg translate_bg_de xx.es.translate_to.bi translate_bi_es xx.fr.translate_to.bzs translate_bzs_fr xx.fr.translate_to.bg translate_bg_fr xx.fr.translate_to.chk translate_chk_fr xx.ru.translate_to.bg translate_bg_ru xx.fi.translate_to.cs translate_cs_fi xx.ha.translate_to.de translate_de_ha xx.ee.translate_to.de translate_de_ee xx.eo.translate_to.de translate_de_eo xx.gil.translate_to.de translate_de_gil xx.fj.translate_to.de translate_de_fj xx.fr.translate_to.de translate_de_fr xx.sv.translate_to.cs translate_cs_sv xx.es.translate_to.csn translate_csn_es xx.ru.translate_to.da translate_da_ru xx.no.translate_to.da translate_da_no xx.iso.translate_to.de translate_de_iso xx.eu.translate_to.de translate_de_eu xx.nl.translate_to.de translate_de_nl xx.ilo.translate_to.de translate_de_ilo xx.hr.translate_to.de translate_de_hr xx.mt.translate_to.de translate_de_mt xx.es.translate_to.da translate_da_es xx.ar.translate_to.de translate_de_ar xx.is.translate_to.de translate_de_is xx.sv.translate_to.crs translate_crs_sv xx.fr.translate_to.da translate_da_fr xx.gaa.translate_to.de translate_de_gaa xx.niu.translate_to.de translate_de_niu xx.da.translate_to.de translate_de_da xx.de.translate_to.da translate_da_de xx.ase.translate_to.de translate_de_ase xx.ig.translate_to.de translate_de_ig xx.lua.translate_to.de translate_de_lua xx.de.translate_to.de translate_de_de xx.bi.translate_to.de translate_de_bi xx.fr.translate_to.cs translate_cs_fr xx.ms.translate_to.de translate_de_ms xx.fi.translate_to.crs translate_crs_fi xx.eo.translate_to.da translate_da_eo xx.af.translate_to.de translate_de_af xx.uk.translate_to.cs translate_cs_uk xx.bg.translate_to.de translate_de_bg xx.no.translate_to.de translate_de_no xx.de.translate_to.cs translate_cs_de xx.it.translate_to.de translate_de_it xx.ho.translate_to.de translate_de_ho xx.ln.translate_to.de translate_de_ln xx.guw.translate_to.de translate_de_guw xx.efi.translate_to.de translate_de_efi xx.hil.translate_to.de translate_de_hil xx.cs.translate_to.de translate_de_cs xx.es.translate_to.csg translate_csg_es xx.es.translate_to.de translate_de_es xx.bcl.translate_to.de translate_de_bcl xx.ht.translate_to.de translate_de_ht xx.loz.translate_to.de translate_de_loz xx.kg.translate_to.de translate_de_kg xx.eo.translate_to.cs translate_cs_eo xx.el.translate_to.de translate_de_el xx.fi.translate_to.de translate_de_fi xx.he.translate_to.de translate_de_he xx.bzs.translate_to.de translate_de_bzs xx.fr.translate_to.crs translate_crs_fr xx.crs.translate_to.de translate_de_crs xx.fi.translate_to.da translate_da_fi xx.hu.translate_to.de translate_de_hu xx.et.translate_to.de translate_de_et xx.lt.translate_to.de translate_de_lt xx.ca.translate_to.de translate_de_ca xx.pl.translate_to.de translate_de_pl xx.sv.translate_to.el translate_el_sv xx.de.translate_to.ee translate_ee_de xx.pag.translate_to.de translate_de_pag xx.ar.translate_to.el translate_el_ar xx.nso.translate_to.de translate_de_nso xx.pon.translate_to.de translate_de_pon xx.pap.translate_to.de translate_de_pap xx.fr.translate_to.efi translate_efi_fr xx.pis.translate_to.de translate_de_pis xx.de.translate_to.efi translate_efi_de xx.eo.translate_to.el translate_el_eo xx.fi.translate_to.ee translate_ee_fi xx.es.translate_to.ee translate_ee_es xx.fr.translate_to.ee translate_ee_fr xx.fi.translate_to.efi translate_efi_fi xx.fr.translate_to.el translate_el_fr xx.tl.translate_to.de translate_de_tl xx.ny.translate_to.de translate_de_ny xx.uk.translate_to.de translate_de_uk xx.sv.translate_to.efi translate_efi_sv xx.sv.translate_to.ee translate_ee_sv xx.vi.translate_to.de translate_de_vi xx.fi.translate_to.el translate_el_fi xx.cs.translate_to.eo translate_eo_cs xx.bzs.translate_to.es translate_es_bzs xx.he.translate_to.eo translate_eo_he xx.hu.translate_to.eo translate_eo_hu xx.ro.translate_to.eo translate_eo_ro xx.ber.translate_to.es translate_es_ber xx.ca.translate_to.es translate_es_ca xx.bcl.translate_to.es translate_es_bcl xx.ceb.translate_to.es translate_es_ceb xx.da.translate_to.eo translate_eo_da xx.bi.translate_to.es translate_es_bi xx.ee.translate_to.es translate_es_ee xx.ru.translate_to.eo translate_eo_ru xx.csg.translate_to.es translate_es_csg xx.fi.translate_to.eo translate_eo_fi xx.it.translate_to.eo translate_eo_it xx.nl.translate_to.eo translate_eo_nl xx.et.translate_to.es translate_es_et xx.bg.translate_to.es translate_es_bg xx.de.translate_to.eo translate_eo_de xx.ar.translate_to.es translate_es_ar xx.cs.translate_to.es translate_es_cs xx.aed.translate_to.es translate_es_aed xx.ase.translate_to.es translate_es_ase xx.el.translate_to.es translate_es_el xx.eo.translate_to.es translate_es_eo xx.af.translate_to.eo translate_eo_af xx.af.translate_to.es translate_es_af xx.pl.translate_to.eo translate_eo_pl xx.de.translate_to.es translate_es_de xx.es.translate_to.eo translate_eo_es xx.da.translate_to.es translate_es_da xx.crs.translate_to.es translate_es_crs xx.pt.translate_to.eo translate_eo_pt xx.eu.translate_to.es translate_es_eu xx.es.translate_to.es translate_es_es xx.csn.translate_to.es translate_es_csn xx.sv.translate_to.eo translate_eo_sv xx.efi.translate_to.es translate_es_efi xx.sh.translate_to.eo translate_eo_sh xx.bg.translate_to.eo translate_eo_bg xx.fr.translate_to.eo translate_eo_fr xx.el.translate_to.eo translate_eo_el xx.pl.translate_to.es translate_es_pl xx.ro.translate_to.es translate_es_ro xx.is.translate_to.es translate_es_is xx.ln.translate_to.es translate_es_ln xx.to.translate_to.es translate_es_to xx.no.translate_to.es translate_es_no xx.nl.translate_to.es translate_es_nl xx.pag.translate_to.es translate_es_pag xx.tvl.translate_to.es translate_es_tvl xx.fr.translate_to.es translate_es_fr xx.he.translate_to.es translate_es_he xx.lus.translate_to.es translate_es_lus xx.hil.translate_to.es translate_es_hil xx.ny.translate_to.es translate_es_ny xx.pap.translate_to.es translate_es_pap xx.id.translate_to.es translate_es_id xx.wls.translate_to.es translate_es_wls xx.gaa.translate_to.es translate_es_gaa xx.nso.translate_to.es translate_es_nso xx.mk.translate_to.es translate_es_mk xx.mt.translate_to.es translate_es_mt xx.pis.translate_to.es translate_es_pis xx.gl.translate_to.es translate_es_gl xx.sn.translate_to.es translate_es_sn xx.hr.translate_to.es translate_es_hr xx.swc.translate_to.es translate_es_swc xx.lua.translate_to.es translate_es_lua xx.it.translate_to.es translate_es_it xx.fj.translate_to.es translate_es_fj xx.gil.translate_to.es translate_es_gil xx.sm.translate_to.es translate_es_sm xx.guw.translate_to.es translate_es_guw xx.kg.translate_to.es translate_es_kg xx.tl.translate_to.es translate_es_tl xx.rn.translate_to.es translate_es_rn xx.mfs.translate_to.es translate_es_mfs xx.iso.translate_to.es translate_es_iso xx.loz.translate_to.es translate_es_loz xx.tpi.translate_to.es translate_es_tpi xx.ha.translate_to.es translate_es_ha xx.ht.translate_to.es translate_es_ht xx.uk.translate_to.es translate_es_uk xx.tw.translate_to.es translate_es_tw xx.st.translate_to.es translate_es_st xx.sg.translate_to.es translate_es_sg xx.ilo.translate_to.es translate_es_ilo xx.ru.translate_to.es translate_es_ru xx.yo.translate_to.es translate_es_yo xx.pon.translate_to.es translate_es_pon xx.niu.translate_to.es translate_es_niu xx.lt.translate_to.es translate_es_lt xx.ty.translate_to.es translate_es_ty xx.ig.translate_to.es translate_es_ig xx.tzo.translate_to.es translate_es_tzo xx.rw.translate_to.es translate_es_rw xx.war.translate_to.es translate_es_war xx.tll.translate_to.es translate_es_tll xx.prl.translate_to.es translate_es_prl xx.xh.translate_to.es translate_es_xh xx.yua.translate_to.es translate_es_yua xx.ho.translate_to.es translate_es_ho xx.ve.translate_to.es translate_es_ve xx.sl.translate_to.es translate_es_sl xx.tn.translate_to.es translate_es_tn xx.vi.translate_to.es translate_es_vi xx.srn.translate_to.es translate_es_srn xx.fi.translate_to.es translate_es_fi xx.lua.translate_to.fi translate_fi_lua xx.ny.translate_to.fi translate_fi_ny xx.pon.translate_to.fi translate_fi_pon xx.crs.translate_to.fi translate_fi_crs xx.nso.translate_to.fi translate_fi_nso xx.iso.translate_to.fi translate_fi_iso xx.kqn.translate_to.fi translate_fi_kqn xx.gaa.translate_to.fi translate_fi_gaa xx.ru.translate_to.eu translate_eu_ru xx.eo.translate_to.fi translate_fi_eo xx.ig.translate_to.fi translate_fi_ig xx.bem.translate_to.fi translate_fi_bem xx.es.translate_to.et translate_et_es xx.fj.translate_to.fi translate_fi_fj xx.et.translate_to.fi translate_fi_et xx.bcl.translate_to.fi translate_fi_bcl xx.fi.translate_to.fi translate_fi_fi xx.el.translate_to.fi translate_fi_el xx.efi.translate_to.fi translate_fi_efi xx.ht.translate_to.fi translate_fi_ht xx.ceb.translate_to.fi translate_fi_ceb xx.lg.translate_to.fi translate_fi_lg xx.pap.translate_to.fi translate_fi_pap xx.kg.translate_to.fi translate_fi_kg xx.ee.translate_to.fi translate_fi_ee xx.lv.translate_to.fi translate_fi_lv xx.fr.translate_to.et translate_et_fr xx.de.translate_to.et translate_et_de xx.bzs.translate_to.fi translate_fi_bzs xx.mos.translate_to.fi translate_fi_mos xx.zh.translate_to.es translate_es_zh xx.id.translate_to.fi translate_fi_id xx.gil.translate_to.fi translate_fi_gil xx.pis.translate_to.fi translate_fi_pis xx.no.translate_to.fi translate_fi_no xx.it.translate_to.fi translate_fi_it xx.es.translate_to.fi translate_fi_es xx.ha.translate_to.fi translate_fi_ha xx.fr.translate_to.fi translate_fi_fr xx.de.translate_to.fi translate_fi_de xx.bg.translate_to.fi translate_fi_bg xx.zai.translate_to.es translate_es_zai xx.hil.translate_to.fi translate_fi_hil xx.cs.translate_to.fi translate_fi_cs xx.es.translate_to.eu translate_eu_es xx.ilo.translate_to.fi translate_fi_ilo xx.pag.translate_to.fi translate_fi_pag xx.ln.translate_to.fi translate_fi_ln xx.sv.translate_to.et translate_et_sv xx.niu.translate_to.fi translate_fi_niu xx.hr.translate_to.fi translate_fi_hr xx.de.translate_to.eu translate_eu_de xx.lus.translate_to.fi translate_fi_lus xx.ru.translate_to.et translate_et_ru xx.af.translate_to.fi translate_fi_af xx.mh.translate_to.fi translate_fi_mh xx.guw.translate_to.fi translate_fi_guw xx.mfe.translate_to.fi translate_fi_mfe xx.ho.translate_to.fi translate_fi_ho xx.fse.translate_to.fi translate_fi_fse xx.lu.translate_to.fi translate_fi_lu xx.hu.translate_to.fi translate_fi_hu xx.mk.translate_to.fi translate_fi_mk xx.nl.translate_to.fi translate_fi_nl xx.mg.translate_to.fi translate_fi_mg xx.mt.translate_to.fi translate_fi_mt xx.he.translate_to.fi translate_fi_he xx.fi.translate_to.et translate_et_fi xx.is.translate_to.fi translate_fi_is xx.lue.translate_to.fi translate_fi_lue xx.guw.translate_to.fr translate_fr_guw xx.ber.translate_to.fr translate_fr_ber xx.uk.translate_to.fi translate_fi_uk xx.efi.translate_to.fr translate_fr_efi xx.tr.translate_to.fi translate_fi_tr xx.tn.translate_to.fi translate_fi_tn xx.es.translate_to.fr translate_fr_es xx.srn.translate_to.fi translate_fi_srn xx.bcl.translate_to.fr translate_fr_bcl xx.sl.translate_to.fi translate_fi_sl xx.ht.translate_to.fr translate_fr_ht xx.zne.translate_to.fi translate_fi_zne xx.de.translate_to.fr translate_fr_de xx.war.translate_to.fi translate_fi_war xx.tpi.translate_to.fi translate_fi_tpi xx.ca.translate_to.fr translate_fr_ca xx.yap.translate_to.fi translate_fi_yap xx.sn.translate_to.fi translate_fi_sn xx.hr.translate_to.fr translate_fr_hr xx.gil.translate_to.fr translate_fr_gil xx.id.translate_to.fr translate_fr_id xx.sv.translate_to.fi translate_fi_sv xx.toi.translate_to.fi translate_fi_toi xx.sk.translate_to.fi translate_fi_sk xx.he.translate_to.fr translate_fr_he xx.sq.translate_to.fi translate_fi_sq xx.ve.translate_to.fi translate_fi_ve xx.tw.translate_to.fi translate_fi_tw xx.tvl.translate_to.fi translate_fi_tvl xx.hil.translate_to.fr translate_fr_hil xx.sw.translate_to.fi translate_fi_sw xx.eo.translate_to.fr translate_fr_eo xx.xh.translate_to.fi translate_fi_xh xx.bi.translate_to.fr translate_fr_bi xx.ru.translate_to.fi translate_fi_ru xx.ceb.translate_to.fr translate_fr_ceb xx.ig.translate_to.fr translate_fr_ig xx.el.translate_to.fr translate_fr_el xx.sm.translate_to.fi translate_fi_sm xx.to.translate_to.fi translate_fi_to xx.ase.translate_to.fr translate_fr_ase xx.yo.translate_to.fi translate_fi_yo xx.sg.translate_to.fi translate_fi_sg xx.rw.translate_to.fi translate_fi_rw xx.ts.translate_to.fi translate_fi_ts xx.wls.translate_to.fi translate_fi_wls xx.ho.translate_to.fr translate_fr_ho xx.tll.translate_to.fi translate_fi_tll xx.st.translate_to.fi translate_fi_st xx.fiu.translate_to.fiu translate_fiu_fiu xx.ro.translate_to.fi translate_fi_ro xx.tiv.translate_to.fi translate_fi_tiv xx.ha.translate_to.fr translate_fr_ha xx.ee.translate_to.fr translate_fr_ee xx.gaa.translate_to.fr translate_fr_gaa xx.hu.translate_to.fr translate_fr_hu xx.ty.translate_to.fi translate_fi_ty xx.fr.translate_to.fj translate_fj_fr xx.run.translate_to.fi translate_fi_run xx.bem.translate_to.fr translate_fr_bem xx.bzs.translate_to.fr translate_fr_bzs xx.fj.translate_to.fr translate_fr_fj xx.ar.translate_to.fr translate_fr_ar xx.swc.translate_to.fi translate_fi_swc xx.crs.translate_to.fr translate_fr_crs xx.bg.translate_to.fr translate_fr_bg xx.af.translate_to.fr translate_fr_af xx.loz.translate_to.fr translate_fr_loz xx.st.translate_to.fr translate_fr_st xx.tn.translate_to.fr translate_fr_tn xx.srn.translate_to.fr translate_fr_srn xx.to.translate_to.fr translate_fr_to xx.sk.translate_to.fr translate_fr_sk xx.tum.translate_to.fr translate_fr_tum xx.ts.translate_to.fr translate_fr_ts xx.iso.translate_to.fr translate_fr_iso xx.sv.translate_to.fr translate_fr_sv xx.mt.translate_to.fr translate_fr_mt xx.pap.translate_to.fr translate_fr_pap xx.wls.translate_to.fr translate_fr_wls xx.lua.translate_to.fr translate_fr_lua xx.ro.translate_to.fr translate_fr_ro xx.tll.translate_to.fr translate_fr_tll xx.ilo.translate_to.fr translate_fr_ilo xx.ve.translate_to.fr translate_fr_ve xx.ny.translate_to.fr translate_fr_ny xx.tpi.translate_to.fr translate_fr_tpi xx.uk.translate_to.fr translate_fr_uk xx.ln.translate_to.fr translate_fr_ln xx.mfe.translate_to.fr translate_fr_mfe xx.lue.translate_to.fr translate_fr_lue xx.mos.translate_to.fr translate_fr_mos xx.pon.translate_to.fr translate_fr_pon xx.tvl.translate_to.fr translate_fr_tvl xx.run.translate_to.fr translate_fr_run xx.pag.translate_to.fr translate_fr_pag xx.sg.translate_to.fr translate_fr_sg xx.no.translate_to.fr translate_fr_no xx.ty.translate_to.fr translate_fr_ty xx.tl.translate_to.fr translate_fr_tl xx.sl.translate_to.fr translate_fr_sl xx.tiv.translate_to.fr translate_fr_tiv xx.rw.translate_to.fr translate_fr_rw xx.lus.translate_to.fr translate_fr_lus xx.swc.translate_to.fr translate_fr_swc xx.sm.translate_to.fr translate_fr_sm xx.pl.translate_to.fr translate_fr_pl xx.kg.translate_to.fr translate_fr_kg xx.niu.translate_to.fr translate_fr_niu xx.lg.translate_to.fr translate_fr_lg xx.ms.translate_to.fr translate_fr_ms xx.nso.translate_to.fr translate_fr_nso xx.war.translate_to.fr translate_fr_war xx.xh.translate_to.fr translate_fr_xh xx.pis.translate_to.fr translate_fr_pis xx.tw.translate_to.fr translate_fr_tw xx.kwy.translate_to.fr translate_fr_kwy xx.rnd.translate_to.fr translate_fr_rnd xx.vi.translate_to.fr translate_fr_vi xx.lu.translate_to.fr translate_fr_lu xx.mh.translate_to.fr translate_fr_mh xx.ru.translate_to.fr translate_fr_ru xx.sn.translate_to.fr translate_fr_sn xx.kqn.translate_to.fr translate_fr_kqn xx.ar.translate_to.he translate_he_ar xx.de.translate_to.he translate_he_de xx.es.translate_to.gil translate_gil_es xx.de.translate_to.gaa translate_gaa_de xx.fr.translate_to.hu translate_hu_fr xx.fr.translate_to.gil translate_gil_fr xx.de.translate_to.guw translate_guw_de xx.fr.translate_to.ht translate_ht_fr xx.uk.translate_to.he translate_he_uk xx.fi.translate_to.hu translate_hu_fi xx.uk.translate_to.hu translate_hu_uk xx.zne.translate_to.fr translate_fr_zne xx.sv.translate_to.gaa translate_gaa_sv xx.es.translate_to.guw translate_guw_es xx.gmq.translate_to.gmq translate_gmq_gmq xx.fi.translate_to.hil translate_hil_fi xx.fi.translate_to.guw translate_guw_fi xx.es.translate_to.he translate_he_es xx.ur.translate_to.hi translate_hi_ur xx.de.translate_to.hil translate_hil_de xx.gmw.translate_to.gmw translate_gmw_gmw xx.fi.translate_to.gaa translate_gaa_fi xx.fi.translate_to.he translate_he_fi xx.eo.translate_to.hu translate_hu_eo xx.fi.translate_to.ht translate_ht_fi xx.yo.translate_to.fr translate_fr_yo xx.sv.translate_to.hr translate_hr_sv xx.fr.translate_to.ha translate_ha_fr xx.fi.translate_to.ha translate_ha_fi xx.sv.translate_to.ha translate_ha_sv xx.pt.translate_to.gl translate_gl_pt xx.fr.translate_to.guw translate_guw_fr xx.es.translate_to.ht translate_ht_es xx.de.translate_to.hu translate_hu_de xx.sv.translate_to.ht translate_ht_sv xx.es.translate_to.hr translate_hr_es xx.fr.translate_to.gaa translate_gaa_fr xx.ru.translate_to.he translate_he_ru xx.es.translate_to.gl translate_gl_es xx.ru.translate_to.hy translate_hy_ru xx.fi.translate_to.gil translate_gil_fi xx.sv.translate_to.hu translate_hu_sv xx.sv.translate_to.gil translate_gil_sv xx.fi.translate_to.fse translate_fse_fi xx.gem.translate_to.gem translate_gem_gem xx.es.translate_to.ha translate_ha_es xx.it.translate_to.he translate_he_it xx.sv.translate_to.guw translate_guw_sv xx.sv.translate_to.he translate_he_sv xx.yap.translate_to.fr translate_fr_yap xx.fr.translate_to.hr translate_hr_fr xx.eo.translate_to.he translate_he_eo xx.es.translate_to.gaa translate_gaa_es xx.fi.translate_to.hr translate_hr_fi xx.fr.translate_to.he translate_he_fr xx.fi.translate_to.ilo translate_ilo_fi xx.sv.translate_to.iso translate_iso_sv xx.he.translate_to.ja translate_ja_he xx.fi.translate_to.id translate_id_fi xx.de.translate_to.ja translate_ja_de xx.he.translate_to.it translate_it_he xx.it.translate_to.ja translate_ja_it xx.is.translate_to.it translate_it_is xx.bg.translate_to.ja translate_ja_bg xx.de.translate_to.ig translate_ig_de xx.bg.translate_to.it translate_it_bg xx.es.translate_to.id translate_id_es xx.fr.translate_to.id translate_id_fr xx.es.translate_to.ja translate_ja_es xx.sv.translate_to.ja translate_ja_sv xx.es.translate_to.iso translate_iso_es xx.es.translate_to.ilo translate_ilo_es xx.it.translate_to.is translate_is_it xx.sv.translate_to.it translate_it_sv xx.sv.translate_to.is translate_is_sv xx.ru.translate_to.ja translate_ja_ru xx.es.translate_to.kg translate_kg_es xx.fi.translate_to.ig translate_ig_fi xx.fr.translate_to.iso translate_iso_fr xx.de.translate_to.ko translate_ko_de xx.sv.translate_to.ilo translate_ilo_sv xx.es.translate_to.is translate_is_es xx.da.translate_to.ja translate_ja_da xx.nl.translate_to.ja translate_ja_nl xx.inc.translate_to.inc translate_inc_inc xx.de.translate_to.is translate_is_de xx.fr.translate_to.is translate_is_fr xx.lt.translate_to.it translate_it_lt xx.sv.translate_to.ig translate_ig_sv xx.de.translate_to.ilo translate_ilo_de xx.ar.translate_to.it translate_it_ar xx.fr.translate_to.kg translate_kg_fr xx.vi.translate_to.ja translate_ja_vi xx.ru.translate_to.ka translate_ka_ru xx.uk.translate_to.it translate_it_uk xx.vi.translate_to.it translate_it_vi xx.ms.translate_to.it translate_it_ms xx.ar.translate_to.ja translate_ja_ar xx.eo.translate_to.is translate_is_eo xx.ca.translate_to.it translate_it_ca xx.sh.translate_to.ja translate_ja_sh xx.fi.translate_to.ja translate_ja_fi xx.iir.translate_to.iir translate_iir_iir xx.itc.translate_to.itc translate_itc_itc xx.ms.translate_to.ja translate_ja_ms xx.fr.translate_to.it translate_it_fr xx.fr.translate_to.ja translate_ja_fr xx.pt.translate_to.ja translate_ja_pt xx.eo.translate_to.it translate_it_eo xx.fi.translate_to.iso translate_iso_fi xx.pl.translate_to.ja translate_ja_pl xx.tr.translate_to.ja translate_ja_tr xx.es.translate_to.ig translate_ig_es xx.fr.translate_to.ig translate_ig_fr xx.sv.translate_to.id translate_id_sv xx.hu.translate_to.ja translate_ja_hu xx.sv.translate_to.kg translate_kg_sv xx.es.translate_to.it translate_it_es xx.ine.translate_to.ine translate_ine_ine xx.de.translate_to.it translate_it_de xx.fi.translate_to.is translate_is_fi xx.es.translate_to.mk translate_mk_es xx.es.translate_to.lue translate_lue_es xx.es.translate_to.lv translate_lv_es xx.fi.translate_to.lue translate_lue_fi xx.es.translate_to.ln translate_ln_es xx.fr.translate_to.loz translate_loz_fr xx.sv.translate_to.kwy translate_kwy_sv xx.es.translate_to.lus translate_lus_es xx.fr.translate_to.lv translate_lv_fr xx.fr.translate_to.lu translate_lu_fr xx.de.translate_to.lt translate_lt_de xx.tr.translate_to.lt translate_lt_tr xx.fr.translate_to.lus translate_lus_fr xx.es.translate_to.mg translate_mg_es xx.sv.translate_to.lua translate_lua_sv xx.fr.translate_to.lg translate_lg_fr xx.fr.translate_to.kwy translate_kwy_fr xx.es.translate_to.lt translate_lt_es xx.sv.translate_to.ko translate_ko_sv xx.es.translate_to.kqn translate_kqn_es xx.fr.translate_to.ko translate_ko_fr xx.sv.translate_to.kqn translate_kqn_sv xx.fi.translate_to.ko translate_ko_fi xx.es.translate_to.mh translate_mh_es xx.fr.translate_to.lua translate_lua_fr xx.it.translate_to.lt translate_lt_it xx.sv.translate_to.lt translate_lt_sv xx.es.translate_to.lu translate_lu_es xx.fi.translate_to.lua translate_lua_fi xx.fr.translate_to.kqn translate_kqn_fr xx.de.translate_to.loz translate_loz_de xx.fr.translate_to.ms translate_ms_fr xx.fr.translate_to.lt translate_lt_fr xx.ru.translate_to.lv translate_lv_ru xx.ms.translate_to.ms translate_ms_ms xx.sv.translate_to.lus translate_lus_sv xx.fr.translate_to.lue translate_lue_fr xx.fi.translate_to.lu translate_lu_fi xx.eo.translate_to.lt translate_lt_eo xx.fi.translate_to.mk translate_mk_fi xx.es.translate_to.ko translate_ko_es xx.sv.translate_to.lue translate_lue_sv xx.pl.translate_to.lt translate_lt_pl xx.es.translate_to.mfe translate_mfe_es xx.fi.translate_to.loz translate_loz_fi xx.sv.translate_to.loz translate_loz_sv xx.ru.translate_to.ko translate_ko_ru xx.fi.translate_to.lg translate_lg_fi xx.fi.translate_to.mh translate_mh_fi xx.sv.translate_to.lv translate_lv_sv xx.hu.translate_to.ko translate_ko_hu xx.es.translate_to.lua translate_lua_es xx.fi.translate_to.lv translate_lv_fi xx.ru.translate_to.lt translate_lt_ru xx.de.translate_to.ms translate_ms_de xx.fi.translate_to.lus translate_lus_fi xx.es.translate_to.lg translate_lg_es xx.de.translate_to.ln translate_ln_de xx.es.translate_to.mfs translate_mfs_es xx.fr.translate_to.mk translate_mk_fr xx.fr.translate_to.ln translate_ln_fr xx.es.translate_to.loz translate_loz_es xx.sv.translate_to.lu translate_lu_sv xx.it.translate_to.ms translate_ms_it xx.sv.translate_to.lg translate_lg_sv xx.ar.translate_to.pl translate_pl_ar xx.fr.translate_to.ro translate_ro_fr xx.sv.translate_to.niu translate_niu_sv xx.eo.translate_to.pl translate_pl_eo xx.nl.translate_to.no translate_no_nl xx.es.translate_to.no translate_no_es xx.es.translate_to.pag translate_pag_es xx.ru.translate_to.rn translate_rn_ru xx.sv.translate_to.pag translate_pag_sv xx.uk.translate_to.pt translate_pt_uk xx.uk.translate_to.pl translate_pl_uk xx.de.translate_to.pl translate_pl_de xx.sv.translate_to.nl translate_nl_sv xx.fr.translate_to.no translate_no_fr xx.es.translate_to.niu translate_niu_es xx.uk.translate_to.no translate_no_uk xx.lt.translate_to.pl translate_pl_lt xx.tl.translate_to.pt translate_pt_tl xx.gl.translate_to.pt translate_pt_gl xx.da.translate_to.ru translate_ru_da xx.da.translate_to.no translate_no_da xx.uk.translate_to.nl translate_nl_uk xx.sv.translate_to.pon translate_pon_sv xx.fr.translate_to.pis translate_pis_fr xx.fr.translate_to.niu translate_niu_fr xx.af.translate_to.nl translate_nl_af xx.fi.translate_to.nso translate_nso_fi xx.fi.translate_to.pon translate_pon_fi xx.de.translate_to.pap translate_pap_de xx.de.translate_to.rn translate_rn_de xx.es.translate_to.pon translate_pon_es xx.es.translate_to.pis translate_pis_es xx.ca.translate_to.pt translate_pt_ca xx.sv.translate_to.rnd translate_rnd_sv xx.sv.translate_to.pl translate_pl_sv xx.ru.translate_to.no translate_no_ru xx.fi.translate_to.niu translate_niu_fi xx.de.translate_to.pag translate_pag_de xx.fr.translate_to.pl translate_pl_fr xx.fi.translate_to.no translate_no_fi xx.pl.translate_to.no translate_no_pl xx.de.translate_to.nso translate_nso_de xx.fr.translate_to.rn translate_rn_fr xx.sv.translate_to.nso translate_nso_sv xx.sv.translate_to.ro translate_ro_sv xx.no.translate_to.pl translate_pl_no xx.fr.translate_to.nl translate_nl_fr xx.es.translate_to.nso translate_nso_es xx.no.translate_to.nl translate_nl_no xx.fi.translate_to.pis translate_pis_fi xx.ca.translate_to.nl translate_nl_ca xx.es.translate_to.nl translate_nl_es xx.es.translate_to.ny translate_ny_es xx.fr.translate_to.pap translate_pap_fr xx.fi.translate_to.nl translate_nl_fi xx.sv.translate_to.no translate_no_sv xx.fr.translate_to.pon translate_pon_fr xx.fr.translate_to.rnd translate_rnd_fr xx.es.translate_to.pap translate_pap_es xx.es.translate_to.prl translate_prl_es xx.eo.translate_to.ro translate_ro_eo xx.sv.translate_to.pis translate_pis_sv xx.af.translate_to.ru translate_ru_af xx.fr.translate_to.nso translate_nso_fr xx.eo.translate_to.pt translate_pt_eo xx.ar.translate_to.ru translate_ru_ar xx.fr.translate_to.mt translate_mt_fr xx.es.translate_to.rn translate_rn_es xx.sv.translate_to.mt translate_mt_sv xx.de.translate_to.niu translate_niu_de xx.es.translate_to.mt translate_mt_es xx.es.translate_to.pl translate_pl_es xx.fi.translate_to.pag translate_pag_fi xx.de.translate_to.no translate_no_de xx.de.translate_to.ny translate_ny_de xx.fi.translate_to.mt translate_mt_fi xx.no.translate_to.no translate_no_no xx.eo.translate_to.nl translate_nl_eo xx.bg.translate_to.ru translate_ru_bg xx.fi.translate_to.pap translate_pap_fi xx.fi.translate_to.ro translate_ro_fi xx.sv.translate_to.st translate_st_sv xx.kg.translate_to.sv translate_sv_kg xx.sv.translate_to.sq translate_sq_sv xx.ee.translate_to.sv translate_sv_ee xx.es.translate_to.srn translate_srn_es xx.lv.translate_to.ru translate_ru_lv xx.cs.translate_to.sv translate_sv_cs xx.ha.translate_to.sv translate_sv_ha xx.kqn.translate_to.sv translate_sv_kqn xx.fr.translate_to.rw translate_rw_fr xx.fr.translate_to.sn translate_sn_fr xx.eu.translate_to.ru translate_ru_eu xx.fi.translate_to.st translate_st_fi xx.efi.translate_to.sv translate_sv_efi xx.ho.translate_to.sv translate_sv_ho xx.id.translate_to.sv translate_sv_id xx.eo.translate_to.sv translate_sv_eo xx.guw.translate_to.sv translate_sv_guw xx.sv.translate_to.sk translate_sk_sv xx.fr.translate_to.srn translate_srn_fr xx.ceb.translate_to.sv translate_sv_ceb xx.es.translate_to.sq translate_sq_es xx.sv.translate_to.rw translate_rw_sv xx.is.translate_to.sv translate_sv_is xx.es.translate_to.sm translate_sm_es xx.bcl.translate_to.sv translate_sv_bcl xx.kwy.translate_to.sv translate_sv_kwy xx.es.translate_to.run translate_run_es xx.el.translate_to.sv translate_sv_el xx.es.translate_to.sk translate_sk_es xx.iso.translate_to.sv translate_sv_iso xx.lu.translate_to.sv translate_sv_lu xx.af.translate_to.sv translate_sv_af xx.bg.translate_to.sv translate_sv_bg xx.fr.translate_to.sm translate_sm_fr xx.hr.translate_to.sv translate_sv_hr xx.sv.translate_to.sn translate_sn_sv xx.no.translate_to.ru translate_ru_no xx.fr.translate_to.sg translate_sg_fr xx.es.translate_to.sl translate_sl_es xx.bzs.translate_to.sv translate_sv_bzs xx.fr.translate_to.st translate_st_fr xx.hu.translate_to.sv translate_sv_hu xx.sv.translate_to.sg translate_sg_sv xx.sem.translate_to.sem translate_sem_sem xx.uk.translate_to.sh translate_sh_uk xx.ln.translate_to.sv translate_sv_ln xx.fi.translate_to.sk translate_sk_fi xx.ht.translate_to.sv translate_sv_ht xx.es.translate_to.st translate_st_es xx.fr.translate_to.ru translate_ru_fr xx.chk.translate_to.sv translate_sv_chk xx.fr.translate_to.sk translate_sk_fr xx.lg.translate_to.sv translate_sv_lg xx.sv.translate_to.srn translate_srn_sv xx.crs.translate_to.sv translate_sv_crs xx.uk.translate_to.ru translate_ru_uk xx.et.translate_to.ru translate_ru_et xx.et.translate_to.sv translate_sv_et xx.es.translate_to.rw translate_rw_es xx.sla.translate_to.sla translate_sla_sla xx.ru.translate_to.sl translate_sl_ru xx.fj.translate_to.sv translate_sv_fj xx.es.translate_to.sn translate_sn_es xx.lua.translate_to.sv translate_sv_lua xx.hil.translate_to.sv translate_sv_hil xx.es.translate_to.ru translate_ru_es xx.lue.translate_to.sv translate_sv_lue xx.gaa.translate_to.sv translate_sv_gaa xx.hy.translate_to.ru translate_ru_hy xx.bem.translate_to.sv translate_sv_bem xx.sv.translate_to.run translate_run_sv xx.gil.translate_to.sv translate_sv_gil xx.lus.translate_to.sv translate_sv_lus xx.he.translate_to.ru translate_ru_he xx.vi.translate_to.ru translate_ru_vi xx.he.translate_to.sv translate_sv_he xx.sv.translate_to.ru translate_ru_sv xx.fi.translate_to.ru translate_ru_fi xx.es.translate_to.sv translate_sv_es xx.es.translate_to.sg translate_sg_es xx.eo.translate_to.ru translate_ru_eo xx.lv.translate_to.sv translate_sv_lv xx.fi.translate_to.sg translate_sg_fi xx.es.translate_to.ssp translate_ssp_es xx.ilo.translate_to.sv translate_sv_ilo xx.fi.translate_to.sv translate_sv_fi xx.lt.translate_to.ru translate_ru_lt xx.bi.translate_to.sv translate_sv_bi xx.sv.translate_to.sl translate_sl_sv xx.fr.translate_to.sv translate_sv_fr xx.uk.translate_to.sl translate_sl_uk xx.fi.translate_to.sl translate_sl_fi xx.sl.translate_to.ru translate_ru_sl xx.ig.translate_to.sv translate_sv_ig xx.ase.translate_to.sv translate_sv_ase xx.eo.translate_to.sh translate_sh_eo xx.fr.translate_to.sl translate_sl_fr xx.es.translate_to.tl translate_tl_es xx.sv.translate_to.tw translate_tw_sv xx.lt.translate_to.tr translate_tr_lt xx.fi.translate_to.tll translate_tll_fi xx.sn.translate_to.sv translate_sv_sn xx.tn.translate_to.sv translate_sv_tn xx.sv.translate_to.toi translate_toi_sv xx.uk.translate_to.sv translate_sv_uk xx.tiv.translate_to.sv translate_sv_tiv xx.sk.translate_to.sv translate_sv_sk xx.ty.translate_to.sv translate_sv_ty xx.es.translate_to.toi translate_toi_es xx.rw.translate_to.sv translate_sv_rw xx.ny.translate_to.sv translate_sv_ny xx.rnd.translate_to.sv translate_sv_rnd xx.es.translate_to.tn translate_tn_es xx.sv.translate_to.tn translate_tn_sv xx.es.translate_to.tvl translate_tvl_es xx.pon.translate_to.sv translate_sv_pon xx.ve.translate_to.sv translate_sv_ve xx.fr.translate_to.tvl translate_tvl_fr xx.es.translate_to.tum translate_tum_es xx.run.translate_to.sv translate_sv_run xx.de.translate_to.tl translate_tl_de xx.fi.translate_to.tw translate_tw_fi xx.es.translate_to.ty translate_ty_es xx.fr.translate_to.toi translate_toi_fr xx.sv.translate_to.tll translate_tll_sv xx.sg.translate_to.sv translate_sv_sg xx.az.translate_to.tr translate_tr_az xx.es.translate_to.ts translate_ts_es xx.fr.translate_to.ts translate_ts_fr xx.fr.translate_to.th translate_th_fr xx.zne.translate_to.sv translate_sv_zne xx.tw.translate_to.sv translate_sv_tw xx.mh.translate_to.sv translate_sv_mh xx.pag.translate_to.sv translate_sv_pag xx.fr.translate_to.tum translate_tum_fr xx.no.translate_to.sv translate_sv_no xx.ts.translate_to.sv translate_sv_ts xx.mt.translate_to.sv translate_sv_mt xx.yo.translate_to.sv translate_sv_yo xx.fr.translate_to.to translate_to_fr xx.sv.translate_to.sv translate_sv_sv xx.fi.translate_to.toi translate_toi_fi xx.ro.translate_to.sv translate_sv_ro xx.es.translate_to.tw translate_tw_es xx.niu.translate_to.sv translate_sv_niu xx.uk.translate_to.tr translate_tr_uk xx.to.translate_to.sv translate_sv_to xx.fi.translate_to.ts translate_ts_fi xx.tll.translate_to.sv translate_sv_tll xx.fr.translate_to.tll translate_tll_fr xx.pt.translate_to.tl translate_tl_pt xx.nso.translate_to.sv translate_sv_nso xx.sq.translate_to.sv translate_sv_sq xx.sv.translate_to.tpi translate_tpi_sv xx.yap.translate_to.sv translate_sv_yap xx.sv.translate_to.tr translate_tr_sv xx.fr.translate_to.swc translate_swc_fr xx.nl.translate_to.sv translate_sv_nl xx.fi.translate_to.ty translate_ty_fi xx.fr.translate_to.tr translate_tr_fr xx.sv.translate_to.tum translate_tum_sv xx.swc.translate_to.sv translate_sv_swc xx.fi.translate_to.swc translate_swc_fi xx.eo.translate_to.tr translate_tr_eo xx.xh.translate_to.sv translate_sv_xh xx.sv.translate_to.tvl translate_tvl_sv xx.sl.translate_to.sv translate_sv_sl xx.tum.translate_to.sv translate_sv_tum xx.es.translate_to.to translate_to_es xx.fr.translate_to.tn translate_tn_fr xx.sv.translate_to.ty translate_ty_sv xx.sv.translate_to.swc translate_swc_sv xx.mos.translate_to.sv translate_sv_mos xx.ar.translate_to.tr translate_tr_ar xx.ru.translate_to.sv translate_sv_ru xx.srn.translate_to.sv translate_sv_srn xx.pis.translate_to.sv translate_sv_pis xx.pap.translate_to.sv translate_sv_pap xx.tvl.translate_to.sv translate_sv_tvl xx.sv.translate_to.to translate_to_sv xx.th.translate_to.sv translate_sv_th xx.war.translate_to.sv translate_sv_war xx.sv.translate_to.ts translate_ts_sv xx.fr.translate_to.tw translate_tw_fr xx.st.translate_to.sv translate_sv_st xx.fr.translate_to.tiv translate_tiv_fr xx.tpi.translate_to.sv translate_sv_tpi xx.fi.translate_to.tvl translate_tvl_fi xx.fr.translate_to.ty translate_ty_fr xx.sm.translate_to.sv translate_sv_sm xx.es.translate_to.swc translate_swc_es xx.sv.translate_to.tiv translate_tiv_sv xx.toi.translate_to.sv translate_sv_toi xx.mfe.translate_to.sv translate_sv_mfe xx.wls.translate_to.sv translate_sv_wls xx.umb.translate_to.sv translate_sv_umb xx.es.translate_to.tr translate_tr_es xx.es.translate_to.tll translate_tll_es xx.pt.translate_to.uk translate_uk_pt xx.it.translate_to.zh translate_zh_it xx.no.translate_to.uk translate_uk_no xx.sh.translate_to.uk translate_uk_sh xx.sv.translate_to.wls translate_wls_sv xx.pl.translate_to.uk translate_uk_pl xx.es.translate_to.yo translate_yo_es xx.es.translate_to.war translate_war_es xx.sv.translate_to.zh translate_zh_sv xx.tr.translate_to.uk translate_uk_tr xx.fi.translate_to.war translate_war_fi xx.de.translate_to.zh translate_zh_de xx.uk.translate_to.zh translate_zh_uk xx.eo.translate_to.vi translate_vi_eo xx.bg.translate_to.zh translate_zh_bg xx.es.translate_to.zne translate_zne_es xx.fr.translate_to.uk translate_uk_fr xx.zls.translate_to.zls translate_zls_zls xx.fr.translate_to.yo translate_yo_fr xx.bg.translate_to.uk translate_uk_bg xx.fr.translate_to.xh translate_xh_fr xx.ca.translate_to.uk translate_uk_ca xx.fi.translate_to.zh translate_zh_fi xx.es.translate_to.zai translate_zai_es xx.es.translate_to.uk translate_uk_es xx.nl.translate_to.uk translate_uk_nl xx.sv.translate_to.yap translate_yap_sv xx.he.translate_to.uk translate_uk_he xx.sl.translate_to.uk translate_uk_sl xx.es.translate_to.ve translate_ve_es xx.zlw.translate_to.zlw translate_zlw_zlw xx.es.translate_to.tzo translate_tzo_es xx.hu.translate_to.uk translate_uk_hu xx.de.translate_to.vi translate_vi_de xx.fi.translate_to.yo translate_yo_fi xx.ru.translate_to.uk translate_uk_ru xx.ms.translate_to.zh translate_zh_ms xx.urj.translate_to.urj translate_urj_urj xx.it.translate_to.uk translate_uk_it xx.sv.translate_to.war translate_war_sv xx.fr.translate_to.wls translate_wls_fr xx.zle.translate_to.zle translate_zle_zle xx.vi.translate_to.zh translate_zh_vi xx.es.translate_to.vsl translate_vsl_es xx.fi.translate_to.zne translate_zne_fi xx.fi.translate_to.uk translate_uk_fi xx.ru.translate_to.vi translate_vi_ru xx.nl.translate_to.zh translate_zh_nl xx.sv.translate_to.xh translate_xh_sv xx.es.translate_to.xh translate_xh_es xx.he.translate_to.zh translate_zh_he xx.fr.translate_to.war translate_war_fr xx.fr.translate_to.zne translate_zne_fr xx.sv.translate_to.yo translate_yo_sv xx.fr.translate_to.vi translate_vi_fr xx.it.translate_to.vi translate_vi_it xx.sv.translate_to.zne translate_zne_sv xx.fr.translate_to.yap translate_yap_fr xx.cs.translate_to.uk translate_uk_cs xx.es.translate_to.vi translate_vi_es xx.de.translate_to.uk translate_uk_de xx.sv.translate_to.uk translate_uk_sv Bugfixes Fixed bugs that occured when loading a model from disk. 140+ NLU Tutorials Streamlit visualizations docs The complete list of all 1100+ models &amp; pipelines in 192+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 NLU Version 3.0.2 This release contains examples and tutorials on how to visualize the 1000+ state-of-the-art NLP models provided by NLU in just 1 line of code in streamlit. It includes simple 1-liners you can sprinkle into your Streamlit app to for features like Dependency Trees, Named Entities (NER), text classification results, semantic simmilarity, embedding visualizations via ELMO, BERT, ALBERT, XLNET and much more . Additionally, improvements for T5, various resolvers have been added and models Farsi, Hebrew, Korean, and Turkish This is the ultimate NLP research tool. You can visualize and compare the results of hundreds of context aware deep learning embeddings and compare them with classical vanilla embeddings like Glove and can see with your own eyes how context is encoded by transformer models like BERT or XLNETand many more ! Besides that, you can also compare the results of the 200+ NER models John Snow Labs provides and see how peformances changes with varrying ebeddings, like Contextual, Static and Domain Specific Embeddings. Install For detailed instructions refer to the NLU install documentation here You need Open JDK 8 installed and the following python packages pip install nlu streamlit pyspark==3.0.1 sklearn plotly Problems? Connect with us on Slack! Impatient and want some action? Just run this Streamlit app, you can use it to generate python code for each NLU-Streamlit building block streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Quick Starter cheat sheet - All you need to know in 1 picture for NLU + Streamlit For NLU models to load, see the NLU Namespace or the John Snow Labs Modelshub or go straight to the source. Examples Just try out any of these. You can use the first example to generate python-code snippets which you can recycle as building blocks in your streamlit apps! Example: 01_dashboard streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Example: 02_NER streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/02_NER.py Example: 03_text_similarity_matrix streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/03_text_similarity_matrix.py Example: 04_dependency_tree streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/04_dependency_tree.py Example: 05_classifiers streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/05_classifiers.py Example: 06_token_features streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/06_token_features.py How to use NLU? All you need to know about NLU is that there is the nlu.load() method which returns a NLUPipeline object which has a .predict() that works on most common data types in the pydata stack like Pandas dataframes . Ontop of that, there are various visualization methods a NLUPipeline provides easily integrate in Streamlit as re-usable components. viz() method Overview of NLU + Streamlit buildingblocks Method Description nlu.load(&#39;&lt;Model&gt;&#39;).predict(data) Load any of the 1000+ models by providing the model name any predict on most Pythontic data strucutres like Pandas, strings, arrays of strings and more nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit(data) Display full NLU exploration dashboard, that showcases every feature avaiable with dropdown selectors for 1000+ models nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_similarity([string1, string2]) Display similarity matrix and scalar similarity for every word embedding loaded and 2 strings. nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_ner(data) Visualize predicted NER tags from Named Entity Recognizer model nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_dep_tree(data) Visualize Dependency Tree together with Part of Speech labels nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_classes(data) Display all extracted class features and confidences for every classifier loaded in pipeline nlu.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_token(data) Display all detected token features and informations in Streamlit nlu.load(&#39;&lt;Model&gt;&#39;).viz(data, write_to_streamlit=True) Display the raw visualization without any UI elements. See viz docs for more info. By default all aplicable nlu model references will be shown. nlu.enable_streamlit_caching() Enable caching the nlu.load() call. Once enabled, the nlu.load() method will automatically cached. This is recommended to run first and for large peformance gans Detailed visualizer information and API docs function pipe.viz_streamlit Display a highly configurable UI that showcases almost every feature available for Streamlit visualization with model selection dropdowns in your applications. Ths includes : Similarity Matrix &amp; Scalars &amp; Embedding Information for any of the 100+ Word Embedding Models NER visualizations for any of the 200+ Named entity recognizers Labled &amp; Unlabled Dependency Trees visualizations with Part of Speech Tags for any of the 100+ Part of Speech Models Token informations predicted by any of the 1000+ models Classification results predicted by any of the 100+ models classification models Pipeline Configuration &amp; Model Information &amp; Link to John Snow Labs Modelshub for all loaded pipelines Auto generate Python code that can be copy pasted to re-create the individual Streamlit visualization blocks. NlLU takes the first model specified as nlu.load() for the first visualization run. Once the Streamlit app is running, additional models can easily be added via the UI. It is recommended to run this first, since you can generate Python code snippets to recreate individual Streamlit visualization blocks nlu.load(&#39;ner&#39;).viz_streamlit([&#39;I love NLU and Streamlit!&#39;,&#39;I hate buggy software&#39;]) function parameters pipe.viz_streamlit Argument Type Default Description text Union [str, List[str], pd.DataFrame, pd.Series] &#39;NLU and Streamlit go together like peanutbutter and jelly&#39; Default text for the Classification, Named Entitiy Recognizer, Token Information and Dependency Tree visualizations similarity_texts Union[List[str],Tuple[str,str]] (&#39;Donald Trump Likes to part&#39;, &#39;Angela Merkel likes to party&#39;) Default texts for the Text similarity visualization. Should contain exactly 2 strings which will be compared token embedding wise. For each embedding active, a token wise similarity matrix and a similarity scalar model_selection List[str] [] List of nlu references to display in the model selector, see the NLU Namespace or the John Snow Labs Modelshub or go straight to the source for more info title str &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app sub_title str &#39;Play with over 1000+ scalable enterprise NLP models&#39; Sub title of the Streamlit app visualizers List[str] ( &quot;dependency_tree&quot;, &quot;ner&quot;, &quot;similarity&quot;, &quot;token_information&quot;, &#39;classification&#39;) Define which visualizations should be displayed. By default all visualizations are displayed. show_models_info bool True Show information for every model loaded in the bottom of the Streamlit app. show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_viz_selection bool False Show a selector in the sidebar which lets you configure which visualizations are displayed. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_code_snippets bool False Display Python code snippets above visualizations that can be used to re-create the visualization num_similarity_cols int 2 How many columns should for the layout in Streamlit when rendering the similarity matrixes. function pipe.viz_streamlit_classes Visualize the predicted classes and their confidences and additional metadata to streamlit. Aplicable with any of the 100+ classifiers nlu.load(&#39;sentiment&#39;).viz_streamlit_classes([&#39;I love NLU and Streamlit!&#39;,&#39;I love buggy software&#39;, &#39;Sign up now get a chance to win 1000$ !&#39;, &#39;I am afraid of Snakes&#39;,&#39;Unicorns have been sighted on Mars!&#39;,&#39;Where is the next bus stop?&#39;]) function parameters pipe.viz_streamlit_classes Argument Type Default Description text Union[str,list,pd.DataFrame, pd.Series, pyspark.sql.DataFrame ] &#39;I love NLU and Streamlit and sunny days!&#39; Text to predict classes for. Will predict on each input of the iteratable or dataframe if type is not str. output_level Optional[str] document Outputlevel of NLU pipeline, see pipe.predict() docsmore info include_text_col bool True Whether to include a e text column in the output table or just the prediction data title Optional[str] Text Classification Title of the Streamlit building block that will be visualized to screen metadata bool False whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info positions bool False whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_ner Visualize the predicted classes and their confidences and additional metadata to Streamlit. Aplicable with any of the 250+ NER models. You can filter which NER tags to highlight via the dropdown in the main window. Basic usage nlu.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;) Example for coloring # Color all entities of class GPE black nlu.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;,colors={&#39;PERSON&#39;:&#39;#6e992e&#39;, &#39;GPE&#39;:&#39;#000000&#39;}) function parameters pipe.viz_streamlit_ner Argument Type Default Description text str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views&#39; Text to predict classes for. ner_tags Optional[List[str]] None Tags to display. By default all tags will be displayed show_label_select bool True Whether to include the label selector show_table bool True Whether show to predicted pandas table or not title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen sub_title Optional[str] &#39;&quot;Recognize various Named Entities (NER) in text entered and filter them. You can select from over 100 languages in the dropdown. On the left side.&quot;,&#39; Sub-title of the Streamlit building block that will be visualized to screen colors Dict[str,str] {} Dict with KEY=ENTITY_LABEL and VALUE=COLOR_AS_HEX_CODE,which will change color of highlighted entities.See custom color labels docs for more info. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_text_input bool True Show text input field to input text in show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_dep_tree Visualize a typed dependency tree, the relations between tokens and part of speech tags predicted. Aplicable with any of the 100+ Part of Speech(POS) models and dep tree model nlu.load(&#39;dep.typed&#39;).viz_streamlit_dep_tree(&#39;POS tags define a grammatical label for each token and the Dependency Tree classifies Relations between the tokens&#39;) function parameters pipe.viz_streamlit_dep_tree Argument Type Default Description text str &#39;Billy likes to swim&#39; Text to predict classes for. title Optional[str] &#39;Dependency Parse Tree &amp; Part-of-speech tags&#39; Title of the Streamlit building block that will be visualized to screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_token Visualize predicted token and text features for every model loaded. You can use this with any of the 1000+ models and select them from the left dropdown. nlu.load(&#39;stemm pos spell&#39;).viz_streamlit_token(&#39;I liek pentut buttr and jelly !&#39;) function parameters pipe.viz_streamlit_token Argument Type Default Description text str &#39;NLU and Streamlit are great!&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen show_feature_select bool True Whether to include the token feature selector features Optional[List[str]] None Features to to display. By default all Features will be displayed metadata bool False Whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info output_level Optional[str] &#39;token&#39; Outputlevel of NLU pipeline, see pipe.predict() docsmore info positions bool False Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. function pipe.viz_streamlit_similarity Displays a similarity matrix, where x-axis is every token in the first text and y-axis is every token in the second text. Index i,j in the matrix describes the similarity of token-i to token-j based on the loaded embeddings and distance metrics, based on Sklearns Pariwise Metrics.. See this article for more elaboration on similarities Displays a dropdown selectors from which various similarity metrics and over 100 embeddings can be selected. -There will be one similarity matrix per metric and embedding pair selected. num_plots = num_metric*num_embeddings Also displays embedding vector information. Applicable with any of the 100+ Word Embedding models nlu.load(&#39;bert&#39;).viz_streamlit_word_similarity([&#39;I love love loooove NLU! &lt;3&#39;,&#39;I also love love looove Streamlit! &lt;3&#39;]) function parameters pipe.viz_streamlit_similarity Argument Type Default Description texts str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views.&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen similarity_matrix bool None Whether to display similarity matrix or not show_algo_select bool True Whether to show dist algo select or not show_table bool True Whether show to predicted pandas table or not threshold float 0.5 Threshold for displaying result red on screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info write_raw_pandas bool False Write the raw pandas similarity df to streamlit display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. dist_metrics List[str] [&#39;cosine&#39;] Which distance metrics to apply. If multiple are selected, there will be multiple plots for each embedding and metric. num_plots = num_metric*num_embeddings. Can use multiple at the same time, any of of cityblock,cosine,euclidean,l2,l1,manhattan,nan_euclidean. Provided via Sklearn metrics.pairwise package num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. display_scalar_similarities bool False Display scalar simmilarities in an additional field. display_similarity_summary bool False Display summary of all similarities for all embeddings and metrics. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLU namespace structure. ## In addition have added some new features to our T5 Transformer annotator to help with longer and more accurate text generation, trained some new multi-lingual models and pipelines in Farsi, Hebrew, Korean, and Turkish. T5 Model Improvements Add 6 new features to T5Transformer for longer and better text generation doSample: Whether or not to use sampling; use greedy decoding otherwise temperature: The value used to module the next token probabilities topK: The number of highest probability vocabulary tokens to keep for top-k-filtering topP: If set to float &lt; 1, only the most probable tokens with probabilities that add up to top_p or higher are kept for generation repetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See CTRL: A Conditional Transformer Language Model for Controllable Generation paper for more details noRepeatNgramSize: If set to int &gt; 0, all ngrams of that size can only occur once New Open Source Model in NLU 3.0.2 New multilingual models and pipelines for Farsi, Hebrew, Korean, and Turkish Model NLU Reference Spark NLP Reference Lang ClassifierDLModel tr.classify.news classifierdl_bert_news tr UniversalSentenceEncoder xx.use.multi tfhub_use_multi xx UniversalSentenceEncoder xx.use.multi_lg tfhub_use_multi_lg xx Pipeline NLU Reference Spark NLP Reference Lang PretrainedPipeline fa.ner.dl recognize_entities_dl fa PretrainedPipeline he.explain_document explain_document_lg he PretrainedPipeline ko.explain_document explain_document_lg ko New Healthcare Models in NLU 3.0.2 Five new resolver models: en.resolve.umls: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms. en.resolve.umls.findings: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings. en.resolve.loinc: Map clinical NER entities to LOINC codes using sbiobert. en.resolve.loinc.bluebert: Map clinical NER entities to LOINC codes using sbluebert. en.resolve.HPO: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code: Related NLU Notebook Model NLU Reference Spark NLP Reference Resolver en.resolve.umls sbiobertresolve_umls_major_concepts Resolver en.resolve.umls.findings sbiobertresolve_umls_findings Resolver en.resolve.loinc sbiobertresolve_loinc Resolver en.resolve.loinc.biobert sbiobertresolve_loinc Resolver en.resolve.loinc.bluebert sbluebertresolve_loinc Resolver en.resolve.HPO sbiobertresolve_HPO en.resolve.HPO nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.HPO&#39;).viz(&quot;&quot;&quot;These disorders include cancer, bipolar disorder, schizophrenia, autism, Cri-du-chat syndrome, myopia, cortical cataract-linked Alzheimer&#39;s disease, and infectious diseases&quot;&quot;&quot;) en.resolve.loinc.bluebert nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc.bluebert&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.umls.findings nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.umls.findings&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot; ) en.resolve.umls nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.umls&#39;).viz(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.loinc nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc&#39;).predict(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) en.resolve.loinc.biobert nlu.load(&#39;med_ner.jsl.wip.clinical en.resolve.loinc.biobert&#39;).predict(&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (TSS2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;) 140+ tutorials New Streamlit visualizations docs The complete list of all 1100+ models &amp; pipelines in 192+ languages is available on Models Hub. Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : !wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.1 NLU Version 3.0.1 We are very excited to announce NLU 3.0.1 has been released! This is one of the most visually appealing releases, with the integration of the Spark-NLP-Display library and visualizations for dependency trees, entity resolution, entity assertion, relationship between entities and named entity recognition. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+ Finally, new multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese are now available. New Features and Enhancements 1 line to visualization for NER, Dependency, Resolution, Assertion and Relation via Spark-NLP-Display integration Improved column naming schema Over 140 + NLU tutorial Notebooks updated and improved to reflect latest changes in NLU 3.0.0 + New multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese Improved Column Name generation NLU categorized each internal component now with boolean labels for name_deductable and always_name_deductable . Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the pipe and there are multiple components of same type, i.e. multiple NER models, NLU will deduct a base name for the final output columns from the NLU reference each NER model is pointing to. If on the other hand, there is only one NER model in the pipeline, only the default ner column prefixed will be generated. For some components, like embeddings and classifiers are now defined as always_name_deductable, for those NLU will always try to infer a meaningful base name for the output columns. Newly trained component output columns will now be prefixed with trained_&lt;type&gt; , for types pos , ner, cLassifier, sentiment and multi_classifier Enhanced offline mode You can still load a model from a path as usual with nlu.load(path=model_path) and output columns will be suffixed with from_disk You can now optionally also specify request parameter during load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of from_disk, i.e. by calling nlu.load(request =&#39;en.embed_sentence.biobert.pubmed_pmc_base_cased&#39;, path=model_path) NLU visualization The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don’t need to worry about anything! See the visualization tutorial notebook and visualization docs for more info. NER visualization Applicable to any of the 100+ NER models! See here for an overview nlu.load(&#39;ner&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions.&quot;) Dependency tree visualization Visualizes the structure of the labeled dependency tree and part of speech tags nlu.load(&#39;dep.typed&#39;).viz(&quot;Billy went to the mall&quot;) #Bigger Example nlu.load(&#39;dep.typed&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions but they both love John Snow Labs software&quot;) Assertion status visualization Visualizes asserted statuses and entities. Applicable to any of the 10 + Assertion models! See here for an overview nlu.load(&#39;med_ner.clinical assert&#39;).viz(&quot;The MRI scan showed no signs of cancer in the left lung&quot;) #bigger example data =&#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&#39; nlu.load(&#39;med_ner.clinical assert&#39;).viz(data) Relationship between entities visualization Visualizes the extracted entities between relationship. Applicable to any of the 20 + Relation Extractor models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical relation.temporal_events&#39;).viz(&#39;The patient developed cancer after a mercury poisoning in 1999 &#39;) # bigger example data = &#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&#39; pipe = nlu.load(&#39;med_ner.jsl.wip.clinical relation.clinical&#39;).viz(data) Entity Resolution visualization for chunks Visualizes resolutions of entities Applicable to any of the 100+ Resolver models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(&quot;He took Prevacid 30 mg daily&quot;) # bigger example data = &quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret &#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&quot; nlu.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(data) Entity Resolution visualization for sentences Visualizes resolutions of entities in sentences Applicable to any of the 100+ Resolver models See here for an overview nlu.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(&#39;She was diagnosed with a respiratory congestion&#39;) # bigger example data = &#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&#39; nlu.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(data) Configure visualizations Define custom colors for labels Some entity and relation labels will be highlighted with a pre-defined color, which you can find here. For labels that have no color defined, a random color will be generated. You can define colors for labels manually, by specifying via the viz_colors parameter and defining hex color codes in a dictionary that maps labels to colors . data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Define custom colors for labels viz_colors={&#39;STRENGTH&#39;:&#39;#800080&#39;, &#39;DRUG_BRANDNAME&#39;:&#39;#77b5fe&#39;, &#39;GENDER&#39;:&#39;#77ffe&#39;} nlu.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,viz_colors =viz_colors) Filter entities that get highlighted By default every entity class will be visualized. The labels_to_viz can be used to define a set of labels to highlight. Applicable for ner, resolution and assert. data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Filter wich NER label to viz labels_to_viz=[&#39;SYMPTOM&#39;] nlu.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,labels_to_viz=labels_to_viz) New models New multilingual models for Afrikaans, Welsh, Maltese, Tamil, andVietnamese nlu.load() Refrence Spark NLP Refrence vi.lemma lemma mt.lemma lemma ta.lemma lemma af.lemma lemma af.pos pos_afribooms cy.lemma lemma Reworked and updated NLU tutorial notebooks All of the 140+ NLU tutorial Notebooks have been updated and reworked to reflect the latest changes in NLU 3.0.0+ Bugfixes Fixed a bug that caused resolution algorithms output level to be inferred incorrectly Fixed a bug that caused stranger cols got dropped Fixed a bug that caused endings to miss when .predict(position=True) was specified Fixed a bug that caused pd.Series to be converted incorrectly internally Fixed a bug that caused output level transformations to crash Fixed a bug that caused verbose mode not to turn of properly after turning it on. fixed a bug that caused some models to crash when loaded for HDD 140+ updates tutorials Updated visualization docs Models Hub with new models Spark NLP publications NLU in Action NLU documentation Discussions Engage with other community members, share ideas, and show off how you use Spark NLP and NLU! Install NLU in 1 line!aaa * Install NLU on Google Colab : ! wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU on Kaggle : ! wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in NLU 3.0 Release and much more We are incredible excited to announce the release of NLU 3.0.0 which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU. These models are the most accurate in their domains and highly scalable in Spark clusters. In addition, Spark 3.0.X and Spark 3.1.X is now supported, together with Python3.8 This is enabled by the the amazing Spark NLP3.0.1 and Spark NLP for Healthcare 3.0.1 releases. New Features Over 200 new models for the healthcare domain 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models Spark 3.0.X and 3.1.X support Python 3.8 Support New Output level relation 1 Line to install NLU just run !wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash Various new EMR and Databricks versions supported GPU Mode, more then 600% speedup by enabling GPU mode. Authorized mode for licensed features New Documentation NLU for Healthcare Examples Instrunctions to authorize your environment to use Licensed features New Notebooks Medical Named Entity Extraction (NER) notebook Relation extraction notebook Entity Resolution overview notebook Assertion overview notebook De-Identification overview notebook Graph NLU tutorial for the GRAPH+AI Summit hosted by Tigergraph AssertionDLModels Language nlu.load() reference Spark NLP Model reference English assert assertion_dl English assert.biobert assertion_dl_biobert English assert.healthcare assertion_dl_healthcare English assert.large assertion_dl_large New Word Embeddings Language nlu.load() reference Spark NLP Model reference English embed.glove.clinical embeddings_clinical English embed.glove.biovec embeddings_biovec English embed.glove.healthcare embeddings_healthcare English embed.glove.healthcare_100d embeddings_healthcare_100d English en.embed.glove.icdoem embeddings_icdoem English en.embed.glove.icdoem_2ng embeddings_icdoem_2ng Sentence Entity resolvers Language nlu.load() reference Spark NLP Model reference English embed_sentence.biobert.mli sbiobert_base_cased_mli English resolve sbiobertresolve_cpt English resolve.cpt sbiobertresolve_cpt English resolve.cpt.augmented sbiobertresolve_cpt_augmented English resolve.cpt.procedures_augmented sbiobertresolve_cpt_procedures_augmented English resolve.hcc.augmented sbiobertresolve_hcc_augmented English resolve.icd10cm sbiobertresolve_icd10cm English resolve.icd10cm.augmented sbiobertresolve_icd10cm_augmented English resolve.icd10cm.augmented_billable sbiobertresolve_icd10cm_augmented_billable_hcc English resolve.icd10pcs sbiobertresolve_icd10pcs English resolve.icdo sbiobertresolve_icdo English resolve.rxcui sbiobertresolve_rxcui English resolve.rxnorm sbiobertresolve_rxnorm English resolve.snomed sbiobertresolve_snomed_auxConcepts English resolve.snomed.aux_concepts sbiobertresolve_snomed_auxConcepts English resolve.snomed.aux_concepts_int sbiobertresolve_snomed_auxConcepts_int English resolve.snomed.findings sbiobertresolve_snomed_findings English resolve.snomed.findings_int sbiobertresolve_snomed_findings_int RelationExtractionModel Language nlu.load() reference Spark NLP Model reference English relation.posology posology_re English relation redl_bodypart_direction_biobert English relation.bodypart.direction redl_bodypart_direction_biobert English relation.bodypart.problem redl_bodypart_problem_biobert English relation.bodypart.procedure redl_bodypart_procedure_test_biobert English relation.chemprot redl_chemprot_biobert English relation.clinical redl_clinical_biobert English relation.date redl_date_clinical_biobert English relation.drug_drug_interaction redl_drug_drug_interaction_biobert English relation.humen_phenotype_gene redl_human_phenotype_gene_biobert English relation.temporal_events redl_temporal_events_biobert NERDLModels Language nlu.load() reference Spark NLP Model reference English med_ner.ade.clinical ner_ade_clinical English med_ner.ade.clinical_bert ner_ade_clinicalbert English med_ner.ade.ade_healthcare ner_ade_healthcare English med_ner.anatomy ner_anatomy English med_ner.anatomy.biobert ner_anatomy_biobert English med_ner.anatomy.coarse ner_anatomy_coarse English med_ner.anatomy.coarse_biobert ner_anatomy_coarse_biobert English med_ner.aspect_sentiment ner_aspect_based_sentiment English med_ner.bacterial_species ner_bacterial_species English med_ner.bionlp ner_bionlp English med_ner.bionlp.biobert ner_bionlp_biobert English med_ner.cancer ner_cancer_genetics Englishs med_ner.cellular ner_cellular English med_ner.cellular.biobert ner_cellular_biobert English med_ner.chemicals ner_chemicals English med_ner.chemprot ner_chemprot_biobert English med_ner.chemprot.clinical ner_chemprot_clinical English med_ner.clinical ner_clinical English med_ner.clinical.biobert ner_clinical_biobert English med_ner.clinical.noncontrib ner_clinical_noncontrib English med_ner.diseases ner_diseases English med_ner.diseases.biobert ner_diseases_biobert English med_ner.diseases.large ner_diseases_large English med_ner.drugs ner_drugs English med_ner.drugsgreedy ner_drugs_greedy English med_ner.drugs.large ner_drugs_large English med_ner.events_biobert ner_events_biobert English med_ner.events_clinical ner_events_clinical English med_ner.events_healthcre ner_events_healthcare English med_ner.financial_contract ner_financial_contract English med_ner.healthcare ner_healthcare English med_ner.human_phenotype.gene_biobert ner_human_phenotype_gene_biobert English med_ner.human_phenotype.gene_clinical ner_human_phenotype_gene_clinical English med_ner.human_phenotype.go_biobert ner_human_phenotype_go_biobert English med_ner.human_phenotype.go_clinical ner_human_phenotype_go_clinical English med_ner.jsl ner_jsl English med_ner.jsl.biobert ner_jsl_biobert English med_ner.jsl.enriched ner_jsl_enriched English med_ner.jsl.enriched_biobert ner_jsl_enriched_biobert English med_ner.measurements ner_measurements_clinical English med_ner.medmentions ner_medmentions_coarse English med_ner.posology ner_posology English med_ner.posology.biobert ner_posology_biobert English med_ner.posology.greedy ner_posology_greedy English med_ner.posology.healthcare ner_posology_healthcare English med_ner.posology.large ner_posology_large English med_ner.posology.large_biobert ner_posology_large_biobert English med_ner.posology.small ner_posology_small English med_ner.radiology ner_radiology English med_ner.radiology.wip_clinical ner_radiology_wip_clinical English med_ner.risk_factors ner_risk_factors English med_ner.risk_factors.biobert ner_risk_factors_biobert English med_ner.i2b2 nerdl_i2b2 English med_ner.tumour nerdl_tumour_demo English med_ner.jsl.wip.clinical jsl_ner_wip_clinical English med_ner.jsl.wip.clinical.greedy jsl_ner_wip_greedy_clinical English med_ner.jsl.wip.clinical.modifier jsl_ner_wip_modifier_clinical English med_ner.jsl.wip.clinical.rd jsl_rd_ner_wip_greedy_clinical De-Identification Models Language nlu.load() reference Spark NLP Model reference English med_ner.deid.augmented ner_deid_augmented English med_ner.deid.biobert ner_deid_biobert English med_ner.deid.enriched ner_deid_enriched English med_ner.deid.enriched_biobert ner_deid_enriched_biobert English med_ner.deid.large ner_deid_large English med_ner.deid.sd ner_deid_sd English med_ner.deid.sd_large ner_deid_sd_large English med_ner.deid nerdl_deid English med_ner.deid.synthetic ner_deid_synthetic English med_ner.deid.dl ner_deidentify_dl English en.de_identify deidentify_rb English de_identify.rules deid_rules English de_identify.clinical deidentify_enriched_clinical English de_identify.large deidentify_large English de_identify.rb deidentify_rb English de_identify.rb_no_regex deidentify_rb_no_regex Chunk resolvers Language nlu.load() reference Spark NLP Model reference English resolve_chunk.athena_conditions chunkresolve_athena_conditions_healthcare English resolve_chunk.cpt_clinical chunkresolve_cpt_clinical English resolve_chunk.icd10cm.clinical chunkresolve_icd10cm_clinical English resolve_chunk.icd10cm.diseases_clinical chunkresolve_icd10cm_diseases_clinical English resolve_chunk.icd10cm.hcc_clinical chunkresolve_icd10cm_hcc_clinical English resolve_chunk.icd10cm.hcc_healthcare chunkresolve_icd10cm_hcc_healthcare English resolve_chunk.icd10cm.injuries chunkresolve_icd10cm_injuries_clinical English resolve_chunk.icd10cm.musculoskeletal chunkresolve_icd10cm_musculoskeletal_clinical English resolve_chunk.icd10cm.neoplasms chunkresolve_icd10cm_neoplasms_clinical English resolve_chunk.icd10cm.poison chunkresolve_icd10cm_poison_ext_clinical English resolve_chunk.icd10cm.puerile chunkresolve_icd10cm_puerile_clinical English resolve_chunk.icd10pcs.clinical chunkresolve_icd10pcs_clinical English resolve_chunk.icdo.clinical chunkresolve_icdo_clinical English resolve_chunk.loinc chunkresolve_loinc_clinical English resolve_chunk.rxnorm.cd chunkresolve_rxnorm_cd_clinical English resolve_chunk.rxnorm.in chunkresolve_rxnorm_in_clinical English resolve_chunk.rxnorm.in_healthcare chunkresolve_rxnorm_in_healthcare English resolve_chunk.rxnorm.sbd chunkresolve_rxnorm_sbd_clinical English resolve_chunk.rxnorm.scd chunkresolve_rxnorm_scd_clinical English resolve_chunk.rxnorm.scdc chunkresolve_rxnorm_scdc_clinical English resolve_chunk.rxnorm.scdc_healthcare chunkresolve_rxnorm_scdc_healthcare English resolve_chunk.rxnorm.xsmall.clinical chunkresolve_rxnorm_xsmall_clinical English resolve_chunk.snomed.findings chunkresolve_snomed_findings_clinical New Classifiers Language nlu.load() reference Spark NLP Model reference English classify.icd10.clinical classifier_icd10cm_hcc_clinical English classify.icd10.healthcare classifier_icd10cm_hcc_healthcare English classify.ade.biobert classifierdl_ade_biobert English classify.ade.clinical classifierdl_ade_clinicalbert English classify.ade.conversational classifierdl_ade_conversational_biobert English classify.gender.biobert classifierdl_gender_biobert English classify.gender.sbert classifierdl_gender_sbert English classify.pico classifierdl_pico_biobert German Medical models nlu.load() reference Spark NLP Model reference [embed] w2v_cc_300d [embed.w2v] w2v_cc_300d [resolve_chunk] chunkresolve_ICD10GM [resolve_chunk.icd10gm] chunkresolve_ICD10GM resolve_chunk.icd10gm.2021 chunkresolve_ICD10GM_2021 med_ner.legal ner_legal med_ner ner_healthcare med_ner.healthcare ner_healthcare med_ner.healthcare_slim ner_healthcare_slim med_ner.traffic ner_traffic Spanish Medical models nlu.load() reference Spark NLP Model reference embed.scielo.150d embeddings_scielo_150d embed.scielo.300d embeddings_scielo_300d embed.scielo.50d embeddings_scielo_50d embed.scielowiki.150d embeddings_scielowiki_150d embed.scielowiki.300d embeddings_scielowiki_300d embed.scielowiki.50d embeddings_scielowiki_50d embed.sciwiki.150d embeddings_sciwiki_150d embed.sciwiki.300d embeddings_sciwiki_300d embed.sciwiki.50d embeddings_sciwiki_50d med_ner ner_diag_proc med_ner.neoplasm ner_neoplasms med_ner.diag_proc ner_diag_proc GPU Mode You can now enable NLU GPU mode by setting gpu=true while loading a model. I.e. nlu.load(&#39;train.sentiment&#39; gpu=True) . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode. Output Level Relation This new output level is used for relation extractors and will give you 1 row per relation extracted. Bug fixes Fixed a bug that caused loading NLU models in offline mode not to work in some occasions Install NLU in 1 line! * Install NLU on Google Colab : !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash * Install NLU via Pip : ! pip install nlu pyspark==3.0.3 Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github Suggestions or Questions? Contact us in Slack! NLU Version 1.1.3 Intent and Action Classification, analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text, and much more in NLU 1.1.3 We are very excited to announce that the latest NLU release comes with a new pretrained Intent Classifier and NER Action Extractor for text related to music, restaurants, and movies trained on the SNIPS dataset. Make sure to check out the models hub and the easy 1-liners for more info! In addition to that, new NER and Embedding models for Bengali are now available Finally, there is a new NLU Webinar with 9 accompanying tutorial notebooks which teach you a lot of things and is segmented into the following parts : Part1: Easy 1 Liners Spell checking/Sentiment/POS/NER/ BERTtology embeddings Part2: Data analysis and NLP tasks on Crypto News Headline dataset Preprocessing and extracting Emotions, Keywords, Named Entities and visualize them Part3: NLU Multi-Lingual 1 Liners with Microsoft’s Marian Models Translate between 200+ languages (and classify lang afterward) Part 4: Data analysis and NLP tasks on Chinese News Article Dataset Word Segmentation, Lemmatization, Extract Keywords, Named Entities and translate to english Part 5: Train a sentiment Classifier that understands 100+ Languages Train on a french sentiment dataset and predict the sentiment of 100+ languages with language-agnostic BERT Sentence Embedding Part 6: Question answering, Summarization, Squad and more with Google’s T5 T5 Question answering and 18 + other NLP tasks (SQUAD / GLUE / SUPER GLUE) New Models NLU 1.1.3 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Bengali bn.ner.cc_300d bengaliner_cc_300d NerDLModel Bengali bn.embed bengali_cc_300d NerDLModel Bengali bn.embed.cc_300d bengali_cc_300d Word Embeddings Model (Alias) Bengali bn.embed.glove bengali_cc_300d Word Embeddings Model (Alias) NLU 1.1.3 New English Models Language nlu.load() reference Spark NLP Model reference Type English en.classify.snips nerdl_snips_100d NerDLModel English en.ner.snips classifierdl_use_snips ClassifierDLModel New NLU Webinar State-of-the-art Natural Language Processing for 200+ Languages with 1 Line of code Talk Abstract Learn to harness the power of 1,000+ production-grade &amp; scalable NLP models for 200+ languages - all available with just 1 line of Python code by leveraging the open-source NLU library, which is powered by the widely popular Spark NLP. John Snow Labs has delivered over 80 releases of Spark NLP to date, making it the most widely used NLP library in the enterprise and providing the AI community with state-of-the-art accuracy and scale for a variety of common NLP tasks. The most recent releases include pre-trained models for over 200 languages - including languages that do not use spaces for word segmentation algorithms like Chinese, Japanese, and Korean, and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. All software and models are free and open source under an Apache 2.0 license. This webinar will show you how to leverage the multi-lingual capabilities of Spark NLP &amp; NLU - including automated language detection for up to 375 languages, and the ability to perform translation, named entity recognition, stopword removal, lemmatization, and more in a variety of language families. We will create Python code in real-time and solve these problems in just 30 minutes. The notebooks will then be made freely available online. You can watch the video here, NLU 1.1.3 New Notebooks and tutorials New Webinar Notebooks NLU basics, easy 1-liners (Spellchecking, sentiment, NER, POS, BERT Analyze Crypto News dataset with Keyword extraction, NER, Emotional distribution, and stemming Translate Crypto News dataset between 300 Languages with the Marian Model (German, French, Hebrew examples) Translate Crypto News dataset between 300 Languages with the Marian Model (Hindi, Russian, Chinese examples) Analyze Chinese News Headlines with Chinese Word Segmentation, Lemmatization, NER, and Keyword extraction Train a Sentiment Classifier that will understand 100+ languages on just a French Dataset with the powerful Language Agnostic Bert Embeddings Summarize text and Answer Questions with T5 Solve any task in 1 line from SQUAD, GLUE and SUPER GLUE with T5 Overview of models for various languages New easy NLU 1-liners in NLU 1.1.3 Detect actions in general commands related to music, restaurant, movies. nlu.load(&quot;en.classify.snips&quot;).predict(&quot;book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri&quot;,output_level = &quot;document&quot;) outputs : ner_confidence entities document Entities_Classes [1.0, 1.0, 0.9997000098228455, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990000128746033, 1.0, 1.0, 1.0, 0.9965000152587891, 0.9998999834060669, 0.9567000269889832, 1.0, 1.0, 1.0, 0.9980000257492065, 0.9991999864578247, 0.9988999962806702, 1.0, 1.0, 0.9998999834060669] [‘nona gray myrtle and alison’, ‘top-rated’, ‘brasserie’, ‘distant’, ‘wilson av’, ‘nov the 4th 2030’, ‘ouzeri’] book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri [‘party_size_description’, ‘sort’, ‘restaurant_type’, ‘spatial_relation’, ‘poi’, ‘timeRange’, ‘cuisine’] Named Entity Recognition (NER) Model in Bengali (bengaliner_cc_300d) # Bengali for: &#39;Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.&#39; nlu.load(&quot;bn.ner.cc_300d&quot;).predict(&quot;১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন&quot;,output_level = &quot;document&quot;) outputs : ner_confidence entities Entities_Classes document [0.9987999796867371, 0.9854000210762024, 0.8604000210762024, 0.6686999797821045, 0.5289999842643738, 0.7009999752044678, 0.7684999704360962, 0.9979000091552734, 0.9976000189781189, 0.9930999875068665, 0.9994000196456909, 0.9879000186920166, 0.7407000064849854, 0.9215999841690063, 0.7657999992370605, 0.39419999718666077, 0.9124000072479248, 0.9932000041007996, 0.9919999837875366, 0.995199978351593, 0.9991999864578247] [‘সালে’, ‘ইয়াজউদ্দিন আহম্মেদ’, ‘মুন্সিগঞ্জ উচ্চ বিদ্যালয়’, ‘সালে’, ‘মুন্সিগঞ্জ হরগঙ্গা কলেজ’] [‘TIME’, ‘PER’, ‘ORG’, ‘TIME’, ‘ORG’] ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন Identify intent in general text - SNIPS dataset nlu.load(&quot;en.ner.snips&quot;).predict(&quot;I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area&quot;,output_level = &quot;document&quot;) outputs : document snips snips_confidence I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area BookRestaurant 1 Word Embeddings for Bengali (bengali_cc_300d) # Bengali for : &#39;Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.&#39; nlu.load(&quot;bn.embed&quot;).predict(&quot;১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন&quot;,output_level = &quot;document&quot;) outputs : document bn_embed_embeddings ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন [-0.0828 0.0683 0.0215 … 0.0679 -0.0484…] NLU 1.1.3 Enhancements Added automatic conversion to Sentence Embeddings of Word Embeddings when there is no Sentence Embedding Avaiable and a model needs the converted version to run. NLU 1.1.3 Bug Fixes Fixed a bug that caused ur.sentiment NLU pipeline to build incorrectly Fixed a bug that caused sentiment.imdb.glove NLU pipeline to build incorrectly Fixed a bug that caused en.sentiment.glove.imdb NLU pipeline to build incorrectly Fixed a bug that caused Spark 2.3.X environments to crash. NLU Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github Suggestions or Questions? Contact us in Slack! NLU Version 1.1.2 Hindi WordEmbeddings , Bengali Named Entity Recognition (NER), 30+ new models, analyze Crypto news with John Snow Labs NLU 1.1.2 We are very happy to announce NLU 1.1.2 has been released with the integration of 30+ models and pipelines Bengali Named Entity Recognition, Hindi Word Embeddings, and state-of-the-art transformer based OntoNotes models and pipelines from the incredible Spark NLP 2.7.3 Release in addition to a few bugfixes. In addition to that, there is a new NLU Webinar video showcasing in detail how to use NLU to analyze a crypto news dataset to extract keywords unsupervised and predict sentimential/emotional distributions of the dataset and much more! Python’s NLU library: 1,000+ models, 200+ Languages, State of the Art Accuracy, 1 Line of code - NLU NYC/DC NLP Meetup Webinar Using just 1 line of Python code by leveraging the NLU library, which is powered by the award-winning Spark NLP. This webinar covers, using live coding in real-time, how to deliver summarization, translation, unsupervised keyword extraction, emotion analysis, question answering, spell checking, named entity recognition, document classification, and other common NLP tasks. T his is all done with a single line of code, that works directly on Python strings or pandas data frames. Since NLU is based on Spark NLP, no code changes are required to scale processing to multi-core or cluster environment - integrating natively with Ray, Dask, or Spark data frames. The recent releases for Spark NLP and NLU include pre-trained models for over 200 languages and language detection for 375 languages. This includes 20 languages families; non-Latin alphabets; languages that do not use spaces for word segmentation like Chinese, Japanese, and Korean; and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. We’ll also cover some of the algorithms and models that are included. The code notebooks will be freely available online. NLU 1.1.2 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Bengali bn.ner ner_jifs_glove_840B_300d Word Embeddings Model (Alias) Bengali bn.ner.glove ner_jifs_glove_840B_300d Word Embeddings Model (Alias) Hindi hi.embed hindi_cc_300d NerDLModel Bengali bn.lemma lemma Lemmatizer Japanese ja.lemma lemma Lemmatizer Bihari bh.lemma lemma Lemma Amharic am.lemma lemma Lemma NLU 1.1.2 New English Models and Pipelines Language nlu.load() reference Spark NLP Model reference Type English en.ner.onto.bert.small_l2_128 onto_small_bert_L2_128 NerDLModel English en.ner.onto.bert.small_l4_256 onto_small_bert_L4_256 NerDLModel English en.ner.onto.bert.small_l4_512 onto_small_bert_L4_512 NerDLModel English en.ner.onto.bert.small_l8_512 onto_small_bert_L8_512 NerDLModel English en.ner.onto.bert.cased_base onto_bert_base_cased NerDLModel English en.ner.onto.bert.cased_large onto_bert_large_cased NerDLModel English en.ner.onto.electra.uncased_small onto_electra_small_uncased NerDLModel English en.ner.onto.electra.uncased_base onto_electra_base_uncased NerDLModel English en.ner.onto.electra.uncased_large onto_electra_large_uncased NerDLModel English en.ner.onto.bert.tiny onto_recognize_entities_bert_tiny Pipeline English en.ner.onto.bert.mini onto_recognize_entities_bert_mini Pipeline English en.ner.onto.bert.small onto_recognize_entities_bert_small Pipeline English en.ner.onto.bert.medium onto_recognize_entities_bert_medium Pipeline English en.ner.onto.bert.base onto_recognize_entities_bert_base Pipeline English en.ner.onto.bert.large onto_recognize_entities_bert_large Pipeline English en.ner.onto.electra.small onto_recognize_entities_electra_small Pipeline English en.ner.onto.electra.base onto_recognize_entities_electra_base Pipeline English en.ner.onto.large onto_recognize_entities_electra_large Pipeline New Tutorials and Notebooks NYC/DC NLP Meetup Webinar video analyze Crypto News, Unsupervised Keywords, Translate between 300 Languages, Question Answering, Summerization, POS, NER in 1 line of code in almost just 20 minutes NLU basics POS/NER/Sentiment Classification/BERTology Embeddings Explore Crypto Newsarticle dataset, unsupervised Keyword extraction, Stemming, Emotion/Sentiment distribution Analysis Translate between more than 300 Languages in 1 line of code with the Marian Models New NLU 1.1.2 Models Showcase Notebooks, Bengali NER, Hindi Embeddings, 30 new_models NLU 1.1.2 Bug Fixes Fixed a bug that caused NER confidences not beeing extracted Fixed a bug that caused nlu.load(‘spell’) to crash Fixed a bug that caused Uralic/Estonian/ET language models not to be loaded properly New Easy NLU 1-liners in 1.1.2 Named Entity Recognition for Bengali (GloVe 840B 300d) #Bengali for : It began to be widely used in the United States in the early &#39;90s. nlu.load(&quot;bn.ner&quot;).predict(&quot;৯০ এর দশকের শুরুর দিকে বৃহৎ আকারে মার্কিন যুক্তরাষ্ট্রে এর প্রয়োগের প্রক্রিয়া শুরু হয়&#39;&quot;) output : entities token Entities_classes ner_confidence [‘মার্কিন যুক্তরাষ্ট্রে’] ৯০ [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] এর [‘LOC’] 0.9999 [‘মার্কিন যুক্তরাষ্ট্রে’] দশকের [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] শুরুর [‘LOC’] 0.9969 [‘মার্কিন যুক্তরাষ্ট্রে’] দিকে [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] বৃহৎ [‘LOC’] 0.9994 [‘মার্কিন যুক্তরাষ্ট্রে’] আকারে [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] মার্কিন [‘LOC’] 0.9602 [‘মার্কিন যুক্তরাষ্ট্রে’] যুক্তরাষ্ট্রে [‘LOC’] 0.4134 [‘মার্কিন যুক্তরাষ্ট্রে’] এর [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] প্রয়োগের [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] প্রক্রিয়া [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] শুরু [‘LOC’] 0.9999 [‘মার্কিন যুক্তরাষ্ট্রে’] হয় [‘LOC’] 1 [‘মার্কিন যুক্তরাষ্ট্রে’] ’ [‘LOC’] 1 Bengali Lemmatizer #Bengali for : One morning in the marble-decorated building of Vaidyanatha, an obese monk was engaged in the enchantment of Duis and the milk service of one and a half Vaidyanatha. Give me two to eat nlu.load(&quot;bn.lemma&quot;).predict(&quot;একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও&quot;) output : lemma document [‘একদিন’, ‘প্রাতঃ’, ‘বৈদ্যনাথ’, ‘মার্বলমণ্ডিত’, ‘দালান’, ‘এক’, ‘স্থূলউদর’, ‘সন্ন্যাসী’, ‘দুইসের’, ‘মোহনভোগ’, ‘এবং’, ‘দেড়সের’, ‘দুগ্ধ’, ‘সেবা’, ‘নিযুক্ত’, ‘আছে’, ‘বৈদ্যনাথ’, ‘গা’, ‘একখান’, ‘চাদর’, ‘দেওয়া’, ‘জোড়কর’, ‘একান্ত’, ‘বিনীতভাব’, ‘ভূতল’, ‘বসা’, ‘ভক্তিভরা’, ‘পবিত্র’, ‘ভোজনব্যাপার’, ‘নিরীক্ষণ’, ‘করা’, ‘এমন’, ‘সময়’, ‘কোনোমত’, ‘দ্বারী’, ‘দৃষ্টি’, ‘এড়ানো’, ‘জীর্ণদেহ’, ‘বালক’, ‘সহিত’, ‘এক’, ‘অতি’, ‘শীর্ণকায়া’, ‘রমণী’, ‘গৃহ’, ‘প্রবেশ’, ‘বিশ্বাস’, ‘ক্ষীণস্বর’, ‘কহা’, ‘বাবু’, ‘দুই’, ‘খাওয়া’, ‘দাওয়া’] একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও Japanese Lemmatizer #Japanese for : Some residents were uncomfortable with this, but it seems that no one is now openly protesting or protesting. nlu.load(&quot;ja.lemma&quot;).predict(&quot;これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。&quot;) output : lemma document [‘これ’, ‘にる’, ‘不快’, ‘感’, ‘を’, ‘示す’, ‘住民’, ‘はる’, ‘いる’, ‘まする’, ‘たる’, ‘がる’, ‘,’, ‘現在’, ‘,’, ‘表立つ’, ‘てる’, ‘反対’, ‘やる’, ‘抗議’, ‘のる’, ‘声’, ‘を’, ‘挙げる’, ‘てる’, ‘いる’, ‘住民’, ‘はる’, ‘いる’, ‘なぐ’, ‘よう’, ‘です’, ‘。’] これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。 Amharic Lemmatizer #Aharic for : Bookmark the permalink. nlu.load(&quot;am.lemma&quot;).predict(&quot;መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ።&quot;) output : lemma document [‘’, ‘መጽሐፍ’, ‘ኡ’, ‘ን’, ‘’, ‘አስያዝ’, ‘ኧ’, ‘ኣት’, ‘።’] መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ። Bhojpuri Lemmatizer #Bhojpuri for : In this event, participation of World Bhojpuri Conference, Purvanchal Ekta Manch, Veer Kunwar Singh Foundation, Purvanchal Bhojpuri Mahasabha, and Herf - Media. nlu.load(&quot;bh.lemma&quot;).predict(&quot;एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा ।&quot;) output : lemma document [‘एह’, ‘आयोजन’, ‘में’, ‘विश्व’, ‘भोजपुरी’, ‘सम्मेलन’, ‘COMMA’, ‘पूर्वांचल’, ‘एकता’, ‘मंच’, ‘COMMA’, ‘वीर’, ‘कुँवर’, ‘सिंह’, ‘फाउन्डेशन’, ‘COMMA’, ‘पूर्वांचल’, ‘भोजपुरी’, ‘महासभा’, ‘COMMA’, ‘अउर’, ‘हर्फ’, ‘-‘, ‘मीडिया’, ‘को’, ‘सहभागिता’, ‘बा’, ‘।’] एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा । Named Entity Recognition - BERT Tiny (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l2_128&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.8536999821662903, 0.7195000052452087, 0.746…] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] Named Entity Recognition - BERT Mini (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l4_256&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.835099995136261, 0.40450000762939453, 0.331…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘ORG’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Small (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l4_512&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.964900016784668, 0.8299000263214111, 0.9607…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Medium (OntoNotes) nlu.load(&quot;en.ner.onto.bert.small_l8_512&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.916700005531311, 0.5873000025749207, 0.8816…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Base (OntoNotes) nlu.load(&quot;en.ner.onto.bert.cased_base&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.504800021648407, 0.47290000319480896, 0.462…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s and 1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - BERT Large (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_small&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.7213000059127808, 0.6384000182151794, 0.731…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - ELECTRA Small (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_small&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence Entities_classes entities [0.8496000170707703, 0.4465999901294708, 0.568…] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] Named Entity Recognition - ELECTRA Base (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_base&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadellabase.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.5134000182151794, 0.9419000148773193, 0.802…] [‘William Henry Gates III’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘the 1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’] Named Entity Recognition - ELECTRA Large (OntoNotes) nlu.load(&quot;en.ner.onto.electra.uncased_large&quot;).predict(&quot;&quot;&quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world&#39;s largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000. He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadellabase.&quot;&quot;&quot;,output_level = &quot;document&quot;) output : ner_confidence entities Entities_classes [0.8442000150680542, 0.26840001344680786, 0.57…] [‘William Henry Gates’, ‘October 28, 1955’, ‘American’, ‘Microsoft Corporation’, ‘Microsoft’, ‘Gates’, ‘May 2014’, ‘one’, ‘1970s’, ‘1980s’, ‘Seattle’, ‘Washington’, ‘Gates co-founded’, ‘Microsoft’, ‘Paul Allen’, ‘1975’, ‘Albuquerque’, ‘New Mexico’, ‘largest’] [‘PERSON’, ‘DATE’, ‘NORP’, ‘ORG’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘CARDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘GPE’, ‘PERSON’, ‘ORG’, ‘PERSON’, ‘DATE’, ‘GPE’, ‘GPE’, ‘GPE’] Recognize Entities OntoNotes - BERT Tiny nlu.load(&quot;en.ner.onto.bert.tiny&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.994700014591217, 0.9412999749183655, 0.9685…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Mini nlu.load(&quot;en.ner.onto.bert.mini&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.996399998664856, 0.9733999967575073, 0.8766…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Small nlu.load(&quot;en.ner.onto.bert.small&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9987999796867371, 0.9610000252723694, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - BERT Medium nlu.load(&quot;en.ner.onto.bert.medium&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9969000220298767, 0.8575999736785889, 0.995…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - BERT Base nlu.load(&quot;en.ner.onto.bert.base&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.996999979019165, 0.933899998664856, 0.99930…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - BERT Large nlu.load(&quot;en.ner.onto.bert.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9786999821662903, 0.9549000263214111, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008 to 2016’, ‘Parliament’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘ORG’] Recognize Entities OntoNotes - ELECTRA Small nlu.load(&quot;en.ner.onto.electra.small&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9952999949455261, 0.8589000105857849, 0.996…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] Recognize Entities OntoNotes - ELECTRA Base nlu.load(&quot;en.ner.onto.electra.base&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9987999796867371, 0.9474999904632568, 0.999…] [‘Johnson’, ‘first’, ‘2001’, ‘Parliament’, ‘eight years’, ‘London’, ‘2008’, ‘2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘ORG’, ‘DATE’, ‘GPE’, ‘DATE’, ‘DATE’] Recognize Entities OntoNotes - ELECTRA Large nlu.load(&quot;en.ner.onto.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London, from 2008 to 2016, before rejoining Parliament.&quot;,output_level=&quot;document&quot;) output : ner_confidence entities Entities_classes [0.9998000264167786, 0.9613999724388123, 0.998…] [‘Johnson’, ‘first’, ‘2001’, ‘eight years’, ‘London’, ‘2008 to 2016’] [‘PERSON’, ‘ORDINAL’, ‘DATE’, ‘DATE’, ‘GPE’, ‘DATE’] NLU Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.1.1 We are very excited to release NLU 1.1.1! This release features 3 new tutorial notebooks for Open/Closed book question answering with Google’s T5, Intent classification and Aspect Based NER. In Addition NLU 1.1.0 comes with 25+ pretrained models and pipelines in Amharic, Bengali, Bhojpuri, Japanese, and Korean languages from the amazing Spark2.7.2 release Finally NLU now supports running on Spark 2.3 clusters. NLU 1.1.1 New Non-English Models Language nlu.load() reference Spark NLP Model reference Type Arabic ar.ner arabic_w2v_cc_300d Named Entity Recognizer Arabic ar.embed.aner aner_cc_300d Word Embedding Arabic ar.embed.aner.300d aner_cc_300d Word Embedding (Alias) Bengali bn.stopwords stopwords_bn Stopwords Cleaner Bengali bn.pos pos_msri Part of Speech Thai th.segment_words wordseg_best Word Segmenter Thai th.pos pos_lst20 Part of Speech Thai th.sentiment sentiment_jager_use Sentiment Classifier Thai th.classify.sentiment sentiment_jager_use Sentiment Classifier (Alias) Chinese zh.pos.ud_gsd_trad pos_ud_gsd_trad Part of Speech Chinese zh.segment_words.gsd wordseg_gsd_ud_trad Word Segmenter Bihari bh.pos pos_ud_bhtb Part of Speech Amharic am.pos pos_ud_att Part of Speech NLU 1.1.1 New English Models and Pipelines Language nlu.load() reference Spark NLP Model reference Type English en.sentiment.glove analyze_sentimentdl_glove_imdb Sentiment Classifier English en.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.sentiment.glove.imdb analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.sentiment.glove analyze_sentimentdl_glove_imdb Sentiment Classifier (Alias) English en.classify.trec50.pipe classifierdl_use_trec50_pipeline Language Classifier English en.ner.onto.large onto_recognize_entities_electra_large Named Entity Recognizer English en.classify.questions.atis classifierdl_use_atis Intent Classifier English en.classify.questions.airline classifierdl_use_atis Intent Classifier (Alias) English en.classify.intent.atis classifierdl_use_atis Intent Classifier (Alias) English en.classify.intent.airline classifierdl_use_atis Intent Classifier (Alias) English en.ner.atis nerdl_atis_840b_300d Aspect based NER English en.ner.airline nerdl_atis_840b_300d Aspect based NER (Alias) English en.ner.aspect.airline nerdl_atis_840b_300d Aspect based NER (Alias) English en.ner.aspect.atis nerdl_atis_840b_300d Aspect based NER (Alias) New Easy NLU 1-liner Examples : Extract aspects and entities from airline questions (ATIS dataset) nlu.load(&quot;en.ner.atis&quot;).predict(&quot;i want to fly from baltimore to dallas round trip&quot;) output: [&quot;baltimore&quot;,&quot; dallas&quot;, &quot;round trip&quot;] Intent Classification for Airline Traffic Information System queries (ATIS dataset) nlu.load(&quot;en.classify.questions.atis&quot;).predict(&quot;what is the price of flight from newyork to washington&quot;) output: &quot;atis_airfare&quot; Recognize Entities OntoNotes - ELECTRA Large nlu.load(&quot;en.ner.onto.large&quot;).predict(&quot;Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London.&quot;) output: [&quot;Johnson&quot;, &quot;first&quot;, &quot;2001&quot;, &quot;eight years&quot;, &quot;London&quot;] Question classification of open-domain and fact-based questions Pipeline - TREC50 nlu.load(&quot;en.classify.trec50.component_list&quot;).predict(&quot;When did the construction of stone circles begin in the UK? &quot;) output: LOC_other Traditional Chinese Word Segmentation # &#39;However, this treatment also creates some problems&#39; in Chinese nlu.load(&quot;zh.segment_words.gsd&quot;).predict(&quot;然而，這樣的處理也衍生了一些問題。&quot;) output: [&quot;然而&quot;,&quot;,&quot;,&quot;這樣&quot;,&quot;的&quot;,&quot;處理&quot;,&quot;也&quot;,&quot;衍生&quot;,&quot;了&quot;,&quot;一些&quot;,&quot;問題&quot;,&quot;。&quot;] Part of Speech for Traditional Chinese # &#39;However, this treatment also creates some problems&#39; in Chinese nlu.load(&quot;zh.pos.ud_gsd_trad&quot;).predict(&quot;然而，這樣的處理也衍生了一些問題。&quot;) Output: Token POS 然而 ADV ， PUNCT 這樣 PRON 的 PART 處理 NOUN 也 ADV 衍生 VERB 了 PART 一些 ADJ 問題 NOUN 。 PUNCT Thai Word Segment Recognition # &#39;Mona Lisa is a 16th-century oil painting created by Leonardo held at the Louvre in Paris&#39; in Thai nlu.loadnlu.load(&quot;th.segment_words&quot;).predict(&quot;Mona Lisa เป็นภาพวาดสีน้ำมันในศตวรรษที่ 16 ที่สร้างโดย Leonardo จัดขึ้นที่พิพิธภัณฑ์ลูฟร์ในปารีส&quot;) Output: token M o n a Lisa เป็น ภาพ ว า ด สีน้ำ มัน ใน ศตวรรษ ที่ 16 ที่ สร้าง โ ด ย L e o n a r d o จัด ขึ้น ที่ พิพิธภัณฑ์ ลูฟร์ ใน ปารีส Part of Speech for Bengali (POS) # &#39;The village is also called &#39;Mod&#39; in Tora language&#39; in Behgali nlu.load(&quot;bn.pos&quot;).predict(&quot;বাসস্থান-ঘরগৃহস্থালি তোড়া ভাষায় গ্রামকেও বলে ` মোদ &#39; ৷&quot;) Output: token pos বাসস্থান-ঘরগৃহস্থালি NN তোড়া NNP ভাষায় NN গ্রামকেও NN বলে VM ` SYM মোদ NN ’ SYM ৷ SYM Stop Words Cleaner for Bengali # &#39;This language is not enough&#39; in Bengali df = nlu.load(&quot;bn.stopwords&quot;).predict(&quot;এই ভাষা যথেষ্ট নয়&quot;) Output: cleanTokens token ভাষা এই যথেষ্ট ভাষা নয় যথেষ্ট None নয় Part of Speech for Bengali # &#39;The people of Ohu know that the foundation of Bhojpuri was shaken&#39; in Bengali nlu.load(&#39;bh.pos&#39;).predict(&quot;ओहु लोग के मालूम बा कि श्लील होखते भोजपुरी के नींव हिल जाई&quot;) Output: pos token DET ओहु NOUN लोग ADP के NOUN मालूम VERB बा SCONJ कि ADJ श्लील VERB होखते PROPN भोजपुरी ADP के NOUN नींव VERB हिल AUX जाई Amharic Part of Speech (POS) # &#39; &quot;Son, finish the job,&quot; he said.&#39; in Amharic nlu.load(&#39;am.pos&#39;).predict(&#39;ልጅ ኡ ን ሥራ ው ን አስጨርስ ኧው ኣል ኧሁ ።&quot;&#39;) Output: pos token NOUN ልጅ DET ኡ PART ን NOUN ሥራ DET ው PART ን VERB አስጨርስ PRON ኧው AUX ኣል PRON ኧሁ PUNCT ። NOUN ” Thai Sentiment Classification # &#39;I love peanut butter and jelly!&#39; in thai nlu.load(&#39;th.classify.sentiment&#39;).predict(&#39;ฉันชอบเนยถั่วและเยลลี่!&#39;)[[&#39;sentiment&#39;,&#39;sentiment_confidence&#39;]] Output: sentiment sentiment_confidence positive 0.999998 Arabic Named Entity Recognition (NER) # &#39;In 1918, the forces of the Arab Revolt liberated Damascus with the help of the British&#39; in Arabic nlu.load(&#39;ar.ner&#39;).predict(&#39;في عام 1918 حررت قوات الثورة العربية دمشق بمساعدة من الإنكليز&#39;,output_level=&#39;chunk&#39;)[[&#39;entities_confidence&#39;,&#39;ner_confidence&#39;,&#39;entities&#39;]] Output: entity_class ner_confidence entities ORG [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] قوات الثورة العربية LOC [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] دمشق PER [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] الإنكليز NLU 1.1.1 Enhancements : Spark 2.3 compatibility New NLU Notebooks and Tutorials Open and Closed book question Ansering Aspect based NER for Airline ATIS Intent Classification for Airline emssages ATIS Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.1.0 We are incredibly excited to release NLU 1.1.0! This release integrates the 720+ new models from the latest Spark-NLP 2.7.0 + releases. You can now achieve state-of-the-art results with Sequence2Sequence transformers for problems like text summarization, question answering, translation between 192+ languages and extract Named Entity in various Right to Left written languages like Korean, Japanese, Chinese and many more in 1 line of code! These new features are possible because of the integration of the Google’s T5 models and Microsoft’s Marian models transformers NLU 1.1.0 has over 720+ new pretrained models and pipelines while extending the support of multi-lingual models to 192+ languages such as Chinese, Japanese, Korean, Arabic, Persian, Urdu, and Hebrew. NLU 1.1.0 New Features 720+ new models you can find an overview of all NLU models here and further documentation in the models hub NEW: Introducing MarianTransformer annotator for machine translation based on MarianNMT models. Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team (646+ pretrained models &amp; pipelines in 192+ languages) NEW: Introducing T5Transformer annotator for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on NEW: Introducing brand new and refactored language detection and identification models. The new LanguageDetectorDL is faster, more accurate, and supports up to 375 languages NEW: Introducing WordSegmenter model for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean NEW: Introducing DocumentNormalizer component for cleaning content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters NLU 1.1.0 New Notebooks, Tutorials and Articles Translate between 192+ languages with marian Try out the 18 Tasks like Summarization Question Answering and more on T5 Tokenize, extract POS and NER in Chinese Tokenize, extract POS and NER in Korean Tokenize, extract POS and NER in Japanese Normalize documents Aspect based sentiment NER sentiment for restaurants NLU 1.1.0 New Training Tutorials Binary Classifier training Jupyter tutorials 2 class Finance News sentiment classifier training 2 class Reddit comment sentiment classifier training 2 class Apple Tweets sentiment classifier training 2 class IMDB Movie sentiment classifier training 2 class twitter classifier training Multi Class text Classifier training Jupyter tutorials 5 class WineEnthusiast Wine review classifier training 3 class Amazon Phone review classifier training 5 class Amazon Musical Instruments review classifier training 5 class Tripadvisor Hotel review classifier training 5 class Phone review classifier training NLU 1.1.0 New Medium Tutorials 1 line to Glove Word Embeddings with NLU with t-SNE plots 1 line to Xlnet Word Embeddings with NLU with t-SNE plots 1 line to AlBERT Word Embeddings with NLU with t-SNE plots 1 line to CovidBERT Word Embeddings with NLU with t-SNE plots 1 line to Electra Word Embeddings with NLU with t-SNE plots 1 line to BioBERT Word Embeddings with NLU with t-SNE plots Translation Translation example You can translate between more than 192 Languages pairs with the Marian Models You need to specify the language your data is in as start_language and the language you want to translate to as target_language. The language references must be ISO language codes nlu.load(&#39;&lt;start_language&gt;.translate.&lt;target_language&gt;&#39;) Translate Turkish to English: nlu.load(&#39;tr.translate_to.fr&#39;) Translate English to French: nlu.load(&#39;en.translate_to.fr&#39;) Translate French to Hebrew: nlu.load(&#39;en.translate_to.fr&#39;) translate_pipe = nlu.load(&#39;en.translate_to.fr&#39;) df = translate_pipe.predict(&#39;Billy likes to go to the mall every sunday&#39;) df sentence translation Billy likes to go to the mall every sunday Billy geht gerne jeden Sonntag ins Einkaufszentrum Overview of every task available with T5 The T5 model is trained on various datasets for 17 different tasks which fall into 8 categories. Text summarization Question answering Translation Sentiment analysis Natural Language inference Coreference resolution Sentence Completion Word sense disambiguation Every T5 Task with explanation: Task Name Explanation 1.CoLA Classify if a sentence is gramaticaly correct 2.RTE Classify whether if a statement can be deducted from a sentence 3.MNLI Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class). 4.MRPC Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent) 5.QNLI Classify whether the answer to a question can be deducted from an answer candidate. 6.QQP Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent) 7.SST2 Classify the sentiment of a sentence as positive or negative 8.STSB Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes) 9.CB Classify for a premise and a hypothesis whether they contradict each other or not (binary). 10.COPA Classify for a question, premise, and 2 choices which choice the correct choice is (binary). 11.MultiRc Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary), 12.WiC Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences. 13.WSC/DPR Predict for an ambiguous pronoun in a sentence what it is referring to. 14.Summarization Summarize text into a shorter representation. 15.SQuAD Answer a question for a given context. 16.WMT1. Translate English to German 17.WMT2. Translate English to French 18.WMT3. Translate English to Romanian refer to this notebook to see how to use every T5 Task. Question Answering Question answering example) Predict an answer to a question based on input context. This is based on SQuAD - Context based question answering Predicted Answer Question Context carbon monoxide What does increased oxygen concentrations in the patient’s lungs displace? Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. pie What did Joey eat for breakfast? Once upon a time, there was a squirrel named Joey. Joey loved to go outside and play with his cousin Jimmy. Joey and Jimmy played silly games together, and were always laughing. One day, Joey and Jimmy went swimming together 50 at their Aunt Julie’s pond. Joey woke up early in the morning to eat some food before they left. Usually, Joey would eat cereal, fruit (a pear), or oatmeal for breakfast. After he ate, he and Jimmy went to the pond. On their way there they saw their friend Jack Rabbit. They dove into the water and swam for several hours. The sun was out, but the breeze was cold. Joey and Jimmy got out of the water and started walking home. Their fur was wet, and the breeze chilled them. When they got home, they dried off, and Jimmy put on his favorite purple shirt. Joey put on a blue shirt with red and green dots. The two squirrels ate some food that Joey’s mom, Jasmine, made and went off to bed,’ # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;question &#39;) # define Data, add additional tags between sentences data = [&#39;&#39;&#39; What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. &#39;&#39;&#39;] #Predict on text data with T5 t5.predict(data) How to configure T5 task parameter for Squad Context based question answering and pre-process data .setTask(&#39;question:) and prefix the context which can be made up of multiple sentences with context: Example pre-processed input for T5 Squad Context based question answering: question: What does increased oxygen concentrations in the patient’s lungs displace? context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin. Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment. Text Summarization Summarization example Summarizes a paragraph into a shorter version with the same semantic meaning, based on Text summarization # Set the task on T5 pipe = nlu.load(&#39;summarize&#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . &#39;&#39;&#39;, &#39;&#39;&#39; Calculus, originally called infinitesimal calculus or &quot;the calculus of infinitesimals&quot;, is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally &quot;small pebble&quot; (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.&#39;&#39;&#39; ] #Predict on text data with T5 pipe.predict(data) Predicted summary Text manchester united face newcastle in the premier league on wednesday . louis van gaal’s side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends . the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . Binary Sentence similarity/ Paraphrasing Binary sentence similarity example Classify whether one sentence is a re-phrasing or similar to another sentence This is a sub-task of GLUE and based on MRPC - Binary Paraphrasing/ sentence similarity classification t5 = nlu.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;mrpc &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11 &quot; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: I like to eat peanutbutter for breakfast sentence2: I like to play football. &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) | Sentence1 | Sentence2 | prediction| |————|————|———-| |We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , “ Rumsfeld said .| Rather , the US acted because the administration saw “ existing evidence in a new light , through the prism of our experience on September 11 “ . | equivalent | | I like to eat peanutbutter for breakfast| I like to play football | not_equivalent | How to configure T5 task for MRPC and pre-process text .setTask(&#39;mrpc sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity mrpc sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , &quot; Rumsfeld said . sentence2: Rather , the US acted because the administration saw &quot; existing evidence in a new light , through the prism of our experience on September 11&quot;, Regressive Sentence similarity/ Paraphrasing Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label. This is a sub-task of GLUE and based onSTSB - Regressive semantic sentence similarity . t5 = nlu.load(&#39;en.t5.base&#39;) # Set the task on T5 t5[&#39;t5&#39;].setTask(&#39;stsb &#39;) # define Data, add additional tags between sentences data = [ &#39;&#39;&#39; sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39; &#39;&#39;&#39; , &#39;&#39;&#39; sentence1: What was it like in Ancient rome? sentence2: What was Ancient rome like? &#39;&#39;&#39;, &#39;&#39;&#39; sentence1: What was live like as a King in Ancient Rome?? sentence2: What was Ancient rome like? &#39;&#39;&#39; ] #Predict on text data with T5 t5.predict(data) Question1 Question2 prediction What attributes would have made you highly desirable in ancient Rome? How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? 0 What was it like in Ancient rome? What was Ancient rome like? 5.0 What was live like as a King in Ancient Rome?? What is it like to live in Rome? 3.2 How to configure T5 task for stsb and pre-process text .setTask(&#39;stsb sentence1:) and prefix second sentence with sentence2: Example pre-processed input for T5 STSB - Regressive semantic sentence similarity stsb sentence1: What attributes would have made you highly desirable in ancient Rome? sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?&#39;, Grammar Checking Grammar checking with T5 example) Judges if a sentence is grammatically acceptable. Based on CoLA - Binary Grammatical Sentence acceptability classification pipe = nlu.load(&#39;grammar_correctness&#39;) # Set the task on T5 pipe[&#39;t5&#39;].setTask(&#39;cola sentence: &#39;) # define Data data = [&#39;Anna and Mike is going skiing and they is liked is&#39;,&#39;Anna and Mike like to dance&#39;] #Predict on text data with T5 pipe.predict(data) |sentence | prediction| |————|————| | Anna and Mike is going skiing and they is liked is | unacceptable | | Anna and Mike like to dance | acceptable | Document Normalization Document Normalizer example The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters pipe = nlu.load(&#39;norm_document&#39;) data = &#39;&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;&#39; df = pipe.predict(data,output_level=&#39;document&#39;) df |text|normalized_text| |——|————-| | &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; |Example This is an example of a simple HTML page with one paragraph.| Word Segmenter Word Segmenter Example The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean pipe = nlu.load(&#39;ja.segment_words&#39;) # japanese for &#39;Donald Trump and Angela Merkel dont share many opinions&#39; ja_data = [&#39;ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません&#39;] df = pipe.predict(ja_data, output_level=&#39;token&#39;) df token ドナルド ・ トランプ と アンゲラ ・ メルケル は 多く の 意見 を 共有 し て い ませ ん Installation # PyPi !pip install nlu pyspark==2.4.7 #Conda # Install NLU from Anaconda/Conda conda install -os_components johnsnowlabs nlu Additional NLU ressources NLU Website All NLU Tutorial Notebooks NLU Videos and Blogposts on NLU NLU on Github NLU Version 1.0.6 Trainable Multi Label Classifiers, predict Stackoverflow Tags and much more in 1 Line of with NLU 1.0.6 We are glad to announce NLU 1.0.6 has been released! NLU 1.0.6 comes with the Multi Label classifier, it can learn to map strings to multiple labels. The Multi Label Classifier is using Bidirectional GRU and CNNs inside TensorFlow and supports up to 100 classes. NLU 1.0.6 New Features Multi Label Classifier The Multi Label Classifier learns a 1 to many mapping between text and labels. This means it can predict multiple labels at the same time for a given input string. This is very helpful for tasks similar to content tag prediction (HashTags/RedditTags/YoutubeTags/Toxic/E2e etc..) Support up to 100 classes Pre-trained Multi Label Classifiers are already avaiable as Toxic and E2E classifiers Multi Label Classifier Train Multi Label Classifier on E2E dataset Demo Train Multi Label Classifier on Stack Overflow Question Tags dataset Demo This model can predict multiple labels for one sentence. To train the Multi Label text classifier model, you must pass a dataframe with a text column and a y column for the label. The y label must be a string column where each label is seperated with a seperator. By default, , is assumed as line seperator. If your dataset is using a different label seperator, you must configure the label_seperator parameter while calling the fit() method. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings for training. fitted_pipe = nlu.load(&#39;train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) If you add a nlu sentence embeddings reference, before the train reference, NLU will use that Sentence embeddings instead of the default USE. #Train on BERT sentence emebddings fitted_pipe = nlu.load(&#39;embed_sentence.bert train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Configure a custom line seperator #Use ; as label seperator fitted_pipe = nlu.load(&#39;embed_sentence.electra train.multi_classifier&#39;).fit(train_df, label_seperator=&#39;;&#39;) preds = fitted_pipe.predict(train_df) NLU 1.0.6 Enhancements Improved outputs for Toxic and E2E Classifier. by default, all predicted classes and their confidences which are above the threshold will be returned inside of a list in the Pandas dataframe by configuring meta=True, the confidences for all classes will be returned. NLU Version 1.0.6 Train Multi Label Classifier on E2E dataset Train Multi Label Classifier on Stack Overflow Question Tags dataset NLU 1.0.6 Bug-fixes Fixed a bug that caused en.ner.dl.bert to be inaccessible Fixed a bug that caused pt.ner.large to be inaccessible Fixed a bug that caused USE embeddings not properly beeing configured to document level output when using multiple embeddings at the same time NLU Version 1.0.5 Trainable Part of Speech Tagger (POS), Sentiment Classifier with BERT/USE/ELECTRA sentence embeddings in 1 Line of code! Latest NLU Release 1.0.5 We are glad to announce NLU 1.0.5 has been released! This release comes with a trainable Sentiment classifier and a Trainable Part of Speech (POS) models! These Neural Network Architectures achieve the state of the art (SOTA) on most binary Sentiment analysis and Part of Speech Tagging tasks! You can train the Sentiment Model on any of the 100+ Sentence Embeddings which include BERT, ELECTRA, USE, Multi Lingual BERT Sentence Embeddings and many more! Leverage this and achieve the state of the art in any of your datasets, all of this in just 1 line of Python code NLU 1.0.5 New Features Trainable Sentiment DL classifier Trainable POS NLU 1.0.5 New Notebooks and Tutorials Sentiment Classification Training Demo Part Of Speech Tagger Training demo Sentiment Classifier Training Sentiment Classification Training Demo To train the Binary Sentiment classifier model, you must pass a dataframe with a ‘text’ column and a ‘y’ column for the label. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlu.load(&#39;train.sentiment&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) If you add a nlu sentence embeddings reference, before the train reference, NLU will use that Sentence embeddings instead of the default USE. #Train Classifier on BERT sentence embeddings fitted_pipe = nlu.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) #Train Classifier on ELECTRA sentence embeddings fitted_pipe = nlu.load(&#39;embed_sentence.electra train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Part Of Speech Tagger Training Part Of Speech Tagger Training demo fitted_pipe = nlu.load(&#39;train.pos&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) NLU 1.0.5 Installation changes Starting from version 1.0.5 NLU will not automatically install pyspark for users anymore. This enables easier customizing the Pyspark version which makes it easier to use in various cluster enviroments. To install NLU from now on, please run pip install nlu pyspark==2.4.7 or install any pyspark&gt;=2.4.0 with pyspark&lt;3 NLU 1.0.5 Improvements Improved Databricks path handling for loading and storing models. NLU Version 1.0.4 John Snow Labs NLU 1.0.4 : Trainable Named Entity Recognizer (NER) , achieve SOTA in 1 line of code and easy scaling to 100’s of Spark nodes We are glad to announce NLU 1.0.4 releases the State of the Art breaking Neural Network architecture for NER, Char CNNs - BiLSTM - CRF! #fit and predict in 1 line! nlu.load(&#39;train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with BERT! nlu.load(&#39;bert train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with ALBERT! nlu.load(&#39;albert train.ner&#39;).fit(dataset).predict(dataset) #fit and predict in 1 line with ELMO! nlu.load(&#39;elmo train.ner&#39;).fit(dataset).predict(dataset) Any NLU pipeline stored can now be loaded as pyspark ML pipeline # Ready for big Data with Spark distributed computing import pyspark nlu_pipe.save(path) pyspark_pipe = pyspark.ml.PipelineModel.load(stored_model_path) pyspark_pipe.transform(spark_df) NLU 1.0.4 New Features Trainable Named Entity Recognizer NLU pipeline loadable as Spark pipelines NLU 1.0.4 New Notebooks,Tutorials and Docs NER training demo Multi Class Text Classifier Training Demo updated to showcase usage of different Embeddings New Documentation Page on how to train Models with NLU Databricks Notebook showcasing Scaling with NLU NLU 1.0.4 Bug Fixes Fixed a bug that NER token confidences do not appear. They now appear when nlu.load(‘ner’).predict(df, meta=True) is called. Fixed a bug that caused some Spark NLP models to not be loaded properly in offline mode NLU Version 1.0.3 We are happy to announce NLU 1.0.3 comes with a lot new features, training classifiers, saving them and loading them offline, enabling running NLU with no internet connection, new notebooks and articles! NLU 1.0.3 New Features Train a Deep Learning classifier in 1 line! The popular ClassifierDL which can achieve state of the art results on any multi class text classification problem is now trainable! All it takes is just nlu.load(‘train.classifier).fit(dataset) . Your dataset can be a Pandas/Spark/Modin/Ray/Dask dataframe and needs to have a column named x for text data and a column named y for labels Saving pipelines to HDD is now possible with nlu.save(path) Loading pipelines from disk now possible with nlu.load(path=path). NLU offline mode: Loading from disk makes running NLU offline now possible, since you can load pipelines/models from your local hard drive instead of John Snow Labs AWS servers. NLU 1.0.3 New Notebooks and Tutorials New colab notebook showcasing nlu training, saving and loading from disk Sentence Similarity with BERT, Electra and Universal Sentence Encoder Medium Tutorial Sentence Similarity with BERT, Electra and Universal Sentence Encoder Train a Deep Learning Classifier Sentence Detector Notebook Updated New Workshop video NLU 1.0.3 Bug fixes Sentence Detector bugfix NLU Version 1.0.2 We are glad to announce nlu 1.0.2 is released! NLU 1.0.2 Enhancements More semantically concise output levels sentence and document enforced : If a pipe is set to output_level=’document’ : Every Sentence Embedding will generate 1 Embedding per Document/row in the input Dataframe, instead of 1 embedding per sentence. Every Classifier will classify an entire Document/row Each row in the output DF is a 1 to 1 mapping of the original input DF. 1 to 1 mapping from input to output. If a pipe is set to output_level=’sentence’ : Every Sentence Embedding will generate 1 Embedding per Sentence, Every Classifier will classify exactly one sentence Each row in the output DF can is mapped to one row in the input DF, but one row in the input DF can have multiple corresponding rows in the output DF. 1 to N mapping from input to output. Improved generation of column names for classifiers. based on input nlu reference Improved generation of column names for embeddings, based on input nlu reference Improved automatic output level inference Various test updates Integration of CI pipeline with Github Actions New Documentation is out! Check it out here : http://nlp.johnsnowlabs.com/ NLU Version 1.0.1 NLU 1.0.1 Bugfixes Fixed bug that caused NER pipelines to crash in NLU when input string caused the NER model to predict without additional metadata NLU Version 1.0.0 Automatic to Numpy conversion of embeddings Added various testing classes New 6 embeddings at once notebook with t-SNE and Medium article Integration of Spark NLP 2.6.2 enhancements and bugfixes https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.2 Updated old T-SNE notebooks with more elegant and simpler generation of t-SNE embeddings NLU Version 0.2.1 Various bugfixes Improved output column names when using multiple classifirs at once NLU Version 0.2.0 Improved output column names classifiers NLU Version 0.1.0 We are glad to announce that NLU 0.1 has been released! NLU makes the 350+ models and annotators in Spark NLPs arsenal available in just 1 line of python code and it works with Pandas dataframes! A picture says more than a 1000 words, so here is a demo clip of the 12 coolest features in NLU, all just in 1 line! NLU in action What does NLU 0.1 include? NLU provides everything a data scientist might want to wish for in one line of code! 350 + pre-trained models 100+ of the latest NLP word embeddings ( BERT, ELMO, ALBERT, XLNET, GLOVE, BIOBERT, ELECTRA, COVIDBERT) and different variations of them 50+ of the latest NLP sentence embeddings ( BERT, ELECTRA, USE) and different variations of them 50+ Classifiers (NER, POS, Emotion, Sarcasm, Questions, Spam) 40+ Supported Languages Labeled and Unlabeled Dependency parsing Various Text Cleaning and Pre-Processing methods like Stemming, Lemmatizing, Normalizing, Filtering, Cleaning pipelines and more NLU 0.1 Features Google Collab Notebook Demos Named Entity Recognition (NER) NER pretrained on ONTO Notes NER pretrained on CONLL NER pretrained on ONTO Notes NER pretrained on CONLL Part of speech (POS) POS pretrained on ANC dataset Classifiers Unsupervised Keyword Extraction with YAKE Toxic Text Classifier Twitter Sentiment Classifier Movie Review Sentiment Classifier Sarcasm Classifier 50 Class Questions Classifier 20 Class Languages Classifier Fake News Classifier E2E Classifier Cyberbullying Classifier Spam Classifier Word and Sentence Embeddings BERT Word Embeddings and T-SNE plotting BERT Sentence Embeddings and T-SNE plotting ALBERT Word Embeddings and T-SNE plotting ELMO Word Embeddings and T-SNE plotting XLNET Word Embeddings and T-SNE plotting ELECTRA Word Embeddings and T-SNE plotting COVIDBERT Word Embeddings and T-SNE plotting BIOBERT Word Embeddings and T-SNE plotting GLOVE Word Embeddings and T-SNE plotting USE Sentence Embeddings and T-SNE plotting Depenency Parsing Untyped Dependency Parsing Typed Dependency Parsing Text Pre Processing and Cleaning Tokenization Stopwords removal Stemming Lemmatization Normalizing Spellchecking Sentence Detecting Chunkers N Gram Entity Chunking Matchers Date Matcher",
    "url": "/docs/en/jsl/release_notes",
    "relUrl": "/docs/en/jsl/release_notes"
  },
  "1340": {
    "id": "1340",
    "title": "Release Notes",
    "content": "4.8.1 Release date: 22-03-2023 More Powerful Prompts, New Annotation Gesture, and Enhanced Support for Floating Licences in NLP Lab 4.8 NLP Lab 4.8 brings more power to the prompts allowing a more efficient text preannotation, it adapts to the user’s preferences in terms of annotation gestures, adds supports for bundles of floating licenses shared across the annotation team for parallel preannotation, training, and experiments in the playground. It also includes a long list of optimizations covering project configuration steps, large projects export, or automatic download of missing resources. Here are the highlights of this release: More Powerful Prompts NLP Lab 4.8 introduces several new features that enhance prompt-based preannotation. One significant improvement is the incorporation of negative questions into prompt definitions, which allows users to establish characteristics that do not apply to the target entity or relation. This version also enables the creation of relation prompts using labels from custom models even if trained with different embeddings, providing more flexibility for prompt-based preannotation. Additionally, the software now automatically downloads prompt dependencies and supports prompt import/export. The prompt definition page also features a dynamic question count and filters for easy navigation. Combining Positive and Negative Questions for More Precise Prompts Definition NLP Lab 4.8 enhances the precision of entity annotation using prompts by incorporating negative questions. On the prompt definition screen, users can now specify two categories of questions - Questions that establish the characteristics of the target entity and Questions that establish the characteristics that do not apply to the entity. Both the affirmative and negative definitions will be executed as separate prompts, integrated into the same pipeline, enabling users to eliminate incorrect entities generated by the prompts. This feature will substantially boost the efficiency of prompt-based entity generation and streamline the process for our users. Relation Prompts Combine Entities from Models Trained with Different Embeddings NLP Lab allows the definition of relation prompts by combining entities defined in pre-trained models, rules, and prompts. However, previous versions of the software did not allow users to create relation prompts using custom-trained models. In this update, users can implement and use relation prompts linking 2 entities defined in custom-trained models (e.g. trained via the NLP Lab). Moreover, there is no restriction for the reference models which can also be trained using different embeddings. We are confident that this new feature will enhance the power of the prompts and offer more flexibility for prompt-based preannotation. Automatically Download Necessary Prompt Dependencies NLP Lab Prompts are created based on Zero Shot models. The later are part of the Healthcare, Finance and Legal libraries and are accessible only in the presence of a valid license key. The prompt definition options are populated according to license availability: e.g. if a Healthcare NLP license is available, the Healthcare option will be active in the Domain dropdown. As such, when creating a prompt, the user has to choose the domain of the prompt, and based on that, NLP Lab will infer the Zero Shot model needed by the prompt. When users select one of the active domains if the corresponding Zero Shot model is not available locally, NLP Lab will automatically download it from the NLP Models Hub. Import/Export Prompts Prompts are preannotation resources that users often want to move from one instance of the NLP Lab to another or to archive for future reference. NLP Lab now supports prompt import and export from the UI. The user can import a ZIP/JSON file containing one or several prompt definitions. The imported prompts will become available on the Prompts page under the Hub menu item. Users can also export prompts in JSON format via the burger menu available for each prompt. Dynamic Count of Questions on the Prompt Definition Page Each prompt can include a maximum of 30 positive questions and 30 negative questions. For facilitating user actions when defining/updating prompts, NLP Lab now includes a count of the number of questions added so far. For instance, if two questions have been added while creating a prompt, then the UI should show Questions(2/30) Filters in the prompt page The Prompts page can become crowded very quickly as prompts are quite popular and easy to define and use for preannotation, especially by non technical users. For helping users quickly identify the prompts they need, a search option is available as well as 2 filters. Using the 2 dropdown menus at the top right side of the page, prompts can be filtered based on their Type or Domain. Undo Changes For Prompt and Rules in the playground We are thrilled to introduce the Undo feature added to the NLP Lab Playground. This function enables users to quickly undo any changes made during their current experimental session. By selecting the &quot;Undo Changes&quot; button, all modifications made to the prompt/rules will be reverted to their original state. We are confident that this feature will significantly improve the user experience by providing greater control over the editing process. New Annotation Gesture Some of our users suggested updating the annotation gesture we initially offered, as it was counter-intuitive, especially for users accustomed to modern text editing tools. Specifically, the process of first selecting the Label and then selecting the chunk to annotate may not feel natural anymore, as tools such as MS Word, where you first select a text and then have options to format or access contextual menus that open next to your selection, have changed the way we all feel about text manipulation. We hear you! To make NLP Lab more intuitive and user-friendly, NLP Lab now supports a new way of annotating text. This new feature allows users to select the text first and then choose the label to apply. We believe that this will make the annotation process more intuitive and efficient for many users. This feature is available for both text projects and Visual NER projects. You are now able to switch between the two options: selecting text and assigning an entity, or selecting an entity and assigning text. Both will work. This way, users can choose the annotation method that works best for their project and their personal preferences. Optimized Project Configurations Automatic Model Download During Project Import When a user imports a project in NLP Lab 4.8, the system automatically downloads any absent models utilized by the imported project. To enable users to check whether the models have been downloaded or not, a new section named &quot;Download Models&quot; has been included in the Import status. If the required models have been downloaded or are already present, a green tick will be displayed. On the other hand, if the download process is unsuccessful, a red cross will be shown. When the automatic download of a model/embeddings fails, an error message is displayed on the model card in the Hub-&gt;Models page. Users can hover over the question mark icon to see the details. Update the behavior of the save button on the Project configuration page While setting up the configuration, the user can now choose to save the settings on all configuration sections without being redirected to another page or having to deploy a preannotation server. After saving the configuration, the user can deploy the pre-annotation server by pressing the Pre-Annotate button from the tasks page or navigating to the Configuration -&gt; Customize Labels page and save the configuration there. Once the server is deployed, the user will either be directed to the Tasks page or to the Import page. Missing Embeddings Warning in the Configuration Page If embeddings are missing for a model that is part of a project configuration, a black warning message was displayed on the configuration page to alert the user. This warning message was not visible before, but now the displayed text ensures that the user can see the error. Efficient Export for Large Projects Visual NER projects, pre-annotations, and training have substantially increased NLP Lab project sizes. Unfortunately, this growth has made importing and exporting tasks or projects time-consuming, especially when dealing with large files. The new version of the system has addressed this issue by enhancing both project and task exports, making it possible to quickly export large files and manage a vast number of tasks. This optimization also applies to text-based projects, where the export time has been reduced by a factor of ten. The current version of the system includes a pop-up message that appears before exporting both tasks and projects. This message notifies the user that the system is preparing the data for download and advises them to remain on the page and avoid enabling pop-ups to prevent any interruptions. Once the data preparation is complete, the download will start automatically, and the user will not need to take any additional steps. Enhanced Support for Floating Licenses Support for Bundles of Licenses We are delighted to inform you that NLP Lab now offers support for bundles of floating licenses. Those are licenses that enable multiple pre-annotation/training servers to run concurrently based on the values of the &quot;max_parallel_jobs&quot; parameter. In the previous version, our floating license system only allowed for one pre-annotation/training server to operate at a time. With this new update, users can enjoy the benefits of a single floating license that can support multiple pre-annotation/training servers simultaneously. Display a banner showing the number of days remaining for the available trial license NLP Lab improves the user experience by providing more accessible information about license validity. Currently, users can only check their license status on the Licenses page, which may not be convenient as it requires manual action. To address this issue, we have added a new feature that displays a warning on the user interface before the license expires. This notification reminds you to review your subscription status or renew your license before it expires. For trial licenses with less than 30 days remaining, a banner will be displayed on the UI indicating the remaining trial days and a link to create a new subscription. This way, you can easily keep track of your trial period and take the necessary steps before it ends. Improvements Increased Flexibility in Username Definition With the latest release of NLP Lab, users can create usernames with increased flexibility and ease. Specifically, support has been added for the use of the underscore symbol &quot;&quot; in usernames. This enhancement will enable users to create unique and more expressive usernames that better represent their identity or brand. Furthermore, this feature will allow users to avoid any potential conflicts or duplications with other usernames. Improved User Experience with Clearer Relation Prompts NLP Lab has recently introduced an improvement to the way relation prompts are displayed in the Pre-annotation pop-up. Previously, the relation prompts were shown under the generic &quot;Pre-annotation prompts&quot; category, which may have caused confusion for users. With this update, relation prompts are now shown under a separate sub-heading of &quot;RE prompts&quot; or &quot;Relation prompts,&quot; providing clearer and more organized categorization. This improvement will enable users to manage the creation and deployment of relation prompts more intuitively and efficiently. Enhanced Accessibility and Functionality of Model Hub Page To improve the accessibility and functionality of the Model Hub page, NLP Lab has implemented several changes in its latest version. One such improvement is the ability to distinguish between downloadable models and license-restricted models. Models that require a license will now be disabled when the appropriate license is not available, making it easier for users to navigate and select models to reuse. Another enhancement is the introduction of a new menu on the model/rules card, which allows users to effortlessly download models from Modelshub or open them in the playground. This menu provides a more streamlined and convenient way for users to access and utilize the available models and resources. Versions 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/release_notes",
    "relUrl": "/docs/en/alab/release_notes"
  },
  "1341": {
    "id": "1341",
    "title": "Release Notes",
    "content": "0.7.1 Fields Details Name NLP Server Version 0.7.1 Type Patch Release Date 2022-06-17 Overview We are excited to release NLP Server v0.7.1! We are committed to continuously improve the experience for our users and make our product reliable and easy to use. This release focuses on solving a few bugs and improving the stability of the NLP Server. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplaces. Bug Fixes Issue when running NER ONTO spell. Issue when running dep spell. Since the spell was broken it is temporarily blacklisted. Document normalizer included the HTML, XML tags to the output even after normalization. Issue when running language translation spells &lt;from_lang&gt;.translate_to.&lt;to_lang&gt;. Upon cancelation of custom model uploading job exception was seen in the logs. Some few UI related issues and abnormalities during operation. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes"
  },
  "1342": {
    "id": "1342",
    "title": "Spark NLP release notes",
    "content": "",
    "url": "/docs/en/release_notes",
    "relUrl": "/docs/en/release_notes"
  },
  "1343": {
    "id": "1343",
    "title": "NLP Server release notes 0.4.0",
    "content": "0.4.0 Highlights This version of NLP Server offers support for licensed models and annotators. Users can now upload a Spark NLP for Healthcare license file and get access to a wide range of additional annotators and transformers. A valid license key also gives access to more than 400 state-of-the-art healthcare models. Those can be used via easy to learn NLU spells or via API calls. NLP Server now supports better handling of large amounts of data to quickly analyze via UI by offering support for uploading CSV files. Support for floating licenses. Users can now take advantage of the floating license flexibility and use those inside of the NLP Server. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_4_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_4_0"
  },
  "1344": {
    "id": "1344",
    "title": "NLP Server release notes 0.5.0",
    "content": "0.5.0 Highlights Support for easy license import from my.johnsnowlabs.com. Visualize annotation results with Spark NLP Display. Examples of results obtained using popular spells on sample texts have been added to the UI. Performance improvement when previewing the annotations. Support for 22 new models for 23 languages including various African and Indian languages as well as Medical Spanish models powered by NLU 3.4.1 Various bug fixes Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_5_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_5_0"
  },
  "1345": {
    "id": "1345",
    "title": "NLP Server release notes 0.6.0",
    "content": "0.6.0 Fields Details Name NLP Server Version 0.6.0 Type Minor Release Date 2022-04-06 Overview We are excited to release NLP Server v0.6.0! This new release comes with exciting new features and improvements that extend and enhance the capabilities of the NLP Server. This release comes with the ability to share the models with the Annotation Lab. This will enable easy access to custom models uploaded to or trained with the Annotation Lab or to pre-trained models downloaded to Annotation Lab from the NLP Models Hub. As such the NLP Server becomes an easy and quick tool for testing our trained models locally on your own infrastructure with zero data sharing. Another important feature we have introduced is the support for Spark OCR spells. Now we can upload images, PDFs, or other documents to the NLP Server and run OCR spells on top of it. The results of the processed documents are also available for export. The release also includes a few improvements to the existing features and some bug fixes. Key Information For a smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications NLP Server is now available on Azure Marketplace as well as on AWS marketplace. Major Features and Improvements Support for custom models trained with the Annotation Lab Models trained with the Annotation Lab are now available as “custom” spells in the NLP Server. Similarly, models manually uploaded to the Annotation Lab, or downloaded from the NLP Models Hub are also made available for use in the NLP Server. This is only supported in a docker setup at present when both tools are deployed in the same machine. Support for Spark OCR spells OCR spells are now supported by NLP Server in the presence of a valid OCR license. Users can upload an image, PDF, or other supported document format and run the OCR spells on it. The processed results are also available for download as a text document. It is also possible to upload multiple files at once for OCR operation. These files can be images, PDFs, word documents, or a zipped file. Other Improvements Now users can chain multiple spells together to analyze the input data. The order of operation on the input data will be in the sequence of the spell chain from left to right. NLP Server now supports more than 5000+ models in 250+ languages powered by NLU. Bug Fixes Not found error seen when running predictions using certain spells. The prediction job runs in an infinite loop when using certain spells. For input data having new line characters JSON exception was seen when processing the output from NLU. Incorrect license information was seen in the license popup. Spell field cleared abruptly when typing the spells. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_0"
  },
  "1346": {
    "id": "1346",
    "title": "NLP Server release notes 0.6.1",
    "content": "0.6.1 Fields Details Name NLP Server Version 0.6.1 Type Patch Release Date 2022-05-06 Overview We are excited to release NLP Server v0.6.1! We are continually committed towards improving the experience for our users and making our product reliable and easy to use. This release focuses on improving the stability of the NLP Server and cleaning up some annoying bugs. To enhance the user experience, the product now provides interactive and informative responses to the users. The improvements and bug fixes are mentioned in their respective sections below. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplace. Improvements Support for new models for Lemmatizers, Parts of Speech Taggers, and Word2Vec Embeddings for over 66 languages, with 20 languages being covered for the first time by NLP Server, including ancient and exotic languages like Ancient Greek, Old Russian, Old French and much more. Bug Fixes The prediction job runs in an infinite loop when using certain spells. Now after 3 retries it aborts the process and informs users appropriately. Issue when running lang spell for language classification. The prediction job runs in an infinite loop when incorrect data format is selected for a given input data. The API request for processing spell didn’t work when format parameter was not provided. Now it uses a default value in such case. Users were unable to login to their MYJSL account from NLP Server. Proper response when there is issue in internet connectivity when running spell. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_1",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_6_1"
  },
  "1347": {
    "id": "1347",
    "title": "NLP Server release notes 0.7.0",
    "content": "0.7.0 Fields Details Name NLP Server Version 0.7.0 Type Minor Release Date 2022-06-07 Overview We are excited to release NLP Server v0.7.0! This new release comes with an exciting new feature of table extraction from various file formats. Table extraction feature enables extracting tabular content from the document. This extracted content is available as JSON and hence can again be processed with different spells for further predictions. The various supported files formats are documents (pdf, doc, docx), slides (ppt, pptx), and zipped content containing the mentioned formats. The improvements are mentioned in their respective sections below. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplace. Major Features and Improvements Support for Table extraction NLP Server now supports extracting tabular content from various file types. The currently supported file types are documents (pdf, doc, docx), slides (ppt, pptx), and zipped content containing any of the mentioned formats. These extracted contents are available as JSON output from both UI and API that can easily be converted to suitable Data Frames (e.g., pandas DF) for further processing. The output of the table extraction process can also be viewed in the NLP Server UI as a flat table. Currently, if multiple tables are extracted from the document, then only one of the tables selected randomly will be shown as a preview in the UI. However, upon downloading all the extracted tables are exported in separate JSON dumps combined in a single zipped file. For this version, the table extraction on PDF files is successful only if the PDF contains necessary metadata about the table content. Other Improvements Support for over 600 new models, and over 75 new languages including ancient, dead, and extinct languages. Transformer-based embeddings and token classifiers are powered by state-of-the-art CamemBertEmbeddings and DeBertaForTokenClassification based architectures. Added Portuguese De-identification models, NER models for Gene detection, and RxNorm Sentence resolution model for mapping and extracting pharmaceutical actions as well as treatments. JSON payload is now supported in the request body when using create result API. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_0",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_0"
  },
  "1348": {
    "id": "1348",
    "title": "NLP Server release notes 0.7.1",
    "content": "0.7.1 Fields Details Name NLP Server Version 0.7.1 Type Patch Release Date 2022-06-17 Overview We are excited to release NLP Server v0.7.1! We are committed to continuously improve the experience for our users and make our product reliable and easy to use. This release focuses on solving a few bugs and improving the stability of the NLP Server. Key Information For smooth and optimal performance, it is recommended to use an instance with 8 core CPU, and 32GB RAM specifications. NLP Server is available on both AWS and Azure marketplaces. Bug Fixes Issue when running NER ONTO spell. Issue when running dep spell. Since the spell was broken it is temporarily blacklisted. Document normalizer included the HTML, XML tags to the output even after normalization. Issue when running language translation spells &lt;from_lang&gt;.translate_to.&lt;to_lang&gt;. Upon cancelation of custom model uploading job exception was seen in the logs. Some few UI related issues and abnormalities during operation. Versions Version Version Version 0.7.1 0.7.0 0.6.1 0.6.0 0.5.0 0.4.0",
    "url": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_1",
    "relUrl": "/docs/en/nlp_server/nlp_server_versions/release_notes_0_7_1"
  },
  "1349": {
    "id": "1349",
    "title": "Spark NLP release notes 1.0.0",
    "content": "1.0.0 Release date: 12-02-2020 Overview Spark NLP OCR functionality was reimplemented as set of Spark ML transformers and moved to separate Spark OCR library. New Features Added extraction coordinates of each symbol in ImageToText Added ImageDrawRegions transformer Added ImageToPdf transformer Added ImageMorphologyOpening transformer Added ImageRemoveObjects transformer Added ImageAdaptiveThresholding transformer Enhancements Reimplement main functionality as Spark ML transformers Moved DrawRectangle functionality to PdfDrawRegions transformer Added ‘start’ function with support SparkMonitor initialization Moved PositionFinder to Spark OCR Bugfixes Fixed bug with transforming complex pdf to image Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_0_0"
  },
  "1350": {
    "id": "1350",
    "title": "Spark NLP release notes 1.10.0",
    "content": "1.10.0 Release date: 20-01-2021 Overview Support Microsoft Docx documents. New Features Added DocToText transformer for extract text from DOCX documents. Added DocToTextTable transformer for extract table data from DOCX documents. Added DocToPdf transformer for convert DOCX documents to PDF format. Bugfixes Fixed issue with loading model data on some cluster configurations Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_10_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_10_0"
  },
  "1351": {
    "id": "1351",
    "title": "Spark NLP release notes 1.11.0",
    "content": "1.11.0 Release date: 25-02-2021 Overview Support German, French, Spanish and Russian languages. Improving PositionsFinder and ImageToText for better support de-identification. New Features Loading model data from S3 in ImageToText. Added support German, French, Spanish, Russian languages in ImageToText. Added different OCR model types: Base, Best, Fast in ImageToText. Enhancements Added spaces symbols to the output positions in the ImageToText transformer. Eliminate python-levensthein from dependencies for simplify installation. Bugfixes Fixed issue with extracting coordinates in in ImageToText. Fixed loading model data on cluster in yarn mode. New notebooks Languages Support Image DeIdentification Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_11_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_11_0"
  },
  "1352": {
    "id": "1352",
    "title": "Spark NLP release notes 1.1.0",
    "content": "1.1.0 Release date: 03-03-2020 Overview This release contains improvements for preprocessing image before run OCR and added possibility to store results to PDF for keep original formatting. New Features Added auto calculation maximum size of objects for removing in ImageRemoveObjects. This improvement avoids to remove . and affect symbols with dots (i, !, ?). Added minSizeFont param to ImageRemoveObjects transformer for activate this functional. Added ocrParams parameter to ImageToText transformer for set any ocr params. Added extraction font size in ImageToText Added TextToPdf transformer for render text with positions to pdf file. Enhancements Added setting resolution in ImageToText. And added ignoreResolution param with default true value to ImageToText transformer for back compatibility. Added parsing resolution from image metadata in BinaryToImage transformer. Added storing resolution in PdfToImage transformer. Added resolution field to Image schema. Updated ‘start’ function for set ‘PYSPARK_PYTHON’ env variable. Improve auto-scaling/skew correction: improved access to images values removing unnecessary copies of images adding more test cases improving auto-correlation in auto-scaling. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_0"
  },
  "1353": {
    "id": "1353",
    "title": "Spark NLP release notes 1.1.1",
    "content": "1.1.1 Release date: 06-03-2020 Overview Integration with license server. Enhancements Added license validation. License can be set in following waysq: Environment variable. Set variable ‘JSL_OCR_LICENSE’. System property. Set property ‘jsl.sparkocr.settings.license’. Application.conf file. Set property ‘jsl.sparkocr.settings.license’. Added auto renew license using jsl license server. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_1"
  },
  "1354": {
    "id": "1354",
    "title": "Spark NLP release notes 1.1.2",
    "content": "1.1.2 Release date: 09-03-2020 Overview Minor improvements and fixes Enhancements Improved messages during license validation Bugfixes Fixed dependencies issue Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_1_2",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_1_2"
  },
  "1355": {
    "id": "1355",
    "title": "Spark NLP release notes 1.2.0",
    "content": "1.2.0 Release date: 08-04-2020 Overview Improved support Databricks and processing selectable pdfs. Enhancements Adapted Spark OCR for run on Databricks. Added rewriting positions in ImageToText when run together with PdfToText. Added ‘positionsCol’ param to ImageToText. Improved support Spark NLP. Changed start function. New Features Added showImage implicit to Dataframe for display images in Scala Databricks notebooks. Added display_images function for display images in Python Databricks notebooks. Added propagation selectable pdf file in TextToPdf. Added ‘inputContent’ param to ‘TextToPdf’. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_2_0"
  },
  "1356": {
    "id": "1356",
    "title": "Spark NLP release notes 1.3.0",
    "content": "1.3.0 Release date: 22-05-2020 Overview New functionality for de-identification problem. Enhancements Renamed TesseractOCR to ImageToText. Simplified installation. Added check license from SPARK_NLP_LICENSE env varibale. New Features Support storing for binaryFormat. Added support storing Image and PDF files. Support selectable pdf for TextToPdf transformer. Added UpdateTextPosition transformer. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_3_0"
  },
  "1357": {
    "id": "1357",
    "title": "Spark NLP release notes 1.4.0",
    "content": "1.4.0 Release date: 23-06-2020 Overview Added support Dicom format and improved support image morphological operations. Enhancements Updated start function. Improved support Spark NLP internal. ImageMorphologyOpening and ImageErosion are removed. Improved existing transformers for support de-identification Dicom documents. Added possibility to draw filled rectangles to ImageDrawRegions. New Features Support reading and writing Dicom documents. Added ImageMorphologyOperation transformer which support: erosion, dilation, opening and closing operations. Bugfixes Fixed issue in ImageToText related to extraction coordinates. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_4_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_4_0"
  },
  "1358": {
    "id": "1358",
    "title": "Spark NLP release notes 1.5.0",
    "content": "1.5.0 Release date: 22-07-2020 Overview FoundationOne report parsing support. Enhancements Optimized memory usage during image processing New Features Added FoundationOneReportParser which support parsing patient info, genomic and biomarker findings. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_5_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_5_0"
  },
  "1359": {
    "id": "1359",
    "title": "Spark NLP release notes 1.6.0",
    "content": "1.6.0 Release date: 05-09-2020 Overview Support parsing data from tables for selectable PDFs. New Features Added PdfToTextTable transformer for extract tables from Pdf document per each page. Added ImageCropper transformer for crop images. Added ImageBrandsToText transformer for detect text in defined areas. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_6_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_6_0"
  },
  "1360": {
    "id": "1360",
    "title": "Spark NLP release notes 1.7.0",
    "content": "1.7.0 Release date: 22-09-2020 Overview Support Spark 2.3.3. Bugfixes Restored read JPEG2000 image Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_7_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_7_0"
  },
  "1361": {
    "id": "1361",
    "title": "Spark NLP release notes 1.8.0",
    "content": "1.8.0 Release date: 20-11-2020 Overview Optimisation performance for processing multipage PDF documents. Support up to 10k pages per document. New Features Added ImageAdaptiveBinarizer Scala transformer with support: Gaussian local thresholding Otsu thresholding Sauvola local thresholding Added possibility to split pdf to small documents for optimize processing in PdfToImage. Enhancements Added applying binarization in PdfToImage for optimize memory usage. Added pdfCoordinates param to the ImageToText transformer. Added ‘total_pages’ field to the PdfToImage transformer. Added different splitting strategies to the PdfToImage transformer. Simplified paging PdfToImage when run it with splitting to small PDF. Added params to the PdfToText for disable extra functionality. Added master_url param to the python start function. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_8_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_8_0"
  },
  "1362": {
    "id": "1362",
    "title": "Spark NLP release notes 1.9.0",
    "content": "1.9.0 Release date: 11-12-2020 Overview Extension of FoundationOne report parser and support HOCR output format. New Features Added ImageToHocr transformer for recognize text from image and store it to HOCR format. Added parsing gene lists from ‘Appendix’ in FoundationOneReportParser transformer. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_1_9_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_1_9_0"
  },
  "1363": {
    "id": "1363",
    "title": "Annotation Lab Release Notes 2.0.1",
    "content": "2.0.1 Highlights Inter-Annotation Agreement Charts. To get a measure of how well multiple annotators can make the same annotation decision for a certain category, we are shipping seven different charts. To see these charts users can click on the third tab “Inter-Annotator Agreement” of the Analytics Dashboard of NER projects. There are dropdown boxes to change annotators for comparison purposes. It is also possible to download the data of some charts in CSV format by clicking the download button present at the bottom right corner of each of them. Updated CONLL Export. In previous versions, numerous files were created based on Tasks and Completions. There were issues in the Header and no sentences were detected. Also, some punctuations were not correctly exported or were missing. The new CONLL export implementation results in a single file and fixes all the above issues. As in previous versions, if only Starred completions are needed in the exported file, users can select the “Only ground truth” checkbox. Search tasks by label. Now, it is possible to list the tasks based on some annotation criteria. Examples of supported queries: “label: ABC”, “label: ABC=DEF”, “choice: Mychoice”, “label: ABC=DEF”. Validation of labels and models is done beforehand. An error message is shown if the label is incompatible with models. Transfer Learning support for Training Models. Now its is possible to continue model training from an already available model. If a Medical NER model is present in the system, the project owner or manager can go to Advanced Options settings of the Training section in the Setup Page and choose it to Fine Tune the model. When Fine Tuning is enabled, the embeddings that were used to train the model need to be present in the system. If present, it will be automatically selected, otherwise users need to go to the Models Hub page and download or upload it. Training Community Models without the need of License. In previous versions, Annotation Lab didn’t allow training without the presence of Spark NLP for Healthcare license. But now the training with community embeddings is allowed even without the presence of Valid license. Support for custom training scripts. If users want to change the default Training script present within the Annotation Lab, they can upload their own training pipeline. In the Training section of the Project Setup Page, only admin users can upload the training scripts. At the moment we are supporting the NER custom training script only. Users can now see a proper message on the Modelshub page when annotationlab is not connected to the internet (AWS S3 to be more precise). This happens in air-gapped environments or some issues in the enterprise network. Users now have the option to download the trained models from the Models Hub page. The download option is available under the overflow menu of each Model on the “Available Models” tab. Training Live Logs are improved in terms of content and readability. Not all Embeddings present in the Models Hub are supported by NER and Assertion Status Training. These are now properly validated from the UI. Conflict when trying to use deleted embeddings. The existence of the embeddings in training as well as in deployment is ensured and a readable message is shown to users. Support for adding custom CA certificate chain. Follow the instructions described in instruction.md file present in the installation artifact. Bug fixes When multiple paged OCR file was imported using Spark OCR, the task created did not have pagination. Due to a bug in the Assertion Status script, the training was not working at all. Any AdminUser could delete the main “admin” user as well as itself. We have added proper validation to avoid such situations. Read more Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_0_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_0_1"
  },
  "1364": {
    "id": "1364",
    "title": "Annotation Lab Release Notes 2.1.0",
    "content": "2.1.0 Highlights A new project configuration “Visual NER Labeling” was added, which provides the skeleton for text annotation on scanned images. Project Owners or Project Manager can train open-source models too. The UI components and navigation of Annotation Lab - as a SPA - continues to improve its performance. The application has an increased performance (security and bug fixes, general optimizations). More models &amp; embeddings included in the Annotation Lab image used for deployments. This should reduce the burden for system admins during the installation in air-gapped or enterprise environments. Easier way to add relations. Project Owners and Managers can see the proper status of tasks, taking into account their own completions. Security Fixes. We understand and take the security issues as the highest priority. On every release, we run our artifacts and images through series of security testings (Static Code analysis, PenTest, Images Vulnerabilities Test, AWS AMI Scan Test). This version resolves a few critical issues that were recently identified in Python Docker image we use. We have upgraded it to a higher version. Along with this upgrade, we have also refactored our codebase to pass our standard Static Code Analysis. Bug fixes An issue with using Uploaded models was fixed so any uploaded models can be loaded in Project Config and used for preannotation. Issues related to error messages when uploading a valid Spark OCR license and when trying to train NER models while Spark OCR license was expired are now fixed. The issue with exporting annotations in COCO format for image projects was fixed. Project Owners and Managers should be able to export COCO format which also includes images used for annotations. The bug reports related to unexpected scrolling of the Labeling page, issues in Swagger documentation, and typos in some hover texts are now fixed. Read more Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_1_0"
  },
  "1365": {
    "id": "1365",
    "title": "Annotation Lab Release Notes 2.2.20",
    "content": "2.2.2 Highlights Support for pretrained Relation Extraction and Assertion Status models. A valid Spark NLP for HealthCare License is needed to download pretrained models via the Models Hub page. After download, they can be added to the Project Config and used for preannotations. Support for uploading local images. Until this version, only images from remote URLs could be uploaded for Image projects. With this version the Annotation Lab supports uploading images from you local storage/computer. It is possible to either import one image or multiple images by zipping them together. The maximum image file size is 16 MB. If you need to upload files exceding the default configuration, please contact your system administrator who will change the limit size in the installation artifact and run the upgrade script. Improved support for Visual NER projects. A sample task can be imported from the Import page by clicking the “Add Sample Task” button. Also default config for the Visual NER project contains zoom feature which supports maximum possible width for low resolution images when zooming. Improved Relation Labeling. Creating numerous relations in a single task can look a bit clumsy. The limited space in Labeling screen, the relation arrows and different relation types all at once could create difficulty to visualize them properly. We improved the UX for this feature: Spaces between two lines if relations are present Ability to Filter by certain relations When hovered on one relation, only that is focused Miscellaneous. Generally when a first completion in a task is submitted, it is very likely for that completion to be the ground truth for that task. Starting with this version, the first submitted completion gets automatically starred. Hitting submit button on next completion, annotator are asked to either just submit or submit and star it. Bug fixes On restart of the Annotation Lab machine/VM all Downloaded models (from Models Hub) compatible with Spark NLP 3.1 version were deleted. We have now fixed this issue. Going forward, it is user’s responsibility to remove any incompatible models. Those will only be marked as “Incompatible” in Models Hub. This version also fixes some reported issues in training logs. The CONLL exports were including Assertion Status labels too. Going forward Assertion Status labels will be excluded given correct Project Config is setup. Read more Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_2_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_2_2"
  },
  "1366": {
    "id": "1366",
    "title": "Annotation Lab Release Notes 2.3.0",
    "content": "2.3.0 Highlights Multipage PDF annotation. Annotation Lab 2.3.0 supports the complete flow of import, annotation, and export for multi-page PDF files. Users have two options for importing a new PDF file into the Visual NER project: Import PDF file from local storage Add a link to the PDF file in the file attribute. After import, the user can see a task on the task page with a file name. On the labeling page, the user can view the PDF file with pagination so that the user can annotate the PDF one page at a time. After completing the annotation, the user can submit a task and it is ready to be exported to JSON and the user can import this exported file into any Visual NER project. [Note: Export in COCO format is not yet supported for PDF file] Redesign of the Project Setup Page. With the addition of many new features on every release, the Project Setup page became crowded and difficult to digest by users. In this release we have split its main components into multiple tabs: Project Description, Sharing, Configuration, and Training. Train and Test Dataset. Project Owner/Manager can tag the tasks that will be used for train and for test purposes. For this, two predefined tags will be available in all projects: Train and Test. Enhanced Relation Annotation. The user experience while annotating relations on the Labeling page has been improved. Annotators can now select the desired relation(s) by clicking the plus “+” sign present next to the relations arrow. Other UX improvements: Multiple items selection with Shift Key in Models Hub and Tasks page, Click instead of hover on more options in Models Hub and Tasks page, Tabbed View on the ModelsHub page. Bug fixes Validations related to Training Settings across different types of projects were fixed. It is not very common to upload an expired license given a valid license is already present. But in case users did that there was an issue while using a license in the spark session because only the last uploaded license was used. Now it has been fixed to use any valid license no matter the order of upload. Sometimes search and filters in the ModelsHub page were not working. Also, there was an issue while removing defined labels on the Upload Models Form. Both of these issues are fixed. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_3_0"
  },
  "1367": {
    "id": "1367",
    "title": "Spark NLP for Healthcare Release Notes 2.4.0",
    "content": "2.4.0 Overview We are glad to announce Spark NLP for Healthcare 2.4.0. This is an important release because of several refactorizations achieved in the core library, plus the introduction of several state of the art algorithms, new features and enhancements. We have included several architecture and performance improvements, that aim towards making the library more robust in terms of storage handling for Big Data. In the NLP aspect, we have introduced a ContextualParser, DocumentLogRegClassifier and a ChunkEntityResolverSelector. These last two Annotators also target performance time and memory consumption by lowering the order of computation and data loaded to memory in each step when designed following a hierarchical pattern. We have put a big effort on this one, so please enjoy and share your comments. Your words are always welcome through all our different channels. Thank you very much for your important doubts, bug reports and feedback; they are always welcome and much appreciated. New Features BigChunkEntityResolver Annotator: New experimental approach to reduce memory consumption at expense of disk IO. ContextualParser Annotator: New entity parser that works based on context parameters defined in a JSON file. ChunkEntityResolverSelector Annotator: New AnnotatorModel that takes advantage of the RecursivePipelineModel + LazyAnnotator pattern to annotate with different LazyAnnotators at runtime. DocumentLogregClassifier Annotator: New Annotator that provides a wrapped TFIDF Vectorizer + LogReg Classifier for TOKEN AnnotatorTypes (either at Document level or Chunk level) Enhancements normalizedColumn Param is no longer required in ChunkEntityResolver Annotator (defaults to the labelCol Param value). ChunkEntityResolverMetadata now has more data to infer whether the match is meaningful or not. Bugfixes Fixed a bug on ContextSpellChecker Annotator where unrecognized tokens would cause an exception if not in vocabulary. Fixed a bug on ChunkEntityResolver Annotator where undetermined results were coming out of negligible confidence scores for matches. Fixed a bug on ChunkEntityResolver Annotator where search would fail if the neighbours Param was grater than the number of nodes in the tree. Now it returns up to the number of nodes in the tree. Deprecations OCR Moves to its own JSL Spark OCR project. Infrastructure Spark NLP License is now required to utilize the library. Please follow the instructions on the shared email. Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_0"
  },
  "1368": {
    "id": "1368",
    "title": "Annotation Lab Release Notes 2.4.0",
    "content": "2.4.0 Annotation Lab v2.4.0 adds relation creation features for Visual NER projects and redesigns the Spark NLP Pipeline Config on the Project Setup Page. Several bug fixes and stabilizations are also included. Following are the highlights: Highlights Relations on Visual NER Projects. Annotators can create relations between annotated tokens/regions in Visual NER projects. This functionality is similar to what we already had in text-based projects. It is also possible to assign relation labels using the contextual widget (the “+” sign displayed next to the relation arrow). SparkNLP Pipeline Config page was redesigned. The SparkNLP Pipeline Config in the Setup Page was redesigned to ease filtering, collapsing, and expanding models and labels. For a more intuitive use, the Add Label button was moved to the top right side of the tab and no longer scrolls with the config list. This version also adds many improvements to the new Setup Page. The Training and Active Learning Tabs are only available to projects for which Annotation Lab supports training. When unsaved changes are present in the configuration, the user cannot move to the Training and Active Learning Tab and/or Training cannot be started. When the OCR server was not deployed, imports in the Visual NER project were failing. With this release, when a valid Spark OCR license is present, the OCR server is deployed and the import of pdf and image files is executed. Bug fixes When a login session is timed out and cookies are expired, users had to refresh the page to get the login screen. This known issue has been fixed and the user will be redirected to the login page. When a task was assigned to an annotator who does not have completions for it, the task status was shown incorrectly. This was fixed in this version. While preannotating tasks with some specific types of models, only the first few lines were annotated. We have fixed the Spark NLP pipeline for such models and now the entire document gets preannotations. When Spark NLP for Healthcare license was expired, the deployment was allowed but it used to fail. Now a proper message is shown to Project Owners/Managers and the deployment is not started in such cases. Inconsistencies were present in training logs and some embeddings were not successfully used for models training. Along with these fixes, several UI bugs are also fixed in this release. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_4_0"
  },
  "1369": {
    "id": "1369",
    "title": "Spark NLP for Healthcare Release Notes 2.4.1",
    "content": "2.4.1 Overview Introducing Spark NLP for Healthcare 2.4.1 after all the feedback we received in the form of issues and suggestions on our different communication channels. Even though 2.4.0 was very stable, version 2.4.1 is here to address minor bug fixes that we summarize in the following lines. Bugfixes Changing the license Spark property key to be “jsl” instead of “sparkjsl” as the latter generates inconsistencies Fix the alignment logic for tokens and chunks in the ChunkEntityResolverSelector because when tokens and chunks did not have the same begin-end indexes the resolution was not executed Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_1"
  },
  "1370": {
    "id": "1370",
    "title": "Spark NLP for Healthcare Release Notes 2.4.2",
    "content": "2.4.2 Overview We are glad to announce Spark NLP for Healthcare 2.4.2. As a new feature we are happy to introduce our new Disambiguation Annotator, which will let the users resolve different kind of entities based on Knowledge bases provided in the form of Records in a RocksDB database. We also enhanced / fixed DocumentLogRegClassifier, ChunkEntityResolverModel and ChunkEntityResolverSelector Annotators. New Features Disambiguation Annotator (NerDisambiguator and NerDisambiguatorModel) which accepts annotator types CHUNK and SENTENCE_EMBEDDINGS and returns DISAMBIGUATION annotator type. This output annotation type includes all the matches in the result and their similarity scores in the metadata. Enhancements ChunkEntityResolver Annotator now supports both EUCLIDEAN and COSINE distance for the KNN search and WMD calculation. Bugfixes Fixed a bug in DocumentLogRegClassifier Annotator to support its serialization to disk. Fixed a bug in ChunkEntityResolverSelector Annotator to group by both SENTENCE and CHUNK at the time of forwarding tokens and embeddings to the lazy annotators. Fixed a bug in ChunkEntityResolverModel in which the same exact embeddings was not included in the neighbours. Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_2"
  },
  "1371": {
    "id": "1371",
    "title": "Spark NLP for Healthcare Release Notes 2.4.5",
    "content": "2.4.5 Overview We are glad to announce Spark NLP for Healthcare 2.4.5. As a new feature we are happy to introduce our new EnsembleEntityResolver which allows our Entity Resolution architecture to scale up in multiple orders of magnitude and handle datasets of millions of records on a sub-log computation increase We also enhanced our ChunkEntityResolverModel with 5 new distance calculations with weighting-array and aggregation-strategy params that results in more levers to finetune its performance against a given dataset. New Features EnsembleEntityResolver consisting of an integrated TFIDF-Logreg classifier in the first layer + Multiple ChunkEntityResolvers in the second layer (one per each class) Five (5) new distances calculations for ChunkEntityResolver, namely: Token Based: TFIDF-Cosine, Jaccard, SorensenDice Character Based: JaroWinkler and Levenshtein Weight parameter that works as a multiplier for each distance result to be considered during their aggregation Three (3) aggregation strategies for the enabled distance in a particular instance, namely: AVERAGE, MAX and MIN Enhancements ChunkEntityResolver can now compute distances over all the neighbours found and return the metadata just for the best alternatives that meet the threshold; before it would calculate them over the neighbours and return them all in the metadata ChunkEntityResolver now has an extramassPenalty parameter to accoun for penalization of token-length difference in compared strings Metadata for the ChunkEntityResolver has been updated accordingly to reflect all new features StringDistances class has been included in utils to aid in the calculation and organization of different types of distances for Strings HasFeaturesJsl trait has been included to support the serialization of Features including [T] &lt;: AnnotatorModel[T] types Bugfixes Frequency calculation for WMD in ChunkEntityResolver has been adjusted to account for real word count representation AnnotatorType for DocumentLogRegClassifier has been changed to CATEGORY to align with classifiers in Open Source library Deprecations Legacy EntityResolver{Approach, Model} classes have been deprecated in favor of ChunkEntityResolver classes ChunkEntityResolverSelector classes has been deprecated in favor of EnsembleEntityResolver Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_5"
  },
  "1372": {
    "id": "1372",
    "title": "Spark NLP for Healthcare Release Notes 2.4.6",
    "content": "2.4.6 Overview We release Spark NLP for Healthcare 2.4.6 to fix some minor bugs. Bugfixes Updated IDF value calculation to be probabilistic based log[(N - df_t) / df_t + 1] as opposed to log[N / df_t] TFIDF cosine distance was being calculated with the rooted norms rather than with the original squared norms Validation of label cols is now performed at the beginning of EnsembleEntityResolver Environment Variable for License value named jsl.settings.license Now DocumentLogRegClassifier can be serialized from Python (bug introduced with the implementation of RecursivePipelines, LazyAnnotator attribute) Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_6",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_4_6"
  },
  "1373": {
    "id": "1373",
    "title": "Spark NLP for Healthcare Release Notes 2.5.0",
    "content": "2.5.0 Overview We are happy to bring you Spark NLP for Healthcare 2.5.0 with new Annotators, Models and Data Readers. Model composition and iteration is now faster with readers and annotators designed for real world tasks. We introduce ChunkMerge annotator to combine all CHUNKS extracted by different Entity Extraction Annotators. We also introduce an Annotation Reader for JSL AI Platform’s Annotation Tool. This release is also the first one to support the models: ner_large_clinical, ner_events_clinical, assertion_dl_large, chunkresolve_loinc_clinical, deidentify_large And of course we have fixed some bugs. New Features AnnotationToolJsonReader is a new class that imports a JSON from AI Platform’s Annotation Tool an generates NER and Assertion training datasets ChunkMerge Annotator is a new functionality that merges two columns of CHUNKs handling overlaps with a very straightforward logic: max coverage, max # entities ChunkMerge Annotator handles inputs from NerDLModel, RegexMatcher, ContextualParser, TextMatcher A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode Enhancements DeIdentification Annotator has a more consistent API: mode param with values (‘mask’l’obfuscate’) to drive its behavior dateFormats param a list of string values to to select which dateFormats to obfuscate (and which to just mask) DeIdentification Annotator no longer automatically obfuscates dates. Obfuscation is now driven by mode and dateFormats params A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode Bugfixes DeIdentification Annotator now correctly deduplicates protected entities coming from NER / Regex DeIdentification Annotator now indexes chunks correctly after merging them AssertionDLApproach Annotator can now be trained with the graph in any folder specified by setting graphFolder param AssertionDLApproach now has the setClasses param setter in Python wrapper JVM Memory and Kryo Max Buffer size increased to 32G and 2000M respectively in sparknlp_jsl.start(secret) function Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_0"
  },
  "1374": {
    "id": "1374",
    "title": "Annotation Lab Release Notes 2.5.0",
    "content": "2.5.0 Annotation Lab v2.5.0 introduces support for rule based annotations, new search feature and COCO format export for Visual NER projects. It also includes fixes for the recently identified security issues and other known bugs. Below are the highlights of this release. Highlights Rule Based Annotations. Spark NLP for Healthcare supports rule-based annotations via the ContextualParser Annotator. In this release Annotationlab adds support for creating and using ContextualParser rules in NER project. Any user with admin privilegis can see rules under the Available Rules tab on the Models Hub page and can create new rules using the + Add Rule button. After adding a rule on Models Hub page, the Project Owner or Manager can add the rule to the configuration of the project where he wants to use it. This can be done via the Rules tab from the Project Setup page under the Project Configuration tab. A valid Spark NLP for Healthcare licence is required to deploy rules from project config. Two types of rules are supported:1. Regex Based: User can enter the Regex which matches to the entities of the required label; and 2. Dictionary Based: User can create a dictionary of labels and user can upload the CSV of the list of entity that comes under the label. Search through Visual NER Projects. For the Visual NER Projects, it is now possible to search for a keyword inside of image/pdf based tasks using the search box available on the top of the Labeling page. Currently, the search is performed on the current page only. Furthermore, we have also extended the keyword-based task search already available for text-based projects for Visual NER Projects. On the Tasks page, use the search bar on the upper right side of the screen like you would do in other text-based projects, to identify all image/pdf tasks containing a given text. COCO export for pdf tasks in Visual NER Projects. Up until now, the COCO format export was limited to simple image documents. With version 2.5.0, this functionality is extended to single-page or multi-page pdf documents. In Classification Project, users are now able to use different layouts for the list of choices: layout=&quot;select&quot;: It will change choices from list of choices inline to dropdown layout. Possible values are &quot;select&quot;, &quot;inline&quot;, &quot;vertical&quot; choice=&quot;multiple&quot;: Allow user to select multiple values from dropdown. Possible values are: &quot;single&quot;, &quot;single-radio&quot;, &quot;multiple&quot; Better Toasts, Confirmation-Boxes and Masking UI on potentially longer operations. Security Fixes Annotationlab v2.5.0 got different Common Vulnerabilities and Exposures(CVE) issues fixed. As always, in this release we performed security scans to detect CVE issues, upgraded python packages to eliminate known vulnerabilities and also we made sure the CVE-2021-44228 (Log4j2 issue) is not present in any images used by Annotation Lab. A reported issue when logout endpoint was sometimes redirected to insecure http after access token expired was also fixed. Bug Fixes The Filters option in the Models Hub page was not working properly. Now the “Free/Licensed” filter can be selected/deselected without getting any error. After creating relations and saving/updating annotations for the Visual NER projects with multi-paged pdf files, the annotations and relations were not saved. An issue with missing text tokens in the exported JSON file for the Visual NER projects also have been fixed. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_5_0"
  },
  "1375": {
    "id": "1375",
    "title": "Spark NLP for Healthcare Release Notes 2.5.2",
    "content": "2.5.2 Overview We are really happy to bring you Spark NLP for Healthcare 2.5.2, with a couple new features and several enhancements in our existing annotators. This release was mainly dedicated to generate adoption in our AnnotationToolJsonReader, a connector that provide out-of-the-box support for out Annotation Tool and our practices. Also the ChunkMerge annotator has ben provided with extra functionality to remove entire entity types and to modify some chunk’s entity type We also dedicated some time in finalizing some refactorization in DeIdentification annotator, mainly improving type consistency and case insensitive entity dictionary for obfuscation. Thanks to the community for all the feedback and suggestions, it’s really comfortable to navigate together towards common functional goals that keep us agile in the SotA. New Features Brand new IOBTagger Annotator NerDL Metrics provides an intuitive DataFrame API to calculate NER metrics at tag (token) and entity (chunk) level Enhancements AnnotationToolJsonReader includes parameters for document cleanup, sentence boundaries and tokenizer split chars AnnotationToolJsonReader uses the task title if present and uses IOBTagger annotator AnnotationToolJsonReader has improved alignment in assertion train set generation by using an alignTol parameter as tollerance in chunk char alignment DeIdentification refactorization: Improved typing and replacement logic, case insensitive entities for obfuscation ChunkMerge Annotator now handles: Drop all chunks for an entity Replace entity name Change entity type for a specific (chunk, entity) pair Drop specific (chunk, entity) pairs caseSensitive param to EnsembleEntityResolver Output logs for AssertionDLApproach loss Disambiguator is back with improved dependency management Bugfixes Bugfix in python when Annotators shared domain parts across public and internal Bugfix in python when ChunkMerge annotator was loaded from disk ChunkMerge now weights the token coverage correctly when multiple multi-token entities overlap Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_2"
  },
  "1376": {
    "id": "1376",
    "title": "Spark NLP for Healthcare Release Notes 2.5.3",
    "content": "2.5.3 Overview We are pleased to announce the release of Spark NLP for Healthcare 2.5.3. This time we include four (4) new Annotators: FeatureAssembler, GenericClassifier, Yake Keyword Extractor and NerConverterInternal. We also include helper classes to read datasets from CodiEsp and Cantemist Spanish NER Challenges. This is also the first release to support the following models: ner_diag_proc (spanish), ner_neoplasms (spanish), ner_deid_enriched (english). We have also included Bugifxes and Enhancements for AnnotationToolJsonReader and ChunkMergeModel. New Features FeatureAssembler Transformer: Receives a list of column names containing numerical arrays and concatenates them to form one single feature_vector annotation GenericClassifier Annotator: Receives a feature_vector annotation and outputs a category annotation Yake Keyword Extraction Annotator: Receives a token annotation and outputs multi-token keyword annotations NerConverterInternal Annotator: Similar to it’s open source counterpart in functionality, performs smarter extraction for complex tokenizations and confidence calculation Readers for CodiEsp and Cantemist Challenges Enhancements AnnotationToolJsonReader includes parameter for preprocessing pipeline (from Document Assembling to Tokenization) AnnotationToolJsonReader includes parameter to discard specific entity types Bugfixes ChunkMergeModel now prioritizes highest number of different entities when coverage is the same Models We have 2 new spanish models for Clinical Entity Recognition: ner_diag_proc and ner_neoplasms We have a new english Named Entity Recognition model for deidentification: ner_deid_enriched Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_3"
  },
  "1377": {
    "id": "1377",
    "title": "Spark NLP for Healthcare Release Notes 2.5.5",
    "content": "2.5.5 Overview We are very happy to release Spark NLP for Healthcare 2.5.5 with a new state-of-the-art RelationExtraction annotator to identify relationships between entities coming from our pretrained NER models. This is also the first release to support Relation Extraction with the following two (2) models: re_clinical and re_posology in the clinical/models repository. We also include multiple bug fixes as usual. New Features RelationExtraction annotator that receives WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY and returns the CATEGORY of the relationship and a confidence score. Enhancements AssertionDL Annotator now keeps logs of the metrics while training DeIdentification now has a default behavior of merging entities close in Levenshtein distance with setConsistentObfuscation and setSameEntityThreshold params. DeIdentification now has a specific parameter setObfuscateDate to obfuscate dates (which will be otherwise just masked). The only formats obfuscated when the param is true will be the ones present in dateFormats param. NerConverterInternal now has a greedyMode param that will merge all contiguous tags of the same type regardless of boundary tags like “B”,”E”,”S”. AnnotationToolJsonReader includes mergeOverlapping parameter to merge (or not) overlapping entities from the Annotator jsons i.e. not included in the assertion list. Bugfixes DeIdentification documentation bug fix (typo) DeIdentification training bug fix in obfuscation dictionary IOBTagger now has the correct output type NAMED_ENTITY Deprecations EnsembleEntityResolver has been deprecated Models We have 2 new english Relationship Extraction model for Clinical and Posology NERs: re_clinical: with ner_clinical and embeddings_clinical re_posology: with ner_posology and embeddings_clinical Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_5_5"
  },
  "1378": {
    "id": "1378",
    "title": "Spark NLP for Healthcare Release Notes 2.6.0",
    "content": "2.6.0 Overview We are honored to announce that Spark NLP Enterprise 2.6.0 has been released. The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases. The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains. Models Pretrained Pipelines: The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows: pipeline = PretrainedPipeline(&#39;explain_clinical_doc_carp&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipeline.annotate(&#39;my string&#39;) Pipeline descriptions: explain_clinical_doc_carp a pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities. explain_clinical_doc_era a pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities. recognize_entities_posology a pipeline with ner_posology. It will only extract medication entities. More information and examples are available here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb. Pretrained Named Entity Recognition and Relationship Extraction Models (English) RE models: re_temporal_events_clinical re_temporal_events_enriched_clinical re_human_phenotype_gene_clinical re_drug_drug_interaction_clinical re_chemprot_clinical NER models: ner_human_phenotype_gene_clinical ner_human_phenotype_go_clinical ner_chemprot_clinical More information and examples here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb Pretrained Named Entity Recognition and Relationship Extraction Models (German) The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains. German Clinical NER model for 19 clinical entities German Legal NER model for 19 legal entities German ICD-10GM More information and examples here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/15.German_Legal_Model.ipynb Other Pretrained Models We now have Named Entity Disambiguation model out of the box. Disambiguation models map words of interest, such as names of persons, locations and companies, from an input text document to corresponding unique entities in a target Knowledge Base (KB). https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/12.Named_Entity_Disambiguation.ipynb Due to ongoing requests about Clinical Entity Resolvers, we release a notebook to let you see how to train an entity resolver using an open source dataset based on Snomed. https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_0"
  },
  "1379": {
    "id": "1379",
    "title": "Annotation Lab Release Notes 2.6.0",
    "content": "2.6.0 Annotation Lab v2.6.0 improves the performance of the Project Setup page, adds a “View as” option in the Labeling Page, improves the layout of OCR-ed documents, adds the option to stop training and model server deployment from UI. Many more cool features are also delivered in this version to enhance usability and stabilize the product. Here are details of features and bug fixes included in this release. Highlights Performance improvement in Setup page. In previous versions of Annotation Lab, changes in Project Configuration would take a long time to validate if that project included a high volume of completions. The configuration validation time is now almost instant, even for projects with thousand of tasks. Multiple tests were conducted on projects with more than 13K+ tasks and thousands of extractions per task. For all of those test situations, the validation of the Project Configuration took under 2 seconds. Those tests results were replicated for all types of projects including NER, Image, Audio, Classification, and HTML projects. New “View as” option in the labeling screen. When a user has multiple roles (Manager, Annotator, Reviewer), the Labeling Page should present and render different content and specific UX, depending on the role impersonated by the user. For a better user experience, this version adds a “View as” switch in the Labeling Page. Once the “View as” option is used to select a certain role, the selection is preserved even when the tab is closed or refreshed. OCR Layout improvement. In previous versions of the Annotation Lab, layout was not preserved in OCRed tasks. Recognized texts would be placed in a top to bottom approach without considering the paragraph each token belonged to. From this version on, we are using layout-preserving transformers from Spark OCR. As a result, tokens that belong to the same paragraph are now grouped together, producing more meaningful output. Ability to stop training and model server deployment. Up until now, training and model server deployment could be stopped by system admins only. This version of Annotation Lab provides Project Owners/Managers with the option to stop these processes simply by clicking a button in the UI. This option is necessary in many cases, such as when a manager/project owner starts the training process on a big project that takes a lot of resources and time, blocking access to preannotations to the other projects. Display meaningful message when training fails due to memory issues. In case the training of a model fails due to memory issues, the reason for the failure are available via the UI (i.e. out of memory error). Allow combining NER labels and Classification classes from Spark NLP pipeline config. The earlier version had an issue with adding choice from the predefined classification model to an existing NER project. This issue has been fixed in this version. Bug Fixes Previously there was a UI reloading issue when a User was removed from the “Annotators” user group, which has now been fixed. The user can log in without the reloading issue, a warning is shown in UI regarding the missing annotator privilege. Also, setting up the HTML NER Tagging project was not possible in the earlier version which has been fixed in this release. On the labeling page, the renamed title of the next served task was not displayed. Similarly, in the Import page, the count of the tasks imported was missing in the Import Status dialog box. Now both these issues are fixed. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_6_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_6_0"
  },
  "1380": {
    "id": "1380",
    "title": "Spark NLP for Healthcare Release Notes 2.6.2",
    "content": "2.6.2 Overview We are very happy to announce that version 2.6.2 of Spark NLP Enterprise is ready to be installed and used. We are making available Named Entity Recognition, Sentence Classification and Entity Resolution models to analyze Adverse Drug Events in natural language text from clinical domains. Models NERs We are pleased to announce that we have a brand new named entity recognition (NER) model for Adverse Drug Events (ADE) to extract ADE and DRUG entities from a given text. ADE NER will have four versions in the library, trained with different size of word embeddings: ner_ade_bioert (768d Bert embeddings) ner_ade_clinicalbert (768d Bert embeddings) ner_ade_clinical (200d clinical embeddings) ner_ade_healthcare (100d healthcare embeddings) More information and examples here We are also releasing our first clinical pretrained classifier for ADE classification tasks. This new ADE classifier is trained on various ADE datasets, including the mentions in tweets to represent the daily life conversations as well. So it works well on the texts coming from academic context, social media and clinical notes. It’s trained with Clinical Biobert embeddings, which is the most powerful contextual language model in the clinical domain out there. Classifiers ADE classifier will have two versions in the library, trained with different Bert embeddings: classifierdl_ade_bioert (768d BioBert embeddings) classifierdl_adee_clinicalbert (768d ClinicalBert embeddings) More information and examples here Pipeline By combining ADE NER and Classifier, we are releasing a new pretrained clinical pipeline for ADE tasks to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows: pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) pipeline.annotate(&#39;my string&#39;) explain_clinical_doc_ade is bundled with ner_ade_clinicalBert, and classifierdl_ade_clinicalBert. It can extract ADE and DRUG clinical entities, and then assign ADE status to a text (True means ADE, False means not related to ADE). More information and examples here Entity Resolver We are releasing the first Entity Resolver for Athena (Automated Terminology Harmonization, Extraction and Normalization for Analytics, http://athena.ohdsi.org/) to extract concept ids via standardized medical vocabularies. For now, it only supports conditions section and can be used to map the clinical conditions with the corresponding standard terminology and then get the concept ids to store them in various database schemas. It is named as chunkresolve_athena_conditions_healthcare. We added slim versions of several clinical NER models that are trained with 100d healthcare word embeddings, which is lighter and smaller in size. ner_healthcare assertion_dl_healthcare ner_posology_healthcare ner_events_healthcare Graph Builder Spark NLP Licensed version has several DL based annotators (modules) such as NerDL, AssertionDL, RelationExtraction and GenericClassifier, and they are all based on Tensorflow (tf) with custom graphs. In order to make the creating and customizing the tf graphs for these models easier for our licensed users, we added a graph builder to the Python side of the library. Now you can customize your graphs and use them in the respected models while training a new DL model. from sparknlp_jsl.training import tf_graph tf_graph.build(&quot;relation_extraction&quot;,build_params={&quot;input_dim&quot;: 6000, &quot;output_dim&quot;: 3, &#39;batch_norm&#39;:1, &quot;hidden_layers&quot;: [300, 200], &quot;hidden_act&quot;: &quot;relu&quot;, &#39;hidden_act_l2&#39;:1}, model_location=&quot;.&quot;, model_filename=&quot;re_with_BN&quot;) More information and examples here Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_6_2"
  },
  "1381": {
    "id": "1381",
    "title": "Spark NLP for Healthcare Release Notes 2.7.0",
    "content": "2.7.0 We are glad to announce that Spark NLP for Healthcare 2.7 has been released ! In this release, we introduce the following features: 1. Text2SQL Text2SQL Annotator that translates natural language text into SQL queries against a predefined database schema, which is one of the most sought-after features of NLU. With the help of a pretrained text2SQL model, you will be able to query your database without writing a SQL query: Example 1 Query: What is the name of the nurse who has the most appointments? Generated SQL query from the model: SELECT T1.Name FROM Nurse AS T1 JOIN Appointment AS T2 ON T1.EmployeeID = T2.PrepNurse GROUP BY T2.prepnurse ORDER BY count(*) DESC LIMIT 1 Response:   Name 0 Carla Espinosa Example 2 Query: How many patients do each physician take care of? List their names and number of patients they take care of. Generated SQL query from the model: SELECT T1.Name, count(*) FROM Physician AS T1 JOIN Patient AS T2 ON T1.EmployeeID = T2.PCP GROUP BY T1.Name Response:   Name count(*) 0 Christopher Turk 1 1 Elliot Reid 2 2 John Dorian 1 For now, it only comes with one pretrained model (trained on Spider dataset) and new pretrained models will be released soon. Check out the Colab notebook to see more examples and run on your data. 2. SentenceEntityResolvers In addition to ChunkEntityResolvers, we now release our first BioBert-based entity resolvers using the SentenceEntityResolver annotator. It’s fully trainable and comes with several pretrained entity resolvers for the following medical terminologies: CPT: biobertresolve_cpt ICDO: biobertresolve_icdo ICD10CM: biobertresolve_icd10cm ICD10PCS: biobertresolve_icd10pcs LOINC: biobertresolve_loinc SNOMED_CT (findings): biobertresolve_snomed_findings SNOMED_INT (clinical_findings): biobertresolve_snomed_findings_int RXNORM (branded and clinical drugs): biobertresolve_rxnorm_bdcd Example: text = &#39;He has a starvation ketosis but nothing significant for dry oral mucosa&#39; df = get_icd10_codes (light_pipeline_icd10, &#39;icd10cm_code&#39;, text)   chunks begin end code 0 a starvation ketosis 7 26 E71121 1 dry oral mucosa 66 80 K136 Check out the Colab notebook to see more examples and run on your data. You can also train your own entity resolver using any medical terminology like MedRa and UMLS. Check this notebook to learn more about training from scratch. 3. ChunkMerge Annotator In order to use multiple NER models in the same pipeline, Spark NLP Healthcare has ChunkMerge Annotator that is used to return entities from each NER model by overlapping. Now it has a new parameter to avoid merging overlapping entities (setMergeOverlapping) to return all the entities regardless of char indices. It will be quite useful to analyze what every NER module returns on the same text. 4. Starting SparkSession We now support starting SparkSession with a different version of the open source jar and not only the one it was built against by sparknlp_jsl.start(secret, public=&quot;x.x.x&quot;) for extreme cases. 5. Biomedical NERs We are releasing 3 new biomedical NER models trained with clinical embeddings (all one single entity models) ner_bacterial_species (comprising of Linneaus and Species800 datasets) ner_chemicals (general purpose and bio chemicals, comprising of BC4Chem and BN5CDR-Chem) ner_diseases_large (comprising of ner_disease, NCBI_Disease and BN5CDR-Disease) We are also releasing the biobert versions of the several clinical NER models stated below: ner_clinical_biobert ner_anatomy_biobert ner_bionlp_biobert ner_cellular_biobert ner_deid_biobert ner_diseases_biobert ner_events_biobert ner_jsl_biobert ner_chemprot_biobert ner_human_phenotype_gene_biobert ner_human_phenotype_go_biobert ner_posology_biobert ner_risk_factors_biobert Metrics (micro averages excluding O’s):   model_name clinical_glove_micro biobert_micro 0 ner_chemprot_clinical 0.816 0.803 1 ner_bionlp 0.748 0.808 2 ner_deid_enriched 0.934 0.918 3 ner_posology 0.915 0.911 4 ner_events_clinical 0.801 0.809 5 ner_clinical 0.873 0.884 6 ner_posology_small 0.941   7 ner_human_phenotype_go_clinical 0.922 0.932 8 ner_drugs 0.964   9 ner_human_phenotype_gene_clinical 0.876 0.870 10 ner_risk_factors 0.728   11 ner_cellular 0.813 0.812 12 ner_posology_large 0.921   13 ner_anatomy 0.851 0.831 14 ner_deid_large 0.942   15 ner_diseases 0.960 0.966 In addition to these, we release two new German NER models: ner_healthcare_slim (‘TIME_INFORMATION’, ‘MEDICAL_CONDITION’, ‘BODY_PART’, ‘TREATMENT’, ‘PERSON’, ‘BODY_PART’) ner_traffic (extract entities regarding traffic accidents e.g. date, trigger, location etc.) 6. PICO Classifier Successful evidence-based medicine (EBM) applications rely on answering clinical questions by analyzing large medical literature databases. In order to formulate a well-defined, focused clinical question, a framework called PICO is widely used, which identifies the sentences in a given medical text that belong to the four components: Participants/Problem (P) (e.g., diabetic patients), Intervention (I) (e.g., insulin), Comparison (C) (e.g., placebo) and Outcome (O) (e.g., blood glucose levels). Spark NLP now introduces a pretrained PICO Classifier that is trained with Biobert embeddings. Example: text = “There appears to be no difference in smoking cessation effectiveness between 1mg and 0.5mg varenicline.” pico_lp_pipeline.annotate(text)[&#39;class&#39;][0] ans: CONCLUSIONS Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_0"
  },
  "1382": {
    "id": "1382",
    "title": "Annotation Lab Release Notes 2.7.0",
    "content": "2.7.0 Release date: 17-02-2022 Annotation Lab 2.7.0 is here! This is another feature reach release from John Snow Labs - Annotation Lab Team. It is powered by the latest Spark NLP and Spark NLP for Healthcare libraries and offers improved support for Rule Base Annotation. With the upgrade of Spark NLP libraries, the Models Hub page inside the application gets more than 100 new models for English along with the introduction of Spanish and German models. In Visual NER projects it is now easier to annotate cross line chunks. As always, there are many security and stabilizations shipped. Highlights Annotation Lab 2.7.0 includes Spark NLP 3.4.1 and Spark NLP for Healthcare. Model training is now significantly faster and issues related to Rule-based annotation have been solved. The Models Hub has increased the list of models and old incompatible models are now marked as “incompatible”. If there are any incompatible models downloaded on the machine, we recommend deleting them. Spanish and German Models have been added to Models Hub. In previous versions of the Annotation Lab, the Models Hub only offered English language models. But from version 2.7.0, models for two other languages are included as well, namely Spanish and German. It is possible to download or upload these models and use them for preannotation, in the same way as for English language models. Rule-Based Annotation improvement. Rule-based annotation, introduced in 2.6.0 with limited options, was improved in this release. The Rule creation UI form was simplified and extended, and help tips were added on each field. While creating a rule, the user can define the scope of the rule as being sentence or document. A new toggle parameter Complete Match Regex is added to the rules. It can be toggled on to preannotate the entity that exactly matches the regex or dictionary value regardless of the Match Scope. Also case-sensitive is always true (and hence the toggle is hidden in this case) for REGEX while the case-sensitive toggle for dictionary can be toggled on or off. Users can now download the uploaded dictionary of an existing rule. In the previous release, if a dictionary-based rule was defined with an invalid CSV file, the preannotation server would crash and would only recover when the rule was removed from the configuration. This issue has been fixed and it is also possible to upload both vertical and horizontal CSV files consisting of multi-token dictionary values. Flexible annotations for Visual NER Projects. The chunk annotation feature added to Visual NER projects, allows the annotation of several consecutive tokens as one chunk. It also supports multiple lines selection. Users can now select multiple tokens and annotate them together in Visual NER Projects. The label assigned to a connected group can be updated. This change will apply to all regions in the group. Constraints for relation labeling can be defined. While annotating projects with Relations between Entities, defining constraints (the direction, the domain, the co-domain) of relations is important. Annotation Lab 2.7.0 offers a way to define such constraints by editing the Project Configuration. The Project Owner or Project Managers can specify which Relation needs to be bound to which Labels and in which direction. This will hide some Relations in Labeling Page for NER Labels which will simplify the annotation process and will avoid the creation of any incorrect relations in the scope of the project. Security Security issues related to SQL Injection Vulnerability and Host Header Attack were fixed in this release. Bug Fixes Issues related to chunk annotation; Incorrect bounding boxes, Multiple stacking of bounding boxes, Inconsistent IDs of the regions, unchanged labels of one connected region to other were identified and fixed and annotators can now select multiple tokens at once and annotate them as a single chunk In the previous release, after an Assertion Status model was trained, it would get deployed without the NER model and hence the preannotation was not working as expected. Going forward, the trained Assertion Model cannot be deployed for projects without a NER model. For this to happen, the “Yes” button in the confirmation box for deploying an assertion model right after training is enabled only when the Project Configuration consists of at least one NER model. A bug in the default Project templates (Project Setup page) was preventing users to create projects using “Conditional classification” and “Pairwise comparison” templates. These default Project templates can be used with no trouble as any other 40+ default templates. Reviewers were able to view unassigned submitted tasks via the “Next” button on the Labeling page. This bug is also fixed now and the reviewers can only see tasks that are assigned to them both on the Task List page or while navigating through the “Next” button. For better user experience, the labeling page has been optimized and the tasks on the page render quicker than in previous versions. When adding a user to the UserAdmins group, the delay in enabling the checkbox has been fixed. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_0"
  },
  "1383": {
    "id": "1383",
    "title": "Spark NLP for Healthcare Release Notes 2.7.1",
    "content": "2.7.1 We are glad to announce that Spark NLP for Healthcare 2.7.1 has been released ! In this release, we introduce the following features: 1. Sentence BioBert and Bluebert Transformers that are fine tuned on MedNLI dataset. Sentence Transformers offers a framework that provides an easy method to compute dense vector representations for sentences and paragraphs (also known as sentence embeddings). The models are based on BioBert and BlueBert, and are tuned specifically to meaningful sentence embeddings such that sentences with similar meanings are close in vector space. These are the first PyTorch based models we managed to port into Spark NLP. Here is how you can load these: sbiobert_embeddins = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) sbluebert_embeddins = BertSentenceEmbeddings .pretrained(&quot;sbluebert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) 2. SentenceEntityResolvers powered by s-Bert embeddings. The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before. Using sbiobert_base_cased_mli, we trained the following Clinical Entity Resolvers: sbiobertresolve_icd10cm sbiobertresolve_icd10pcs sbiobertresolve_snomed_findings (with clinical_findings concepts from CT version) sbiobertresolve_snomed_findings_int (with clinical_findings concepts from INT version) sbiobertresolve_snomed_auxConcepts (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from CT version) sbiobertresolve_snomed_auxConcepts_int (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from INT version) sbiobertresolve_rxnorm sbiobertresolve_icdo sbiobertresolve_cpt Code sample: (after getting the chunk from ChunkConverter) c2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_ct_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_snomed_findings&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_ct_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) Output:   chunks begin end code resolutions 2 COPD 113 116 13645005 copd - chronic obstructive pulmonary disease 8 PTCA 324 327 373108000 post percutaneous transluminal coronary angioplasty (finding) 16 close monitoring 519 534 417014005 on examination - vigilance See the notebook for details. 3. We are releasing the following pretrained clinical NER models: ner_drugs_large (trained with medications dataset, and extracts drugs with the dosage, strength, form and route at once as a single entity; entities: drug) ner_deid_sd_large (extracts PHI entities, trained with augmented dataset) ner_anatomy_coarse (trained with enriched anatomy NER dataset; entities: anatomy) ner_anatomy_coarse_biobert chunkresolve_ICD10GM_2021 (German ICD10GM resolver) We are also releasing two new NER models: ner_aspect_based_sentiment (extracts positive, negative and neutral aspects about restaurants from the written feedback given by reviewers. ) ner_financial_contract (extract financial entities from contracts. See the notebook for details.) Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_1"
  },
  "1384": {
    "id": "1384",
    "title": "Annotation Lab Release Notes 2.7.1",
    "content": "2.7.1 Release date: 22-02-2022 Annotation Lab v2.7.1 introduces an upgrade to K3s v1.22.4 and support for Redhat. It also includes improvements and fixes for identified bug. Below are the highlights of this release. Highlights For new installations, Annotation Lab is now installed on top of K3s v1.22.4. In near future we will provide similar support for existing installations. AWS market place also runs using the upgraded version. With this release Annotation lab can be installed on RedHat servers. Annotation lab 2.7.1 included release version of Spark NLP 3.4.1 and Spark NLP for Healthcare Bug Fixes In the previous release, saving Visual NER project configuration took a long time. With this release, the issue has been fixed and the Visual NER project can be created instantly. Due to a bug in Relation Constraint, all the relations we visible when the UI was refreshed. This issue has been resolved and only a valid list of relations is shown after the UI is refreshed. Previously, labels with spaces at the end were considered different. This has been fixed such that the label name with or without space at the end is treated as the same label. Importing multiple images as a zip file was not working correctly in the case of Visual NER. This issue was fixed. This version also fixes issues in Transfer Learning/Fine Tuning some NER models. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_1"
  },
  "1385": {
    "id": "1385",
    "title": "Spark NLP for Healthcare Release Notes 2.7.2",
    "content": "2.7.2 We are glad to announce that Spark NLP for Healthcare 2.7.2 has been released ! In this release, we introduce the following features: Far better accuracy for resolving medication terms to RxNorm codes: ondansetron 8 mg tablet&#39; -&gt; &#39;312086 Far better accuracy for resolving diagnosis terms to ICD-10-CM codes: TIA -&gt; transient ischemic attack (disorder) ‘S0690’ New ability to map medications to pharmacological actions (PA): &#39;metformin&#39; -&gt; ‘Hypoglycemic Agents’ 2 new greedy named entity recognition models for medication details: ner_drugs_greedy: ‘magnesium hydroxide 100mg/1ml PO’ ` ner_posology _greedy: ‘12 units of insulin lispro’ ` New model to classify the gender of a patient in a given medical note: &#39;58yo patient with a family history of breast cancer&#39; -&gt; ‘female’ And starting customized spark sessions with rich parameters params = {&quot;spark.driver.memory&quot;:&quot;32G&quot;, &quot;spark.kryoserializer.buffer.max&quot;:&quot;2000M&quot;, &quot;spark.driver.maxResultSize&quot;:&quot;2000M&quot;} spark = sparknlp_jsl.start(secret, params=params) State-of-the-art accuracy is achieved using new healthcare-tuned BERT Sentence Embeddings (s-Bert). The following sections include more details, metrics, and examples. Named Entity Recognizers for Medications A new medication NER (ner_drugs_greedy) that joins the drug entities with neighboring entities such as dosage, route, form and strength; and returns a single entity drug. This greedy NER model would be highly useful if you want to extract a drug with its context and then use it to get a RxNorm code (drugs may get different RxNorm codes based on the dosage and strength information). Metrics label tp fp fn prec rec f1 I-DRUG 37423 4179 3773 0.899 0.908 0.904 B-DRUG 29699 2090 1983 0.934 0.937 0.936 A new medication NER (ner_posology_greedy) that joins the drug entities with neighboring entities such as dosage, route, form and strength. It also returns all the other medication entities even if not related to (or joined with) a drug. Now we have five different medication-related NER models. You can see the outputs from each model below: Text = ‘‘The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.’’ a. ner_drugs_greedy   chunks begin end entities 0 1 capsule of Advil 10 mg 27 50 DRUG 1 magnesium hydroxide 100mg/1ml PO 67 98 DRUG 2 40 units of insulin glargine 168 195 DRUG 3 12 units of insulin lispro 207 232 DRUG b. ner_posology_greedy   chunks begin end entities 0 1 capsule of Advil 10 mg 27 50 DRUG 1 magnesium hydroxide 100mg/1ml PO 67 98 DRUG 2 for 5 days 52 61 DURATION 3 40 units of insulin glargine 168 195 DRUG 4 at night 197 204 FREQUENCY 5 12 units of insulin lispro 207 232 DRUG 6 with meals 234 243 FREQUENCY 7 metformin 1000 mg 250 266 DRUG 8 two times a day 268 282 FREQUENCY c. ner_drugs   chunks begin end entities 0 Advil 40 44 DrugChem 1 magnesium hydroxide 67 85 DrugChem 2 metformin 261 269 DrugChem d.ner_posology   chunks begin end entities 0 1 27 27 DOSAGE 1 capsule 29 35 FORM 2 Advil 40 44 DRUG 3 10 mg 46 50 STRENGTH 4 for 5 days 52 61 DURATION 5 magnesium hydroxide 67 85 DRUG 6 100mg/1ml 87 95 STRENGTH 7 PO 97 98 ROUTE 8 40 units 168 175 DOSAGE 9 insulin glargine 180 195 DRUG 10 at night 197 204 FREQUENCY 11 12 units 207 214 DOSAGE 12 insulin lispro 219 232 DRUG 13 with meals 234 243 FREQUENCY 14 metformin 250 258 DRUG 15 1000 mg 260 266 STRENGTH 16 two times a day 268 282 FREQUENCY e. ner_drugs_large   chunks begin end entities 0 Advil 10 mg 40 50 DRUG 1 magnesium hydroxide 100mg/1ml PO. 67 99 DRUG 2 insulin glargine 180 195 DRUG 3 insulin lispro 219 232 DRUG 4 metformin 1000 mg 250 266 DRUG Patient Gender Classification This model detects the gender of the patient in the clinical document. It can classify the documents into Female, Male and Unknown. We release two models: ‘Classifierdl_gender_sbert’ (more accurate, works with licensed sbiobert_base_cased_mli) ‘Classifierdl_gender_biobert’ (works with biobert_pubmed_base_cased) The models are trained on more than four thousands clinical documents (radiology reports, pathology reports, clinical visits etc.), annotated internally. Metrics (Classifierdl_gender_sbert)   precision recall f1-score support Female 0.9224 0.8954 0.9087 239 Male 0.7895 0.8468 0.8171 124 Text= ‘‘social history: shows that does not smoke cigarettes or drink alcohol, lives in a nursing home. family history: shows a family history of breast cancer.’’ gender_classifier.annotate(text)[&#39;class&#39;][0] &gt;&gt; `Female` See this Colab notebook for further details. a. classifierdl_gender_sbert document = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) .setMaxSentenceLength(512) gender_classifier = ClassifierDLModel .pretrained(&#39;classifierdl_gender_sbert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;class&quot;) gender_pred_pipeline = Pipeline( stages = [ document, sbert_embedder, gender_classifier ]) b. classifierdl_gender_biobert documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) clf_tokenizer = Tokenizer() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;token&quot;) biobert_embeddings = BertEmbeddings().pretrained(&#39;biobert_pubmed_base_cased&#39;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;bert_embeddings&quot;) biobert_embeddings_avg = SentenceEmbeddings() .setInputCols([&quot;document&quot;, &quot;bert_embeddings&quot;]) .setOutputCol(&quot;sentence_bert_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) genderClassifier = ClassifierDLModel.pretrained(&#39;classifierdl_gender_biobert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;document&quot;, &quot;sentence_bert_embeddings&quot;]) .setOutputCol(&quot;gender&quot;) gender_pred_pipeline = Pipeline( stages = [ documentAssembler, clf_tokenizer, biobert_embeddings, biobert_embeddings_avg, genderClassifier ]) New ICD10CM and RxCUI resolvers powered by s-Bert embeddings The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before. We now release two new resolvers: sbiobertresolve_icd10cm_augmented (augmented with synonyms, four times richer than previous resolver accuracy: 73% for top-1 (exact match), 89% for top-5 (previous accuracy was 59% and 64% respectively) sbiobertresolve_rxcui (extract RxNorm concept unique identifiers to map with ATC or durg families) accuracy: 71% for top-1 (exact match), 72% for top-5 (previous accuracy was 22% and 41% respectively) a. ICD10CM augmented resolver Text = “This is an 82 year old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret&#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU . “   chunk begin end code term 0 hypertension 66 77 I10 hypertension 1 chronic renal insufficiency 81 107 N189 chronic renal insufficiency 2 COPD 111 114 J449 copd - chronic obstructive pulmonary disease 3 gastritis 118 126 K2970 gastritis 4 TIA 134 136 S0690 transient ischemic attack (disorder) 5 a non-ST elevation MI 180 200 I219 silent myocardial infarction (disorder) 6 Guaiac positive stools 206 227 K921 guaiac-positive stools 7 mid LAD lesion 330 343 I2102 stemi involving left anterior descending coronary artery 8 hypotension 360 370 I959 hypotension 9 bradycardia 376 386 O9941 bradycardia b. RxCUI resolver Text= “He was seen by the endocrinology service and she was discharged on 50 mg of eltrombopag oral at night, 5 mg amlodipine with meals, and metformin 1000 mg two times a day . “   chunk begin end code term 0 50 mg of eltrombopag oral 67 91 825427 eltrombopag 50 MG Oral Tablet 1 5 mg amlodipine 103 117 197361 amlodipine 5 MG Oral Tablet 2 metformin 1000 mg 135 151 861004 metformin hydrochloride 1000 MG Oral Tablet Using this new resolver and some other resources like Snomed Resolver, RxTerm, MESHPA and ATC dictionary, you can link the drugs to the pharmacological actions (PA), ingredients and the disease treated with that. Code sample: (after getting the chunk from ChunkConverter) c2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icd10_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) See the notebook for details. Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_2"
  },
  "1386": {
    "id": "1386",
    "title": "Annotation Lab Release Notes 2.7.2",
    "content": "2.7.2 Release date: 28-02-2022 Annotation Lab v2.7.2 includes Visual NER improvements Bug Fixes The text token in Visual NER project were missing in some cases when the labeling setting “Select regions after creating” was disabled. Now the setting is always enabled when labeling a Visual NER project. Previously, without any changes made by the user on the configuration page “unsaved changes” message used to pop up. Now, the message only pops up when there is an unsaved configuration change. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_7_2"
  },
  "1387": {
    "id": "1387",
    "title": "Spark NLP for Healthcare Release Notes 2.7.3",
    "content": "2.7.3 We are glad to announce that Spark NLP for Healthcare 2.7.3 has been released! Highlights: Introducing a brand-new RelationExtractionDL Annotator – Achieving SOTA results in clinical relation extraction using BioBert. Massive Improvements &amp; feature enhancements in De-Identification module: Introduction of faker augmentation in Spark NLP for Healthcare to generate random data for obfuscation in de-identification module. Brand-new annotator for Structured De-Identification. Drug Normalizer: Normalize medication-related phrases (dosage, form and strength) and abbreviations in text and named entities extracted by NER models. Confidence scores in assertion output : just like NER output, assertion models now also support confidence scores for each prediction. Cosine similarity metrics in entity resolvers to get more informative and semantically correct results. AuxLabel in the metadata of entity resolvers to return additional mappings. New Relation Extraction models to extract relations between body parts and clinical entities. New Entity Resolver models to extract billable medical codes. New Clinical Pretrained NER models. Bug fixes &amp; general improvements. Matching the version with Spark NLP open-source v2.7.3. 1. Improvements in De-Identification Module: Integration of faker library to automatically generate random data like names, dates, addresses etc so users dont have to specify dummy data (custom obfuscation files can still be used). It also improves the obfuscation results due to a bigger pool of random values. How to use: Set the flag setObfuscateRefSource to faker deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) For more details: Check out this notebook 2. Structured De-Identification Module: Introduction of a new annotator to handle de-identification of structured data. it allows users to define a mapping of columns and their obfuscation policy. Users can also provide dummy data and map them to columns they want to replace values in. How to use: obfuscator = StructuredDeidentification (spark,{&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;}, obfuscateRefSource = &quot;faker&quot;) obfuscator_df = obfuscator.obfuscateColumns(df) obfuscator_df.select(&quot;NAME&quot;,&quot;AGE&quot;).show(truncate=False) Example: Input Data: Name Age Cecilia Chapman 83 Iris Watson 9 Bryar Pitts 98 Theodore Lowe 16 Calista Wise 76 Deidentified: Name Age Menne Erdôs 20 Longin Robinson 31 Flynn Fiedlerová 50 John Wakeland 21 Vanessa Andersson 12 For more details: Check out this notebook. 3. Introducing SOTA relation extraction model using BioBert A brand-new end-to-end trained BERT model, resulting in massive improvements. Another new annotator (ReChunkFilter) is also developed for this new model to allow syntactic features work well with BioBert to extract relations. How to use: re_ner_chunk_filter = RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) .setRelationPairs(pairs) .setMaxSyntacticDistance(4) re_model = RelationExtractionDLModel() .pretrained(“redl_temporal_events_biobert”, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.9) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) Benchmarks: on benchmark datasets model Spark NLP ML model Spark NLP DL model benchmark re_temporal_events_clinical 68.29 71.0 80.2 1 re_clinical 56.45 69.2 68.2 2 re_human_pheotype_gene_clinical - 87.9 67.2 3 re_drug_drug_interaction - 72.1 83.8 4 re_chemprot 76.69 94.1 83.64 5 on in-house annotations model Spark NLP ML model Spark NLP DL model re_bodypart_problem 84.58 85.7 re_bodypart_procedure 61.0 63.3 re_date_clinical 83.0 84.0 re_bodypart_direction 93.5 92.5 For more details: Check out the notebook or modelshub. 4. Drug Normalizer: Standardize units of drugs and handle abbreviations in raw text or drug chunks identified by any NER model. This normalization significantly improves performance of entity resolvers. How to use: drug_normalizer = DrugNormalizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document_normalized&quot;) .setPolicy(&quot;all&quot;) #all/abbreviations/dosages Examples: drug_normalizer.transform(&quot;adalimumab 54.5 + 43.2 gm”) &gt;&gt;&gt; &quot;adalimumab 97700 mg&quot; Changes: combine 54.5 + 43.2 and normalize gm to mg drug_normalizer.transform(&quot;Agnogenic one half cup”) &gt;&gt;&gt; &quot;Agnogenic 0.5 oral solution&quot; Changes: replace one half to the 0.5, normalize cup to the oral solution drug_normalizer.transform(&quot;interferon alfa-2b 10 million unit ( 1 ml ) injec”) &gt;&gt;&gt; &quot;interferon alfa - 2b 10000000 unt ( 1 ml ) injection &quot; Changes: convert 10 million unit to the 10000000 unt, replace injec with injection For more details: Check out this notebook 5. Assertion models to support confidence in output: Just like NER output, assertion models now also provides confidence scores for each prediction. chunks entities assertion confidence a headache PROBLEM present 0.9992 anxious PROBLEM conditional 0.9039 alopecia PROBLEM absent 0.9992 pain PROBLEM absent 0.9238 .setClasses() method is deprecated in AssertionDLApproach and users do not need to specify number of classes while training, as it will be inferred from the dataset. 6. New Relation Extraction Models: We are also releasing new relation extraction models to link the clinical entities to body parts and dates. These models are trained using binary relation extraction approach for better accuracy. - re_bodypart_direction : Relation Extraction between Body Part and Direction entities. Example: Text: “MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia” relations entity1 chunk1 entity2 chunk2 confidence 1 Direction upper bodyPart brain stem 0.999 0 Direction upper bodyPart cerebellum 0.999 0 Direction upper bodyPart basil ganglia 0.999 0 bodyPart brain stem Direction left 0.999 0 bodyPart brain stem Direction right 0.999 1 Direction left bodyPart cerebellum 1.0 0 Direction left bodyPart basil ganglia 0.976 0 bodyPart cerebellum Direction right 0.953 1 Direction right bodyPart basil ganglia 1.0 - re_bodypart_problem : Relation Extraction between Body Part and Problem entities. Example: Text: “No neurologic deficits other than some numbness in his left hand.” relation entity1 chunk1 entity2 chunk2 confidence 0 Symptom neurologic deficits bodyPart hand 1 1 Symptom numbness bodyPart hand 1 - re_bodypart_proceduretest : Relation Extraction between Body Part and Procedure, Test entities. Example: Text: “TECHNIQUE IN DETAIL: After informed consent was obtained from the patient and his mother, the chest was scanned with portable ultrasound.” relation entity1 chunk1 entity2 chunk2 confidence 1 bodyPart chest Test portable ultrasound 0.999 -re_date_clinical : Relation Extraction between Date and different clinical entities. Example: Text: “This 73 y/o patient had CT on 1/12/95, with progressive memory and cognitive decline since 8/11/94.” relations entity1 chunk1 entity2 chunk2 confidence 1 Test CT Date 1/12/95 1.0 1 Symptom progressive memory and cognitive decline Date 8/11/94 1.0 How to use: re_model = RelationExtractionModel() .pretrained(&quot;re_bodypart_direction&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(4) .setRelationPairs([‘Internal_organ_or_component’, ‘Direction’]) For more details: Check out the notebook or modelshub. New matching scheme for entity resolvers - improved accuracy: Adding the option to use cosine similarity to resolve entities and find closest matches, resulting in better, more semantically correct results. 7. New Resolver Models using JSL SBERT: sbiobertresolve_icd10cm_augmented sbiobertresolve_cpt_augmented sbiobertresolve_cpt_procedures_augmented sbiobertresolve_icd10cm_augmented_billable_hcc sbiobertresolve_hcc_augmented Returning auxilary columns mapped to resolutions: Chunk entity resolver and sentence entity resolver now returns auxilary data that is mapped the resolutions during training. This will allow users to get multiple resolutions with single model without using any other annotator in the pipeline (In order to get billable codes otherwise there needs to be other modules in the same pipeline) Example: sbiobertresolve_icd10cm_augmented_billable_hcc Input Text: “bladder cancer” idx chunks code resolutions all_codes billable hcc_status hcc_score all_distances 0 bladder cancer C679 [‘bladder cancer’, ‘suspected bladder cancer’, ‘cancer in situ of urinary bladder’, ‘tumor of bladder neck’, ‘malignant tumour of bladder neck’] [‘C679’, ‘Z126’, ‘D090’, ‘D494’, ‘C7911’] [‘1’, ‘1’, ‘1’, ‘1’, ‘1’] [‘1’, ‘0’, ‘0’, ‘0’, ‘1’] [‘11’, ‘0’, ‘0’, ‘0’, ‘8’] [‘0.0000’, ‘0.0904’, ‘0.0978’, ‘0.1080’, ‘0.1281’] sbiobertresolve_cpt_augmented Input Text: “ct abdomen without contrast” idx cpt code distance resolutions 0 74150 0.0802 Computed tomography, abdomen; without contrast material 1 65091 0.1312 Evisceration of ocular contents; without implant 2 70450 0.1323 Computed tomography, head or brain; without contrast material 3 74176 0.1333 Computed tomography, abdomen and pelvis; without contrast material 4 74185 0.1343 Magnetic resonance imaging without contrast 5 77059 0.1343 Magnetic resonance imaging without contrast 8. New Pretrained Clinical NER Models NER Radiology Input Text: “Bilateral breast ultrasound was subsequently performed, which demonstrated an ovoid mass measuring approximately 0.5 x 0.5 x 0.4 cm in diameter located within the anteromedial aspect of the left shoulder. This mass demonstrates isoechoic echotexture to the adjacent muscle, with no evidence of internal color flow. This may represent benign fibrous tissue or a lipoma.” idx chunks entities 0 Bilateral Direction 1 breast BodyPart 2 ultrasound ImagingTest 3 ovoid mass ImagingFindings 4 0.5 x 0.5 x 0.4 Measurements 5 cm Units 6 anteromedial aspect Direction 7 left Direction 8 shoulder BodyPart 9 mass ImagingFindings 10 isoechoic echotexture ImagingFindings 11 muscle BodyPart 12 internal color flow ImagingFindings 13 benign fibrous tissue ImagingFindings 14 lipoma Disease_Syndrome_Disorder Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_3"
  },
  "1388": {
    "id": "1388",
    "title": "Spark NLP for Healthcare Release Notes 2.7.4",
    "content": "2.7.4 We are glad to announce that Spark NLP for Healthcare 2.7.4 has been released! Highlights: Introducing a new annotator to extract chunks with NER tags using regex-like patterns: NerChunker. Introducing two new annotators to filter chunks: ChunkFilterer and AssertionFilterer. Ability to change the entity type in NerConverterInternal without using ChunkMerger (setReplaceDict). In DeIdentification model, ability to use faker and static look-up lists at the same time randomly in Obfuscation mode. New De-Identification NER model, augmented with synthetic datasets to detect uppercased name entities. Bug fixes &amp; general improvements. 1. NerChunker: Similar to what we used to do in POSChunker with POS tags, now we can also extract phrases that fits into a known pattern using the NER tags. NerChunker would be quite handy to extract entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. Lets say we want to extract clinical findings and body parts together as a single chunk even if there are some unwanted tokens between. How to use: ner_model = NerDLModel.pretrained(&quot;ner_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_chunker = NerChunker(). .setInputCols([&quot;sentence&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setRegexParsers([&quot;&lt;IMAGINGFINDINGS&gt;*&lt;BODYPART&gt;&quot;]) text = &#39;She has cystic cyst on her kidney.&#39; &gt;&gt; ner tags: [(cystic, B-IMAGINGFINDINGS), (cyst,I-IMAGINGFINDINGS), (kidney, B-BODYPART) &gt;&gt; ner_chunk: [&#39;cystic cyst on her kidney&#39;] 2. ChunkFilterer: ChunkFilterer will allow you to filter out named entities by some conditions or predefined look-up lists, so that you can feed these entities to other annotators like Assertion Status or Entity Resolvers. It can be used with two criteria: isin and regex. How to use: ner_model = NerDLModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setCriteria(&quot;isin&quot;) .setWhiteList([&#39;severe fever&#39;,&#39;sore throat&#39;]) text = &#39;Patient with severe fever, sore throat, stomach pain, and a headache.&#39; &gt;&gt; ner_chunk: [&#39;severe fever&#39;,&#39;sore throat&#39;,&#39;stomach pain&#39;,&#39;headache&#39;] &gt;&gt; chunk_filtered: [&#39;severe fever&#39;,&#39;sore throat&#39;] 3. AssertionFilterer: AssertionFilterer will allow you to filter out the named entities by the list of acceptable assertion statuses. This annotator would be quite handy if you want to set a white list for the acceptable assertion statuses like present or conditional; and do not want absent conditions get out of your pipeline. How to use: clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;present&quot;]) text = &#39;Patient with severe fever and sore throat, but no stomach pain.&#39; &gt;&gt; ner_chunk: [&#39;severe fever&#39;,&#39;sore throat&#39;,&#39;stomach pain&#39;,&#39;headache&#39;] &gt;&gt; assertion_filtered: [&#39;severe fever&#39;,&#39;sore throat&#39;] Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_4"
  },
  "1389": {
    "id": "1389",
    "title": "Spark NLP for Healthcare Release Notes 2.7.5",
    "content": "2.7.5 We are glad to announce that Spark NLP for Healthcare 2.7.5 has been released! Highlights: New pretrained Relation Extraction model to link clinical tests to test results and dates to clinical entities: re_test_result_date Adding two new Admission and Discharge entities to ner_events_clinical and renaming it to ner_events_admission_clinical Improving ner_deid_enriched NER model to cover Doctor and Patient name entities in various context and notations. Bug fixes &amp; general improvements. 1. re_test_result_date : text = “Hospitalized with pneumonia in June, confirmed by a positive PCR of any specimen, evidenced by SPO2 &lt;/= 93% or PaO2/FiO2 &lt; 300 mmHg”   Chunk-1 Entity-1 Chunk-2 Entity-2 Relation 0 pneumonia Problem june Date is_date_of 1 PCR Test positive Test_Result is_result_of 2 SPO2 Test 93% Test_Result is_result_of 3 PaO2/FiO2 Test 300 mmHg Test_Result is_result_of 2. ner_events_admission_clinical : ner_events_clinical NER model is updated &amp; improved to include Admission and Discharge entities. text =”She is diagnosed as cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001”   chunk entity 0 diagnosed OCCURRENCE 1 cancer PROBLEM 2 1991 DATE 3 admitted ADMISSION 4 Mayo Clinic CLINICAL_DEPT 5 May 2000 DATE 6 discharged DISCHARGE 7 October 2001 DATE 3. Improved ner_deid_enriched : PHI NER model is retrained to cover Doctor and Patient name entities even there is a punctuation between tokens as well as all upper case or lowercased. text =”A . Record date : 2093-01-13 , DAVID HALE , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street”   chunk entity 0 2093-01-13 MEDICALRECORD 1 DAVID HALE DOCTOR 2 Hendrickson , Ora PATIENT 3 7194334 MEDICALRECORD 4 01/13/93 DATE 5 Oliveira DOCTOR 6 25 AGE 7 2079-11-09 MEDICALRECORD 8 Cocke County Baptist Hospital HOSPITAL 9 0295 Keats Street STREET Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_5",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_5"
  },
  "1390": {
    "id": "1390",
    "title": "Spark NLP for Healthcare Release Notes 2.7.6",
    "content": "2.7.6 We are glad to announce that Spark NLP for Healthcare 2.7.6 has been released! Highlights: New pretrained Radiology Assertion Status model to assign Confirmed, Suspected, Negative assertion scopes to imaging findings or any clinical tests. Obfuscating the same sensitive information (patient or doctor name) with the same fake names across the same clinical note. Version compatibility checker for the pretrained clinical models and builds to keep up with the latest development efforts in production. Adding more English names to faker module in Deidentification. Updated &amp; improved clinical SentenceDetectorDL model. New upgrades on ner_deid_large and ner_deid_enriched NER models to cover more use cases with better resolutions. Adding more examples to workshop repo for Scala users to practice more on healthcare annotators. Bug fixes &amp; general improvements. 1. Radiology Assertion Status Model We trained a new assertion model to assign Confirmed, Suspected, Negative assertion scopes to imaging findings or any clinical tests. It will try to assign these statuses to any named entity you would feed to the assertion annotater in the same pipeline. radiology_assertion = AssertionDLModel.pretrained(&quot;assertion_dl_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) text = Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. No right-sided pleural effusion or pneumothorax is definitively seen. There are mildly displaced fractures of the left lateral 8th and likely 9th ribs. sentences chunk ner_label sent_id assertion Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. Blunting ImagingFindings 0 Confirmed Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. effusion ImagingFindings 0 Suspected No right-sided pleural effusion or pneumothorax is definitively seen. effusion ImagingFindings 1 Negative No right-sided pleural effusion or pneumothorax is definitively seen. pneumothorax ImagingFindings 1 Negative There are mildly displaced fractures of the left lateral 8th and likely 9th ribs. displaced fractures ImagingFindings 2 Confirmed You can also use this with AssertionFilterer to return clinical findings from a note only when it is i.e. confirmed or suspected. assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;confirmed&quot;,&quot;suspected&quot;]) &gt;&gt; [&quot;displaced fractures&quot;, &quot;effusion&quot;] 2. Obfuscating with the same fake name across the same note: obfuscation = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setSameEntityThreshold(0.8) .setObfuscateRefSource(&quot;faker&quot;) text =&#39;&#39;&#39; Provider: David Hale, M.D. Pt: Jessica Parker David told Jessica that she will need to visit the clinic next month.&#39;&#39;&#39;   sentence obfuscated 0 Provider: David Hale, M.D. Provider: Dennis Perez, M.D. 1 Pt: Jessica Parker Pt: Gerth Bayer 2 David told Jessica that she will need to visit the clinic next month. Dennis told Gerth that she will need to visit the clinic next month. 3. Library Version Compatibility Table : We are releasing the version compatibility table to help users get to see which Spark NLP licensed version is built against which core (open source) version. We are going to release a detailed one after running some tests across the jars from each library. Healthcare Public 2.7.6 2.7.4 2.7.5 2.7.4 2.7.4 2.7.3 2.7.3 2.7.3 2.7.2 2.6.5 2.7.1 2.6.4 2.7.0 2.6.3 2.6.2 2.6.2 2.6.0 2.6.0 2.5.5 2.5.5 2.5.3 2.5.3 2.5.2 2.5.2 2.5.0 2.5.0 2.4.7 2.4.5 2.4.6 2.4.5 2.4.5 2.4.5 2.4.2 2.4.2 2.4.1 2.4.1 2.4.0 2.4.0 2.3.6 2.3.6 2.3.5 2.3.5 2.3.4 2.3.4 4. Pretrained Models Version Control : Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. This is an highly experimental feature of which we plan to improve and add more capability later on. from sparknlp_jsl.check_compatibility import Compatibility checker = sparknlp_jsl.Compatibility() result = checker.find_version(aws_access_key_id=license_keys[&#39;AWS_ACCESS_KEY_ID&#39;], aws_secret_access_key=license_keys[&#39;AWS_SECRET_ACCESS_KEY&#39;], metadata_path=None, model = &#39;all&#39; , # or a specific model name target_version=&#39;all&#39;, cache_pretrained_path=&#39;/home/ubuntu/cache_pretrained&#39;) &gt;&gt; result[&#39;outdated_models&#39;] [{&#39;model_name&#39;: &#39;clinical_ner_assertion&#39;, &#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}, {&#39;model_name&#39;: &#39;jsl_rd_ner_wip_greedy_clinical&#39;, &#39;current_version&#39;: &#39;2.6.1&#39;, &#39;latest_version&#39;: &#39;2.6.2&#39;}, {&#39;model_name&#39;: &#39;ner_anatomy&#39;, &#39;current_version&#39;: &#39;2.4.2&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}, {&#39;model_name&#39;: &#39;ner_aspect_based_sentiment&#39;, &#39;current_version&#39;: &#39;2.6.2&#39;, &#39;latest_version&#39;: &#39;2.7.2&#39;}, {&#39;model_name&#39;: &#39;ner_bionlp&#39;, &#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.7.0&#39;}, {&#39;model_name&#39;: &#39;ner_cellular&#39;, &#39;current_version&#39;: &#39;2.4.2&#39;, &#39;latest_version&#39;: &#39;2.5.0&#39;}] &gt;&gt; result[&#39;version_comparison_dict&#39;] [{&#39;clinical_ner_assertion&#39;: {&#39;current_version&#39;: &#39;2.4.0&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}}, {&#39;jsl_ner_wip_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.5&#39;, &#39;latest_version&#39;: &#39;2.6.1&#39;}}, {&#39;jsl_ner_wip_greedy_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.5&#39;, &#39;latest_version&#39;: &#39;2.6.5&#39;}}, {&#39;jsl_ner_wip_modifier_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.4&#39;, &#39;latest_version&#39;: &#39;2.6.4&#39;}}, {&#39;jsl_rd_ner_wip_greedy_clinical&#39;: {&#39;current_version&#39;: &#39;2.6.1&#39;,&#39;latest_version&#39;: &#39;2.6.2&#39;}}] 5. Updated Pretrained Models: (requires fresh .pretraned()) ner_deid_large ner_deid_enriched Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_6",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_2_7_6"
  },
  "1391": {
    "id": "1391",
    "title": "Annotation Lab Release Notes 2.8.0",
    "content": "2.8.0 Release date: 19-03-2022 Annotation Lab 2.8.0 simplifies the annotation workflows, adds dynamic pagination features, supports cross-page NER annotation and relation definition for text projects, adds UI features for infrastructure configuration and backup, updates the way the analytics dashboards are processed, offers improved support for rules and support for model training in German and Spanish. Highlights New features offered by Annotation Lab: Dynamic Task Pagination replaced the &lt;pagebreak&gt; style pagination. Cross Page Annotation is now supported for NER and Relation annotations. Simplified workflow are now supported for simpler projects. Furthermore, overall work progress has been added on the Labeling Page. Infrastucture used for preannotation and training can now be configured from the Annotation Lab UI. Support for training German and Spanish models. Some changes in Analytics Dashboard were implemented. By default, the Analytics dashboard page is now disabled. Users can request Admin to enable the Analytics page. The refresh of the charts is done manually. Import &amp; Export Rules from the Model Hub page. Download model dependencies is now automatic. The project configuration box can now be edited in full screen mode. Trim leading and ending spaces in annotated chunks. Reserved words cannot be used in project names. Task numbering now start from 1. ‘a’ was removed as hotkey for VisualNER multi-chunk selection. Going forward only use ‘shift’ key for chunk selection. Only alphanumeric characters can be used as the Task Tag Names. Allow the export of tasks without completions. Bug Fixes On the Labeling Page, the following issues related to completions were identified and fixed: In the Visual NER Project, when an annotator clicks on the Next button to load the next available task, the PDF was not correctly loaded and the text selection doesn’t work properly. Shortcut keys were not working when creating new completions. It happened that completions were no longer visible after creating relations. Previously, after each project configuration edit, when validating the correctness of the configuration the cursor position was reset to the end of the config file. The user had to manually move the cursor back to its previous position to continue editing. Now, the cursor position is saved so that the editing can continue with ease. Removing a user from the “UserAdmins” group was not possible. This has been fixed. Any user can be added or removed from the “UserAdmins”. In previous versions, choosing an already existing name for the current project did not show any error messages. Now, an error message appears on the right side of the screen asking users to choose another name for the project. In the previous version, when a user was deleted and a new user with the same name was created through Keycloak, on the next login the UI did not load. Now, this issue was fixed. Validations were added to Swagger API for completions data such that random values could not be added to completion data via API. Previously, when a rule was edited, previously deployed preannotation pipelines using the edited rules were not updated to use the latest version of the rule. Now the user is notified about the edited rule via an alert message “Redeploy preannotation server to apply these changes” on the rule edit form so that the users can redeploy the preannotation model. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_2_8_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_2_8_0"
  },
  "1392": {
    "id": "1392",
    "title": "Spark NLP release notes 3.0.0",
    "content": "3.0.0 Release date: 02-04-2021 Overview We are very excited to release Spark OCR 3.0.0! Spark OCR 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We will support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x. Spark OCR started to support Tensorflow models. First model is VisualDocumentClassifier. New Features Support for Apache Spark and PySpark 3.0.x on Scala 2.12 Support for Apache Spark and PySpark 3.1.x on Scala 2.12 Support 9x new Databricks runtimes: Databricks 7.3 Databricks 7.3 ML GPU Databricks 7.4 Databricks 7.4 ML GPU Databricks 7.5 Databricks 7.5 ML GPU Databricks 7.6 Databricks 7.6 ML GPU Databricks 8.0 Databricks 8.0 ML (there is no GPU in 8.0) Databricks 8.1 Support 2x new EMR 6.x: EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1) EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1) VisualDocumentClassifier model for classification documents using text and layout data. Added support Vietnamese language. New notebooks Visual Document Classifier Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_0_0"
  },
  "1393": {
    "id": "1393",
    "title": "Spark NLP for Healthcare Release Notes 3.0.0",
    "content": "3.0.0 We are very excited to announce that Spark NLP for Healthcare 3.0.0 has been released! This has been one of the biggest releases we have ever done and we are so proud to share this with our customers. Highlights: Spark NLP for Healthcare 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We now support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x helping the customers to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP support. Highlights: Support for Apache Spark and PySpark 3.0.x on Scala 2.12 Support for Apache Spark and PySpark 3.1.x on Scala 2.12 Migrate to TensorFlow v2.3.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x A brand new MedicalNerModel annotator to train &amp; load the licensed clinical NER models. Two times faster NER and Entity Resolution due to new batch annotation technique. Welcoming 9x new Databricks runtimes to our Spark NLP family: Databricks 7.3 Databricks 7.3 ML GPU Databricks 7.4 Databricks 7.4 ML GPU Databricks 7.5 Databricks 7.5 ML GPU Databricks 7.6 Databricks 7.6 ML GPU Databricks 8.0 Databricks 8.0 ML (there is no GPU in 8.0) Databricks 8.1 Beta Welcoming 2x new EMR 6.x series to our Spark NLP family: EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1) EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1) Starting Spark NLP for Healthcare 3.0.0 the default packages for CPU and GPU will be based on Apache Spark 3.x and Scala 2.12. Deprecated Text2SQL annotator is deprecated and will not be maintained going forward. We are working on a better and faster version of Text2SQL at the moment and will announce soon. 1. MedicalNerModel Annotator Starting Spark NLP for Healthcare 3.0.0, the licensed clinical and biomedical pretrained NER models will only work with this brand new annotator called MedicalNerModel and will not work with NerDLModel in open source version. In order to make this happen, we retrained all the clinical NER models (more than 80) and uploaded to models hub. Example: clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) 2. Speed Improvements A new batch annotation technique implemented in Spark NLP 3.0.0 for NerDLModel,BertEmbeddings, and BertSentenceEmbeddings annotators will be reflected in MedicalNerModel and it improves prediction/inferencing performance radically. From now on the batchSize for these annotators means the number of rows that can be fed into the models for prediction instead of sentences per row. You can control the throughput when you are on accelerated hardware such as GPU to fully utilise it. Here are the overall speed comparison: Now, NER inference and Entity Resolution are two times faster on CPU and three times faster on GPU. 3. JSL Clinical NER Model We are releasing the richest clinical NER model ever, spanning over 80 entities. It has been under development for the last 6 months and we manually annotated more than 4000 clinical notes to cover such a high number of entities in a single model. It has 4 variants at the moment: jsl_ner_wip_clinical jsl_ner_wip_greedy_clinical jsl_ner_wip_modifier_clinical jsl_rd_ner_wip_greedy_clinical Entities: Kidney_Disease, HDL, Diet, Test, Imaging_Technique, Triglycerides, Obesity, Duration, Weight, Social_History_Header, ImagingTest, Labour_Delivery, Disease_Syndrome_Disorder, Communicable_Disease, Overweight, Units, Smoking, Score, Substance_Quantity, Form, Race_Ethnicity, Modifier, Hyperlipidemia, ImagingFindings, Psychological_Condition, OtherFindings, Cerebrovascular_Disease, Date, Test_Result, VS_Finding, Employment, Death_Entity, Gender, Oncological, Heart_Disease, Medical_Device, Total_Cholesterol, ManualFix, Time, Route, Pulse, Admission_Discharge, RelativeDate, O2_Saturation, Frequency, RelativeTime, Hypertension, Alcohol, Allergen, Fetus_NewBorn, Birth_Entity, Age, Respiration, Medical_History_Header, Oxygen_Therapy, Section_Header, LDL, Treatment, Vital_Signs_Header, Direction, BMI, Pregnancy, Sexually_Active_or_Sexual_Orientation, Symptom, Clinical_Dept, Measurements, Height, Family_History_Header, Substance, Strength, Injury_or_Poisoning, Relationship_Status, Blood_Pressure, Drug, Temperature, EKG_Findings, Diabetes, BodyPart, Vaccine, Procedure, Dosage 4. JSL Clinical Assertion Model We are releasing a brand new clinical assertion model, supporting 8 assertion statuses. jsl_assertion_wip Assertion Labels : Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical 5. Library Version Compatibility Table : Spark NLP for Healthcare 3.0.0 is compatible with Spark NLP 3.0.1 6. Pretrained Models Version Control (Beta): Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This is the second version of the model checker we released with 2.7.6 and will replace that soon. from sparknlp_jsl.compatibility_beta import CompatibilityBeta compatibility = CompatibilityBeta(spark) print(compatibility.findVersion(&quot;ner_deid&quot;)) 7. Updated Pretrained Models: (requires fresh .pretraned()) None Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_0"
  },
  "1394": {
    "id": "1394",
    "title": "Annotation Lab Release Notes 3.0.0",
    "content": "3.0.0 Release date: 06-04-2022 We are very excited to release Annotation Lab 3.0.0 with support for Floating Licenses and for parallel training and preannotation jobs, created on demand by Project Owners and Managers across various projects. Below are more details about the release. Highlights Annotation Lab now supports floating licenses with different scopes (ocr: training, ocr: inference, healthcare: inference, healthcare: training). Depending on the scope of the available license, users can perform model training and/or deploy preannotation servers. Licenses are a must only for training Spark NLP for Healthcare models and for deploying Spark NLP for Healthcare models as preannotation servers. Parallel Trainings and Preannotations. Annotation Lab now offers support for running model training and document preannotation across multiple projects and/or teams in parallel. If the infrastructure dedicated to the Annotation Lab includes sufficient resources, each team/project can run smoothly without being blocked. On demand deployment of preannotation servers and training jobs: Deploy a new training job Deploy a new preannotation server OCR and Visual NER servers The infrastucture page now hosts a new tab for managing preannotation, training and OCR servers. New options available on preannotate action. Updates for the license page. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_0"
  },
  "1395": {
    "id": "1395",
    "title": "Spark NLP for Healthcare Release Notes 3.0.1",
    "content": "3.0.1 We are very excited to announce that Spark NLP for Healthcare 3.0.1 has been released! Highlights: Fixed problem in Assertion Status internal tokenization (reported in Spark-NLP #2470). Fixes in the internal implementation of DeIdentificationModel/Obfuscator. Being able to disable the use of regexes in the Deidentification process Other minor bug fixes &amp; general improvements. DeIdentificationModel Annotator New seed parameter. Now we have the possibility of using a seed to guide the process of obfuscating entities and returning the same result across different executions. To make that possible a new method setSeed(seed:Int) was introduced. Example: Return obfuscated documents in a repeatable manner based on the same seed. Scala deIdentification = DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) This seed controls how the obfuscated values are picked from a set of obfuscation candidates. Fixing the seed allows the process to be replicated. Example: Given the following input to the deidentification: &quot;David Hale was in Cocke County Baptist Hospital. David Hale&quot; If the annotator is set up with a seed of 10: Scala val deIdentification = new DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) The result will be the following for any execution, &quot;Brendan Kitten was in New Megan.Brendan Kitten&quot; Now if we set up a seed of 32, Scala val deIdentification = new DeIdentification() .setInputCols(Array(&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;)) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(32) .setIgnoreRegex(true) Python de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateRefSource(&quot;faker&quot;) .setSeed(10) .setIgnoreRegex(True) The result will be the following for any execution, &quot;Louise Pear was in Lake Edward.Louise Pear&quot; New ignoreRegex parameter. You can now choose to completely disable the use of regexes in the deidentification process by setting the setIgnoreRegex param to True. Example: Scala DeIdentificationModel.setIgnoreRegex(true) Python DeIdentificationModel().setIgnoreRegex(True) The default value for this param is False meaning that regexes will be used by default. New supported entities for Deidentification &amp; Obfuscation: We added new entities to the default supported regexes: SSN - Social security number. PASSPORT - Passport id. DLN - Department of Labor Number. NPI - National Provider Identifier. C_CARD - The id number for credits card. IBAN - International Bank Account Number. DEA - DEA Registration Number, which is an identifier assigned to a health care provider by the United States Drug Enforcement Administration. We also introduced new Obfuscator cases for these new entities. Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_1"
  },
  "1396": {
    "id": "1396",
    "title": "Annotation Lab Release Notes 3.0.1",
    "content": "3.0.1 Release date: 12-04-2022 Annotation Lab v3.0.1 includes some CVE issues are fixed along with application bug fixes Bug Fixes When licensed model is trained, label “label” was added to prediction entities Expired license icon is seen after the user enters new floating license In airgaped machine, deployed licensed preannotation server is shown as open source in active-servers page Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_0_1"
  },
  "1397": {
    "id": "1397",
    "title": "Spark NLP for Healthcare Release Notes 3.0.2",
    "content": "3.0.2 We are very excited to announce that Spark NLP for Healthcare 3.0.2 has been released! This release includes bug fixes and some compatibility improvements. Highlights Dictionaries for Obfuscator were augmented with more than 10K names. Improved support for spark 2.3 and spark 2.4. Bug fixes in DrugNormalizer. New Features Provide confidence scores for all available tags in MedicalNerModel, MedicalNerModel before 3.0.2 [[named_entity, 0, 9, B-PROBLEM, [word -&gt; Pneumonia, confidence -&gt; 0.9998], []] Now in Spark NLP for Healthcare 3.0.2 [[named_entity, 0, 9, B-PROBLEM, [B-PROBLEM -&gt; 0.9998, I-TREATMENT -&gt; 0.0, I-PROBLEM -&gt; 0.0, I-TEST -&gt; 0.0, B-TREATMENT -&gt; 1.0E-4, word -&gt; Pneumonia, B-TEST -&gt; 0.0], []] Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_2"
  },
  "1398": {
    "id": "1398",
    "title": "Spark NLP for Healthcare Release Notes 3.0.3",
    "content": "3.0.3 We are glad to announce that Spark NLP for Healthcare 3.0.3 has been released! Highlights Five new entity resolution models to cover UMLS, HPO and LIONC terminologies. New feature for random displacement of dates on deidentification model. Five new pretrained pipelines to map terminologies across each other (from UMLS to ICD10, from RxNorm to MeSH etc.) AnnotationToolReader support for Spark 2.3. The tool that helps model training on Spark-NLP to leverage data annotated using JSL Annotation Tool now has support for Spark 2.3. Updated documentation (Scaladocs) covering more APIs, and examples. Five new resolver models: sbiobertresolve_umls_major_concepts: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms. sbiobertresolve_umls_findings: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings. sbiobertresolve_loinc: Map clinical NER entities to LOINC codes using sbiobert. sbluebertresolve_loinc: Map clinical NER entities to LOINC codes using sbluebert. sbiobertresolve_HPO: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code: * MeSH (Medical Subject Headings) * SNOMED * UMLS (Unified Medical Language System ) * ORPHA (international reference resource for information on rare diseases and orphan drugs) * OMIM (Online Mendelian Inheritance in Man) Related Notebook: Resolver Models New feature on Deidentification Module isRandomDateDisplacement(True): Be able to apply a random displacement on obfuscation dates. The randomness is based on the seed. Fix random dates when the format is not correct. Now you can repeat an execution using a seed for dates. Random dates will be based on the seed. Five new healthcare code mapping pipelines: icd10cm_umls_mapping: This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;icd10cm&#39;: [&#39;M89.50&#39;, &#39;R82.2&#39;, &#39;R09.01&#39;], &#39;umls&#39;: [&#39;C4721411&#39;, &#39;C0159076&#39;, &#39;C0004044&#39;]} mesh_umls_mapping: This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;mesh&#39;: [&#39;C028491&#39;, &#39;D019326&#39;, &#39;C579867&#39;], &#39;umls&#39;: [&#39;C0970275&#39;, &#39;C0886627&#39;, &#39;C3696376&#39;]} rxnorm_umls_mapping: This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1161611&#39;, &#39;315677&#39;, &#39;343663&#39;], &#39;umls&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;, &#39;C1146501&#39;]} rxnorm_mesh_mapping: This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;rxnorm&#39;: [&#39;1191&#39;, &#39;6809&#39;, &#39;47613&#39;], &#39;mesh&#39;: [&#39;D001241&#39;, &#39;D008687&#39;, &#39;D019355&#39;]} snomed_umls_mapping: This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping. {&#39;snomed&#39;: [&#39;733187009&#39;, &#39;449433008&#39;, &#39;51264003&#39;], &#39;umls&#39;: [&#39;C4546029&#39;, &#39;C3164619&#39;, &#39;C0271267&#39;]} Related Notebook: Healthcare Code Mapping Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_0_3"
  },
  "1399": {
    "id": "1399",
    "title": "Spark NLP release notes 3.10.0",
    "content": "3.10.0 Release date: 10-01-2022 Overview Form recognition using LayoutLMv2 and text detection. New Features Added VisualDocumentNERv2 transformer Added DL based ImageTextDetector transformer Support rotated regions in ImageSplitRegions Support rotated regions in ImageDrawRegions New Models LayoutLMv2 fine-tuned on FUNSD dataset Text detection model based on CRAFT architecture New notebooks Text Detection Visual Document NER v2 Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_10_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_10_0"
  },
  "1400": {
    "id": "1400",
    "title": "Spark NLP release notes 3.11.0",
    "content": "3.11.0 Release date: 28-02-2022 Overview We are glad to announce that Spark OCR 3.11.0 has been released!. This release comes with new models, new features, bug fixes, and notebook examples. New Features Added ImageTextDetectorV2 Python Spark-OCR Transformer for detecting printed and handwritten text using CRAFT architecture with Refiner Net. Added ImageTextRecognizerV2 Python Spark-OCR Transformer for recognizing printed and handwritten text based on Deep Learning Transformer Architecture. Added FormRelationExtractor for detecting relations between key and value entities in forms. Added the capability of fine tuning VisualDocumentNerV2 models for key-value pairs extraction. New Models ImageTextDetectorV2: this extends the ImageTextDetectorV1 character level text detection model with a refiner net architecture. ImageTextRecognizerV2: Text recognition for printed text based on the Deep Learning Transformer Architecture. New notebooks SparkOcrImageToTextV2 ImageTextDetectorV2 Visual Document NER v2 SparkOcrFormRecognition SparkOCRVisualDocumentNERv2FineTune Creating Rest a API with Synapse to extract text from images, SparkOcrRestApi Creating Rest a API with Synapse to extract text from PDFs, SparkOcrRestApiPdf Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_11_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_11_0"
  },
  "1401": {
    "id": "1401",
    "title": "Spark NLP release notes 3.12.0",
    "content": "3.12.0 Release date: 14-04-2022 Overview We’re glad to announce that Spark OCR 3.12.0 has been released! This release comes with new models for Handwritten Text Recognition, Spark 3.2 support, bug fixes, and notebook examples. New Features Added to the ImageTextDetectorV2: New parameter ‘mergeIntersects’: merge bounding boxes corresponding to detected text regions, when multiple bounding boxes that belong to the same text line overlap. New parameter ‘forceProcessing’: now you can force processing of the results to avoid repeating the computation of results in pipelines where the same results are consumed by different transformers. New feature: sizeThreshold parameter sets the expected size for the recognized text. From now on, text size will be automatically detected when sizeThreshold is set to -1. Added to the ImageToTextV2: New parameter ‘usePandasUdf’: support PandasUdf to allow batch processing internally. New support for formatted output, and HOCR. ocr.setOutputFormat(OcrOutputFormat.HOCR) ocr.setOutputFormat(OcrOutputFormat.FORMATTED_TEXT) Support for Spark 3.2: We added support for the latest Spark version, check installation instructions below. Known problems &amp; workarounds: SPARK-38330: S3 access issues, there’s a workaround using the following settings, //Scala spark.sparkContext.hadoopConfiguration.set(&quot;fs.s3a.path.style.access&quot;, &quot;true&quot;) #Python spark.sparkContext._jsc.hadoopConfiguration().set(&quot;fs.s3a.path.style.access&quot;, &quot;true&quot;) SPARK-37577: changes in default behavior of query optimizer, it is already handled in start() function, or if you start the context manually, setting the following Spark properties, #Python spark.conf.set(&quot;spark.sql.optimizer.expression.nestedPruning.enabled&quot;, False) spark.conf.set(&quot;spark.sql.optimizer.nestedSchemaPruning.enabled&quot;, False) Improved documentation on the website. New Models ocr_small_printed: Text recognition small model for printed text based on ImageToTextV2 ocr_small_handwritten: Text recognition small model for handwritten text based on ImageToTextV2 ocr_base_handwritten: Text recognition base model for handwritten text based on ImageToTextV2 Bug Fixes display_table() function failing to display tables coming from digital PDFs. New notebooks SparkOcrImageToTextV2OutputFormats.ipynb, different output formats for ImageToTextV2. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_12_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_12_0"
  },
  "1402": {
    "id": "1402",
    "title": "Spark NLP release notes 3.13.0",
    "content": "3.13.0 Release date: 25-05-2022 We are glad to announce that Spark OCR 3.13.0 has been released!. This release focuses around VisualDocumentNer models, adding ability to fine-tune, fixing bugs, and to leverage the Annotation Lab to generate training data. New Features VisualDocumentNerV21: Now you can fine tune models VisualDocumentNerV21 models on your own dataset. AlabReaders: New class to allow training data from the Annotation Lab to be imported into Spark OCR. Currently, the reader supports Visual Ner only. Bug Fixes Feature extraction on VisualDocumentNer has been improved. New notebooks SparkOcrFormRecognitionFineTuning.ipynb, end to end example on Visual Document Ner Fine-Tuning. Databricks notebooks on Github Spark-OCR Workshop repository have been updated, and fixed. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_13_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_13_0"
  },
  "1403": {
    "id": "1403",
    "title": "Spark NLP release notes 3.14.0",
    "content": "3.14.0 Release date: 13-06-2022 Overview We are glad to announce that Spark OCR 3.14.0 has been released!. This release focuses around Visual Document Classification models, native Image Preprocessing on the JVM, and bug fixes. New Features VisualDocumentClassifierv2: New annotator for classifying documents based on multimodal(text + images) features. VisualDocumentClassifierv3: New annotator for classifying documents based on image features. ImageTransformer: New transformer that provides different image transformations on the JVM. Supported transforms are Scaling, Adaptive Thresholding, Median Blur, Dilation, Erosion, and Object Removal. New notebooks SparkOCRVisualDocumentClassifierv2.ipynb, example of Visual Document Classification using multimodal (text + visual) features. SparkOCRVisualDocumentClassifierv3.ipynb, example of Visual Document Classification using only visual features. SparkOCRCPUImageOperations.ipynb, example of ImageTransformer. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_14_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_14_0"
  },
  "1404": {
    "id": "1404",
    "title": "Spark NLP release notes 3.1.0",
    "content": "3.1.0 Release date: 16-04-2021 Overview Image processing on GPU. It is in 3.5 times faster than on CPU. More details please read in GPU image preprocessing in Spark OCR New Features GPUImageTransformer with support: scaling, erosion, delation, Otsu and Huang thresholding. Added display_images util function for displaying images from Spark DataFrame in Jupyter notebooks. Enhancements Improve display_image util function. Bug fixes Fixed issue with extra dependencies in start function New notebooks GPU image processing Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_1_0"
  },
  "1405": {
    "id": "1405",
    "title": "Spark NLP for Healthcare Release Notes 3.1.0",
    "content": "3.1.0 We are glad to announce that Spark NLP for Healthcare 3.1.0 has been released! Highlights Improved load time &amp; memory consumption for SentenceResolver models. New JSL Bert Models. JSL SBert Model Speed Benchmark. New ICD10CM resolver models. New Deidentification NER models. New column returned in DeidentificationModel New Reidentification feature New Deidentification Pretrained Pipelines Chunk filtering based on confidence Extended regex dictionary fuctionallity in Deidentification Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document MedicalNerApproach can now accept a graph file directly. MedicalNerApproach can now accept a user-defined name for log file. More improvements in Scaladocs. Bug fixes in Deidentification module. New notebooks. Sentence Resolver Models load time improvement Sentence resolver models now have faster load times, with a speedup of about 6X when compared to previous versions. Also, the load process now is more memory friendly meaning that the maximum memory required during load time is smaller, reducing the chances of OOM exceptions, and thus relaxing hardware requirements. New JSL SBert Models We trained new sBert models in TF2 and fined tuned on MedNLI, NLI and UMLS datasets with various parameters to cover common NLP tasks in medical domain. You can find the details in the following table. sbiobert_jsl_cased sbiobert_jsl_umls_cased sbert_jsl_medium_uncased sbert_jsl_medium_umls_uncased sbert_jsl_mini_uncased sbert_jsl_mini_umls_uncased sbert_jsl_tiny_uncased sbert_jsl_tiny_umls_uncased JSL SBert Model Speed Benchmark JSL SBert Model Base Model Is Cased Train Datasets Inference speed (100 rows) sbiobert_jsl_cased biobert_v1.1_pubmed Cased medNLI, allNLI 274,53 sbiobert_jsl_umls_cased biobert_v1.1_pubmed Cased medNLI, allNLI, umls 274,52 sbert_jsl_medium_uncased uncased_L-8_H-512_A-8 Uncased medNLI, allNLI 80,40 sbert_jsl_medium_umls_uncased uncased_L-8_H-512_A-8 Uncased medNLI, allNLI, umls 78,35 sbert_jsl_mini_uncased uncased_L-4_H-256_A-4 Uncased medNLI, allNLI 10,68 sbert_jsl_mini_umls_uncased uncased_L-4_H-256_A-4 Uncased medNLI, allNLI, umls 10,29 sbert_jsl_tiny_uncased uncased_L-2_H-128_A-2 Uncased medNLI, allNLI 4,54 sbert_jsl_tiny_umls_uncased uncased_L-2_H-128_A-2 Uncased medNLI, allNL, umls 4,54 New ICD10CM resolver models: These models map clinical entities and concepts to ICD10 CM codes using sentence bert embeddings. They also return the official resolution text within the brackets inside the metadata. Both models are augmented with synonyms, and previous augmentations are flexed according to cosine distances to unnormalized terms (ground truths). sbiobertresolve_icd10cm_slim_billable_hcc: Trained with classic sbiobert mli. (sbiobert_base_cased_mli) Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbiobertresolve_icd10cm_slim_billable_hcc_en.html sbertresolve_icd10cm_slim_billable_hcc_med: Trained with new jsl sbert(sbert_jsl_medium_uncased) Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbertresolve_icd10cm_slim_billable_hcc_med_en.html Example: ‘bladder cancer’ sbiobertresolve_icd10cm_augmented_billable_hcc chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer C679 [C679, Z126, D090, D494, C7911] [bladder cancer, suspected bladder cancer, cancer in situ of urinary bladder, tumor of bladder neck, malignant tumour of bladder neck] [0.0000, 0.0904, 0.0978, 0.1080, 0.1281] 26,9 ` sbiobertresolve_icd10cm_slim_billable_hcc` chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer D090 [D090, D494, C7911, C680, C679] [cancer in situ of urinary bladder [Carcinoma in situ of bladder], tumor of bladder neck [Neoplasm of unspecified behavior of bladder], malignant tumour of bladder neck [Secondary malignant neoplasm of bladder], carcinoma of urethra [Malignant neoplasm of urethra], malignant tumor of urinary bladder [Malignant neoplasm of bladder, unspecified]] [0.0978, 0.1080, 0.1281, 0.1314, 0.1284] 20,9 sbertresolve_icd10cm_slim_billable_hcc_med chunks code all_codes resolutions all_distances 100x Loop(sec) bladder cancer C671 [C671, C679, C61, C672, C673] [bladder cancer, dome [Malignant neoplasm of dome of bladder], cancer of the urinary bladder [Malignant neoplasm of bladder, unspecified], prostate cancer [Malignant neoplasm of prostate], cancer of the urinary bladder] [0.0894, 0.1051, 0.1184, 0.1180, 0.1200] 12,8 New Deidentification NER Models We trained four new NER models to find PHI data (protected health information) that may need to be deidentified. ner_deid_generic_augmented and ner_deid_subentity_augmented models are trained with a combination of 2014 i2b2 Deid dataset and in-house annotations as well as some augmented version of them. Compared to the same test set coming from 2014 i2b2 Deid dataset, we achieved a better accuracy and generalisation on some entity labels as summarised in the following tables. We also trained the same models with glove_100d embeddings to get more memory friendly versions. ner_deid_generic_augmented : Detects PHI 7 entities (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). Models Hub Page : https://nlp.johnsnowlabs.com/2021/06/01/ner_deid_generic_augmented_en.html entity ner_deid_large (v3.0.3 and before) ner_deid_generic_augmented (v3.1.0) CONTACT 0.8695 0.9592 NAME 0.9452 0.9648 DATE 0.9778 0.9855 LOCATION 0.8755 0.923 ner_deid_subentity_augmented: Detects PHI 23 entities (MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE) Models Hub Page : https://nlp.johnsnowlabs.com/2021/06/01/ner_deid_subentity_augmented_en.html entity ner_deid_enriched (v3.0.3 and before) ner_deid_subentity_augmented (v3.1.0) HOSPITAL 0.8519 0.8983 DATE 0.9766 0.9854 CITY 0.7493 0.8075 STREET 0.8902 0.9772 ZIP 0.8 0.9504 PHONE 0.8615 0.9502 DOCTOR 0.9191 0.9347 AGE 0.9416 0.9469 ner_deid_generic_glove: Small version of ner_deid_generic_augmented and detects 7 entities. ner_deid_subentity_glove: Small version of ner_deid_subentity_augmented and detects 23 entities. Example: Scala ... val deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) ... val nlpPipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter)) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) val result = pipeline.fit(Seq.empty[&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;].toDS.toDF(&quot;text&quot;)).transform(data) Python ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;&quot;&quot;]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25-year-old |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street. |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ New column returned in DeidentificationModel DeidentificationModel now can return a new column to save the mappings between the mask/obfuscated entities and original entities. This column is optional and you can set it up with the .setReturnEntityMappings(True) method. The default value is False. Also, the name for the column can be changed using the following method; .setMappingsColumn(&quot;newAlternativeName&quot;) The new column will produce annotations with the following structure, Annotation( type: chunk, begin: 17, end: 25, result: 47, metadata:{ originalChunk -&gt; 01/13/93 //Original text of the chunk chunk -&gt; 0 // The number of the chunk in the sentence beginOriginalChunk -&gt; 95 // Start index of the original chunk endOriginalChunk -&gt; 102 // End index of the original chunk entity -&gt; AGE // Entity of the chunk sentence -&gt; 2 // Number of the sentence } ) New Reidentification feature With the new ReidetificationModel, the user can go back to the original sentences using the mappings columns and the deidentification sentences. Example: Scala val redeidentification = new ReIdentification() .setInputCols(Array(&quot;mappings&quot;, &quot;deid_chunks&quot;)) .setOutputCol(&quot;original&quot;) Python reDeidentification = ReIdentification() .setInputCols([&quot;mappings&quot;,&quot;deid_chunks&quot;]) .setOutputCol(&quot;original&quot;) New Deidentification Pretrained Pipelines We developed a clinical_deidentification pretrained pipeline that can be used to deidentify PHI information from medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate AGE, CONTACT, DATE, ID, LOCATION, NAME, PROFESSION, CITY, COUNTRY, DOCTOR, HOSPITAL, IDNUM, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, USERNAME, ZIP, ACCOUNT, LICENSE, VIN, SSN, DLN, PLATE, IPADDR entities. Models Hub Page : clinical_deidentification There is also a lightweight version of the same pipeline trained with memory efficient glove_100dembeddings. Here are the model names: clinical_deidentification clinical_deidentification_glove Example: Python: from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) deid_pipeline.annotate(&quot;Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver&#39;s license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&quot;) Scala: import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;,&quot;en&quot;,&quot;clinical/models&quot;) val result = deid_pipeline.annotate(&quot;Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver&#39;s license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&quot;) Result: {&#39;sentence&#39;: [&#39;Record date : 2093-01-13, David Hale, M.D.&#39;, &#39;IP: 203.120.223.13.&#39;, &#39;The driver&#39;s license no:A334455B.&#39;, &#39;the SSN:324598674 and e-mail: hale@gmail.com.&#39;, &#39;Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93.&#39;, &#39;PCP : Oliveira, 25 years-old.&#39;, &#39;Record date : 2079-11-09, Patient&#39;s VIN : 1HGBH41JXMN109286.&#39;], &#39;masked&#39;: [&#39;Record date : &lt;DATE&gt;, &lt;DOCTOR&gt;, M.D.&#39;, &#39;IP: &lt;IPADDR&gt;.&#39;, &#39;The driver&#39;s license &lt;DLN&gt;.&#39;, &#39;the &lt;SSN&gt; and e-mail: &lt;EMAIL&gt;.&#39;, &#39;Name : &lt;PATIENT&gt; MR. # &lt;MEDICALRECORD&gt; Date : &lt;DATE&gt;.&#39;, &#39;PCP : &lt;DOCTOR&gt;, &lt;AGE&gt; years-old.&#39;, &#39;Record date : &lt;DATE&gt;, Patient&#39;s VIN : &lt;VIN&gt;.&#39;], &#39;obfuscated&#39;: [&#39;Record date : 2093-01-18, Dr Alveria Eden, M.D.&#39;, &#39;IP: 001.001.001.001.&#39;, &#39;The driver&#39;s license K783518004444.&#39;, &#39;the SSN-400-50-8849 and e-mail: Merilynn@hotmail.com.&#39;, &#39;Name : Charls Danger MR. # J3366417 Date : 01-18-1974.&#39;, &#39;PCP : Dr Sina Sewer, 55 years-old.&#39;, &#39;Record date : 2079-11-23, Patient&#39;s VIN : 6ffff55gggg666777.&#39;], &#39;ner_chunk&#39;: [&#39;2093-01-13&#39;, &#39;David Hale&#39;, &#39;no:A334455B&#39;, &#39;SSN:324598674&#39;, &#39;Hendrickson, Ora&#39;, &#39;719435&#39;, &#39;01/13/93&#39;, &#39;Oliveira&#39;, &#39;25&#39;, &#39;2079-11-09&#39;, &#39;1HGBH41JXMN109286&#39;]} Chunk filtering based on confidence We added a new annotator ChunkFiltererApproach that allows to load a csv with both entities and confidence thresholds. This annotator will produce a ChunkFilterer model. You can load the dictionary with the following property setEntitiesConfidenceResource(). An example dictionary is: TREATMENT,0.7 With that dictionary, the user can filter the chunks corresponding to treatment entities which have confidence lower than 0.7. Example: We have a ner_chunk column and sentence column with the following data: Ner_chunk |[{chunk, 141, 163, the genomicorganization, {entity -&gt; TREATMENT, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.57785}, []}, {chunk, 209, 267, a candidate gene forType II diabetes mellitus, {entity -&gt; PROBLEM, sentence -&gt; 0, chunk -&gt; 1, confidence -&gt; 0.6614286}, []}, {chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 559, 581, aVal366Ala substitution, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 4, confidence -&gt; 0.61505}, []}, {chunk, 588, 601, an 8 base-pair, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 5, confidence -&gt; 0.29226667}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]| +- Sentence [{document, 0, 298, The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family.Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population., {sentence -&gt; 0}, []}, {document, 300, 460, The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons ,separated byapproximately 2.2 and approximately 2.6 kb introns, respectively., {sentence -&gt; 1}, []}, {document, 462, 601, We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair, {sentence -&gt; 2}, []}, {document, 603, 626, (bp) insertion/deletion., {sentence -&gt; 3}, []}] We can filter the entities using the following annotator: chunker_filter = ChunkFiltererApproach().setInputCols(&quot;sentence&quot;, &quot;ner_chunk&quot;) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;regex&quot;) .setRegex([&quot;.*&quot;]) .setEntitiesConfidenceResource(&quot;entities_confidence.csv&quot;) Where entities-confidence.csv has the following data: TREATMENT,0.7 PROBLEM,0.9 We can use that chunk_filter: chunker_filter.fit(data).transform(data) Producing the following entities: |[{chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]| As you can see, only the treatment entities with confidence score of more than 0.7, and the problem entities with confidence score of more than 0.9 have been kept in the output. Extended regex dictionary fuctionallity in Deidentification The RegexPatternsDictionary can now use a regex that spawns the 2 previous token and the 2 next tokens. That feature is implemented using regex groups. Examples: Given the sentence The patient with ssn 123123123 we can use the following regex to capture the entitty ssn ( d{9}) Given the sentence The patient has 12 years we can use the following regex to capture the entitty ( d{2}) years Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document A new option has been added to RENerChunksFilter to support pairing entities from different sentences using .setDocLevelRelations(True), to pass to the Relation Extraction Model. The RelationExtractionDL Model has also been updated to process document-level relations. How to use: re_dl_chunks = RENerChunksFilter() .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setDocLevelRelations(True) .setMaxSyntacticDistance(7) .setOutputCol(&quot;redl_ner_chunks&quot;) Examples: Given a document containing multiple sentences: John somkes cigrettes. He also consumes alcohol., now we can generate relation pairs across sentences and relate alcohol with John . Set NER graph explicitely in MedicalNerApproach Now MedicalNerApproach can receives the path to the graph directly. When a graph location is provided through this method, previous graph search behavior is disabled. MedicalNerApproach.setGraphFile(graphFilePath) MedicalNerApproach can now accept a user-defined name for log file. Now MedicalNerApproach can accept a user-defined name for the log file. If not such a name is provided, the conventional naming will take place. MedicalNerApproach.setLogPrefix(&quot;oncology_ner&quot;) This will result in oncology_ner_20210605_141701.log filename being used, in which the 20210605_141701 is a timestamp. New Notebooks A new notebook to reproduce our peer-reviewed NER paper (https://arxiv.org/abs/2011.06315) New databricks case study notebooks. In these notebooks, we showed the examples of how to work with oncology notes dataset and OCR on databricks for both DBr and community edition versions. Updated Resolver Models We updated sbiobertresolve_snomed_findings and sbiobertresolve_cpt_procedures_augmented resolver models to reflect the latest changes in the official terminologies. Getting Started with Spark NLP for Healthcare Notebook in Databricks We prepared a new notebook for those who want to get started with Spark NLP for Healthcare in Databricks : Getting Started with Spark NLP for Healthcare Notebook Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_0"
  },
  "1406": {
    "id": "1406",
    "title": "Annotation Lab Release Notes 3.1.0",
    "content": "3.1.0 Release date: 04-05-2022 We are very excited to release Annotation Lab v3.1.0 which includes support for training large documents, improvements for Visual NER Projects, security fixes and stabilizations. Here are the highlights: Highlights Support Training of large documents. Spark NLP feature called Memory Optimization Approach is enabled when the training data is greater then 5MB which enables training of model on machines with lower memory resources. Improvements in Visual NER Projects: Users can provide title in the input JSON along with the URL for tasks to import. This sets the title of the task accordingly. JSON export for the Visual NER projects contains both chunk and token-level annotations. Sample tasks can be imported into the Visual NER project using any available OCR server (created by another project). Multi-chunk annotation can be done without changing the start token when the end token is the last word on the document. For Visual NER project, users can export tasks in the VOC format for multi-page tasks with/without completions. During restoring backup file in the previous versions, the SECRETS (kubernetes) of the old machine needed manual transfer to the target machine. With v3.1.0, all the SECRETS are backed-up automatically along with database backup and hence they are restored without any hassle. Integration with my.johnsnowlabs.com, this means the available licenses can be easily imported by Admin users of Annotation Lab without having to download or copy them manually. The maximum number of words/tokens that can be set in a single page in labeling screen is now limited to 1000. For a large number of multiple relations, the previous version of Annotation Lab used Prev and Next identifiers which was not optimal for mapping to the correct pairs. For increased usability and clarity , the pair connections now use numerical values. While creating new (Contextual Parser) Rules using dictionary, the uploaded CSV file is validated based on: CSV should not contain any null values, CSV should either be a single row or single column. Admin users are now able to remove unused licenses. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_0"
  },
  "1407": {
    "id": "1407",
    "title": "Spark NLP for Healthcare Release Notes 3.1.1",
    "content": "3.1.1 We are glad to announce that Spark NLP for Healthcare 3.1.1 has been released! Highlights MedicalNerModel new parameter includeAllConfidenceScores. MedicalNerModel new parameter inferenceBatchSize. New Resolver Models Updated Resolver Models Getting Started with Spark NLP for Healthcare Notebook in Databricks MedicalNer new parameter includeAllConfidenceScores You can now customize whether you will require confidence score for every token(both entities and non-entities) at the output of the MedicalNerModel, or just for the tokens recognized as entities. MedicalNerModel new parameter inferenceBatchSize You can now control the batch size used during inference as a separate parameter from the one you used during training of the model. This can be useful in the situation in which the hardware on which you run inference has different capacity. For example, when you have lower available memory during inference, you can reduce the batch size. New Resolver Models We trained three new sentence entity resolver models. sbertresolve_snomed_bodyStructure_med and sbiobertresolve_snomed_bodyStructure models map extracted medical (anatomical structures) entities to Snomed codes (body structure version). sbertresolve_snomed_bodyStructure_med : Trained with using sbert_jsl_medium_uncased embeddings. sbiobertresolve_snomed_bodyStructure : Trained with using sbiobert_base_cased_mli embeddings. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) jsl_sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;,&#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_bodyStructure_med, &quot;en&quot;, &quot;clinical/models) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, jsl_sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;Amputation stump&quot;) Result: | | chunks | code | resolutions | all_codes | all_distances | |:|:--|:|:|:|:-| | 0 | amputation stump | 38033009 | [Amputation stump, Amputation stump of upper limb, Amputation stump of left upper limb, Amputation stump of lower limb, Amputation stump of left lower limb, Amputation stump of right upper limb, Amputation stump of right lower limb, ...]| [&#39;38033009&#39;, &#39;771359009&#39;, &#39;771364008&#39;, &#39;771358001&#39;, &#39;771367001&#39;, &#39;771365009&#39;, &#39;771368006&#39;, ...] | [&#39;0.0000&#39;, &#39;0.0773&#39;, &#39;0.0858&#39;, &#39;0.0863&#39;, &#39;0.0905&#39;, &#39;0.0911&#39;, &#39;0.0972&#39;, ...] | sbiobertresolve_icdo_augmented : This model maps extracted medical entities to ICD-O codes using sBioBert sentence embeddings. This model is augmented using the site information coming from ICD10 and synonyms coming from SNOMED vocabularies. It is trained with a dataset that is 20x larger than the previous version of ICDO resolver. Given the oncological entity found in the text (via NER models like ner_jsl), it returns top terms and resolutions along with the corresponding ICD-10 codes to present more granularity with respect to body parts mentioned. It also returns the original histological behavioral codes and descriptions in the aux metadata. Example: ... chunk2doc = Chunk2Doc().setInputCols(&quot;ner_chunk&quot;).setOutputCol(&quot;ner_chunk_doc&quot;) sbert_embedder = BertSentenceEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icdo_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icdo_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, icdo_resolver]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) results = model.transform(spark.createDataFrame([[&quot;The patient is a very pleasant 61-year-old female with a strong family history of colon polyps. The patient reports her first polyps noted at the age of 50. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. She also has history of several malignancies in the family. Her father died of a brain tumor at the age of 81. Her sister died at the age of 65 breast cancer. She has two maternal aunts with history of lung cancer both of whom were smoker. Also a paternal grandmother who was diagnosed with leukemia at 86 and a paternal grandfather who had B-cell lymphoma.&quot;]]).toDF(&quot;text&quot;)) Result: +--+--++--+-+-+-+ | chunk|begin|end| entity| code| all_k_resolutions| all_k_codes| +--+--++--+-+-+-+ | mesothelioma| 255|266|Oncological|9971/3||C38.3|malignant mediastinal ...|9971/3||C38.3:::8854/3...| |several malignancies| 293|312|Oncological|8894/3||C39.8|overlapping malignant ...|8894/3||C39.8:::8070/2...| | brain tumor| 350|360|Oncological|9562/0||C71.9|cancer of the brain:::...|9562/0||C71.9:::9070/3...| | breast cancer| 413|425|Oncological|9691/3||C50.9|carcinoma of breast:::...|9691/3||C50.9:::8070/2...| | lung cancer| 471|481|Oncological|8814/3||C34.9|malignant tumour of lu...|8814/3||C34.9:::8550/3...| | leukemia| 560|567|Oncological|9670/3||C80.9|anemia in neoplastic d...|9670/3||C80.9:::9714/3...| | B-cell lymphoma| 610|624|Oncological|9818/3||C77.9|secondary malignant ne...|9818/3||C77.9:::9655/3...| +--+--++--+-+-+-+ Updated Resolver Models We updated sbiobertresolve_snomed_findings and sbiobertresolve_cpt_procedures_augmented resolver models to reflect the latest changes in the official terminologies. Getting Started with Spark NLP for Healthcare Notebook in Databricks We prepared a new notebook for those who want to get started with Spark NLP for Healthcare in Databricks : Getting Started with Spark NLP for Healthcare Notebook Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_1"
  },
  "1408": {
    "id": "1408",
    "title": "Annotation Lab Release Notes 3.1.1",
    "content": "3.1.1 Release date: 09-05-2022 We are very excited to announce the release of Annotation Lab v3.1.1 which includes Support excel import, CVE fixes and stabilization. Here are the highlights: Highlights Fix more CVEs of docker images Change ClusterRole and ClusterRolebinding to Role and Rolebinding for backup When a trained model is deployed by active learning, “active-learning” is seen in Deployedby column Fix for visibility icon used for connected words Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_1_1"
  },
  "1409": {
    "id": "1409",
    "title": "Spark NLP for Healthcare Release Notes 3.1.2",
    "content": "3.1.2 We are glad to announce that Spark NLP for Healthcare 3.1.2 has been released!. This release comes with new features, new models, bug fixes, and examples. Highlights Support for Fine-tuning of Ner models. More builtin(pre-defined) graphs for MedicalNerApproach. Date Normalizer. New Relation Extraction Models for ADE. Bug Fixes. Support for user-defined Custom Transformer. Java Workshop Examples. Deprecated Compatibility class in Python. Support for Fine Tuning of Ner models Users can now resume training/fine-tune existing(already trained) Spark NLP MedicalNer models on new data. Users can simply provide the path to any existing MedicalNer model and train it further on the new dataset: ner_tagger = MedicalNerApproach().setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) If the new dataset contains new tags/labels/entities, users can choose to override existing tags with the new ones. The default behaviour is to reset the list of existing tags and generate a new list from the new dataset. It is also possible to preserve the existing tags by setting the ‘overrideExistingTags’ parameter: ner_tagger = MedicalNerApproach() .setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) .setOverrideExistingTags(False) Setting overrideExistingTags to false is intended to be used when resuming trainig on the same, or very similar dataset (i.e. with the same tags or with just a few different ones). If tags overriding is disabled, and new tags are found in the training set, then the approach will try to allocate them to unused output nodes, if any. It is also possible to override specific tags of the old model by mapping them to new tags: ner_tagger = MedicalNerApproach() .setPretrainedModelPath(&quot;/path/to/trained/medicalnermodel&quot;) .setOverrideExistingTags(False) .setTagsMapping(&quot;B-PER,B-VIP&quot;, &quot;I-PER,I-VIP&quot;) In this case, the new tags B-VIP and I-VIP will replace the already trained tags ‘B-PER’ and ‘I-PER’. Unmapped old tags will remain in use and unmapped new tags will be allocated to new outpout nodes, if any. Jupyter Notebook: [Finetuning Medical NER Model Notebook] (https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.5.Resume_MedicalNer_Model_Training.ipynb) More builtin graphs for MedicalNerApproach Seventy new TensorFlow graphs have been added to the library of available graphs which are used to train MedicalNer models. The graph with the optimal set of parameters is automatically chosen by MedicalNerApproach. DateNormalizer New annotator that normalize dates to the format YYYY/MM/DD. This annotator identifies dates in chunk annotations, and transform these dates to the format YYYY/MM/DD. Both the input and output formats for the annotator are chunk. Example: sentences = [ [&#39;08/02/2018&#39;], [&#39;11/2018&#39;], [&#39;11/01/2018&#39;], [&#39;12Mar2021&#39;], [&#39;Jan 30, 2018&#39;], [&#39;13.04.1999&#39;], [&#39;3April 2020&#39;], [&#39;next monday&#39;], [&#39;today&#39;], [&#39;next week&#39;], ] df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) chunksDF = document_assembler.transform(df) aa = map_annotations_col(chunksDF.select(&quot;document&quot;), lambda x: [Annotation(&#39;chunk&#39;, a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], &quot;document&quot;, &quot;chunk_date&quot;, &quot;chunk&quot;) dateNormalizer = DateNormalizer().setInputCols(&#39;chunk_date&#39;).setOutputCol(&#39;date&#39;).setAnchorDateYear(2021).setAnchorDateMonth(2).setAnchorDateDay(27) dateDf = dateNormalizer.transform(aa) dateDf.select(&quot;date.result&quot;,&quot;text&quot;).show() +--+-+ |text | date | +--+-+ |08/02/2018 |2018/08/02| |11/2018 |2018/11/DD| |11/01/2018 |2018/11/01| |12Mar2021 |2021/03/12| |Jan 30, 2018|2018/01/30| |13.04.1999 |1999/04/13| |3April 2020 |2020/04/03| |next Monday |2021/06/19| |today |2021/06/12| |next week |2021/06/19| +--+-+ New Relation Extraction Models for ADE We are releasing new Relation Extraction models for ADE (Adverse Drug Event). This model is available in both RelationExtraction and Bert based RelationExtractionDL versions, and is capabale of linking drugs with ADE mentions. Example ade_re_model = new RelationExtractionModel().pretrained(&#39;ner_ade_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setPredictionThreshold(0.5) .setRelationPairs([&#39;ade-drug&#39;, &#39;drug-ade&#39;]) pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, pos_tagger, words_embedder, ner_tagger, ner_converter, dependency_parser, re_ner_chunk_filter, re_model]) text =&quot;&quot;&quot;A 30 year old female presented with tense bullae due to excessive use of naproxin, and leg cramps relating to oxaprozin.&quot;&quot;&quot; p_model = pipeline.fit(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)) result = p_model.transform(data) Results | | chunk1 | entity1 | chunk2 | entity2 | result | |:|:--|:--|:--|:-|--:| | 0 | tense bullae | ADE | naproxin | DRUG | 1 | | 1 | tense bullae | ADE | oxaprozin | DRUG | 0 | | 2 | naproxin | DRUG | leg cramps | ADE | 0 | | 3 | leg cramps | ADE | oxaprozin | DRUG | 1 | Benchmarking Model: re_ade_clinical precision recall f1-score support 0 0.85 0.89 0.87 1670 1 0.88 0.84 0.86 1673 micro avg 0.87 0.87 0.87 3343 macro avg 0.87 0.87 0.87 3343 weighted avg 0.87 0.87 0.87 3343 Model: redl_ade_biobert Relation Recall Precision F1 Support 0 0.894 0.946 0.919 1011 1 0.963 0.926 0.944 1389 Avg. 0.928 0.936 0.932 Weighted Avg. 0.934 0.934 0.933 Bug Fixes RelationExtractionDLModel had an issue(BufferOverflowException) on versions 3.1.0 and 3.1.1, which is fixed with this release. Some pretrained RelationExtractionDLModels got outdated after release 3.0.3, new updated models were created, tested and made available to be used with versions 3.0.3, and later. Some SentenceEntityResolverModels which did not work with Spark 2.4/2.3 were fixed. Support for user-defined Custom Transformer. Utility classes to define custom transformers in python are included in this release. This allows users to define functions in Python to manipulate Spark-NLP annotations. This new Transformers can be added to pipelines like any of the other models you’re already familiar with. Example how to use the custom transformer. def myFunction(annotations): # lower case the content of the annotations return [a.copy(a.result.lower()) for a in annotations] custom_transformer = CustomTransformer(f=myFunction).setInputCol(&quot;ner_chunk&quot;).setOutputCol(&quot;custom&quot;) outputDf = custom_transformer.transform(outdf).select(&quot;custom&quot;).toPandas() Java Workshop Examples Add Java examples in the workshop repository. https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/java/healthcare Deprecated Compatibility class in Python Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models and versions, especially for the users using our models locally in air-gapped networks. We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This new class is now replacing the previous Compatibility class written in Python and CompatibilityBeta class written in Scala. from sparknlp_jsl.compatibility import Compatibility compatibility = Compatibility(spark) print(compatibility.findVersion(&#39;sentence_detector_dl_healthcare&#39;)) Output [{&#39;name&#39;: &#39;sentence_detector_dl_healthcare&#39;, &#39;sparkVersion&#39;: &#39;2.4&#39;, &#39;version&#39;: &#39;2.6.0&#39;, &#39;language&#39;: &#39;en&#39;, &#39;date&#39;: &#39;2020-09-13T14:44:42.565&#39;, &#39;readyToUse&#39;: &#39;true&#39;}, {&#39;name&#39;: &#39;sentence_detector_dl_healthcare&#39;, &#39;sparkVersion&#39;: &#39;2.4&#39;, &#39;version&#39;: &#39;2.7.0&#39;, &#39;language&#39;: &#39;en&#39;, &#39;date&#39;: &#39;2021-03-16T08:42:34.391&#39;, &#39;readyToUse&#39;: &#39;true&#39;}] Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_2"
  },
  "1410": {
    "id": "1410",
    "title": "Spark NLP for Healthcare Release Notes 3.1.3",
    "content": "3.1.3 We are glad to announce that Spark NLP for Healthcare 3.1.3 has been released!. This release comes with new features, new models, bug fixes, and examples. Highlights New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs New Entity Resolver model for SNOMED codes ChunkConverter Annotator BugFix: getAnchorDateMonth method in DateNormalizer. BugFix: character map in MedicalNerModel fine-tuning. New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs We are releasing a new Relation Extraction Model for ADEs. This model is trained using Bert Word embeddings (biobert_pubmed_base_cased), and is capable of linking ADEs and Drugs. Example: re_model = RelationExtractionModel() .pretrained(&quot;re_ade_biobert&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(3) #default: 0 .setPredictionThreshold(0.5) #default: 0.5 .setRelationPairs([&quot;ade-drug&quot;, &quot;drug-ade&quot;]) # Possible relation pairs. Default: All Relations. nlp_pipeline = Pipeline(stages=[documenter, sentencer, tokenizer, words_embedder, pos_tagger, ner_tagger, ner_chunker, dependency_parser, re_model]) light_pipeline = LightPipeline(nlp_pipeline.fit(spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;))) text =&quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot; annotations = light_pipeline.fullAnnotate(text) We also have a new pipeline comprising of all models related to ADE(Adversal Drug Event) as part of this release. This pipeline includes classification, NER, assertion and relation extraction models. Users can now use this pipeline to get classification result, ADE and Drug entities, assertion status for ADE entities, and relations between ADE and Drug entities. Example: pretrained_ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) result = pretrained_ade_pipeline.fullAnnotate(&quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot;)[0] Results: Class: True NER_Assertion: | | chunk | entitiy | assertion | |-|-||-| | 0 | Lipitor | DRUG | - | | 1 | sever fatigue | ADE | Conditional | | 2 | voltaren | DRUG | - | | 3 | cramps | ADE | Conditional | Relations: | | chunk1 | entitiy1 | chunk2 | entity2 | relation | |-|-||-||-| | 0 | sever fatigue | ADE | Lipitor | DRUG | 1 | | 1 | cramps | ADE | Lipitor | DRUG | 0 | | 2 | sever fatigue | ADE | voltaren | DRUG | 0 | | 3 | cramps | ADE | voltaren | DRUG | 1 | New Entity Resolver model for SNOMED codes We are releasing a new SentenceEntityResolver model for SNOMED codes. This model also includes AUX SNOMED concepts and can find codes for Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure entities. In the metadata, the all_k_aux_labels can be divided to get further information: ground truth, concept, and aux . In the example shared below the ground truth is Atherosclerosis, concept is Observation, and aux is Morph Abnormality. Example: snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_snomed_findings_aux_concepts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;atherosclerosis&quot;) Results: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:-|:|:-|:|:|:| | 0 | atherosclerosis | 38716007 | [atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis artery, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, arteriosclerosis, carotid atherosclerosis, cardiovascular arteriosclerosis, aortic atherosclerosis, aortic atherosclerosis, atherosclerotic ischemic disease] | [38716007, 155382007, 155414001, 195251000, 266318005, 194848007, 441574008, 443502000, 41702007, 266231003, 155316000, 194841001, 28960008, 300920004, 39468009, 155415000, 195252007, 129573006] | &#39;Atherosclerosis&#39;, &#39;Observation&#39;, &#39;Morph Abnormality&#39; | [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0280, 0.0451, 0.0451, 0.0451, 0.0451, 0.0451, 0.0462, 0.0477, 0.0466, 0.0490, 0.0490, 0.0485 | ChunkConverter Annotator Allows to use RegexMather chunks as NER chunks and feed the output to the downstream annotators like RE or Deidentification. document_assembler = DocumentAssembler().setInputCol(&#39;text&#39;).setOutputCol(&#39;document&#39;) sentence_detector = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;) regex_matcher = RegexMatcher() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;regex&quot;) .setExternalRules(path=&quot;../src/test/resources/regex-matcher/rules.txt&quot;,delimiter=&quot;,&quot;) chunkConverter = ChunkConverter().setInputCols(&quot;regex&quot;).setOutputCol(&quot;chunk&quot;) Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_1_3"
  },
  "1411": {
    "id": "1411",
    "title": "Spark NLP release notes 3.2.0",
    "content": "3.2.0 Release date: 28-05-2021 Overview Multi-modal visual document understanding, built on the LayoutLM architecture. It achieves new state-of-the-art accuracy in several downstream tasks, including form understanding and receipt understanding. New Features VisualDocumentNER is a DL model for NER problem using text and layout data. Currently available pre-trained model on the SROIE dataset. Enhancements Added support SPARK_OCR_LICENSE env key for read license. Update dependencies and sync Spark versions with Spark NLP. Bugfixes Fixed an issue that some ImageReaderSpi plugins are unavailable in the fat jar. New notebooks Visual Document NER Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_2_0"
  },
  "1412": {
    "id": "1412",
    "title": "Spark NLP for Healthcare Release Notes 3.2.0",
    "content": "3.2.0 We are glad to announce that Spark NLP Healthcare 3.2.0 has been released!. Highlights New Sentence Boundary Detection Model for Healthcare text New Assertion Status Models New Sentence Entity Resolver Model Finetuning Sentence Entity Resolvers with Your Data New Clinical NER Models New CMS-HCC risk-adjustment score calculation module New Embedding generation module for entity resolution New Sentence Boundary Detection Model for Healthcare text We are releasing an updated Sentence Boundary detection model to identify complex sentences containing multiple measurements, and punctuations. This model is trained on an in-house dataset. Example: Python: ... documenter = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentencerDL = SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentences&quot;) text = &quot;&quot;&quot;He was given boluses of MS04 with some effect.he has since been placed on a PCA . He takes 80 mg. of ativan at home ativan for anxiety, with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv. Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS). Estimated volume is 51.9 ml. and is mildly enlarged in size.Normal delineation pattern of the prostate gland is preserved. &quot;&quot;&quot; sd_model = LightPipeline(PipelineModel(stages=[documenter, sentencerDL])) result = sd_model.fullAnnotate(text) Results: | s.no | sentences | |--:|:| | 0 | He was given boluses of MS04 with some effect. | | 1 | he has since been placed on a PCA . | | 2 | He takes 80 mg. of ativan at home ativan for anxiety, | | | with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv. | | 3 | Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS). | | 4 | Estimated volume is | | | 51.9 ml. and is mildly enlarged in size. | | 5 | Normal delineation pattern of the prostate gland is preserved. | New Assertion Status Models We are releasing two new Assertion Status Models based on the BiLSTM architecture. Apart from what we released in other assertion models, an in-house annotations on a curated dataset (6K clinical notes) is used to augment the base assertion dataset (2010 i2b2/VA). assertion_jsl: This model can classify the assertions made on given medical concepts as being Present, Absent, Possible, Planned, Someoneelse, Past, Family, None, Hypotetical. assertion_jsl_large: This model can classify the assertions made on given medical concepts as being present, absent, possible, planned, someoneelse, past. assertion_dl vs assertion_jsl: chunks entities assertion_dl assertion_jsl Mesothelioma PROBLEM present Present CVA PROBLEM absent Absent cancer PROBLEM associated_with_someone_else Family her INR TEST present Planned Amiodarone TREATMENT hypothetical Hypothetical lymphadenopathy PROBLEM absent Absent stage III disease PROBLEM possible Possible IV piggyback TREATMENT conditional Past Example: Python: ... clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, clinical_assertion]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) result = model.transform(spark.createDataFrame([[&quot;The patient is a 41-year-old and has a nonproductive cough that started last week. She has had right-sided chest pain radiating to her back with fever starting today. She has no nausea. She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center and Chest x-ray revealed right-sided pleural effusion. In family history, her father has a colon cancer history.&quot;]], [&quot;text&quot;]) Results: +-+--++-+-++ |chunk |begin|end|ner_label |sent_id|assertion| +-+--++-+-++ |nonproductive cough|35 |53 |Symptom |0 |Present | |last week |68 |76 |RelativeDate |0 |Past | |chest pain |103 |112|Symptom |1 |Present | |fever |141 |145|VS_Finding |1 |Present | |today |156 |160|RelativeDate |1 |Present | |nausea |174 |179|Symptom |2 |Absent | |pericarditis |203 |214|Disease_Syndrome_Disorder|3 |Past | |pericardectomy |220 |233|Procedure |3 |Past | |May 2006 |238 |245|Date |3 |Past | |cough |261 |265|Symptom |3 |Past | |chest pain |284 |293|Symptom |3 |Past | |Chest x-ray |334 |344|Test |3 |Past | |pleural effusion |367 |382|Disease_Syndrome_Disorder|3 |Past | |colon cancer |421 |432|Oncological |4 |Family | +-+--++-+-++ New Sentence Entity Resolver Model We are releasing sbiobertresolve_rxnorm_disposition model that maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using sbiobert_base_cased_mli Sentence Bert Embeddings. In the result, look for the aux_label parameter in the metadata to get dispositions that were divided by |. Example: Python: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_disposition&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver ]) rxnorm_lp = LightPipeline(pipelineModel) result = rxnorm_lp.fullAnnotate(&quot;belimumab 80 mg/ml injectable solution&quot;) Results: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:--|:--|:--|:--|:--|:-| | 0 |belimumab 80 mg/ml injectable solution | 1092440 | [belimumab 80 mg/ml injectable solution, belimumab 80 mg/ml injectable solution [benlysta], ifosfamide 80 mg/ml injectable solution, belimumab 80 mg/ml [benlysta], belimumab 80 mg/ml, ...]| [1092440, 1092444, 107034, 1092442, 1092438, ...] | [Immunomodulator, Immunomodulator, Alkylating agent, Immunomodulator, Immunomodulator, ...] | [0.0000, 0.0145, 0.0479, 0.0619, 0.0636, ...] | Finetuning Sentence Entity Resolvers with Your Data Instead of starting from scratch when training a new Sentence Entity Resolver model, you can train a new model by adding your new data to the pretrained model. There’s a new method setPretrainedModelPath(path), which allows you to point the training process to an existing model, and allows you to initialize your model with the data from the pretrained model. When both the new data and the pretrained model contain the same code, you will see both of the results at the top. Here is a sample notebook : Finetuning Sentence Entity Resolver Model Notebook Example: In the example below, we changed the code of sepsis to X1234 and re-retrain the main ICD10-CM model with this new dataset. So we want to see the X1234 code as a result in the all_codes. Python: ... bertExtractor = SentenceEntityResolverApproach() .setNeighbours(50) .setThreshold(1000) .setInputCols(&quot;sentence_embeddings&quot;) .setNormalizedCol(&quot;description_normalized&quot;) # concept_name .setLabelCol(&quot;code&quot;) # concept_code .setOutputCol(&quot;recognized_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) .setUseAuxLabel(True) # if exist .setPretrainedModelPath(&quot;path_to_a_pretrained_model&quot;) new_model = bertExtractor.fit(&quot;new_dataset&quot;) new_model.save(&quot;models/new_resolver_model&quot;) # save and use later ... resolver_model = SentenceEntityResolverModel.load(&quot;models/new_resolver_model&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;output_code&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sentence_embedder, resolver_model]) light_model = LightPipeline(pipelineModel) light_model.fullAnnotate(&quot;sepsis&quot;) Main Model Results: chunks begin end code all_codes resolutions all_k_aux_labels all_distances sepsis 0 5 A4189 [A4189, L419, A419, A267, E771, …] [sepsis [Other specified sepsis], parapsoriasis [Parapsoriasis, unspecified], postprocedural sepsis [Sepsis, unspecified organism], erysipelothrix sepsis [Erysipelothrix sepsis], fucosidosis [Defects in glycoprotein degradation], … ] [1|1|2, 1|1|2, 1|1|2, 1|1|2, 1|1|23, …] [0.0000, 0.2079, 0.2256, 0.2359, 0.2399,…] Re-Trained Model Results: chunks begin end code all_codes resolutions all_k_aux_labels all_distances sepsis 0 5 X1234 [X1234, A4189, A419, L419, A267, …] [sepsis [Sepsis, new resolution], sepsis [Other specified sepsis], SEPSIS [Sepsis, unspecified organism], parapsoriasis [Parapsoriasis, unspecified], erysipelothrix sepsis [Erysipelothrix sepsis], … ] [1|1|74, 1|1|2, 1|1|2, 1|1|2, 1|1|2, …] [0.0000, 0.0000, 0.0000, 0.2079, 0.2359, …] New Clinical NER Models ner_jsl_slim: This model is trained based on ner_jsl model with more generalized entities. (Death_Entity, Medical_Device, Vital_Sign, Alergen, Drug, Clinical_Dept, Lifestyle, Symptom, Body_Part, Physical_Measurement, Admission_Discharge, Date_Time, Age, Birth_Entity, Header, Oncological, Substance_Quantity, Test_Result, Test, Procedure, Treatment, Disease_Syndrome_Disorder, Pregnancy_Newborn, Demographics) ner_jsl vs ner_jsl_slim: chunks ner_jsl ner_jsl_slim Description: Section_Header Header atrial fibrillation Heart_Disease Disease_Syndrome_Disorder August 24, 2007 Date Date_Time transpleural fluoroscopy Procedure Test last week RelativeDate Date_Time She Gender Demographics fever VS_Finding Vital_Sign PAST MEDICAL HISTORY: Medical_History_Header Header Pericardial window Internal_organ_or_component Body_Part FAMILY HISTORY: Family_History_Header Header CVA Cerebrovascular_Disease Disease_Syndrome_Disorder diabetes Diabetes Disease_Syndrome_Disorder married Relationship_Status Demographics alcohol Alcohol Lifestyle illicit drug Substance Lifestyle Coumadin Drug_BrandName Drug Blood pressure 123/95 Blood_Pressure Vital_Sign heart rate 83 Pulse Vital_Sign anticoagulated Drug_Ingredient Drug Example: Python: ... embeddings_clinical = WordEmbeddingsModel().pretrained(&#39;embeddings_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&#39;sentence&#39;, &#39;token&#39;]) .setOutputCol(&#39;embeddings&#39;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer.&quot;]], [&quot;text&quot;])) Results: | | chunk | entity | |:|:--|:-| | 0 | HISTORY: | Header | | 1 | 30-year-old | Age | | 2 | female | Demographics | | 3 | mammography | Test | | 4 | soft tissue lump | Symptom | | 5 | shoulder | Body_Part | | 6 | breast cancer | Oncological | | 7 | her mother | Demographics | | 8 | age 58 | Age | | 9 | breast cancer | Oncological | ner_jsl_biobert : This model is the BioBert version of ner_jsl model and trained with biobert_pubmed_base_cased embeddings. ner_jsl_greedy_biobert : This model is the BioBert version of ner_jsl_greedy models and trained with biobert_pubmed_base_cased embeddings. Example: Python: ... embeddings_clinical = BertEmbeddings.pretrained(&#39;biobert_pubmed_base_cased&#39;) .setInputCols([&#39;sentence&#39;, &#39;token&#39;]) .setOutputCol(&#39;embeddings&#39;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_greedy_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature.&quot;]], [&quot;text&quot;])) Results: | | chunk | entity | |:|:--|:--| | 0 | 21-day-old | Age | | 1 | Caucasian | Race_Ethnicity | | 2 | male | Gender | | 3 | for 2 days | Duration | | 4 | congestion | Symptom | | 5 | mom | Gender | | 6 | suctioning yellow discharge | Symptom | | 7 | nares | External_body_part_or_region | | 8 | she | Gender | | 9 | mild problems with his breathing while feeding | Symptom | | 10 | perioral cyanosis | Symptom | | 11 | retractions | Symptom | | 12 | One day ago | RelativeDate | | 13 | mom | Gender | | 14 | tactile temperature | Symptom | | 15 | Tylenol | Drug | | 16 | Baby | Age | | 17 | decreased p.o. intake | Symptom | | 18 | His | Gender | | 19 | breast-feeding | External_body_part_or_region | | 20 | q.2h | Frequency | | 21 | to 5 to 10 minutes | Duration | | 22 | his | Gender | | 23 | respiratory congestion | Symptom | | 24 | He | Gender | | 25 | tired | Symptom | | 26 | fussy | Symptom | | 27 | over the past 2 days | RelativeDate | | 28 | albuterol | Drug | | 29 | ER | Clinical_Dept | | 30 | His | Gender | | 31 | urine output has also decreased | Symptom | | 32 | he | Gender | | 33 | per 24 hours | Frequency | | 34 | he | Gender | | 35 | per 24 hours | Frequency | | 36 | Mom | Gender | | 37 | diarrhea | Symptom | | 38 | His | Gender | | 39 | bowel | Internal_organ_or_component | New CMS-HCC risk-adjustment score calculation module We are releasing a new module to calculate medical risk adjusment score by using the Centers for Medicare &amp; Medicaid Service (CMS) risk adjustment model. The main input to this model are ICD codes of the diseases. After getting ICD codes of diseases by Spark NLP Healthcare ICD resolvers, risk score can be calculated by this module in spark environment. Current supported version for the model is CMS-HCC V24. The model needs following parameters in order to calculate the risk score: ICD Codes Age Gender The eligibility segment of the patient Original reason for entitlement If the patient is in Medicaid or not If the patient is disabled or not Example: Python: sample_patients.show() Results: +-++++ |Patient_ID|ICD_codes |Age|Gender| +-++++ |101 |[E1169, I5030, I509, E852] |64 |F | |102 |[G629, D469, D6181] |77 |M | |103 |[D473, D473, D473, M069, C969]|16 |F | +-++++ Python: from sparknlp_jsl.functions import profile df = df.withColumn(&quot;hcc_profile&quot;, profile(df.ICD_codes, df.Age, df.Gender)) df = df.withColumn(&quot;hcc_profile&quot;, F.from_json(F.col(&quot;hcc_profile&quot;), schema)) df= df.withColumn(&quot;risk_score&quot;, df.hcc_profile.getItem(&quot;risk_score&quot;)) .withColumn(&quot;hcc_lst&quot;, df.hcc_profile.getItem(&quot;hcc_map&quot;)) .withColumn(&quot;parameters&quot;, df.hcc_profile.getItem(&quot;parameters&quot;)) .withColumn(&quot;details&quot;, df.hcc_profile.getItem(&quot;details&quot;)) df.select(&#39;Patient_ID&#39;, &#39;risk_score&#39;,&#39;ICD_codes&#39;, &#39;Age&#39;, &#39;Gender&#39;).show(truncate=False ) df.show(truncate=100, vertical=True) Results: +-+-++++ |Patient_ID|risk_score|ICD_codes |Age|Gender| +-+-++++ |101 |0.827 |[E1169, I5030, I509, E852] |64 |F | |102 |1.845 |[G629, D469, D6181] |77 |M | |103 |1.288 |[D473, D473, D473, M069, C969]|16 |F | +-+-++++ RECORD 0- Patient_ID | 101 ICD_codes | [E1169, I5030, I509, E852] Age | 64 Gender | F Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_HCC18&quot;:0.302,&quot;CNA_HCC85&quot;:0.331,&quot;CNA_HCC23&quot;:0.194,&quot;CNA_D3&quot;:0.0,&quot;CNA_HCC85_gDiabetesMellit&quot;:... risk_score | 0.827 hcc_lst | {&quot;E1169&quot;:[&quot;HCC18&quot;],&quot;I5030&quot;:[&quot;HCC85&quot;],&quot;I509&quot;:[&quot;HCC85&quot;],&quot;E852&quot;:[&quot;HCC23&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:64,&quot;sex&quot;:&quot;F&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_HCC18&quot;:0.302,&quot;CNA_HCC85&quot;:0.331,&quot;CNA_HCC23&quot;:0.194,&quot;CNA_D3&quot;:0.0,&quot;CNA_HCC85_gDiabetesMellit&quot;:0.0} -RECORD 1- Patient_ID | 102 ICD_codes | [G629, D469, D6181] Age | 77 Gender | M Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_M75_79&quot;:0.473,&quot;CNA_D1&quot;:0.0,&quot;CNA_HCC46&quot;:1.372}, [&quot;D1&quot;,&quot;HCC46&quot;], {&quot;D469&quot;:[&quot;HCC46&quot;]}, {&quot;elig&quot;... risk_score | 1.845 hcc_lst | {&quot;D469&quot;:[&quot;HCC46&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:77,&quot;sex&quot;:&quot;M&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_M75_79&quot;:0.473,&quot;CNA_D1&quot;:0.0,&quot;CNA_HCC46&quot;:1.372} -RECORD 2- Patient_ID | 103 ICD_codes | [D473, D473, D473, M069, C969] Age | 16 Gender | F Eligibility_Segment | CNA OREC | 0 Medicaid | false Disabled | false hcc_profile | {{&quot;CNA_HCC10&quot;:0.675,&quot;CNA_HCC40&quot;:0.421,&quot;CNA_HCC48&quot;:0.192,&quot;CNA_D3&quot;:0.0}, [&quot;HCC10&quot;,&quot;HCC40&quot;,&quot;HCC48&quot;,&quot;... risk_score | 1.288 hcc_lst | {&quot;D473&quot;:[&quot;HCC48&quot;],&quot;M069&quot;:[&quot;HCC40&quot;],&quot;C969&quot;:[&quot;HCC10&quot;]} parameters | {&quot;elig&quot;:&quot;CNA&quot;,&quot;age&quot;:16,&quot;sex&quot;:&quot;F&quot;,&quot;origds&quot;:&#39;0&#39;,&quot;disabled&quot;:false,&quot;medicaid&quot;:false} details | {&quot;CNA_HCC10&quot;:0.675,&quot;CNA_HCC40&quot;:0.421,&quot;CNA_HCC48&quot;:0.192,&quot;CNA_D3&quot;:0.0} Here is a sample notebook : Calculating Medicare Risk Adjustment Score New Embedding generation module for entity resolution We are releasing a new annotator BertSentenceChunkEmbeddings to let users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. This is specially helpful when ner chunks do not have additional information (like body parts or severity) as explained in the example below. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach. Sample Notebook: Improved_Entity_Resolution_with_SentenceChunkEmbeddings Example: Python: ... sentence_chunk_embeddings = BertSentenceChunkEmbeddings .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_chunk_embeddings&quot;) .setChunkWeight(0.5) resolver = SentenceEntityResolverModel.pretrained(&#39;sbiobertresolve_icd10cm&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence_chunk_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) text = &quot;&quot;&quot;A 20 year old female patient badly tripped while going down stairs. She complains of right leg pain. Her x-ray showed right hip fracture. Hair line fractures also seen on the left knee joint. She also suffered from trauma and slight injury on the head. OTHER CONDITIONS: She was also recently diagnosed with diabetes, which is of type 2. &quot;&quot;&quot; nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter, sentence_chunk_embeddings, resolver]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results: | | chunk | entity | code_with_old_approach | resolutions_with_old_approach | code_with_new_approach | resolutions_with_new_approach | |:|:--|:--|:--|:--|:--|:-| | 0 | leg pain | Symptom | R1033 | Periumbilical pain | M79661 | Pain in right lower leg | | 1 | hip fracture | Injury_or_Poisoning | M84459S | Pathological fracture, hip, unspecified, sequela | M84451S | Pathological fracture, right femur, sequela | | 2 | Hair line fractures | Injury_or_Poisoning | S070XXS | Crushing injury of face, sequela | S92592P | Other fracture of left lesser toe(s), subsequent encounter for fracture with malunion | | 3 | trauma | Injury_or_Poisoning | T794XXS | Traumatic shock, sequela | S0083XS | Contusion of other part of head, sequela | | 4 | slight injury | Injury_or_Poisoning | B03 | Smallpox | S0080XD | Unspecified superficial injury of other part of head, subsequent encounter | | 5 | diabetes | Diabetes | E118 | Type 2 diabetes mellitus with unspecified complications | E1169 | Type 2 diabetes mellitus with other specified complication | To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_0"
  },
  "1413": {
    "id": "1413",
    "title": "Annotation Lab Release Notes 3.2.0",
    "content": "3.2.0 Release date: 31-05-2022 We are very excited to announce the release of Annotation Lab v3.2.0 which includes new and exciting features such as Project cloning and Project backup, Evaluation of Pretrained Models, and Search feature in the Visual NER Project. Support for Multiple files import, ability to view statuses of Model Servers and Training Jobs, and prioritization of completions for CONLL export. Spark NLP and Spark OCR libraries were also upgraded, and some security fixes and stabilizations were also implemented. Here are the highlights: Highlights Import/export of an entire Project. All project-related items (tasks, project configuration, project members, task assignments) can be imported/exported. In addition, users can also clone an existing project. Evaluate Named Entity Models. Project Owner and/or Manager can now test and evaluate annotated tasks against the Pretrained NER models in the Training &amp; Active Learning Settings tab, configured NER models will be tested against the tasks tagged as test. Statuses of Training and Preannotation Server. A new column, status, is added to the server page that gives the status of training and preannotation servers. Also if any issues are encountered during server initialization, those are displayed on mouse-over the status value. Import Multiple Files. Project Owners or Managers can now upload multiple files at once in bulk. Prioritize Annotators For Data Export. When multiple completions are available for the same task, the CONLL export will include completions from higher priority members. Network Policies have been implemented which specify how a pod is allowed to communicate with various network “entities” over the network. The entities that are required to function in Annotation Lab were clearly identified and only traffic coming from them is now allowed. Support for airgap licenses with scope. Previously airgap licenses with scopes were missrecognized as floating licenses. Upgraded Spark NLP and Spark NLP for Health Care v3.4.1 and Spark OCR v3.12.0 Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_2_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_2_0"
  },
  "1414": {
    "id": "1414",
    "title": "Spark NLP for Healthcare Release Notes 3.2.1",
    "content": "3.2.1 We are glad to announce that Spark NLP Healthcare 3.2.1 has been released!. Highlights Deprecated ChunkEntityResolver. New BERT-Based NER Models HCC module added support for versions v22 and v23. Updated Notebooks for resolvers and graph builders. New TF Graph Builder. New BERT-Based NER Models We have two new BERT-based token classifier NER models. These models are the first clinical NER models that use the BertForTokenCLassification approach that was introduced in Spark NLP 3.2.0. bert_token_classifier_ner_clinical: This model is BERT-based version of ner_clinical model. This new model is 4% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Metrics: precision recall f1-score support PROBLEM 0.88 0.92 0.90 30276 TEST 0.91 0.86 0.88 17237 TREATMENT 0.87 0.88 0.88 17298 O 0.97 0.97 0.97 202438 accuracy 0.95 267249 macro avg 0.91 0.91 0.91 267249 weighted avg 0.95 0.95 0.95 267249 Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter ]) p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text = &#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .&#39; res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)).collect() res[0][&#39;label&#39;] bert_token_classifier_ner_jsl: This model is BERT-based version of ner_jsl model. This new model is better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Metrics: precision recall f1-score support Admission_Discharge 0.84 0.97 0.90 415 Age 0.96 0.96 0.96 2434 Alcohol 0.75 0.83 0.79 145 Allergen 0.33 0.16 0.22 25 BMI 1.00 0.77 0.87 26 Birth_Entity 1.00 0.17 0.29 12 Blood_Pressure 0.86 0.88 0.87 597 Cerebrovascular_Disease 0.74 0.77 0.75 266 Clinical_Dept 0.90 0.92 0.91 2385 Communicable_Disease 0.70 0.59 0.64 85 Date 0.95 0.98 0.96 1438 Death_Entity 0.83 0.83 0.83 59 Diabetes 0.95 0.95 0.95 350 Diet 0.60 0.49 0.54 229 Direction 0.88 0.90 0.89 6187 Disease_Syndrome_Disorder 0.90 0.89 0.89 13236 Dosage 0.57 0.49 0.53 263 Drug 0.91 0.93 0.92 15926 Duration 0.82 0.85 0.83 1218 EKG_Findings 0.64 0.70 0.67 325 Employment 0.79 0.85 0.82 539 External_body_part_or_region 0.84 0.84 0.84 4805 Family_History_Header 1.00 1.00 1.00 889 Fetus_NewBorn 0.57 0.56 0.56 341 Form 0.53 0.43 0.48 81 Frequency 0.87 0.90 0.88 1718 Gender 0.98 0.98 0.98 5666 HDL 0.60 1.00 0.75 6 Heart_Disease 0.88 0.88 0.88 2295 Height 0.89 0.96 0.92 134 Hyperlipidemia 1.00 0.95 0.97 194 Hypertension 0.95 0.98 0.97 566 ImagingFindings 0.66 0.64 0.65 601 Imaging_Technique 0.62 0.67 0.64 108 Injury_or_Poisoning 0.85 0.83 0.84 1680 Internal_organ_or_component 0.90 0.91 0.90 21318 Kidney_Disease 0.89 0.89 0.89 446 LDL 0.88 0.97 0.92 37 Labour_Delivery 0.82 0.71 0.76 306 Medical_Device 0.89 0.93 0.91 12852 Medical_History_Header 0.96 0.97 0.96 1013 Modifier 0.68 0.60 0.64 1398 O2_Saturation 0.84 0.82 0.83 199 Obesity 0.96 0.98 0.97 130 Oncological 0.88 0.96 0.92 1635 Overweight 0.80 0.80 0.80 10 Oxygen_Therapy 0.91 0.92 0.92 231 Pregnancy 0.81 0.83 0.82 439 Procedure 0.91 0.91 0.91 14410 Psychological_Condition 0.81 0.81 0.81 354 Pulse 0.85 0.95 0.89 389 Race_Ethnicity 1.00 1.00 1.00 163 Relationship_Status 0.93 0.91 0.92 57 RelativeDate 0.83 0.86 0.84 1562 RelativeTime 0.74 0.79 0.77 431 Respiration 0.99 0.95 0.97 221 Route 0.68 0.69 0.69 597 Section_Header 0.97 0.98 0.98 28580 Sexually_Active_or_Sexual_Orientation 1.00 0.64 0.78 14 Smoking 0.83 0.90 0.86 225 Social_History_Header 0.95 0.99 0.97 825 Strength 0.71 0.55 0.62 227 Substance 0.85 0.81 0.83 193 Substance_Quantity 0.00 0.00 0.00 28 Symptom 0.84 0.86 0.85 23092 Temperature 0.94 0.97 0.96 410 Test 0.84 0.88 0.86 9050 Test_Result 0.84 0.84 0.84 2766 Time 0.90 0.81 0.86 140 Total_Cholesterol 0.69 0.95 0.80 73 Treatment 0.73 0.72 0.73 506 Triglycerides 0.83 0.80 0.81 30 VS_Finding 0.76 0.77 0.76 588 Vaccine 0.70 0.84 0.76 92 Vital_Signs_Header 0.95 0.98 0.97 2223 Weight 0.88 0.89 0.88 306 O 0.97 0.96 0.97 253164 accuracy 0.94 445974 macro avg 0.82 0.82 0.81 445974 weighted avg 0.94 0.94 0.94 445974 Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter ]) p_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) text = &#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .&#39; res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)).collect() res[0][&#39;label&#39;] HCC module added support for versions v22 and v23 Now we can use the version 22 and the version 23 for the new HCC module to calculate CMS-HCC Risk Adjustment score. Added the following parameters elig, orec and medicaid on the profiles functions. These parameters may not be stored in clinical notes, and may require to be imported from other sources. elig : The eligibility segment of the patient. Allowed values are as follows: - &quot;CFA&quot;: Community Full Benefit Dual Aged - &quot;CFD&quot;: Community Full Benefit Dual Disabled - &quot;CNA&quot;: Community NonDual Aged - &quot;CND&quot;: Community NonDual Disabled - &quot;CPA&quot;: Community Partial Benefit Dual Aged - &quot;CPD&quot;: Community Partial Benefit Dual Disabled - &quot;INS&quot;: Long Term Institutional - &quot;NE&quot;: New Enrollee - &quot;SNPNE&quot;: SNP NE orec: Original reason for entitlement code. - &quot;0&quot;: Old age and survivor&#39;s insurance - &quot;1&quot;: Disability insurance benefits - &quot;2&quot;: End-stage renal disease - &quot;3&quot;: Both DIB and ESRD medicaid: If the patient is in Medicaid or not. Required parameters should be stored in Spark dataframe. df.show(truncate=False) +++++--+-+--+ |hcc_profileV24 |icd10_code |age|gender|eligibility|orec|medicaid| +++++--+-+--+ |{&quot;hcc_lst&quot;:[...|[E1169, I5030, I509, E852] |64 |F |CFA |0 |true | |{&quot;hcc_lst&quot;:[...|[G629, D469, D6181] |77 |M |CND |1 |false | |{&quot;hcc_lst&quot;:[...|[D473, D473, D473, M069, C969]|16 |F |CPA |3 |true | +++++--+-+--+ The content of the hcc_profileV24 column is a JSON-parsable string, like in the following example, { &quot;hcc_lst&quot;: [ &quot;HCC18&quot;, &quot;HCC85_gDiabetesMellit&quot;, &quot;HCC85&quot;, &quot;HCC23&quot;, &quot;D3&quot; ], &quot;details&quot;: { &quot;CNA_HCC18&quot;: 0.302, &quot;CNA_HCC85&quot;: 0.331, &quot;CNA_HCC23&quot;: 0.194, &quot;CNA_D3&quot;: 0.0, &quot;CNA_HCC85_gDiabetesMellit&quot;: 0.0 }, &quot;hcc_map&quot;: { &quot;E1169&quot;: [ &quot;HCC18&quot; ], &quot;I5030&quot;: [ &quot;HCC85&quot; ], &quot;I509&quot;: [ &quot;HCC85&quot; ], &quot;E852&quot;: [ &quot;HCC23&quot; ] }, &quot;risk_score&quot;: 0.827, &quot;parameters&quot;: { &quot;elig&quot;: &quot;CNA&quot;, &quot;age&quot;: 56, &quot;sex&quot;: &quot;F&quot;, &quot;origds&quot;: false, &quot;disabled&quot;: false, &quot;medicaid&quot;: false } } We can import different CMS-HCC model versions as seperate functions and use them in the same program. from sparknlp_jsl.functions import profile,profileV22,profileV23 df = df.withColumn(&quot;hcc_profileV24&quot;, profile(df.icd10_code, df.age, df.gender, df.eligibility, df.orec, df.medicaid )) df.withColumn(&quot;hcc_profileV22&quot;, profileV22(df.codes, df.age, df.sex,df.elig,df.orec,df.medicaid)) df.withColumn(&quot;hcc_profileV23&quot;, profileV23(df.codes, df.age, df.sex,df.elig,df.orec,df.medicaid)) df.show(truncate=False) +-++++--+-+--+ |risk_score|icd10_code |age|gender|eligibility|orec|medicaid| +-++++--+-+--+ |0.922 |[E1169, I5030, I509, E852] |64 |F |CFA |0 |true | |3.566 |[G629, D469, D6181] |77 |M |CND |1 |false | |1.181 |[D473, D473, D473, M069, C969]|16 |F |CPA |3 |true | +-++++--+-+--+ Updated Notebooks for resolvers and graph builders We have updated the resolver notebooks on spark-nlp-workshop repo with new BertSentenceChunkEmbeddings annotator. This annotator lets users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The setChunkWeight parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach. text ner_chunk entity icd10_code all_codes resolutions icd10_code_SCE all_codes_SCE resolutions_SCE Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. a respiratory tract infection PROBLEM J988 [J988, J069, A499, J22, J209,…] [respiratory tract infection, upper respiratory tract infection, bacterial respiratory infection, acute respiratory infection, bronchial infection,…] Z870 [Z870, Z8709, J470, J988, A499,… [history of acute lower respiratory tract infection (situation), history of acute lower respiratory tract infection, bronchiectasis with acute lower respiratory infection, rti - respiratory tract infection, bacterial respiratory infection,… Here are the updated resolver notebooks: 3.Clinical_Entity_Resolvers.ipynb 24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb You can also check for more examples of this annotator: 24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb We have updated TF Graph builder notebook to show how to create TF graphs with TF2.x. Here is the updated notebook: 17.Graph_builder_for_DL_models.ipynb To see more, please check: Spark NLP Healthcare Workshop Repo New TF Graph Builder TF graph builder to create graphs and train DL models for licensed annotators (MedicalNer, Relation Extraction, Assertion and Generic Classifier) is made compatible with TF2.x. To see how to create TF Graphs, you can check here: 17.Graph_builder_for_DL_models.ipynb Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_1"
  },
  "1415": {
    "id": "1415",
    "title": "Spark NLP for Healthcare Release Notes 3.2.2",
    "content": "3.2.2 We are glad to announce that Spark NLP Healthcare 3.2.2 has been released!. Highlights New NER Model For Detecting Drugs, Posology, and Administration Cycles New Sentence Entity Resolver Models New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline Re-Augmented Deidentification NER Model New NER Model For Detecting Drugs, Posology, and Administration Cycles We are releasing a new NER posology model ner_posology_experimental. This model is based on the original ner_posology_large model, but trained with additional clinical trials data to detect experimental drugs, experiment cycles, cycle counts, and cycles numbers. Supported Entities: Administration, Cyclenumber, Strength, Cycleday, Duration, Cyclecount, Route, Form, Frequency, Cyclelength, Drug, Dosage Example: ... word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_posology_experimental&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]) model = nlp_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame([[&quot;Y-90 Humanized Anti-Tac: 10 mCi (if a bone marrow transplant was part of the patient&#39;s previous therapy) or 15 mCi of yttrium labeled anti-TAC; followed by calcium trisodium Inj (Ca DTPA).. n nCalcium-DTPA: Ca-DTPA will be administered intravenously on Days 1-3 to clear the radioactive agent from the body.&quot;]]).toDF(&quot;text&quot;)) Results: | | chunk | begin | end | entity | |:|:-|--:|:|:| | 0 | Y-90 Humanized Anti-Tac | 0 | 22 | Drug | | 1 | 10 mCi | 25 | 30 | Dosage | | 2 | 15 mCi | 108 | 113 | Dosage | | 3 | yttrium labeled anti-TAC | 118 | 141 | Drug | | 4 | calcium trisodium Inj | 156 | 176 | Drug | | 5 | Calcium-DTPA | 191 | 202 | Drug | | 6 | Ca-DTPA | 205 | 211 | Drug | | 7 | intravenously | 234 | 246 | Route | | 8 | Days 1-3 | 251 | 258 | Cycleday | New Sentence Entity Resolver Models We have two new sentence entity resolver models trained with using sbert_jsl_medium_uncased embeddings. sbertresolve_rxnorm_disposition : This model maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using sbert_jsl_medium_uncased Sentence Bert Embeddings. If you look for a faster inference with just drug names (excluding dosage and strength), this version of RxNorm model would be a better alternative. In the result, look for the aux_label parameter in the metadata to get dispositions divided by |. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_rxnorm_disposition&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver]) rxnorm_lp = LightPipeline(rxnorm_pipelineModel) rxnorm_lp = LightPipeline(pipelineModel) result = rxnorm_lp.fullAnnotate(&quot;alizapride 25 mg/ml&quot;) Result: | | chunks | code | resolutions | all_codes | all_k_aux_labels | all_distances | |:|:-|:-|:|:-|:|:--| | 0 |alizapride 25 mg/ml | 330948 | [alizapride 25 mg/ml, alizapride 50 mg, alizapride 25 mg/ml oral solution, adalimumab 50 mg/ml, adalimumab 100 mg/ml [humira], adalimumab 50 mg/ml [humira], alirocumab 150 mg/ml, ...]| [330948, 330949, 249531, 358817, 1726845, 576023, 1659153, ...] | [Dopamine receptor antagonist, Dopamine receptor antagonist, Dopamine receptor antagonist, -, -, -, -, ...] | [0.0000, 0.0936, 0.1166, 0.1525, 0.1584, 0.1567, 0.1631, ...] | sbertresolve_snomed_conditions : This model maps clinical entities (domain: Conditions) to Snomed codes using sbert_jsl_medium_uncased Sentence Bert Embeddings. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbert_jsl_medium_uncased&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_conditions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver ]) snomed_lp = LightPipeline(snomed_pipelineModel) result = snomed_lp.fullAnnotate(&quot;schizophrenia&quot;) Result: | | chunks | code | resolutions | all_codes | all_distances | |:|:--|:|:-|:|:--| | 0 | schizophrenia | 58214004 | [schizophrenia, chronic schizophrenia, borderline schizophrenia, schizophrenia, catatonic, subchronic schizophrenia, ...]| [58214004, 83746006, 274952002, 191542003, 191529003, 16990005, ...] | 0.0000, 0.0774, 0.0838, 0.0927, 0.0970, 0.0970, ...] | New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline Normally, when we need to use more than one sentence entity resolver models in the same pipeline, we used to hit BertSentenceEmbeddings annotator more than once given the number of different resolver models in the same pipeline. Now we are introducing a solution with the help of Router annotator that could allow us to feed all the NER chunks to BertSentenceEmbeddings at once and then route the output of Sentence Embeddings to different resolver models needed. You can find an example of how to use this annotator in the updated 3.Clinical_Entity_Resolvers.ipynb Notebook Example: ... # to get PROBLEM entitis clinical_ner = MedicalNerModel().pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;clinical_ner&quot;) clinical_ner_chunk = NerConverter() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;clinical_ner&quot;) .setOutputCol(&quot;clinical_ner_chunk&quot;) .setWhiteList([&quot;PROBLEM&quot;]) # to get DRUG entities posology_ner = MedicalNerModel().pretrained(&quot;ner_posology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;posology_ner&quot;) posology_ner_chunk = NerConverter() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;posology_ner&quot;) .setOutputCol(&quot;posology_ner_chunk&quot;) .setWhiteList([&quot;DRUG&quot;]) # merge the chunks into a single ner_chunk chunk_merger = ChunkMergeApproach() .setInputCols(&quot;clinical_ner_chunk&quot;,&quot;posology_ner_chunk&quot;) .setOutputCol(&quot;final_ner_chunk&quot;) .setMergeOverlapping(False) # convert chunks to doc to get sentence embeddings of them chunk2doc = Chunk2Doc().setInputCols(&quot;final_ner_chunk&quot;).setOutputCol(&quot;final_chunk_doc&quot;) sbiobert_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;final_chunk_doc&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) # filter PROBLEM entity embeddings router_sentence_icd10 = Router() .setInputCols(&quot;sbert_embeddings&quot;) .setFilterFieldsElements([&quot;PROBLEM&quot;]) .setOutputCol(&quot;problem_embeddings&quot;) # filter DRUG entity embeddings router_sentence_rxnorm = Router() .setInputCols(&quot;sbert_embeddings&quot;) .setFilterFieldsElements([&quot;DRUG&quot;]) .setOutputCol(&quot;drug_embeddings&quot;) # use problem_embeddings only icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_slim_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;problem_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) # use drug_embeddings only rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;drug_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, clinical_ner_chunk, posology_ner, posology_ner_chunk, chunk_merger, chunk2doc, sbiobert_embeddings, router_sentence_icd10, router_sentence_rxnorm, icd_resolver, rxnorm_resolver ]) Re-Augmented Deidentification NER Model We re-augmented ner_deid_subentity_augmented deidentification NER model improving the previous metrics by 2%. Example: ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) results = model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227.&quot;&quot;&quot;]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25-year-old |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street. |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ To see more, please check: Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_2"
  },
  "1416": {
    "id": "1416",
    "title": "Spark NLP for Healthcare Release Notes 3.2.3",
    "content": "3.2.3 We are glad to announce that Spark NLP Healthcare 3.2.3 has been released!. Highlights New BERT-Based Deidentification NER Model New Sentence Entity Resolver Models For German Language New Spell Checker Model For Drugs Allow To Use Disambiguator Pretrained Model Allow To Use Seeds in StructuredDeidentification Added Compatibility with Tensorflow 1.15 For Graph Generation. New Setup Videos New BERT-Based Deidentification NER Model We have a new bert_token_classifier_ner_deid model that is BERT-based version of ner_deid_subentity_augmented and annotates text to find protected health information that may need to be de-identified. It can detect 23 different entities (MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE). Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_deid&quot;, &quot;en&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) text = &quot;&quot;&quot;A. Record date : 2093-01-13, David Hale, M.D. Name : Hendrickson, Ora MR. # 7194334. PCP : Oliveira, non-smoking. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient&#39;s complaints first surfaced when he started working for Brothers Coal-Mine.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [text]}))) Results: +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |Oliveira |PATIENT | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street |STREET | |302) 786-5227 |PHONE | |Brothers Coal-Mine |ORGANIZATION | +--+-+ New Sentence Entity Resolver Models For German Language We are releasing two new Sentence Entity Resolver Models for German language that use sent_bert_base_cased (de) embeddings. sbertresolve_icd10gm : This model maps extracted medical entities to ICD10-GM codes for the German language. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;de&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) icd10gm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_icd10gm&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;icd10gm_code&quot;) icd10gm_pipelineModel = PipelineModel( stages = [documentAssembler, sbert_embedder, icd10gm_resolver]) icd_lp = LightPipeline(icd10gm_pipelineModel) icd_lp.fullAnnotate(&quot;Dyspnoe&quot;) Results : chunk code resolutions all_codes all_distances Dyspnoe C671 Dyspnoe, Schlafapnoe, Dysphonie, Frühsyphilis, Hyperzementose, Hypertrichose, … [R06.0, G47.3, R49.0, A51, K03.4, L68, …] [0.0000, 2.5602, 3.0529, 3.3310, 3.4645, 3.7148, …] sbertresolve_snomed : This model maps extracted medical entities to SNOMED codes for the German language. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;de&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) snomed_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver]) snomed_lp = LightPipeline(snomed_pipelineModel) snomed_lp.fullAnnotate(&quot;Bronchialkarzinom &quot;) Results : chunk code resolutions all_codes all_distances Bronchialkarzinom 22628 Bronchialkarzinom, Bronchuskarzinom, Rektumkarzinom, Klavikulakarzinom, Lippenkarzinom, Urothelkarzinom, … [22628, 111139, 18116, 107569, 18830, 22909, …] [0.0000, 0.0073, 0.0090, 0.0098, 0.0098, 0.0102, …] New Spell Checker Model For Drugs We are releasing new spellcheck_drug_norvig model that detects and corrects spelling errors of drugs in a text based on the Norvig’s approach. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) spell = NorvigSweetingModel.pretrained(&quot;spellcheck_drug_norvig&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;spell&quot;) pipeline = Pipeline( stages = [documentAssembler, tokenizer, spell]) model = pipeline.fit(spark.createDataFrame([[&#39;&#39;]]).toDF(&#39;text&#39;)) lp = LightPipeline(model) lp.annotate(&quot;You have to take Neutrcare and colfosrinum and a bit of Fluorometholne &amp; Ribotril&quot;) Results : Original text : You have to take Neutrcare and colfosrinum and a bit of fluorometholne &amp; Ribotril Corrected text : You have to take Neutracare and colforsinum and a bit of fluorometholone &amp; Rivotril Allow to use Disambiguator pretrained model. Now we can use the NerDisambiguatorModel as a pretrained model to disambiguate person entities. text = &quot;The show also had a contestant named Brad Pitt&quot; + &quot;who later defeated Christina Aguilera on the way to become Female Vocalist Champion in the 1989 edition of Star Search in the United States. &quot; data = SparkContextForTest.spark.createDataFrame([ [text]]) .toDF(&quot;text&quot;).cache() da = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) sd = SentenceDetector().setInputCols(&quot;document&quot;).setOutputCol(&quot;sentence&quot;) tk = Tokenizer().setInputCols(&quot;sentence&quot;).setOutputCol(&quot;token&quot;) emb = WordEmbeddingsModel.pretrained().setOutputCol(&quot;embs&quot;) semb = SentenceEmbeddings().setInputCols(&quot;sentence&quot;, &quot;embs&quot;).setOutputCol(&quot;sentence_embeddings&quot;) ner = NerDLModel.pretrained().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;embs&quot;).setOutputCol(&quot;ner&quot;) nc = NerConverter().setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;).setOutputCol(&quot;ner_chunk&quot;).setWhiteList([&quot;PER&quot;]) NerDisambiguatorModel.pretrained().setInputCols(&quot;ner_chunk&quot;, &quot;sentence_embeddings&quot;).setOutputCol(&quot;disambiguation&quot;) pl = Pipeline().setStages([da, sd, tk, emb, semb, ner, nc, disambiguator]) data = pl.fit(data).transform(data) data.select(&quot;disambiguation&quot;).show(10, False) +-+ |disambiguation | +-+ |[[disambiguation, 65, 82, http://en.wikipedia.org/?curid=144171, http://en.wikipedia.org/?curid=6636454, [chunk -&gt; Christina Aguilera, titles -&gt; christina aguilera ::::: christina aguilar, links -&gt; http://en.wikipedia.org/?curid=144171 ::::: http://en.wikipedia.org/?curid=6636454, beginInText -&gt; 65, scores -&gt; 0.9764155197864447, 0.9727793647472524, categories -&gt; Musicians, Singers, Actors, Businesspeople, Musicians, Singers, ids -&gt; 144171, 6636454, endInText -&gt; 82], []]]| +-+ - Allow to use seeds in StructuredDeidentification Now, we can use a seed for a specific column. The seed is used to randomly select the entities used during obfuscation mode. By providing the same seed, you can replicate the same mapping multiple times. df = spark.createDataFrame([ [&quot;12&quot;, &quot;12&quot;, &quot;Juan García&quot;], [&quot;24&quot;, &quot;56&quot;, &quot;Will Smith&quot;], [&quot;56&quot;, &quot;32&quot;, &quot;Pedro Ximénez&quot;] ]).toDF(&quot;ID1&quot;, &quot;ID2&quot;, &quot;NAME&quot;) obfuscator = StructuredDeidentification(spark=spark, columns={&quot;ID1&quot;: &quot;ID&quot;, &quot;ID2&quot;: &quot;ID&quot;, &quot;NAME&quot;: &quot;PATIENT&quot;}, columnsSeed={&quot;ID1&quot;: 23, &quot;ID2&quot;: 23}, obfuscateRefSource=&quot;faker&quot;) result = obfuscator.obfuscateColumns(df) result.show(truncate=False) +-+-+-+ |ID1 |ID2 |NAME | +-+-+-+ |[D3379888]|[D3379888]|[Raina Cleaves] | |[R8448971]|[M8851891]|[Jennell Barre] | |[M8851891]|[L5448098]|[Norene Salines]| +-+-+-+ Here, you can see that as we have provided the same seed `23` for columns `ID1`, and `ID2`, the number `12` which is appears twice in the first row is mapped to the same randomly generated id `D3379888` each time. Added compatibility with Tensorflow 1.15 for graph generation Some users reported problems while using graphs generated by Tensorflow 2.x. We provide compatibility with Tensorflow 1.15 in the tf_graph_1x module, that can be used like this, from sparknlp_jsl.training import tf_graph_1x In next releases, we will provide full support for graph generation using Tensorflow 2.x. New Setup Videos Now we have videos showing how to setup Spark NLP, Spark NLP for Healthcare and Spark OCR on UBUNTU. How to Setup Spark NLP on UBUNTU How to Setup Spark NLP for HEALTHCARE on UBUNTU How to Setup Spark OCR on UBUNTU To see more, please check: Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_2_3"
  },
  "1417": {
    "id": "1417",
    "title": "Spark NLP release notes 3.3.0",
    "content": "3.3.0 Release date: 14-06-2021 Overview Table detection and recognition for scanned documents. For table detection we added ImageTableDetector. It’s based on CascadeTabNet which used Cascade mask Region-based CNN High-Resolution Network (Cascade mask R-CNN HRNet). The model was pre-trained on the COCO dataset and fine-tuned on ICDAR 2019 competitions dataset for table detection. It demonstrates state of the art results for ICDAR 2013 and TableBank. And top results for ICDAR 2019. More details please read in Table Detection &amp; Extraction in Spark OCR New Features ImageTableDetector is a DL model for detect tables on the image. ImageTableCellDetector is a transformer for detect regions of cells in the table image. ImageCellsToTextTable is a transformer for extract text from the detected cells. New notebooks Image Table Detection example Image Cell Recognition example Image Table Recognition Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_3_0"
  },
  "1418": {
    "id": "1418",
    "title": "Spark NLP for Healthcare Release Notes 3.3.0",
    "content": "3.3.0 We are glad to announce that Spark NLP Healthcare 3.3.0 has been released!. Highlights NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) Updated UMLS Entity Resolvers (Dropping Invalid Codes) 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) Radiology NER Model Trained On cheXpert Dataset New Speed Benchmarks on Databricks NerConverterInternal Fixes Simplified Setup and Recommended Use of start() Function NER Evaluation Metrics Fix New Notebooks (Including How to Use SparkNLP with Neo4J) NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text We are releasing two new NER Pretrained Pipelines that can be used to explore all the available pretrained NER models at once. You can check NER Profiling Notebook to see how to use these pretrained pipelines. ner_profiling_clinical : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 48 pretrained clinical NER models trained with embeddings_clinical. Clinical NER Model List ner_ade_clinical ner_posology_greedy ner_risk_factors jsl_ner_wip_clinical ner_human_phenotype_gene_clinical jsl_ner_wip_greedy_clinical ner_cellular ner_cancer_genetics jsl_ner_wip_modifier_clinical ner_drugs_greedy ner_deid_sd_large ner_diseases nerdl_tumour_demo ner_deid_subentity_augmented ner_jsl_enriched ner_genetic_variants ner_bionlp ner_measurements_clinical ner_diseases_large ner_radiology ner_deid_augmented ner_anatomy ner_chemprot_clinical ner_posology_experimental ner_drugs ner_deid_sd ner_posology_large ner_deid_large ner_posology ner_deidentify_dl ner_deid_enriched ner_bacterial_species ner_drugs_large ner_clinical_large jsl_rd_ner_wip_greedy_clinical ner_medmentions_coarse ner_radiology_wip_clinical ner_clinical ner_chemicals ner_deid_synthetic ner_events_clinical ner_posology_small ner_anatomy_coarse ner_human_phenotype_go_clinical ner_jsl_slim ner_jsl ner_jsl_greedy ner_events_admission_clinical ner_profiling_biobert : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 21 pretrained clinical NER models trained with biobert_pubmed_base_cased. BioBert NER Model List ner_cellular_biobert ner_diseases_biobert ner_events_biobert ner_bionlp_biobert ner_jsl_greedy_biobert ner_jsl_biobert ner_anatomy_biobert ner_jsl_enriched_biobert ner_human_phenotype_go_biobert ner_deid_biobert ner_deid_enriched_biobert ner_clinical_biobert ner_anatomy_coarse_biobert ner_human_phenotype_gene_biobert ner_posology_large_biobert jsl_rd_ner_wip_greedy_biobert ner_posology_biobert jsl_ner_wip_greedy_biobert ner_chemprot_biobert ner_ade_biobert ner_risk_factors_biobert You can also check Models Hub page for more information about all these NER models and more. Example : from sparknlp.pretrained import PretrainedPipeline ner_profiling_pipeline = PretrainedPipeline(&#39;ner_profiling_biobert&#39;, &#39;en&#39;, &#39;clinical/models&#39;) result = ner_profiling_pipeline.annotate(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&quot;) Results : sentence : [&#39;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .&#39;] token : [&#39;A&#39;, &#39;28-year-old&#39;, &#39;female&#39;, &#39;with&#39;, &#39;a&#39;, &#39;history&#39;, &#39;of&#39;, &#39;gestational&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;diagnosed&#39;, &#39;eight&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;and&#39;, &#39;subsequent&#39;, &#39;type&#39;, &#39;two&#39;, &#39;diabetes&#39;, &#39;mellitus&#39;, &#39;(&#39;, &#39;T2DM&#39;, &#39;),&#39;, &#39;one&#39;, &#39;prior&#39;, &#39;episode&#39;, &#39;of&#39;, &#39;HTG-induced&#39;, &#39;pancreatitis&#39;, &#39;three&#39;, &#39;years&#39;, &#39;prior&#39;, &#39;to&#39;, &#39;presentation&#39;, &#39;,&#39;, &#39;associated&#39;, &#39;with&#39;, &#39;an&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;,&#39;, &#39;and&#39;, &#39;obesity&#39;, &#39;with&#39;, &#39;a&#39;, &#39;body&#39;, &#39;mass&#39;, &#39;index&#39;, &#39;(&#39;, &#39;BMI&#39;, &#39;)&#39;, &#39;of&#39;, &#39;33.5&#39;, &#39;kg/m2&#39;, &#39;,&#39;, &#39;presented&#39;, &#39;with&#39;, &#39;a&#39;, &#39;one-week&#39;, &#39;history&#39;, &#39;of&#39;, &#39;polyuria&#39;, &#39;,&#39;, &#39;polydipsia&#39;, &#39;,&#39;, &#39;poor&#39;, &#39;appetite&#39;, &#39;,&#39;, &#39;and&#39;, &#39;vomiting&#39;, &#39;.&#39;] ner_cellular_biobert_chunks : [] ner_diseases_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_events_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;eight years&#39;, &#39;presentation&#39;, &#39;type two diabetes mellitus ( T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years&#39;, &#39;presentation&#39;, &#39;an acute hepatitis&#39;, &#39;obesity&#39;, &#39;a body mass index&#39;, &#39;BMI&#39;, &#39;presented&#39;, &#39;a one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_bionlp_biobert_chunks : [] ner_jsl_greedy_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_jsl_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_anatomy_biobert_chunks : [&#39;body&#39;] ner_jsl_enriched_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;acute&#39;, &#39;hepatitis&#39;, &#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_human_phenotype_go_biobert_chunks : [&#39;obesity&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;] ner_deid_biobert_chunks : [&#39;eight years&#39;, &#39;three years&#39;] ner_deid_enriched_biobert_chunks : [] ner_clinical_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;subsequent type two diabetes mellitus ( T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;an acute hepatitis&#39;, &#39;obesity&#39;, &#39;a body mass index ( BMI )&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_anatomy_coarse_biobert_chunks : [&#39;body&#39;] ner_human_phenotype_gene_biobert_chunks : [&#39;obesity&#39;, &#39;mass&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;vomiting&#39;] ner_posology_large_biobert_chunks : [] jsl_rd_ner_wip_greedy_biobert_chunks : [&#39;gestational diabetes mellitus&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;33.5&#39;, &#39;kg/m2&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_posology_biobert_chunks : [] jsl_ner_wip_greedy_biobert_chunks : [&#39;28-year-old&#39;, &#39;female&#39;, &#39;gestational diabetes mellitus&#39;, &#39;eight years prior&#39;, &#39;type two diabetes mellitus&#39;, &#39;T2DM&#39;, &#39;HTG-induced pancreatitis&#39;, &#39;three years prior&#39;, &#39;acute hepatitis&#39;, &#39;obesity&#39;, &#39;body mass index&#39;, &#39;BMI ) of 33.5 kg/m2&#39;, &#39;one-week&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_chemprot_biobert_chunks : [] ner_ade_biobert_chunks : [&#39;pancreatitis&#39;, &#39;acute hepatitis&#39;, &#39;polyuria&#39;, &#39;polydipsia&#39;, &#39;poor appetite&#39;, &#39;vomiting&#39;] ner_risk_factors_biobert_chunks : [&#39;diabetes mellitus&#39;, &#39;subsequent type two diabetes mellitus&#39;, &#39;obesity&#39;] 3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS) sbiobertresolve_hcpcs : This model maps extracted medical entities to Healthcare Common Procedure Coding System (HCPCS) codes using sbiobert_base_cased_mli sentence embeddings. It also returns the domain information of the codes in the all_k_aux_labels parameter in the metadata of the result. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) hcpcs_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_hcpcs&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;hcpcs_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) hcpcs_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, hcpcs_resolver]) res = hcpcs_pipelineModel.transform(spark.createDataFrame([[&quot;Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type&quot;]]).toDF(&quot;text&quot;)) Results : ner_chunk hcpcs_code all_codes all_resolutions domain Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type L8001 [L8001, L8002, L8000, L8033, L8032, …] ‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, bilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, without integrated breast prosthesis form, any size, any type’, ‘Nipple prosthesis, custom fabricated, reusable, any material, any type, each’, … Device, Device, Device, Device, Device, … sbiobertresolve_icd10cm_generalised : This model maps medical entities to 3 digit ICD10CM codes (according to ICD10 code structure the first three characters represent general type of the injury or disease). Difference in results (compared with sbiobertresolve_icd10cm) can be observed in the example below. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_generalised&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) icd_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, icd_resolver]) res = icd_pipelineModel.transform(spark.createDataFrame([[&quot;82 - year-old male with a history of hypertension , chronic renal insufficiency , COPD , and gastritis&quot;]]).toDF(&quot;text&quot;)) Results : | | chunk | entity | code_3char | code_desc_3char | code_full | code_full_description | distance | all_k_resolutions_3char | all_k_codes_3char | |:|:-|:--|:--|:-|:-|:|-:|:|:--| | 0 | hypertension | SYMPTOM | I10 | hypertension | I150 | Renovascular hypertension | 0 | [hypertension, hypertension (high blood pressure), h/o: hypertension, ...] | [I10, I15, Z86, Z82, I11, R03, Z87, E27] | | 1 | chronic renal insufficiency | SYMPTOM | N18 | chronic renal impairment | N186 | End stage renal disease | 0.014 | [chronic renal impairment, renal insufficiency, renal failure, anaemi ...] | [N18, P96, N19, D63, N28, Z87, N17, N25, R94] | | 2 | COPD | SYMPTOM | J44 | chronic obstructive lung disease (disorder) | I2781 | Cor pulmonale (chronic) | 0.1197 | [chronic obstructive lung disease (disorder), chronic obstructive pul ...] | [J44, Z76, J81, J96, R06, I27, Z87] | | 3 | gastritis | SYMPTOM | K29 | gastritis | K5281 | Eosinophilic gastritis or gastroenteritis | 0 | gastritis:::bacterial gastritis:::parasitic gastritis | [K29, B96, K93] | sbiobertresolve_rxnorm_ndc : This model maps DRUG entities to rxnorm codes and their National Drug Codes (NDC) using sbiobert_base_cased_mli sentence embeddings. You can find all NDC codes of drugs seperated by | in the all_k_aux_labels parameter of the metadata. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) rxnorm_ndc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_ndc&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_ndc_pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_ndc_resolver]) res = rxnorm_ndc_pipelineModel.transform(spark.createDataFrame([[&quot;activated charcoal 30000 mg powder for oral suspension&quot;]]).toDF(&quot;text&quot;)) Results : chunk rxnorm_code all_codes resolutions all_k_aux_labels all_distances activated charcoal 30000 mg powder for oral suspension 1440919 1440919, 808917, 1088194, 1191772, 808921,… activated charcoal 30000 MG Powder for Oral Suspension, Activated Charcoal 30000 MG Powder for Oral Suspension, wheat dextrin 3000 MG Powder for Oral Solution [Benefiber], cellulose 3000 MG Oral Powder [Unifiber], fosfomycin 3000 MG Powder for Oral Solution [Monurol] … 69784030828, 00395052791, 08679001362|86790016280|00067004490, 46017004408|68220004416, 00456430001,… 0.0000, 0.0000, 0.1128, 0.1148, 0.1201,… Updated UMLS Entity Resolvers (Dropping Invalid Codes) UMLS model sbiobertresolve_umls_findings and sbiobertresolve_umls_major_concepts were updated by dropping the invalid codes using the latest UMLS release done May 2021. 5 New Clinical NER Models (Trained By BertForTokenClassification Approach) We are releasing four new BERT-based NER models. bert_token_classifier_ner_ade : This model is BERT-Based version of ner_ade_clinical model and performs 5% better. It can detect drugs and adverse reactions of drugs in reviews, tweets, and medical texts using DRUG and ADE labels. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_ade&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;Been taking Lipitor for 15 years , have experienced severe fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |Lipitor |DRUG | |severe fatigue|ADE | |voltaren |DRUG | |cramps |ADE | +--++ bert_token_classifier_ner_jsl_slim : This model is BERT-Based version of ner_jsl_slim model and 2% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. It can detect Death_Entity, Medical_Device, Vital_Sign, Alergen, Drug, Clinical_Dept, Lifestyle, Symptom, Body_Part, Physical_Measurement, Admission_Discharge, Date_Time, Age, Birth_Entity, Header, Oncological, Substance_Quantity, Test_Result, Test, Procedure, Treatment, Disease_Syndrome_Disorder, Pregnancy_Newborn, Demographics entities. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentence_detector, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-++ |chunk |ner_label | +-++ |HISTORY: |Header | |30-year-old |Age | |female |Demographics| |mammography |Test | |soft tissue lump|Symptom | |shoulder |Body_Part | |breast cancer |Oncological | |her mother |Demographics| |age 58 |Age | |breast cancer |Oncological | +-++ bert_token_classifier_ner_drugs : This model is BERT-based version of ner_drugs model and detects drug chemicals. This new model is 3% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_drugs&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]) model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family. Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population. The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons separated byapproximately 2.2 and approximately 2.6 kb introns, respectively. We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair (bp) insertion/deletion. Ourexpression studies revealed the presence of the transcript in various humantissues including pancreas, and two major insulin-responsive tissues: fat andskeletal muscle. The characterization of the KCNJ9 gene should facilitate furtherstudies on the function of the KCNJ9 protein and allow evaluation of thepotential role of the locus in Type II diabetes.BACKGROUND: At present, it is one of the most important issues for the treatment of breast cancer to develop the standard therapy for patients previously treated with anthracyclines and taxanes. With the objective of determining the usefulnessof vinorelbine monotherapy in patients with advanced or recurrent breast cancerafter standard therapy, we evaluated the efficacy and safety of vinorelbine inpatients previously treated with anthracyclines and taxanes.&quot;&quot;&quot; result = model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |potassium |DrugChem | |nucleotide |DrugChem | |anthracyclines|DrugChem | |taxanes |DrugChem | |vinorelbine |DrugChem | |vinorelbine |DrugChem | |anthracyclines|DrugChem | |taxanes |DrugChem | +--++ bert_token_classifier_ner_anatomy : This model is BERT-Based version of ner_anatomy model and 3% better. It can detect Anatomical_system, Cell, Cellular_component, Developing_anatomical_structure, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism_subdivision, Organism_substance, Pathological_formation, Tissue entities. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_anatomy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]) pp_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;This is an 11-year-old female who comes in for two different things. 1. She was seen by the allergist. No allergies present, so she stopped her Allegra, but she is still real congested and does a lot of snorting. They do not notice a lot of snoring at night though, but she seems to be always like that. 2. On her right great toe, she has got some redness and erythema. Her skin is kind of peeling a little bit, but it has been like that for about a week and a half now. nGeneral: Well-developed female, in no acute distress, afebrile. nHEENT: Sclerae and conjunctivae clear. Extraocular muscles intact. TMs clear. Nares patent. A little bit of swelling of the turbinates on the left. Oropharynx is essentially clear. Mucous membranes are moist. nNeck: No lymphadenopathy. nChest: Clear. nAbdomen: Positive bowel sounds and soft. nDermatologic: She has got redness along her right great toe, but no bleeding or oozing. Some dryness of her skin. Her toenails themselves are very short and even on her left foot and her left great toe the toenails are very short.&quot;&quot;&quot; result = pp_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+ |chunk |ner_label | +-+-+ |great toe |Multi-tissue_structure| |skin |Organ | |conjunctivae |Multi-tissue_structure| |Extraocular muscles|Multi-tissue_structure| |Nares |Multi-tissue_structure| |turbinates |Multi-tissue_structure| |Oropharynx |Multi-tissue_structure| |Mucous membranes |Tissue | |Neck |Organism_subdivision | |bowel |Organ | |great toe |Multi-tissue_structure| |skin |Organ | |toenails |Organism_subdivision | |foot |Organism_subdivision | |great toe |Multi-tissue_structure| |toenails |Organism_subdivision | +-+-+ bert_token_classifier_ner_bacteria : This model is BERT-Based version of ner_bacterial_species model and detects different types of species of bacteria in clinical texts using SPECIES label. Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_bacteria&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ner_converter = NerConverter() .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[documentAssembler, tokenizer, tokenClassifier, ner_converter]) p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [&#39;&#39;]}))) test_sentence = &quot;&quot;&quot;Based on these genetic and phenotypic properties, we propose that strain SMSP (T) represents a novel species of the genus Methanoregula, for which we propose the name Methanoregula formicica sp. nov., with the type strain SMSP (T) (= NBRC 105244 (T) = DSM 22288 (T)).&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +--++ |chunk |ner_label| +--++ |SMSP (T) |SPECIES | |Methanoregula formicica|SPECIES | |SMSP (T) |SPECIES | +--++ Radiology NER Model Trained On cheXpert Dataset Ner NER model ner_chexpert trained on Radiology Chest reports to extract anatomical sites and observation entities. The model achieves 92.8% and 77.4% micro and macro f1 scores on the cheXpert dataset. Example : ... embeddings_clinical = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_chexpert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]) model = nlpPipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)) EXAMPLE_TEXT = &quot;&quot;&quot;FINAL REPORT HISTORY : Chest tube leak , to assess for pneumothorax . FINDINGS : In comparison with study of ___ , the endotracheal tube and Swan - Ganz catheter have been removed . The left chest tube remains in place and there is no evidence of pneumothorax. Mild atelectatic changes are seen at the left base.&quot;&quot;&quot; results = model.transform(spark.createDataFrame([[EXAMPLE_TEXT]]).toDF(&quot;text&quot;)) Results : | | chunk | label | |:|:-|:--| | 0 | endotracheal tube | OBS | | 1 | Swan - Ganz catheter | OBS | | 2 | left chest | ANAT | | 3 | tube | OBS | | 4 | in place | OBS | | 5 | pneumothorax | OBS | | 6 | Mild atelectatic changes | OBS | | 7 | left base | ANAT | New Speed Benchmarks on Databricks We prepared a speed benchmark table by running a NER pipeline on various number of cluster configurations (worker number, driver node, specs etc) and also writing the results to parquet or delta formats. You can find all the details of these tries in here : Speed Benchmark Table NerConverterInternal Fixes Now NerConverterInternal can deal with tags that have some dash (-) charachter like B-GENE-N and B-GENE-Y. Simplified Setup and Recommended Use of start() Function Starting with this release, we are shipping AWS credentials inside Spark NLP Healthcare’s license. This removes the requirement of setting the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. To use this feature, you just need to make sure that you always call the start() function at the beginning of your program, from sparknlp_jsl import start spark = start() import com.johnsnowlabs.util.start val spark = start() If for some reason you don’t want to use this mechanism, the keys will continue to be shipped separately, and the environment variables will continue to work as they did in the past. Ner Evaluation Metrics Fix Bug fixed in the NerDLMetrics package. Previously, the full_chunk option was using greedy approach to merge chunks for a strict evaluation, which has been fixed to merge chunks using IOB scheme to get accurate entities boundaries and metrics. Also, the tag option has been fixed to get metrics that align with the default NER logs. New Notebooks Clinical Relation Extraction Knowledge Graph with Neo4j Notebook NER Profiling Pretrained Pipelines Notebook New Databricks Detecting Adverse Drug Events From Conversational Texts case study notebook. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_0"
  },
  "1419": {
    "id": "1419",
    "title": "Annotation Lab Release Notes 3.3.0",
    "content": "3.3.0 Release date: 21-06-2022 We are very excited to announce the release of Annotation Lab v3.3.0 which includes a highly requested new feature for displaying the confidence scores for NER preannotations as well as the ability to filter preannotations by confidence. Also, benchmarking data can now be checked for some of the models on the Models Hub page. This version also includes IAA charts for Visual NER Projects, upgrades of the Spark NLP libraries and fixes for some of the identified Common Vulnerabilities and Exposures (CVEs). Below are more details on the release content. Highlights Confidence Scores for Preannotations, When running preannotations on a Text project, one extra piece of information is now present for the automatic annotations - the confidence score. This score is used to show the confidence the model has for each of the labeled chunks. It is calculated based on the benchmarking information of the model used to preannotate and on the score of each prediction. The confidence score is available when working on Named Entity Recognition, Relation, Assertion, and Classification projects and is also generated when using NER Rules. On the Labeling screen, when selecting the Prediction widget, users can see that all preannotation in the Results section now have a score assigned to them. IAA charts are now available for Visual NER Projects, IAA (Inter-Annotator Agreement) charts were available only for text-based projects. With this release, Annotation Lab supports IAA charts for Visual NER project as well. Auto-save completions, the work of annotators is automatically saved behind the scenes. This way, the user does not risk losing his/her work in case of unforeseen events and does not have to frequently hit the Save/Update button. Improvement of UX for Active Learning, information about the previously triggered Active learning is displayed along with the number of completions required for the next training. Also when the conditions that trigger active learning for a project using a healthcare model are met and all available licenses are in use, an error message appears on the Training and Active Learning page informing the user to make room for the new training server Support for BertForSequenceClassification and MedicalBertForSequenceClassification models, From this version on, support was added for BertForTokenClassification, MedicalBertForTokenClassifier, BertForSequenceClassification and MedicalBertForSequenceClassification. Upgraded Spark NLP and Spark NLP for Health Care v3.5.3 and Spark OCR v3.13.0. With this we have also updated the list of supported models into the Models Hub page. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_0"
  },
  "1420": {
    "id": "1420",
    "title": "Spark NLP for Healthcare Release Notes 3.3.1",
    "content": "3.3.1 We are glad to announce that Spark NLP Healthcare 3.3.1 has been released!. Highlights New ChunkKeyPhraseExtraction Annotator New BERT-Based NER Models New UMLS Sentence Entity Resolver Models Updated RxNorm Entity Resolver Model (Dropping Invalid Codes) New showVersion() Method in Compatibility Class New Docker Images for Spark NLP for Healthcare and Spark OCR New and Updated Deidentification() Parameters New Python API Documentation Updated Spark NLP For Healthcare Notebooks and New Notebooks New ChunkKeyPhraseExtraction Annotator We are releasing ChunkKeyPhraseExtraction annotator that leverages Sentence BERT embeddings to select keywords and key phrases that are most similar to a document. This annotator can be fed by either the output of NER model, NGramGenerator or YAKE, and could be used to generate similarity scores for each NER chunk that is coming out of any (clinical) NER model. That is, you can now sort your clinical entities by the importance of them with respect to document or sentence that they live in. Additionally, you can also use this new annotator to grab new clinical chunks that are missed by a pretrained NER model as well as summarizing the whole document into a few important sentences or phrases. You can find more examples in ChunkKeyPhraseExtraction notebook Example : ... ngram_ner_key_phrase_extractor = ChunkKeyPhraseExtraction.pretrained(&quot;sbert_jsl_medium_uncased &quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setTopN(5) .setDivergence(0.4) .setInputCols([&quot;sentences&quot;, &quot;merged_chunks&quot;]) .setOutputCol(&quot;key_phrases&quot;) ... text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly, her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were: serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27. Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia .&quot; textDF = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) ngram_ner_results = ngram_ner_pipeline.transform(textDF) Results : +--++-+-+--+ |key_phrase |source|DocumentSimilarity |MMRScore |sentence| +--++-+-+--+ |type two diabetes mellitus|NER |0.7639750686118073 |0.4583850593816694 |0 | |HTG-induced pancreatitis |ngrams|0.66933222897749 |0.10416352343367463|0 | |vomiting |ngrams|0.5824238088130589 |0.14864183399720493|0 | |history polyuria |ngrams|0.46337313737310987|0.0959500325843913 |0 | |28-year-old female |ngrams|0.31692529374916967|0.10043002919664669|0 | +--++-+-+--+ New BERT-Based NER Models We have two new BERT-Based token classifier NER models. bert_token_classifier_ner_chemicals : This model is BERT-based version of ner_chemicals model and can detect chemical compounds (CHEM) in the medical texts. Metrics : precision recall f1-score support B-CHEM 0.94 0.92 0.93 30731 I-CHEM 0.95 0.93 0.94 31270 accuracy 0.99 62001 macro avg 0.96 0.95 0.96 62001 weighted avg 0.99 0.93 0.96 62001 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_chemicals&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;The results have shown that the product p - choloroaniline is not a significant factor in chlorhexidine - digluconate associated erosive cystitis. A high percentage of kanamycin - colistin and povidone - iodine irrigations were associated with erosive cystitis.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame([[test_sentence]]).toDF(&quot;text&quot;)) Results : +++ |chunk |ner_label| +++ |p - choloroaniline |CHEM | |chlorhexidine - digluconate|CHEM | |kanamycin |CHEM | |colistin |CHEM | |povidone - iodine |CHEM | +++ bert_token_classifier_ner_chemprot : This model is BERT-based version of ner_chemprot_clinical model and can detect chemical compounds and genes (CHEMICAL, GENE-Y, GENE-N) in the medical texts. Metrics : precision recall f1-score support B-CHEMICAL 0.80 0.79 0.80 8649 B-GENE-N 0.53 0.56 0.54 2752 B-GENE-Y 0.71 0.73 0.72 5490 I-CHEMICAL 0.82 0.79 0.81 1313 I-GENE-N 0.62 0.62 0.62 1993 I-GENE-Y 0.75 0.72 0.74 2420 accuracy 0.96 22617 macro avg 0.75 0.74 0.75 22617 weighted avg 0.83 0.73 0.78 22617 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_chemprot&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;Keratinocyte growth factor and acidic fibroblast growth factor are mitogens for primary cultures of mammary epithelium.&quot; result = p_model.transform(spark.createDataFrame([[test_sentence]]).toDF(&quot;text&quot;)) Results : +-++ |chunk |ner_label| +-++ |Keratinocyte growth factor |GENE-Y | |acidic fibroblast growth factor|GENE-Y | +-++ New UMLS Sentence Entity Resolver Models We are releasing two new UMLS Sentence Entity Resolver models trained on 2021AB UMLS dataset and map clinical entities to UMLS CUI codes. sbiobertresolve_umls_disease_syndrome : This model is trained on the Disease or Syndrome category using sbiobert_base_cased_mli embeddings. Example : ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_disease_syndrome&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... data = spark.createDataFrame([[&quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) results = model.fit(data).transform(data) Results : | | chunk | code | code_description | all_k_codes | all_k_codes_desc | |:|:--|:|:--|:-|:| | 0 | gestational diabetes mellitus | C0085207 | gestational diabetes mellitus | [&#39;C0085207&#39;, &#39;C0032969&#39;, &#39;C2063017&#39;, &#39;C1283034&#39;, &#39;C0271663&#39;] | [&#39;gestational diabetes mellitus&#39;, &#39;pregnancy diabetes mellitus&#39;, &#39;pregnancy complicated by diabetes mellitus&#39;, &#39;maternal diabetes mellitus&#39;, &#39;gestational diabetes mellitus, a2&#39;] | | 1 | subsequent type two diabetes mellitus | C0348921 | pre-existing type 2 diabetes mellitus | [&#39;C0348921&#39;, &#39;C1719939&#39;, &#39;C0011860&#39;, &#39;C0877302&#39;, &#39;C0271640&#39;] | [&#39;pre-existing type 2 diabetes mellitus&#39;, &#39;disorder associated with type 2 diabetes mellitus&#39;, &#39;diabetes mellitus, type 2&#39;, &#39;insulin-requiring type 2 diabetes mellitus&#39;, &#39;secondary diabetes mellitus&#39;] | | 2 | HTG-induced pancreatitis | C0376670 | alcohol-induced pancreatitis | [&#39;C0376670&#39;, &#39;C1868971&#39;, &#39;C4302243&#39;, &#39;C0267940&#39;, &#39;C2350449&#39;] | [&#39;alcohol-induced pancreatitis&#39;, &#39;toxic pancreatitis&#39;, &#39;igg4-related pancreatitis&#39;, &#39;hemorrhage pancreatitis&#39;, &#39;graft pancreatitis&#39;] | | 3 | an acute hepatitis | C0019159 | acute hepatitis | [&#39;C0019159&#39;, &#39;C0276434&#39;, &#39;C0267797&#39;, &#39;C1386146&#39;, &#39;C2063407&#39;] | [&#39;acute hepatitis a&#39;, &#39;acute hepatitis a&#39;, &#39;acute hepatitis&#39;, &#39;acute infectious hepatitis&#39;, &#39;acute hepatitis e&#39;] | | 4 | obesity | C0028754 | obesity | [&#39;C0028754&#39;, &#39;C0342940&#39;, &#39;C0342942&#39;, &#39;C0857116&#39;, &#39;C1561826&#39;] | [&#39;obesity&#39;, &#39;abdominal obesity&#39;, &#39;generalized obesity&#39;, &#39;obesity gross&#39;, &#39;overweight and obesity&#39;] | | 5 | polyuria | C0018965 | hematuria | [&#39;C0018965&#39;, &#39;C0151582&#39;, &#39;C3888890&#39;, &#39;C0268556&#39;, &#39;C2936921&#39;] | [&#39;hematuria&#39;, &#39;uricosuria&#39;, &#39;polyuria-polydipsia syndrome&#39;, &#39;saccharopinuria&#39;, &#39;saccharopinuria&#39;] | | 6 | polydipsia | C0268813 | primary polydipsia | [&#39;C0268813&#39;, &#39;C0030508&#39;, &#39;C3888890&#39;, &#39;C0393777&#39;, &#39;C0206085&#39;] | [&#39;primary polydipsia&#39;, &#39;parasomnia&#39;, &#39;polyuria-polydipsia syndrome&#39;, &#39;hypnogenic paroxysmal dystonias&#39;, &#39;periodic hypersomnias&#39;] | | 7 | poor appetite | C0003123 | lack of appetite | [&#39;C0003123&#39;, &#39;C0011168&#39;, &#39;C0162429&#39;, &#39;C1282895&#39;, &#39;C0039338&#39;] | [&#39;lack of appetite&#39;, &#39;poor swallowing&#39;, &#39;poor nutrition&#39;, &#39;neurologic unpleasant taste&#39;, &#39;taste dis&#39;] | | 8 | vomiting | C0152164 | periodic vomiting | [&#39;C0152164&#39;, &#39;C0267172&#39;, &#39;C0152517&#39;, &#39;C0011119&#39;, &#39;C0152227&#39;] | [&#39;periodic vomiting&#39;, &#39;habit vomiting&#39;, &#39;viral vomiting&#39;, &#39;choking&#39;, &#39;tearing&#39;] | sbiobertresolve_umls_clinical_drugs : This model is trained on the Clinical Drug category using sbiobert_base_cased_mli embeddings. Example : ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_clinical_drugs&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... data = spark.createDataFrame([[&quot;&quot;&quot;She was immediately given hydrogen peroxide 30 mg to treat the infection on her leg, and has been advised Neosporin Cream for 5 days. She has a history of taking magnesium hydroxide 100mg/1ml and metformin 1000 mg.&quot;&quot;&quot;]]).toDF(&quot;text&quot;) results = model.fit(data).transform(data) Results : | | chunk | code | code_description | all_k_codes | all_k_codes_desc | |:|:|:|:|:-|:-| | 0 | hydrogen peroxide 30 mg | C1126248 | hydrogen peroxide 30 mg/ml | [&#39;C1126248&#39;, &#39;C0304655&#39;, &#39;C1605252&#39;, &#39;C0304656&#39;, &#39;C1154260&#39;] | [&#39;hydrogen peroxide 30 mg/ml&#39;, &#39;hydrogen peroxide solution 30%&#39;, &#39;hydrogen peroxide 30 mg/ml [proxacol]&#39;, &#39;hydrogen peroxide 30 mg/ml cutaneous solution&#39;, &#39;benzoyl peroxide 30 mg/ml&#39;] | | 1 | Neosporin Cream | C0132149 | neosporin cream | [&#39;C0132149&#39;, &#39;C0358174&#39;, &#39;C0357999&#39;, &#39;C0307085&#39;, &#39;C0698810&#39;] | [&#39;neosporin cream&#39;, &#39;nystan cream&#39;, &#39;nystadermal cream&#39;, &#39;nupercainal cream&#39;, &#39;nystaform cream&#39;] | | 2 | magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 mg | [&#39;C1134402&#39;, &#39;C1126785&#39;, &#39;C4317023&#39;, &#39;C4051486&#39;, &#39;C4047137&#39;] | [&#39;magnesium hydroxide 100 mg&#39;, &#39;magnesium hydroxide 100 mg/ml&#39;, &#39;magnesium sulphate 100mg/ml injection&#39;, &#39;magnesium sulfate 100 mg&#39;, &#39;magnesium sulfate 100 mg/ml&#39;] | | 3 | metformin 1000 mg | C0987664 | metformin 1000 mg | [&#39;C0987664&#39;, &#39;C2719784&#39;, &#39;C0978482&#39;, &#39;C2719786&#39;, &#39;C4282269&#39;] | [&#39;metformin 1000 mg&#39;, &#39;metformin hydrochloride 1000 mg&#39;, &#39;metformin hcl 1000mg tab&#39;, &#39;metformin hydrochloride 1000 mg [fortamet]&#39;, &#39;metformin hcl 1000mg sa tab&#39;] | Updated RxNorm Entity Resolver Model (Dropping Invalid Codes) sbiobertresolve_rxnorm model was updated by dropping invalid codes using 02 August 2021 RxNorm dataset. New showVersion() Method in Compatibility Class We added the .showVersion() method in our Compatibility class that shows the name of the models and the version in a pretty way. compatibility = Compatibility() compatibility.showVersion(&#39;sentence_detector_dl_healthcare&#39;) After the execution you will see the following table, ++++ | Pipeline/Model | lang | version | ++++ | sentence_detector_dl_healthcare | en | 2.6.0 | | sentence_detector_dl_healthcare | en | 2.7.0 | | sentence_detector_dl_healthcare | en | 3.2.0 | ++++ New Docker Images for Spark NLP for Healthcare and Spark OCR We are releasing new Docker Images for Spark NLP for Healthcare and Spark OCR containing a jupyter environment. Users having a valid license can run the image on their local system, and connect to pre-configured jupyter instance without installing the library on their local system. Spark NLP for Healthcare Docker Image For running Spark NLP for Healthcare inside a container: Instructions: Spark NLP for Healthcare Docker Image Video Instructions: Youtube Video Spark NLP for Healthcare &amp; OCR Docker Image For users who want to run Spark OCR and then feed the output of OCR pipeline to healthcare modules to process further: Instructions: Spark NLP for Healthcare &amp; OCR Docker Image New and Updated Deidentification() Parameters New Parameter : setBlackList() : List of entities ignored for masking or obfuscation.The default values are: SSN, PASSPORT, DLN, NPI, C_CARD, IBAN, DEA. Updated Parameter : .setObfuscateRefSource() : It was set faker as default. New Python API Documentation We have new Spark NLP for Healthcare Python API Documentation . This page contains information how to use the library with Python examples. Updated Spark NLP For Healthcare Notebooks and New Notebooks New BertForTokenClassification NER Model Training with Transformers Notebook for showing how to train a BertForTokenClassification NER model with transformers and then import into Spark NLP. New ChunkKeyPhraseExtraction notebook for showing how to get chunk key phrases using ChunkKeyPhraseExtraction. Updated all Spark NLP For Healthcare Notebooks with v3.3.0 by adding the new features. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_1"
  },
  "1421": {
    "id": "1421",
    "title": "Annotation Lab Release Notes 3.3.1",
    "content": "3.3.1 Release date: 24-06-2022 We are very excited to announce the release of Annotation Lab v3.3.1 which includes updated Active Learning messages, bug fixed for importing dictionary rule, NER projects and Visual NER projects . Here are the highlights: Highlights Updated Active Learning statuses Fix for importing Visual NER task exported before v3.2.0. Fix for import of project from Windows OS Fix for import of dictionary rules Fix for show Score text is Results widget on the labeling page when the confidence score is null Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_3_1"
  },
  "1422": {
    "id": "1422",
    "title": "Spark NLP for Healthcare Release Notes 3.3.2",
    "content": "3.3.2 We are glad to announce that Spark NLP Healthcare 3.3.2 has been released!. Highlights New Clinical NER Models and Spanish NER Model New BERT-Based Clinical NER Models Updated Clinical NER Model New NER Model Class Distribution Feature New RxNorm Sentence Entity Resolver Model New Spanish SNOMED Sentence Entity Resolver Model New Clinical Question vs Statement BertForSequenceClassification model New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code) Updated ICD10CM Entity Resolver Models Updated NER Profiling Pretrained Pipelines New ChunkSentenceSplitter Annotator Updated Spark NLP For Healthcare Notebooks and New Notebooks New Clinical NER Models (including a new Spanish one) We are releasing three new clinical NER models trained by MedicalNerApproach(). roberta_ner_diag_proc : This models leverages Spanish Roberta Biomedical Embeddings (roberta_base_biomedical) to extract two entities, Diagnosis and Procedures (DIAGNOSTICO, PROCEDIMIENTO). It’s a renewed version of ner_diag_proc_es, available here, that was trained with embeddings_scielowiki_300d embeddings instead. Example : ... embeddings = RoBertaEmbeddings.pretrained(&quot;roberta_base_biomedical&quot;, &quot;es&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;roberta_ner_diag_proc&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&#39;sentence&#39;, &#39;token&#39;, &#39;ner&#39;]) .setOutputCol(&#39;ner_chunk&#39;) pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, embeddings, ner, ner_converter]) empty = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) p_model = pipeline.fit(empty) test_sentence = &#39;Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días Previous a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.&#39; res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +++ | text|ner_label | +++ | diabetes mellitus gestacional|DIAGNOSTICO| | diabetes mellitus tipo dos|DIAGNOSTICO| | DM2|DIAGNOSTICO| | pancreatitis inducida por HTG|DIAGNOSTICO| | hepatitis aguda|DIAGNOSTICO| | obesidad|DIAGNOSTICO| | índice de masa corporal|DIAGNOSTICO| | IMC|DIAGNOSTICO| | poliuria|DIAGNOSTICO| | polidipsia|DIAGNOSTICO| | vómitos|DIAGNOSTICO| |infección del tracto respiratorio|DIAGNOSTICO| | DM2|DIAGNOSTICO| | HTG|DIAGNOSTICO| | dolor|DIAGNOSTICO| | rigidez|DIAGNOSTICO| | cetosis|DIAGNOSTICO| |infección del tracto respiratorio|DIAGNOSTICO| ++--+ ner_covid_trials : This model is trained to extract covid-specific medical entities in clinical trials. It supports the following entities ranging from virus type to trial design: Stage, Severity, Virus, Trial_Design, Trial_Phase, N_Patients, Institution, Statistical_Indicator, Section_Header, Cell_Type, Cellular_component, Viral_components, Physiological_reaction, Biological_molecules, Admission_Discharge, Age, BMI, Cerebrovascular_Disease, Date, Death_Entity, Diabetes, Disease_Syndrome_Disorder, Dosage, Drug_Ingredient, Employment, Frequency, Gender, Heart_Disease, Hypertension, Obesity, Pulse, Race_Ethnicity, Respiration, Route, Smoking, Time, Total_Cholesterol, Treatment, VS_Finding, Vaccine . Example : ... covid_ner = MedicalNerModel.pretrained(&#39;ner_covid_trials&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = covid_model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;In December 2019 , a group of patients with the acute respiratory disease was detected in Wuhan , Hubei Province of China . A month later , a new beta-coronavirus was identified as the cause of the 2019 coronavirus infection . SARS-CoV-2 is a coronavirus that belongs to the group of β-coronaviruses of the subgenus Coronaviridae . The SARS-CoV-2 is the third known zoonotic coronavirus disease after severe acute respiratory syndrome ( SARS ) and Middle Eastern respiratory syndrome ( MERS ). The diagnosis of SARS-CoV-2 recommended by the WHO , CDC is the collection of a sample from the upper respiratory tract ( nasal and oropharyngeal exudate ) or from the lower respiratory tract such as expectoration of endotracheal aspirate and bronchioloalveolar lavage and its analysis using the test of real-time polymerase chain reaction ( qRT-PCR ).&quot;&quot;&quot;]}))) Results : | | chunk | begin | end | entity | |:|:|--:|:|:--| | 0 | December 2019 | 3 | 15 | Date | | 1 | acute respiratory disease | 48 | 72 | Disease_Syndrome_Disorder | | 2 | beta-coronavirus | 146 | 161 | Virus | | 3 | 2019 coronavirus infection | 198 | 223 | Disease_Syndrome_Disorder | | 4 | SARS-CoV-2 | 227 | 236 | Virus | | 5 | coronavirus | 243 | 253 | Virus | | 6 | β-coronaviruses | 284 | 298 | Virus | | 7 | subgenus Coronaviridae | 307 | 328 | Virus | | 8 | SARS-CoV-2 | 336 | 345 | Virus | | 9 | zoonotic coronavirus disease | 366 | 393 | Disease_Syndrome_Disorder | | 10 | severe acute respiratory syndrome | 401 | 433 | Disease_Syndrome_Disorder | | 11 | SARS | 437 | 440 | Disease_Syndrome_Disorder | | 12 | Middle Eastern respiratory syndrome | 448 | 482 | Disease_Syndrome_Disorder | | 13 | MERS | 486 | 489 | Disease_Syndrome_Disorder | | 14 | SARS-CoV-2 | 511 | 520 | Virus | | 15 | WHO | 541 | 543 | Institution | | 16 | CDC | 547 | 549 | Institution | ner_chemd_clinical : This model extract the names of chemical compounds and drugs in medical texts. The entities that can be detected are as follows : SYSTEMATIC, IDENTIFIERS, FORMULA, TRIVIAL, ABBREVIATION, FAMILY, MULTIPLE . For reference click here . Example : ... chemd_ner = MedicalNerModel.pretrained(&#39;ner_chemd&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = chemd_model.transform(spark.createDataFrame(pd.DataFrame({&quot;text&quot;: [&quot;&quot;&quot;Isolation, Structure Elucidation, and Iron-Binding Properties of Lystabactins, Siderophores Isolated from a Marine Pseudoalteromonas sp. The marine bacterium Pseudoalteromonas sp. S2B, isolated from the Gulf of Mexico after the Deepwater Horizon oil spill, was found to produce lystabactins A, B, and C (1-3), three new siderophores. The structures were elucidated through mass spectrometry, amino acid analysis, and NMR. The lystabactins are composed of serine (Ser), asparagine (Asn), two formylated/hydroxylated ornithines (FOHOrn), dihydroxy benzoic acid (Dhb), and a very unusual nonproteinogenic amino acid, 4,8-diamino-3-hydroxyoctanoic acid (LySta). The iron-binding properties of the compounds were investigated through a spectrophotometric competition.&quot;&quot;&quot;]}))) Results : +-++ |chunk |ner_label | +-++ |Lystabactins |FAMILY | |lystabactins A, B, and C |MULTIPLE | |amino acid |FAMILY | |lystabactins |FAMILY | |serine |TRIVIAL | |Ser |FORMULA | |asparagine |TRIVIAL | |Asn |FORMULA | |formylated/hydroxylated ornithines|FAMILY | |FOHOrn |FORMULA | |dihydroxy benzoic acid |SYSTEMATIC | |amino acid |FAMILY | |4,8-diamino-3-hydroxyoctanoic acid|SYSTEMATIC | |LySta |ABBREVIATION| +-++ New BERT-Based Clinical NER Models We have two new BERT-Based token classifier NER models. bert_token_classifier_ner_bionlp : This model is BERT-based version of ner_bionlp model and can detect biological and genetics terms in cancer-related texts. (Amino_acid, Anatomical_system, Cancer, Cell, Cellular_component, Developing_anatomical_Structure, Gene_or_gene_product, Immaterial_anatomical_entity, Multi-tissue_structure, Organ, Organism, Organism_subdivision, Simple_chemical, Tissue) Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_bionlp&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;Both the erbA IRES and the erbA/myb virus constructs transformed erythroid cells after infection of bone marrow or blastoderm cultures. The erbA/myb IRES virus exhibited a 5-10-fold higher transformed colony forming efficiency than the erbA IRES virus in the blastoderm assay.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+ |chunk |ner_label | +-+-+ |erbA IRES |Organism | |erbA/myb virus |Organism | |erythroid cells |Cell | |bone marrow |Multi-tissue_structure| |blastoderm cultures|Cell | |erbA/myb IRES virus|Organism | |erbA IRES virus |Organism | |blastoderm |Cell | +-+-+ bert_token_classifier_ner_cellular : This model is BERT-based version of ner_cellular model and can detect molecular biology-related terms (DNA, Cell_type, Cell_line, RNA, Protein) in medical texts. Metrics : precision recall f1-score support B-DNA 0.87 0.77 0.82 1056 B-RNA 0.85 0.79 0.82 118 B-cell_line 0.66 0.70 0.68 500 B-cell_type 0.87 0.75 0.81 1921 B-protein 0.90 0.85 0.88 5067 I-DNA 0.93 0.86 0.90 1789 I-RNA 0.92 0.84 0.88 187 I-cell_line 0.67 0.76 0.71 989 I-cell_type 0.92 0.76 0.84 2991 I-protein 0.94 0.80 0.87 4774 accuracy 0.80 19392 macro avg 0.76 0.81 0.78 19392 weighted avg 0.89 0.80 0.85 19392 Example : ... tokenClassifier = BertForTokenClassification.pretrained(&quot;bert_token_classifier_ner_cellular&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... test_sentence = &quot;&quot;&quot;Detection of various other intracellular signaling proteins is also described. Genetic characterization of transactivation of the human T-cell leukemia virus type 1 promoter: Binding of Tax to Tax-responsive element 1 is mediated by the cyclic AMP-responsive members of the CREB/ATF family of transcription factors. To achieve a better understanding of the mechanism of transactivation by Tax of human T-cell leukemia virus type 1 Tax-responsive element 1 (TRE-1), we developed a genetic approach with Saccharomyces cerevisiae. We constructed a yeast reporter strain containing the lacZ gene under the control of the CYC1 promoter associated with three copies of TRE-1. Expression of either the cyclic AMP response element-binding protein (CREB) or CREB fused to the GAL4 activation domain (GAD) in this strain did not modify the expression of the reporter gene. Tax alone was also inactive.&quot;&quot;&quot; result = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-++ |chunk |ner_label| +-++ |intracellular signaling proteins |protein | |human T-cell leukemia virus type 1 promoter|DNA | |Tax |protein | |Tax-responsive element 1 |DNA | |cyclic AMP-responsive members |protein | |CREB/ATF family |protein | |transcription factors |protein | |Tax |protein | |human T-cell leukemia virus type 1 |DNA | |Tax-responsive element 1 |DNA | |TRE-1 |DNA | |lacZ gene |DNA | |CYC1 promoter |DNA | |TRE-1 |DNA | |cyclic AMP response element-binding protein|protein | |CREB |protein | |CREB |protein | |GAL4 activation domain |protein | |GAD |protein | |reporter gene |DNA | |Tax |protein | +-++ Updated Clinical NER Model We have updated ner_jsl_enriched model by enriching the training data using clinical trials data to make it more robust. This model is capable of predicting up to 87 different entities and is based on ner_jsl model. Here are the entities this model can detect; Social_History_Header, Oncology_Therapy, Blood_Pressure, Respiration, Performance_Status, Family_History_Header, Dosage, Clinical_Dept, Diet, Procedure, HDL, Weight, Admission_Discharge, LDL, Kidney_Disease, Oncological, Route, Imaging_Technique, Puerperium, Overweight, Temperature, Diabetes, Vaccine, Age, Test_Result, Employment, Time, Obesity, EKG_Findings, Pregnancy, Communicable_Disease, BMI, Strength, Tumor_Finding, Section_Header, RelativeDate, ImagingFindings, Death_Entity, Date, Cerebrovascular_Disease, Treatment, Labour_Delivery, Pregnancy_Delivery_Puerperium, Direction, Internal_organ_or_component, Psychological_Condition, Form, Medical_Device, Test, Symptom, Disease_Syndrome_Disorder, Staging, Birth_Entity, Hyperlipidemia, O2_Saturation, Frequency, External_body_part_or_region, Drug_Ingredient, Vital_Signs_Header, Substance_Quantity, Race_Ethnicity, VS_Finding, Injury_or_Poisoning, Medical_History_Header, Alcohol, Triglycerides, Total_Cholesterol, Sexually_Active_or_Sexual_Orientation, Female_Reproductive_Status, Relationship_Status, Drug_BrandName, RelativeTime, Duration, Hypertension, Metastasis, Gender, Oxygen_Therapy, Pulse, Heart_Disease, Modifier, Allergen, Smoking, Substance, Cancer_Modifier, Fetus_NewBorn, Height . Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl_enriched&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = model.transform(spark.createDataFrame([[&quot;The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient&#39;s nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature.&quot;]], [&quot;text&quot;])) Results : | | chunk | begin | end | entity | |:|:|--:|:|:--| | 0 | 21-day-old | 17 | 26 | Age | | 1 | Caucasian | 28 | 36 | Race_Ethnicity | | 2 | male | 38 | 41 | Gender | | 3 | 2 days | 52 | 57 | Duration | | 4 | congestion | 62 | 71 | Symptom | | 5 | mom | 75 | 77 | Gender | | 6 | suctioning yellow discharge | 88 | 114 | Symptom | | 7 | nares | 135 | 139 | External_body_part_or_region | | 8 | she | 147 | 149 | Gender | | 9 | mild | 168 | 171 | Modifier | | 10 | problems with his breathing while feeding | 173 | 213 | Symptom | | 11 | perioral cyanosis | 237 | 253 | Symptom | | 12 | retractions | 258 | 268 | Symptom | | 13 | One day ago | 272 | 282 | RelativeDate | | 14 | mom | 285 | 287 | Gender | | 15 | tactile temperature | 304 | 322 | Symptom | | 16 | Tylenol | 345 | 351 | Drug_BrandName | | 17 | Baby | 354 | 357 | Age | | 18 | decreased p.o. intake | 377 | 397 | Symptom | | 19 | His | 400 | 402 | Gender | | 20 | q.2h | 450 | 453 | Frequency | | 21 | 5 to 10 minutes | 459 | 473 | Duration | | 22 | his | 488 | 490 | Gender | | 23 | respiratory congestion | 492 | 513 | Symptom | | 24 | He | 516 | 517 | Gender | | 25 | tired | 550 | 554 | Symptom | | 26 | fussy | 569 | 573 | Symptom | | 27 | over the past 2 days | 575 | 594 | RelativeDate | | 28 | albuterol | 637 | 645 | Drug_Ingredient | | 29 | ER | 671 | 672 | Clinical_Dept | | 30 | His | 675 | 677 | Gender | | 31 | urine output has also decreased | 679 | 709 | Symptom | | 32 | he | 721 | 722 | Gender | | 33 | per 24 hours | 760 | 771 | Frequency | | 34 | he | 778 | 779 | Gender | | 35 | per 24 hours | 807 | 818 | Frequency | | 36 | Mom | 821 | 823 | Gender | | 37 | diarrhea | 836 | 843 | Symptom | | 38 | His | 846 | 848 | Gender | | 39 | bowel | 850 | 854 | Internal_organ_or_component | New NER Model Class Distribution Feature getTrainingClassDistribution : This parameter returns the distribution of labels used when training the NER model. Example: ner_model.getTrainingClassDistribution() &gt;&gt; {&#39;B-Disease&#39;: 2536, &#39;O&#39;: 31659, &#39;I-Disease&#39;: 2960} New RxNorm Sentence Entity Resolver Model sbiobertresolve_rxnorm_augmented : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It trained on the augmented version of the dataset which is used in previous RxNorm resolver models. Additionally, this model returns concept classes of the drugs in all_k_aux_labels column. New Spanish SNOMED Sentence Entity Resolver Model robertaresolve_snomed : This models leverages Spanish Roberta Biomedical Embeddings (roberta_base_biomedical) at sentence-level to map ner chunks into Spanish SNOMED codes. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) word_embeddings = RoBertaEmbeddings.pretrained(&quot;roberta_base_biomedical&quot;, &quot;es&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;roberta_embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;roberta_ner_diag_proc&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;roberta_embeddings&quot;) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) c2doc = Chunk2Doc() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = SentenceEmbeddings() .setInputCols([&quot;ner_chunk_doc&quot;, &quot;roberta_embeddings&quot;]) .setOutputCol(&quot;chunk_embeddings&quot;) .setPoolingStrategy(&quot;AVERAGE&quot;) er = SentenceEntityResolverModel.pretrained(&quot;robertaresolve_snomed&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) snomed_training_pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, word_embeddings, ner, ner_converter, c2doc, chunk_embeddings, er]) empty = spark.createDataFrame([[&#39;&#39;]]).toDF(&quot;text&quot;) p_model = snomed_pipeline .fit(empty) test_sentence = &#39;Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días Previous a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.&#39; res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: [test_sentence]}))) Results : +-+-+-+--+ | | ner_chunk | entity | snomed_code| |-+-+-+--| | 0 | diabetes mellitus gestacional | DIAGNOSTICO | 11687002 | | 1 | diabetes mellitus tipo dos ( | DIAGNOSTICO | 44054006 | | 2 | pancreatitis | DIAGNOSTICO | 75694006 | | 3 | HTG | DIAGNOSTICO | 266569009 | | 4 | hepatitis aguda | DIAGNOSTICO | 37871000 | | 5 | obesidad | DIAGNOSTICO | 5476005 | | 6 | índice de masa corporal | DIAGNOSTICO | 162859006 | | 7 | poliuria | DIAGNOSTICO | 56574000 | | 8 | polidipsia | DIAGNOSTICO | 17173007 | | 9 | falta de apetito | DIAGNOSTICO | 49233005 | | 10 | vómitos | DIAGNOSTICO | 422400008 | | 11 | infección | DIAGNOSTICO | 40733004 | | 12 | HTG | DIAGNOSTICO | 266569009 | | 13 | dolor | DIAGNOSTICO | 22253000 | | 14 | rigidez | DIAGNOSTICO | 271587009 | | 15 | cetosis | DIAGNOSTICO | 2538008 | | 16 | infección | DIAGNOSTICO | 40733004 | +-+-+-+--+ New Clinical Question vs Statement BertForSequenceClassification model bert_sequence_classifier_question_statement_clinical : This model classifies sentences into one of these two classes: question (interrogative sentence) or statement (declarative sentence) and trained with BertForSequenceClassification. This model is at first trained on SQuAD and SPAADIA dataset and then fine tuned on the clinical visit documents and MIMIC-III dataset annotated in-house. Using this model, you can find the question statements and exclude &amp; utilize in the downstream tasks such as NER and relation extraction models. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained() .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) seq = BertForSequenceClassification.pretrained(&#39;bert_sequence_classifier_question_statement_clinical&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;label&quot;) .setCaseSensitive(True) pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, seq]) test_sentences = [&quot;&quot;&quot;Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested. I had the tests on day 23 of my cycle. My progresterone level is 10. What does this mean? What does progesterone level of 10 indicate? Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle.So there&#39;s nothing to worry as it&#39;s perfectly alright&quot;&quot;&quot;] res = p_model.transform(spark.createDataFrame(pd.DataFrame({&#39;text&#39;: test_sentences}))) Results : +--++ |sentence |label | +--++ |Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested.|statement| |I had the tests on day 23 of my cycle. |statement| |My progresterone level is 10. |statement| |What does this mean? |question | |What does progesterone level of 10 indicate? |question | |Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle. |statement| |So there&#39;s nothing to worry as it&#39;s perfectly alright |statement| +--+ Metrics : precision recall f1-score support question 0.97 0.94 0.96 243 statement 0.98 0.99 0.99 729 accuracy 0.98 972 macro avg 0.98 0.97 0.97 972 weighted avg 0.98 0.98 0.98 972 New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code) .setOverwriteExistingCode() : This parameter provides overwriting codes over the existing codes if in pretrained Sentence Entity Resolver Model. For example, you want to add a new term to a pretrained resolver model, and if the code of term already exists in the pretrained model, when you .setOverwriteExistingCode(True), it removes all the same codes and their descriptions from the model, then you will have just the new term with its code in the fine-tuned model. .setDropCodesList() : This parameter drops list of codes from a pretrained Sentence Entity Resolver Model. For more examples, please check Fine-Tuning Sentence Entity Resolver Notebook Updated ICD10CM Entity Resolver Models We have updated sbiobertresolve_icd10cm_augmented model with ICD10CM 2022 Dataset and sbiobertresolve_icd10cm_augmented_billable_hcc model by dropping invalid codes. Updated NER Profiling Pretrained Pipelines We have updated ner_profiling_clinical and ner_profiling_biobert pretrained pipelines by adding new clinical NER models and NER model outputs to the previous versions. In this way, you can see all the NER labels of tokens. For examples, please check NER Profiling Pretrained Pipeline Notebook. New ChunkSentenceSplitter Annotator We are releasing ChunkSentenceSplitter annotator that splits documents or sentences by chunks provided. Splitted parts can be named with the splitting chunks. By using this annotator, you can do some some tasks like splitting clinical documents according into sections in accordance with CDA (Clinical Document Architecture). Example : ... ner_converter = NerConverter() .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&quot;Header&quot;]) chunkSentenceSplitter = ChunkSentenceSplitter() .setInputCols(&quot;ner_chunk&quot;,&quot;document&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(True) .setDefaultEntity(&quot;Intro&quot;) .setInsertChunk(False) ... text = [&quot;&quot;&quot;INTRODUCTION: Right pleural effusion and suspected malignant mesothelioma. PREOPERATIVE DIAGNOSIS: Right pleural effusion and suspected malignant mesothelioma. POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignant mesothelioma. PROCEDURE: Right VATS pleurodesis and pleural biopsy.&quot;&quot;&quot;] results = pipeline_model.transform(df) Results : +-++ | result|entity| +-++ |INTRODUCTION: Right pleural effusion and suspected malignant mesoth...|Header| |PREOPERATIVE DIAGNOSIS: Right pleural effusion and suspected malig...|Header| |POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignan...|Header| | PROCEDURE: Right VATS pleurodesis and pleural biopsy|Header| +-++ By using .setInsertChunk() parameter you can remove the chunk from splitted parts. Example : chunkSentenceSplitter = ChunkSentenceSplitter() .setInputCols(&quot;ner_chunk&quot;,&quot;document&quot;) .setOutputCol(&quot;paragraphs&quot;) .setGroupBySentences(True) .setDefaultEntity(&quot;Intro&quot;) .setInsertChunk(False) paragraphs = chunkSentenceSplitter.transform(results) df = paragraphs.selectExpr(&quot;explode(paragraphs) as result&quot;) .selectExpr(&quot;result.result&quot;, &quot;result.metadata.entity&quot;, &quot;result.metadata.splitter_chunk&quot;) Results : +--+++ | result|entity| splitter_chunk| +--+++ | Right pleural effusion and suspected malignant...|Header| INTRODUCTION:| | Right pleural effusion and suspected malignan...|Header| PREOPERATIVE DIAGNOSIS:| | Right pleural effusion, suspected malignant me...|Header|POSTOPERATIVE DIAGNOSIS:| | Right VATS pleurodesis and pleural biopsy|Header| PROCEDURE:| +--+++ Updated Spark NLP For Healthcare Notebooks NER Profiling Pretrained Pipeline Notebook . Fine-Tuning Sentence Entity Resolver Notebook To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_2"
  },
  "1423": {
    "id": "1423",
    "title": "Spark NLP for Healthcare Release Notes 3.3.4",
    "content": "3.3.4 We are glad to announce that Spark NLP Healthcare 3.3.4 has been released! Highlights New Clinical NER Models New NER Model Finder Pretrained Pipeline New Relation Extraction Model New LOINC, MeSH, NDC and SNOMED Entity Resolver Models Updated RxNorm Sentence Entity Resolver Model New Shift Days Feature in StructuredDeid Deidentification Module New Multiple Chunks Merge Ability in ChunkMergeApproach New setBlackList Feature in ChunkMergeApproach New setBlackList Feature in NerConverterInternal New setLabelCasing Feature in MedicalNerModel New Update Models Functionality New and Updated Notebooks New Clinical NER Models We have three new clinical NER models. ner_deid_subentity_augmented_i2b2 : This model annotates text to find protected health information(PHI) that may need to be removed. It is trained with 2014 i2b2 dataset (no augmentation applied) and can detect MEDICALRECORD, ORGANIZATION, DOCTOR, USERNAME, PROFESSION, HEALTHPLAN, URL, CITY, DATE, LOCATION-OTHER, STATE, PATIENT, DEVICE, COUNTRY, ZIP, PHONE, HOSPITAL, EMAIL, IDNUM, SREET, BIOID, FAX, AGE entities. Example : ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented_i2b2&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 years old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient&#39;s complaints first surfaced when he started working for Brothers Coal-Mine.&quot;]], [&quot;text&quot;])) Results : +--+-+ |chunk |ner_label | +--+-+ |2093-01-13 |DATE | |David Hale |DOCTOR | |Hendrickson, Ora |PATIENT | |7194334 |MEDICALRECORD| |01/13/93 |DATE | |Oliveira |DOCTOR | |25 |AGE | |1-11-2000 |DATE | |Cocke County Baptist Hospital|HOSPITAL | |0295 Keats Street |STREET | |(302) 786-5227 |PHONE | |Brothers Coal-Mine Corp |ORGANIZATION | +--+-+ ner_biomarker : This model is trained to extract biomarkers, therapies, oncological, and other general concepts from text. Following are the entities it can detect: Oncogenes, Tumor_Finding, UnspecificTherapy, Ethnicity, Age, ResponseToTreatment, Biomarker, HormonalTherapy, Staging, Drug, CancerDx, Radiotherapy, CancerSurgery, TargetedTherapy, PerformanceStatus, CancerModifier, Radiological_Test_Result, Biomarker_Measurement, Metastasis, Radiological_Test, Chemotherapy, Test, Dosage, Test_Result, Immunotherapy, Date, Gender, Prognostic_Biomarkers, Duration, Predictive_Biomarkers Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_biomarker&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Here , we report the first case of an intraductal tubulopapillary neoplasm of the pancreas with clear cell morphology . Immunohistochemistry revealed positivity for Pan-CK , CK7 , CK8/18 , MUC1 , MUC6 , carbonic anhydrase IX , CD10 , EMA , β-catenin and e-cadherin .&quot;]], [&quot;text&quot;])) Results : | | ner_chunk | entity | confidence | |:|:-|:-|-:| | 0 | intraductal | CancerModifier | 0.9934 | | 1 | tubulopapillary | CancerModifier | 0.6403 | | 2 | neoplasm of the pancreas | CancerDx | 0.758825 | | 3 | clear cell | CancerModifier | 0.9633 | | 4 | Immunohistochemistry | Test | 0.9534 | | 5 | positivity | Biomarker_Measurement | 0.8795 | | 6 | Pan-CK | Biomarker | 0.9975 | | 7 | CK7 | Biomarker | 0.9975 | | 8 | CK8/18 | Biomarker | 0.9987 | | 9 | MUC1 | Biomarker | 0.9967 | | 10 | MUC6 | Biomarker | 0.9972 | | 11 | carbonic anhydrase IX | Biomarker | 0.937567 | | 12 | CD10 | Biomarker | 0.9974 | | 13 | EMA | Biomarker | 0.9899 | | 14 | β-catenin | Biomarker | 0.8059 | | 15 | e-cadherin | Biomarker | 0.9806 | ner_nihss : NER model that can identify entities according to NIHSS guidelines for clinical stroke assessment to evaluate neurological status in acute stroke patients. Here are the labels it can detect : 11_ExtinctionInattention, 6b_RightLeg, 1c_LOCCommands, 10_Dysarthria, NIHSS, 5_Motor, 8_Sensory, 4_FacialPalsy, 6_Motor, 2_BestGaze, Measurement, 6a_LeftLeg, 5b_RightArm, 5a_LeftArm, 1b_LOCQuestions, 3_Visual, 9_BestLanguage, 7_LimbAtaxia, 1a_LOC . Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_nihss&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Abdomen , soft , nontender . NIH stroke scale on presentation was 23 to 24 for , one for consciousness , two for month and year and two for eye / grip , one to two for gaze , two for face , eight for motor , one for limited ataxia , one to two for sensory , three for best language and two for attention . On the neurologic examination the patient was intermittently&quot;]], [&quot;text&quot;])) Results : | | chunk | entity | |:|:-|:-| | 0 | NIH stroke scale | NIHSS | | 1 | 23 to 24 | Measurement | | 2 | one | Measurement | | 3 | consciousness | 1a_LOC | | 4 | two | Measurement | | 5 | month and year and | 1b_LOCQuestions | | 6 | two | Measurement | | 7 | eye / grip | 1c_LOCCommands | | 8 | one to | Measurement | | 9 | two | Measurement | | 10 | gaze | 2_BestGaze | | 11 | two | Measurement | | 12 | face | 4_FacialPalsy | | 13 | eight | Measurement | | 14 | one | Measurement | | 15 | limited | 7_LimbAtaxia | | 16 | ataxia | 7_LimbAtaxia | | 17 | one to two | Measurement | | 18 | sensory | 8_Sensory | | 19 | three | Measurement | | 20 | best language | 9_BestLanguage | | 21 | two | Measurement | | 22 | attention | 11_ExtinctionInattention | New NER Model Finder Pretrained Pipeline We are releasing new ner_model_finder pretrained pipeline trained with bert embeddings that can be used to find the most appropriate NER model given the entity name. Example : from sparknlp.pretrained import PretrainedPipeline finder_pipeline = PretrainedPipeline(&quot;ner_model_finder&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = finder_pipeline.fullAnnotate(&quot;psychology&quot;) Results : entity top models all models resolutions psychology [‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’] [‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’]:::[‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl_slim’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical,… psychological condition:::clinical department::: … New Relation Extraction Model We are releasing new redl_nihss_biobert relation extraction model that can relate scale items and their measurements according to NIHSS guidelines. Example : ... re_model = RelationExtractionDLModel() .pretrained(&#39;redl_nihss_biobert&#39;, &#39;en&#39;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) ... sample_text = &quot;There , her initial NIHSS score was 4 , as recorded by the ED physicians . This included 2 for weakness in her left leg and 2 for what they felt was subtle ataxia in her left arm and leg .&quot; result = re_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : | chunk1 | entity1 | entity1_begin | entity1_end | entity2 | chunk2 | entity2_begin | entity2_end | relation | |:--|:-|-:|--:|:|:|-:|--:|:--| | initial NIHSS score | NIHSS | 12 | 30 | Measurement | 4 | 36 | 36 | Has_Value | | left leg | 6a_LeftLeg | 111 | 118 | Measurement | 2 | 89 | 89 | Has_Value | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 2 | 124 | 124 | Has_Value | | left leg | 6a_LeftLeg | 111 | 118 | Measurement | 4 | 36 | 36 | 0 | | initial NIHSS score | NIHSS | 12 | 30 | Measurement | 2 | 124 | 124 | 0 | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 4 | 36 | 36 | 0 | | subtle ataxia in her left arm and leg | 7_LimbAtaxia | 149 | 185 | Measurement | 2 | 89 | 89 | 0 | New LOINC, MeSH, NDC and SNOMED Entity Resolver Models We have four new Sentence Entity Resolver Models. sbiobertresolve_mesh : This model maps clinical entities to Medical Subject Heading (MeSH) codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example : ... mesh_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_mesh&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;mesh_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text = &quot;&quot;&quot;She was admitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed malignant mesothelioma.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +--++-+-+-+-+ | ner_chunk| entity| mesh_code| all_codes| resolutions| distances| +--++-+-+-+-+ | chest pain| PROBLEM| D002637|D002637:::D059350:::D019547:::D020069:::D015746:::D000072716:::D005157:::D059265:::D001416:::D048...|Chest Pain:::Chronic Pain:::Neck Pain:::Shoulder Pain:::Abdominal Pain:::Cancer Pain:::Facial Pai...|0.0000:::0.0577:::0.0587:::0.0601:::0.0658:::0.0704:::0.0712:::0.0741:::0.0766:::0.0778:::0.0794:...| |bilateral pleural effusion| PROBLEM| D010996|D010996:::D010490:::D011654:::D016724:::D010995:::D016066:::D011001:::D007819:::D035422:::D004653...|Pleural Effusion:::Pericardial Effusion:::Pulmonary Edema:::Empyema, Pleural:::Pleural Diseases::...|0.0309:::0.1010:::0.1115:::0.1213:::0.1218:::0.1398:::0.1425:::0.1401:::0.1451:::0.1464:::0.1464:...| | the pathology| TEST| D010336|D010336:::D010335:::D001004:::D020969:::C001675:::C536472:::D004194:::D003951:::D013631:::C535329...|Pathology:::Pathologic Processes:::Anus Diseases:::Disease Attributes:::malformins:::Upington dis...|0.0788:::0.0977:::0.1364:::0.1396:::0.1419:::0.1459:::0.1418:::0.1393:::0.1514:::0.1541:::0.1491:...| | the pericardectomy|TREATMENT| D010492|D010492:::D011670:::D018700:::D020884:::D011672:::D005927:::D064727:::D002431:::C000678968:::D011...|Pericardiectomy:::Pulpectomy:::Pleurodesis:::Colpotomy:::Pulpotomy:::Glossectomy:::Posterior Caps...|0.1098:::0.1448:::0.1801:::0.1852:::0.1871:::0.1923:::0.1901:::0.2023:::0.2075:::0.2010:::0.1996:...| | mesothelioma| PROBLEM|D000086002|D000086002:::C535700:::D009208:::D032902:::D018301:::D018199:::C562740:::C000686536:::D018276:::D...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Myoepithelioma:::Ganoderma:::Neoplasms, M...|0.0813:::0.1515:::0.1599:::0.1810:::0.1864:::0.1881:::0.1907:::0.1938:::0.1924:::0.1876:::0.2040:...| | chest tube placement|TREATMENT| D015505|D015505:::D019616:::D013896:::D012124:::D013906:::D013510:::D020708:::D035423:::D013903:::D000066...|Chest Tubes:::Thoracic Surgical Procedures:::Thoracic Diseases:::Respiratory Care Units:::Thoraco...|0.0557:::0.1473:::0.1598:::0.1604:::0.1725:::0.1651:::0.1795:::0.1760:::0.1804:::0.1846:::0.1883:...| | drainage of the fluid|TREATMENT| D004322|D004322:::D018495:::C045413:::D021061:::D045268:::D018508:::D005441:::D015633:::D014906:::D001834...|Drainage:::Fluid Shifts:::Bonain&#39;s liquid:::Liquid Ventilation:::Flowmeters:::Water Purification:...|0.1141:::0.1403:::0.1582:::0.1549:::0.1586:::0.1626:::0.1599:::0.1655:::0.1667:::0.1656:::0.1741:...| | thoracoscopy|TREATMENT| D013906|D013906:::D020708:::D035423:::D013905:::D035441:::D013897:::D001468:::D000069258:::D013909:::D013...|Thoracoscopy:::Thoracoscopes:::Thoracic Cavity:::Thoracoplasty:::Thoracic Wall:::Thoracic Duct:::...|0.0000:::0.0359:::0.0744:::0.1007:::0.1070:::0.1143:::0.1186:::0.1257:::0.1228:::0.1356:::0.1354:...| | fluid biopsies| TEST|D000073890|D000073890:::D010533:::D020420:::D011677:::D017817:::D001706:::D005441:::D005751:::D013582:::D000...|Liquid Biopsy:::Peritoneal Lavage:::Cyst Fluid:::Punctures:::Nasal Lavage Fluid:::Biopsy:::Fluids...|0.1408:::0.1612:::0.1763:::0.1744:::0.1744:::0.1810:::0.1744:::0.1828:::0.1896:::0.1909:::0.1950:...| | malignant mesothelioma| PROBLEM|D000086002|D000086002:::C535700:::C562740:::D009236:::D007890:::D012515:::D009208:::C009823:::C000683999:::C...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Hemangiopericytoma, Malignant:::Myxosarco...|0.0737:::0.1106:::0.1658:::0.1627:::0.1660:::0.1639:::0.1728:::0.1676:::0.1791:::0.1843:::0.1849:...| +-+--++-+-+-+-+ sbiobertresolve_ndc : This model maps clinical entities and concepts (like drugs/ingredients) to National Drug Codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Also, if a drug has more than one NDC code, it returns all available codes in the all_k_aux_label column separated by | symbol. Example : ... ndc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_ndc&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;ndc_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text = &quot;&quot;&quot;The patient was transferred secondary to inability and continue of her diabetes, the sacral decubitus, left foot pressure wound, and associated complications of diabetes. She is given aspirin 81 mg, folic acid 1 g daily, insulin glargine 100 UNT/ML injection and metformin 500 mg p.o. p.r.n.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-++--++--+--+--+ | ner_chunk|entity| ndc_code| description| all_codes| all_resolutions| other ndc codes| +-++--++--+--+--+ | aspirin 81 mg| DRUG|73089008114| aspirin 81 mg/81mg, 81 mg in 1 carton , capsule|[73089008114, 71872708704, 71872715401, 68210101500, 69536028110, 63548086706, 71679001000, 68196090051, 00113400500, 69536018112, 73089008112, 63981056362, 63739043402, 63548086705, 00113046708, 7...|[aspirin 81 mg/81mg, 81 mg in 1 carton , capsule, aspirin 81 mg 81 mg/1, 4 blister pack in 1 bag , tablet, aspirin 81 mg/1, 1 blister pack in 1 bag , tablet, coated, aspirin 81 mg/1, 1 bag in 1 dru...| [-, -, -, -, -, -, -, -, -, -, -, 63940060962, -, -, -, -, -, -, -, -, 70000042002|00363021879|41250027408|36800046708|59779027408|49035027408|71476010131|81522046708|30142046708, -, -, -, -]| | folic acid 1 g| DRUG|43744015101| folic acid 1 g/g, 1 g in 1 package , powder|[43744015101, 63238340000, 66326050555, 51552041802, 51552041805, 63238340001, 81919000204, 51552041804, 66326050556, 51552106301, 51927003300, 71092997701, 51927296300, 51552146602, 61281900002, 6...|[folic acid 1 g/g, 1 g in 1 package , powder, folic acid 1 kg/kg, 1 kg in 1 bottle , powder, folic acid 1 kg/kg, 1 kg in 1 drum , powder, folic acid 1 g/g, 5 g in 1 container , powder, folic acid 1...| [-, -, -, -, -, -, -, -, -, -, -, 51552139201, -, -, -, 81919000203, -, 81919000201, -, -, -, -, -, -, -]| |insulin glargine 100 UNT/ML injection| DRUG|00088502101|insulin glargine 100 [iu]/ml, 1 vial, glass in 1 package , injection, solution|[00088502101, 00088222033, 49502019580, 00002771563, 00169320111, 00088250033, 70518139000, 00169266211, 50090127600, 50090407400, 00002771559, 00002772899, 70518225200, 70518138800, 00024592410, 0...|[insulin glargine 100 [iu]/ml, 1 vial, glass in 1 package , injection, solution, insulin glargine 100 [iu]/ml, 1 vial, glass in 1 carton , injection, solution, insulin glargine 100 [iu]/ml, 1 vial ...|[-, -, -, 00088221900, -, -, 50090139800|00088502005, -, 70518146200|00169368712, 00169368512|73070020011, 00088221905|49502019675|50090406800, -, 73070010011|00169750111|50090495500, 66733077301|0...| | metformin 500 mg| DRUG|70010006315| metformin hydrochloride 500 mg/500mg, 500 mg in 1 drum , tablet|[70010006315, 62207041613, 71052050750, 62207049147, 71052091050, 25000010197, 25000013498, 25000010198, 71052063005, 51662139201, 70010049118, 70882012456, 71052011005, 71052065905, 71052050850, 1...|[metformin hydrochloride 500 mg/500mg, 500 mg in 1 drum , tablet, metformin hcl 500 mg/kg, 50 kg in 1 drum , powder, 5-fluorouracil 500 g/500g, 500 g in 1 container , powder, metformin er 500 mg 50...| [-, -, -, 70010049105, -, -, -, -, -, -, -, -, -, -, -, 71800000801|42571036007, -, -, -, -, -, -, -, -, -]| +-++--++--+--+--+ sbiobertresolve_loinc_augmented : This model maps extracted clinical NER entities to LOINC codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It is trained on the augmented version of the dataset which is used in previous LOINC resolver models. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_loinc_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;loinc_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) .setCaseSensitive(False) ... sample_text=&quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a Body mass index (BMI) of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%.&quot;&quot;&quot; result = resolver_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +--+--+++-+--+--+ | chunk|begin|end|entity|Loinc_Code| all_codes| resolutions| +--+--+++-+--+--+ | Body mass index| 74| 88| Test| LP35925-4|LP35925-4:::BDYCRC:::LP172732-2:::39156-5:::LP7...|body mass index:::body circumference:::body mus...| |aspartate aminotransferase| 111|136| Test| LP15426-7|LP15426-7:::14409-7:::LP307348-5:::LP15333-5:::...|aspartate aminotransferase::: aspartate transam...| | alanine aminotransferase| 146|169| Test| LP15333-5|LP15333-5:::LP307326-1:::16324-6:::LP307348-5::...|alanine aminotransferase:::alanine aminotransfe...| | hgba1c| 180|185| Test| 17855-8|17855-8:::4547-6:::55139-0:::72518-4:::45190-6:...| hba1c::: hgb a1::: hb1::: hcds1::: hhc1::: htr...| +--+--+++-+--+--+ sbiobertresolve_clinical_snomed_procedures_measurements : This model maps medical entities to SNOMED codes using sent_biobert_clinical_base_cased Sentence Bert Embeddings. The corpus of this model includes Procedures and Measurement domains. Example : ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_clinical_snomed_procedures_measurements&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) ... light_model = LightPipeline(resolver_model) result = light_model.fullAnnotate([&#39;coronary calcium score&#39;, &#39;heart surgery&#39;, &#39;ct scan&#39;, &#39;bp value&#39;]) Results : | | chunk | code | code_description | all_k_codes | all_k_resolutions | |:|:--|-:|:|:--|:-| | 0 | coronary calcium score | 450360000 | Coronary artery calcium score | [&#39;450360000&#39;, &#39;450734004&#39;, &#39;1086491000000104&#39;, &#39;1086481000000101&#39;, &#39;762241007&#39;] | [&#39;Coronary artery calcium score&#39;, &#39;Coronary artery calcium score&#39;, &#39;Dundee Coronary Risk Disk score&#39;, &#39;Dundee Coronary Risk rank&#39;, &#39;Dundee Coronary Risk Disk&#39;] | | 1 | heart surgery | 2598006 | Open heart surgery | [&#39;2598006&#39;, &#39;64915003&#39;, &#39;119766003&#39;, &#39;34068001&#39;, &#39;233004008&#39;] | [&#39;Open heart surgery&#39;, &#39;Operation on heart&#39;, &#39;Heart reconstruction&#39;, &#39;Heart valve replacement&#39;, &#39;Coronary sinus operation&#39;] | | 2 | ct scan | 303653007 | CT of head | [&#39;303653007&#39;, &#39;431864000&#39;, &#39;363023007&#39;, &#39;418272005&#39;, &#39;241577003&#39;] | [&#39;CT of head&#39;, &#39;CT guided injection&#39;, &#39;CT of site&#39;, &#39;CT angiography&#39;, &#39;CT of spine&#39;] | | 3 | bp value | 75367002 | Blood pressure | [&#39;75367002&#39;, &#39;6797001&#39;, &#39;723232008&#39;, &#39;46973005&#39;, &#39;427732000&#39;] | [&#39;Blood pressure&#39;, &#39;Mean blood pressure&#39;, &#39;Average blood pressure&#39;, &#39;Blood pressure taking&#39;, &#39;Speed of blood pressure response&#39;] | Updated RxNorm Sentence Entity Resolver Model We have updated sbiobertresolve_rxnorm_augmented model training on an augmented version of the dataset used in previous versions of the model. New Shift Days Feature in StructuredDeid Deidentification Module Now we can shift n days in the structured deidentification when the column is a Date. Example : df = spark.createDataFrame([ [&quot;Juan García&quot;, &quot;13/02/1977&quot;, &quot;711 Nulla St.&quot;, &quot;140&quot;, &quot;673 431234&quot;], [&quot;Will Smith&quot;, &quot;23/02/1977&quot;, &quot;1 Green Avenue.&quot;, &quot;140&quot;, &quot;+23 (673) 431234&quot;], [&quot;Pedro Ximénez&quot;, &quot;11/04/1900&quot;, &quot;Calle del Libertador, 7&quot;, &quot;100&quot;, &quot;912 345623&quot;] ]).toDF(&quot;NAME&quot;, &quot;DOB&quot;, &quot;ADDRESS&quot;, &quot;SBP&quot;, &quot;TEL&quot;) obfuscator = StructuredDeidentification(spark=spark, columns={&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, columnsSeed={&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, obfuscateRefSource=&quot;faker&quot;, days=5 ) result = obfuscator.obfuscateColumns(self.df) result.show(truncate=False) Results : +-++--++-+ |NAME |DOB |ADDRESS |SBP|TEL | +-++--++-+ |[T1825511]|[18/02/1977]|711 Nulla St. |140|673 431234 | |[G6835267]|[28/02/1977]|1 Green Avenue. |140|+23 (673) 431234| |[S2371443]|[16/04/1900]|Calle del Libertador, 7|100|912 345623 | +-++--++-+ New Multiple Chunks Merge Ability in ChunkMergeApproach Updated ChunkMergeApproach to admit N input cols (.setInputCols(&quot;ner_chunk&quot;,&quot;ner_chunk_1&quot;,&quot;ner_chunk_2&quot;)). The input columns must be chunk columns. Example : ... deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_large&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList([&#39;DATE&#39;, &#39;AGE&#39;, &#39;NAME&#39;, &#39;PROFESSION&#39;, &#39;ID&#39;]) medical_ner = MedicalNerModel.pretrained(&quot;ner_events_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner2&quot;) ner_converter_2 = NerConverter() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner2&quot;]) .setOutputCol(&quot;ner_chunk_2&quot;) ssn_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity_ssn&quot;) .setJsonPath(&quot;../../src/test/resources/ssn.json&quot;) .setCaseSensitive(False) .setContextMatch(False) chunk_merge = ChunkMergeApproach() .setInputCols(&quot;entity_ssn&quot;,&quot;ner_chunk&quot;,&quot;ner_chunk_2&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) .setChunkPrecedence(&quot;field&quot;) ... New setBlackList Feature in ChunkMergeApproach Now we can filter out the entities in the ChunkMergeApproach using a black list .setBlackList([&quot;NAME&quot;,&quot;ID&quot;]). The entities specified in the blackList will be excluded from the final entity list. Example : chunk_merge = ChunkMergeApproach() .setInputCols(&quot;entity_ssn&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;deid_merged_chunk&quot;) .setBlackList([&quot;NAME&quot;,&quot;ID&quot;]) New setBlackList Feature in NerConverterInternal Now we can filter out the entities in the NerConverterInternal using a black list .setBlackList([&quot;Drug&quot;,&quot;Treatment&quot;]). The entities specified in the blackList will be excluded from the final entity list. Example : ner = MedicalNerModel.pretrained(&quot;ner_jsl_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;) .setOutputCol(&quot;ner&quot;) converter = NerConverterInternal() .setInputCols(&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;) .setOutputCol(&quot;entities&quot;) .setBlackList([&quot;Drug&quot;,&quot;Treatment&quot;]) New setLabelCasing Feature in MedicalNerModel Now we can decide if we want to return the tags in upper or lower case with setLabelCasing(). That method convert the I-tags and B-tags in lower or upper case during the inference. The values will be ‘lower’ for lower case and ‘upper’ for upper case. Example : ... ner_tagger = MedicalNerModel() .pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) .setLabelCasing(&quot;lower&quot;) ... results = LightPipeline(pipelineModel).annotate(&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus &quot;) results[&quot;ner_tags&quot;] Results : [&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;, &#39;I-problem&#39;] New Update Models Functionality We developed a new utility function called UpdateModels that allows you to refresh your cache_pretrained folder without running any annotator or manually checking. It has two methods; UpdateModels.updateCacheModels() : This method lets you update all the models existing in the cache_pretrained folder. It downloads the latest version of all the models existing in the cache_pretrained. Example : # Models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ # Update models in /cache_pretrained from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateCacheModels() Results : # Updated models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ UpdateModels.updateModels(&quot;11/24/2021&quot;) : This method lets you download all the new models uploaded to the Models Hub starting from a cut-off date (i.e. the last sync update). Example : # Models in /cache_pretrained ls ~/cache_pretrained &gt;&gt; ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ # Update models in /cache_pretrained according to date from sparknlp_jsl.updateModels import UpdateModels UpdateModels.updateModels(&quot;11/24/2021&quot;) Results : # Updated models in /cache_pretrained ls ~/cache_pretrained &gt;&gt;ner_clinical_large_en_3.0.0_2.3_1617206114650/ ner_clinical_large_en_3.0.0_3.0_1617206114650/ ner_model_finder_en_3.3.2_2.4_1637761259895/ sbertresolve_ner_model_finder_en_3.3.2_2.4_1637764208798/ New and Updated Notebooks We have a new Connect to Annotation Lab via API Notebook you can find how to; upload pre-annotations to ALAB import a project form ALAB and convert to CoNLL file upload tasks without pre-annotations We have updated Clinical Relation Extraction Notebook by adding a Relation Extraction Model-NER Model-Relation Pairs table that can be used to get the most optimal results when using these models. To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_3_4"
  },
  "1424": {
    "id": "1424",
    "title": "Spark NLP release notes 3.4.0",
    "content": "3.4.0 Release date: 30-06-2021 Overview Signature Detection in image-based documents. More details please read in Signature Detection in Spark OCR New Features ImageSignatureDetector is a DL model for detecting signature on the image. New notebooks Image Signature Detection example Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_4_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_4_0"
  },
  "1425": {
    "id": "1425",
    "title": "Spark NLP for Healthcare Release Notes 3.4.0",
    "content": "3.4.0 We are glad to announce that Spark NLP Healthcare 3.4.0 has been released! This is a massive release: new features, new models, academic papers, and more! Highlights New German Deidentification NER Models New German Deidentification Pretrained Pipeline New Clinical NER Models New AnnotationMerger Annotator New MedicalBertForTokenClassifier Annotator New BERT-Based Clinical NER Models New Clinical Relation Extraction Models New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models New ICD10 to ICD9 Code Mapping Pretrained Pipeline New Clinical Sentence Embedding Models Printing Validation and Test Logs for MedicalNerApproach and AssertionDLApproach Filter Only the Regex Entities Feature in Deidentification Annotator Add .setMaskingPolicy Parameter in Deidentification Annotator Add .cache_folder Parameter in UpdateModels.updateCacheModels() S3 Access Credentials No Longer Shipped Along Licenses Enhanced Security for the Library and log4shell Update New Peer-Reviewed Conference Paper on Clinical Relation Extraction New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction New and Updated Notebooks New German Deidentification NER Models We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in German. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 7 PHI entities in German (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 12 PHI sub-entities in German (PATIENT, HOSPITAL, DATE, ORGANIZATION, CITY, STREET, USERNAME, PROFESSION, PHONE, COUNTRY, DOCTOR, AGE). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;de&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;de&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Michael Berger wird am Morgen des 12 Dezember 2018 ins St. Elisabeth-Krankenhaus in Bad Kissingen eingeliefert. Herr Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : +-+-+-+ |chunk |ner_deid_generic_chunk|ner_deid_subentity_chunk | +-+-+-+ |Michael Berger |NAME |PATIENT | |12 Dezember 2018 |DATE |DATE | |St. Elisabeth-Krankenhaus|LOCATION |HOSPITAL | |Bad Kissingen |LOCATION |CITY | |Berger |NAME |PATIENT | |76 |AGE |AGE | +-+-+-+ New German Deidentification Pretrained Pipeline We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from German medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate PATIENT, HOSPITAL, DATE, ORGANIZATION, CITY, STREET, USERNAME, PROFESSION, PHONE, COUNTRY, DOCTOR, AGE, CONTACT, ID, PHONE, ZIP, ACCOUNT, SSN, DLN, PLATE entities. Example : ... from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;de&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;Zusammenfassung : Michael Berger wird am Morgen des 12 Dezember 2018 ins St.Elisabeth Krankenhaus in Bad Kissingen eingeliefert. Herr Michael Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: T0110053F Platte A-BC124 Kontonummer: DE89370400440532013000 SSN : 13110587M565 Lizenznummer: B072RRE2I55 Adresse : St.Johann-Straße 13 19300&quot;&quot;&quot; result = deid_pipe.annotate(text) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) Results : Zusammenfassung : &lt;PATIENT&gt; wird am Morgen des &lt;DATE&gt; ins &lt;HOSPITAL&gt; eingeliefert. Herr &lt;PATIENT&gt; ist &lt;AGE&gt; Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: &lt;ID&gt; Platte &lt;PLATE&gt; Kontonummer: &lt;ACCOUNT&gt; SSN : &lt;SSN&gt; Lizenznummer: &lt;DLN&gt; Adresse : &lt;STREET&gt; &lt;ZIP&gt; Zusammenfassung : Herrmann Kallert wird am Morgen des 11-26-1977 ins International Neuroscience eingeliefert. Herr Herrmann Kallert ist 79 Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: 136704D357 Platte QA348G Kontonummer: 192837465738 SSN : 1310011981M454 Lizenznummer: XX123456 Adresse : Klingelhöferring 31206 Zusammenfassung : **** wird am Morgen des **** ins **** eingeliefert. Herr **** ist **** Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: **** Platte **** Kontonummer: **** SSN : **** Lizenznummer: **** Adresse : **** **** Zusammenfassung : [************] wird am Morgen des [**************] ins [**********************] eingeliefert. Herr [************] ist ** Jahre alt und hat zu viel Wasser in den Beinen. Persönliche Daten : ID-Nummer: [*******] Platte [*****] Kontonummer: [********************] SSN : [**********] Lizenznummer: [*********] Adresse : [*****************] [***] New Clinical NER Models We have two new clinical NER models. ner_abbreviation_clinical : This model is trained to extract clinical abbreviations and acronyms in texts and labels these entities as ABBR. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_abbreviation_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;]], [&quot;text&quot;])) Results : +--++ |chunk|ner_label| +--++ |CBC |ABBR | |AB |ABBR | |VDRL |ABBR | |HIV |ABBR | +--++ ner_drugprot_clinical : This model detects chemical compounds/drugs and genes/proteins in medical text and research articles. Here are the labels it can detect : GENE, CHEMICAL, GENE_AND_CHEMICAL. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_drugprot_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Anabolic effects of clenbuterol on skeletal muscle are mediated by beta 2-adrenoceptor activation&quot;]], [&quot;text&quot;])) Results : | | chunk | ner_label | |:|:|:| | 0 | clenbuterol | CHEMICAL | | 1 | beta 2-adrenoceptor | GENE | New AnnotationMerger Annotator A new annotator: AnnotationMerger. Besides NERs, now we will be able to merge results of Relation Extraction models and Assertion models as well. Therefore, it can merge results of Relation Extraction models, NER models, and Assertion Status models. Example-1 : ... annotation_merger = AnnotationMerger() .setInputCols(&quot;ade_relations&quot;, &quot;pos_relations&quot;, &quot;events_relations&quot;) .setInputType(&quot;category&quot;) .setOutputCol(&quot;all_relations&quot;) ... results = ann_merger_model.transform(spark.createDataFrame([[&quot;The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.&quot;]], [&quot;text&quot;])) Results-1 : | | all_relations | all_relations_entity1 | all_relations_chunk1 | all_relations_entity2 | all_relations_chunk2 | |:|:-|:|:--|:|:-| | 0 | 1 | DRUG | oxaprozin | ADE | tense bullae | | 1 | 1 | DRUG | oxaprozin | ADE | cutaneous fragility on the face and the back of the hands | | 2 | DOSAGE-DRUG | DOSAGE | 1 unit | DRUG | naproxen | | 3 | DRUG-DURATION | DRUG | naproxen | DURATION | for 5 days | | 4 | DOSAGE-DRUG | DOSAGE | 1 unit | DRUG | oxaprozin | | 5 | DRUG-FREQUENCY | DRUG | oxaprozin | FREQUENCY | daily | | 6 | OVERLAP | TREATMENT | naproxen | DURATION | 5 days | | 7 | OVERLAP | TREATMENT | oxaprozin | FREQUENCY | daily | | 8 | BEFORE | TREATMENT | oxaprozin | PROBLEM | rheumatoid arthritis | | 9 | AFTER | TREATMENT | oxaprozin | OCCURRENCE | presented | | 10 | OVERLAP | FREQUENCY | daily | PROBLEM | rheumatoid arthritis | | 11 | OVERLAP | FREQUENCY | daily | PROBLEM | tense bullae | | 12 | OVERLAP | FREQUENCY | daily | PROBLEM | cutaneous fragility on the face | | 13 | BEFORE | PROBLEM | rheumatoid arthritis | OCCURRENCE | presented | | 14 | OVERLAP | PROBLEM | rheumatoid arthritis | PROBLEM | tense bullae | | 15 | OVERLAP | PROBLEM | rheumatoid arthritis | PROBLEM | cutaneous fragility on the face | | 16 | BEFORE | OCCURRENCE | presented | PROBLEM | tense bullae | | 17 | BEFORE | OCCURRENCE | presented | PROBLEM | cutaneous fragility on the face | | 18 | OVERLAP | PROBLEM | tense bullae | PROBLEM | cutaneous fragility on the face | Example-2 : ... ner_annotation_merger = AnnotationMerger() .setInputCols(&quot;ner_chunk&quot;, &quot;radiology_ner_chunk&quot;, &quot;jsl_ner_chunk&quot;) .setInputType(&quot;chunk&quot;) .setOutputCol(&quot;all_ners&quot;) assertion_annotation_merger = AnnotationMerger() .setInputCols(&quot;clinical_assertion&quot;, &quot;radiology_assertion&quot;, &quot;jsl_assertion&quot;) .setInputType(&quot;assertion&quot;) .setOutputCol(&quot;all_assertions&quot;) ... results = ann_merger_model.transform(spark.createDataFrame([[&quot;The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.&quot;]], [&quot;text&quot;])) Results-2 : | | ners | all_assertions | |:|:--|:--| | 0 | naproxen | present | | 1 | chronic low back pain | present | | 2 | oxaprozin | present | | 3 | rheumatoid arthritis | present | | 4 | tense bullae | present | | 5 | cutaneous fragility on the face | present | | 6 | low back | Confirmed | | 7 | pain | Confirmed | | 8 | rheumatoid arthritis | Confirmed | | 9 | tense bullae | Confirmed | | 10 | cutaneous | Confirmed | | 11 | fragility | Confirmed | | 12 | face | Confirmed | | 13 | back | Confirmed | | 14 | hands | Confirmed | | 15 | 1 unit | Present | | 16 | naproxen | Past | | 17 | for 5 days | Past | | 18 | chronic | Someoneelse | | 19 | low | Past | | 20 | back pain | Present | | 21 | 1 unit | Past | | 22 | oxaprozin | Past | | 23 | daily | Past | | 24 | rheumatoid arthritis | Present | | 25 | tense | Present | | 26 | bullae | Present | | 27 | cutaneous fragility | Present | | 28 | face | Someoneelse | | 29 | back of the hands | Present | New MedicalBertForTokenClassifier Annotator We developed a new annotator called MedicalBertForTokenClassifier that can load BERT-Based clinical token classifier models head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. New BERT-Based Clinical NER Models Here are the MedicalBertForTokenClassifier Models we have in the library at the moment: bert_token_classifier_ner_ade bert_token_classifier_ner_anatomy bert_token_classifier_ner_bionlp bert_token_classifier_ner_cellular bert_token_classifier_ner_chemprot bert_token_classifier_ner_chemicals bert_token_classifier_ner_jsl_slim bert_token_classifier_ner_jsl bert_token_classifier_ner_deid bert_token_classifier_ner_drugs bert_token_classifier_ner_clinical bert_token_classifier_ner_bacteria In addition, we are releasing a new BERT-Based clinical NER model named bert_token_classifier_drug_development_trials. It is a MedicalBertForTokenClassification NER model to identify concepts related to drug development including Trial Groups , End Points , Hazard Ratio, and other entities in free text. It can detect the following entities: Patient_Count, Duration, End_Point, Value, Trial_Group, Hazard_Ratio, Total_Patients Example : ... tokenClassifier= MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_drug_development_trials&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... results = ner_model.transform(spark.createDataFrame([[&quot;In June 2003, the median overall survival with and without topotecan were 4.0 and 3.6 months, respectively. The best complete response ( CR ) , partial response ( PR ) , stable disease and progressive disease were observed in 23, 63, 55 and 33 patients, respectively, with topotecan, and 11, 61, 66 and 32 patients, respectively, without topotecan.&quot;]], [&quot;text&quot;])) Results : | | chunk | entity | |:|:|:--| | 0 | median | Duration | | 1 | overall survival | End_Point | | 2 | with | Trial_Group | | 3 | without topotecan | Trial_Group | | 4 | 4.0 | Value | | 5 | 3.6 months | Value | | 6 | 23 | Patient_Count | | 7 | 63 | Patient_Count | | 8 | 55 | Patient_Count | | 9 | 33 patients | Patient_Count | | 10 | topotecan | Trial_Group | | 11 | 11 | Patient_Count | | 12 | 61 | Patient_Count | | 13 | 66 | Patient_Count | | 14 | 32 patients | Patient_Count | | 15 | without topotecan | Trial_Group | New Clinical Relation Extraction Models We have two new clinical Relation Extraction models for detecting interactions between drugs and proteins. These models work hand-in-hand with the new ner_drugprot_clinical NER model and detect following relations between entities: INHIBITOR, DIRECT-REGULATOR, SUBSTRATE, ACTIVATOR, INDIRECT-UPREGULATOR, INDIRECT-DOWNREGULATOR, ANTAGONIST, PRODUCT-OF, PART-OF, AGONIST. redl_drugprot_biobert : This model was trained using BERT and performs with higher accuracy. re_drugprot_clinical : This model was trained using RelationExtractionApproach(). Example : ... drugprot_ner_tagger = MedicalNerModel.pretrained(&quot;ner_drugprot_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;sentences&quot;, &quot;tokens&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;ner_tags&quot;) ... drugprot_re_biobert = RelationExtractionDLModel() .pretrained(&#39;redl_drugprot_biobert&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setPredictionThreshold(0.9) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) drugprot_re_clinical = RelationExtractionModel() .pretrained(&quot;re_drugprot_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(4) .setPredictionThreshold(0.9) .setRelationPairs([&#39;CHEMICAL-GENE&#39;]) ... sample_text = &quot;Lipid specific activation of the murine P4-ATPase Atp8a1 (ATPase II). The asymmetric transbilayer distribution of phosphatidylserine (PS) in the mammalian plasma membrane and secretory vesicles is maintained, in part, by an ATP-dependent transporter. This aminophospholipid &quot;flippase&quot; selectively transports PS to the cytosolic leaflet of the bilayer and is sensitive to vanadate, Ca(2+), and modification by sulfhydryl reagents. Although the flippase has not been positively identified, a subfamily of P-type ATPases has been proposed to function as transporters of amphipaths, including PS and other phospholipids. A candidate PS flippase ATP8A1 (ATPase II), originally isolated from bovine secretory vesicles, is a member of this subfamily based on sequence homology to the founding member of the subfamily, the yeast protein Drs2, which has been linked to ribosomal assembly, the formation of Golgi-coated vesicles, and the maintenance of PS asymmetry.&quot; result = re_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : ++--+-+--+--+-+-+--+--+-+ | relation| entity1|entity1_begin|entity1_end| chunk1|entity2|entity2_begin|entity2_end| chunk2|confidence| ++--+-+--+--+-+-+--+--+-+ |SUBSTRATE|CHEMICAL| 308| 310| PS| GENE| 275| 283| flippase| 0.998399| |ACTIVATOR|CHEMICAL| 1563| 1578| sn-1,2-glycerol| GENE| 1479| 1509|plasma membrane P...| 0.999304| |ACTIVATOR|CHEMICAL| 1563| 1578| sn-1,2-glycerol| GENE| 1511| 1517| Atp8a1| 0.979057| ++--+-+--+--+-+-+--+--+-+ New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models We have five new Sentence Entity Resolver models. sbiobertresolve_clinical_abbreviation_acronym : This model maps clinical abbreviations and acronyms to their meanings using sbiobert_base_cased_mli Sentence Bert Embeddings. It is a part of ongoing research we have been running in-house, and trained with a limited dataset. We’ll be updating &amp; enriching the model in the upcoming releases. Example : ... abbr_resolver = SentenceEntityResolverModel.pretraind(&quot;sbiobertresolve_clinical_abbreviation_acronym&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;merged_chunk&quot;, &quot;sentence_embeddings&quot;]) .setOutputCol(&quot;abbr_meaning&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;HISTORY OF PRESENT ILLNESS: The patient three weeks ago was seen at another clinic for upper respiratory infection-type symptoms. She was diagnosed with a viral infection and had used OTC medications including Tylenol, Sudafed, and Nyquil.&quot; results = abb_model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : | sent_id | ner_chunk | entity | abbr_meaning | all_k_results | all_k_resolutions | |-:|:|:|:--|:--|:| | 0 | OTC | ABBR | over the counter | [&#39;over the counter&#39;, &#39;ornithine transcarbamoylase&#39;, &#39;enteric-coated&#39;, &#39;thyroxine&#39;] | [&#39;OTC&#39;, &#39;OTC&#39;, &#39;EC&#39;, &#39;T4&#39;] | sbiobertresolve_umls_drug_substance : This model maps clinical entities to UMLS CUI codes. It is trained on 2021AB UMLS dataset. The complete dataset has 127 different categories, and this model is trained on the Clinical Drug, Pharmacologic Substance, Antibiotic, Hazardous or Poisonous Substance categories using sbiobert_base_cased_mli embeddings. Example : ... umls_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_umls_drug_substance&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... results = model.fullAnnotate([&#39;Dilaudid&#39;, &#39;Hydromorphone&#39;, &#39;Exalgo&#39;, &#39;Palladone&#39;, &#39;Hydrogen peroxide 30 mg&#39;, &#39;Neosporin Cream&#39;, &#39;Magnesium hydroxide 100mg/1ml&#39;, &#39;Metformin 1000 mg&#39;]) Results : | | chunk | code | code_description | all_k_code_desc | all_k_codes | |:|:|:|:|:-|:-| | 0 | Dilaudid | C0728755 | dilaudid | [&#39;C0728755&#39;, &#39;C0719907&#39;, &#39;C1448344&#39;, &#39;C0305924&#39;, &#39;C1569295&#39;] | [&#39;dilaudid&#39;, &#39;Dilaudid HP&#39;, &#39;Disthelm&#39;, &#39;Dilaudid Injection&#39;, &#39;Distaph&#39;] | | 1 | Hydromorphone | C0012306 | HYDROMORPHONE | [&#39;C0012306&#39;, &#39;C0700533&#39;, &#39;C1646274&#39;, &#39;C1170495&#39;, &#39;C0498841&#39;] | [&#39;HYDROMORPHONE&#39;, &#39;Hydromorphone HCl&#39;, &#39;Phl-HYDROmorphone&#39;, &#39;PMS HYDROmorphone&#39;, &#39;Hydromorphone injection&#39;] | | 2 | Exalgo | C2746500 | Exalgo | [&#39;C2746500&#39;, &#39;C0604734&#39;, &#39;C1707065&#39;, &#39;C0070591&#39;, &#39;C3660437&#39;] | [&#39;Exalgo&#39;, &#39;exaltolide&#39;, &#39;Exelgyn&#39;, &#39;Extacol&#39;, &#39;exserohilone&#39;] | | 3 | Palladone | C0730726 | palladone | [&#39;C0730726&#39;, &#39;C0594402&#39;, &#39;C1655349&#39;, &#39;C0069952&#39;, &#39;C2742475&#39;] | [&#39;palladone&#39;, &#39;Palladone-SR&#39;, &#39;Palladone IR&#39;, &#39;palladiazo&#39;, &#39;palladia&#39;] | | 4 | Hydrogen peroxide 30 mg | C1126248 | hydrogen peroxide 30 MG/ML | [&#39;C1126248&#39;, &#39;C0304655&#39;, &#39;C1605252&#39;, &#39;C0304656&#39;, &#39;C1154260&#39;] | [&#39;hydrogen peroxide 30 MG/ML&#39;, &#39;Hydrogen peroxide solution 30%&#39;, &#39;hydrogen peroxide 30 MG/ML [Proxacol]&#39;, &#39;Hydrogen peroxide 30 mg/mL cutaneous solution&#39;, &#39;benzoyl peroxide 30 MG/ML&#39;] | | 5 | Neosporin Cream | C0132149 | Neosporin Cream | [&#39;C0132149&#39;, &#39;C0306959&#39;, &#39;C4722788&#39;, &#39;C0704071&#39;, &#39;C0698988&#39;] | [&#39;Neosporin Cream&#39;, &#39;Neosporin Ointment&#39;, &#39;Neomycin Sulfate Cream&#39;, &#39;Neosporin Topical Ointment&#39;, &#39;Naseptin cream&#39;] | | 6 | Magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 MG | [&#39;C1134402&#39;, &#39;C1126785&#39;, &#39;C4317023&#39;, &#39;C4051486&#39;, &#39;C4047137&#39;] | [&#39;magnesium hydroxide 100 MG&#39;, &#39;magnesium hydroxide 100 MG/ML&#39;, &#39;Magnesium sulphate 100mg/mL injection&#39;, &#39;magnesium sulfate 100 MG&#39;, &#39;magnesium sulfate 100 MG/ML&#39;] | | 7 | Metformin 1000 mg | C0987664 | metformin 1000 MG | [&#39;C0987664&#39;, &#39;C2719784&#39;, &#39;C0978482&#39;, &#39;C2719786&#39;, &#39;C4282269&#39;] | [&#39;metformin 1000 MG&#39;, &#39;metFORMIN hydrochloride 1000 MG&#39;, &#39;METFORMIN HCL 1000MG TAB&#39;, &#39;metFORMIN hydrochloride 1000 MG [Fortamet]&#39;, &#39;METFORMIN HCL 1000MG SA TAB&#39;] | sbiobertresolve_loinc_cased : This model maps extracted clinical NER entities to LOINC codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It is trained with augmented cased concept names since sbiobert model is cased. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_loinc_cased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hemoglobin is 8.2%.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]], [&quot;text&quot;])) Results : +-++--+-+--+ | ner_chunk|entity| resolution| all_codes| resolutions| +-++--+-+--+ | BMI| Test| LP35925-4|[LP35925-4, 59574-4, BDYCRC, 73964-9, 59574-4,... |[Body mass index (BMI), Body mass index, Body circumference, Body muscle mass, Body mass index (BMI) [Percentile], ... | | aspartate aminotransferase| Test| 14409-7|[14409-7, 1916-6, 16325-3, 16324-6, 43822-6, 308... |[Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Alanine aminotransferase, Aspartate aminotransferase [Prese... | | alanine aminotransferase| Test| 16324-6|[16324-6, 16325-3, 14409-7, 1916-6, 59245-1, 30... |[Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine glyoxylate aminotransfer,... | | hemoglobin| Test| 14775-1|[14775-1, 16931-8, 12710-0, 29220-1, 15082-1, 72... |[Hemoglobin, Hematocrit/Hemoglobin, Hemoglobin pattern, Haptoglobin, Methemoglobin, Oxyhemoglobin, Hemoglobin test status, Verdohemoglobin, Hemoglobin A, Hemoglobin distribution width, Myoglobin,... | +-++--+-+--+ sbluebertresolve_loinc_uncased : This model maps extracted clinical NER entities to LOINC codes using sbluebert_base_uncased_mli Sentence Bert Embeddings. It trained on the augmented version of the uncased (lowercased) dataset which is used in previous LOINC resolver models. Example : ... loinc_resolver = SentenceEntityResolverModel.pretrained(&quot;sbluebertresolve_loinc_uncased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[sample_text]], [&quot;text&quot;])) Results : +-++--+-+--+ | ner_chunk|entity| resolution| all_codes| resolutions| +-++--+-+--+ | BMI| Test| 39156-5|[39156-5, LP35925-4, BDYCRC, 73964-9, 59574-4,...] |[Body mass index, Body mass index (BMI), Body circumference, Body muscle mass, Body mass index (BMI) [Percentile], ...] | | aspartate aminotransferase| Test| 14409-7|[&#39;14409-7&#39;, &#39;16325-3&#39;, &#39;1916-6&#39;, &#39;16324-6&#39;,...] |[&#39;Aspartate aminotransferase&#39;, &#39;Alanine aminotransferase/Aspartate aminotransferase&#39;, &#39;Aspartate aminotransferase/Alanine aminotransferase&#39;, &#39;Alanine aminotransferase&#39;, ...] | | alanine aminotransferase| Test| 16324-6|[&#39;16324-6&#39;, &#39;1916-6&#39;, &#39;16325-3&#39;, &#39;59245-1&#39;,...] |[&#39;Alanine aminotransferase&#39;, &#39;Aspartate aminotransferase/Alanine aminotransferase&#39;, &#39;Alanine aminotransferase/Aspartate aminotransferase&#39;, &#39;Alanine glyoxylate aminotransferase&#39;,...] | | hgba1c| Test| 41995-2|[&#39;41995-2&#39;, &#39;LP35944-5&#39;, &#39;LP19717-5&#39;, &#39;43150-2&#39;,...]|[&#39;Hemoglobin A1c&#39;, &#39;HbA1c measurement device&#39;, &#39;HBA1 gene&#39;, &#39;HbA1c measurement device panel&#39;, ...] | +-++--+++ sbiobertresolve_snomed_drug : This model maps detected drug entities to SNOMED codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example : ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_snomed_drug&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;She is given Fragmin 5000 units subcutaneously daily, OxyContin 30 mg p.o. q.12 h., folic acid 1 mg daily, levothyroxine 0.1 mg p.o. daily, Avandia 4 mg daily, aspirin 81 mg daily, Neurontin 400 mg p.o. t.i.d., magnesium citrate 1 bottle p.o. p.r.n., sliding scale coverage insulin.&quot; results = model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : +--++--+--+++ | ner_chunk|entity| snomed_code| resolved_text| all_k_results| all_k_resolutions| +--++--+--+++ | Fragmin| DRUG| 9487801000001106| Fragmin|9487801000001106:::130752006:::28999000:::953500100000110...|Fragmin:::Fragilysin:::Fusarin:::Femulen:::Fumonisin:::Fr...| | OxyContin| DRUG| 9296001000001100| OxyCONTIN|9296001000001100:::373470001:::230091000001108:::55452001...|OxyCONTIN:::Oxychlorosene:::Oxyargin:::oxyCODONE:::Oxymor...| | folic acid| DRUG| 63718003| Folic acid|63718003:::6247001:::226316008:::432165000:::438451000124...|Folic acid:::Folic acid-containing product:::Folic acid s...| | levothyroxine| DRUG|10071011000001106| Levothyroxine|10071011000001106:::710809001:::768532006:::126202002:::7...|Levothyroxine:::Levothyroxine (substance):::Levothyroxine...| | Avandia| DRUG| 9217601000001109| avandia|9217601000001109:::9217501000001105:::12226401000001108::...|avandia:::avandamet:::Anatera:::Intanza:::Avamys:::Aragam...| | aspirin| DRUG| 387458008| Aspirin|387458008:::7947003:::5145711000001107:::426365001:::4125...|Aspirin:::Aspirin-containing product:::Aspirin powder:::A...| | Neurontin| DRUG| 9461401000001102| neurontin|9461401000001102:::130694004:::86822004:::952840100000110...|neurontin:::Neurolysin:::Neurine (substance):::Nebilet:::...| |magnesium citrate| DRUG| 12495006|Magnesium citrate|12495006:::387401007:::21691008:::15531411000001106:::408...|Magnesium citrate:::Magnesium carbonate:::Magnesium trisi...| | insulin| DRUG| 67866001| Insulin|67866001:::325072002:::414515005:::39487003:::411530000::...|Insulin:::Insulin aspart:::Insulin detemir:::Insulin-cont...| +--++--+--+++ New ICD10 to ICD9 Code Mapping Pretrained Pipeline We are releasing new icd10_icd9_mapping pretrained pipeline. This pretrained pipeline maps ICD10 codes to ICD9 codes without using any text data. You’ll just feed a comma or white space-delimited ICD10 codes and it will return the corresponding ICD9 codes as a list. Example : from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;icd10_icd9_mapping&quot;, &quot;en&quot;, &quot;clinical/models&quot;) pipeline.annotate(&#39;E669 R630 J988&#39;) Results : {&#39;document&#39;: [&#39;E669 R630 J988&#39;], &#39;icd10&#39;: [&#39;E669&#39;, &#39;R630&#39;, &#39;J988&#39;], &#39;icd9&#39;: [&#39;27800&#39;, &#39;7830&#39;, &#39;5198&#39;]} Code Descriptions: | | ICD10 | Details | |:|:|:--| | 0 | E669 | Obesity | | 1 | R630 | Anorexia | | 2 | J988 | Other specified respiratory disorders | | | ICD9 | Details | |:|:|:--| | 0 | 27800 | Obesity | | 1 | 7830 | Anorexia | | 2 | 5198 | Other diseases of respiratory system | New Clinical Sentence Embedding Models We have two new clinical Sentence Embedding models. sbiobert_jsl_rxnorm_cased : This model maps sentences &amp; documents to a 768 dimensional dense vector space by using average pooling on top of BioBert model. It’s also fine-tuned on RxNorm dataset to help generalization over medication-related datasets. Example : ... sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbiobert_jsl_rxnorm_cased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;sbioert_embeddings&quot;) ... sbert_jsl_medium_rxnorm_uncased : This model maps sentences &amp; documents to a 512-dimensional dense vector space by using average pooling on top of BERT model. It’s also fine-tuned on the RxNorm dataset to help generalization over medication-related datasets. Example : ... sentence_embeddings = BertSentenceEmbeddings.pretrained(&quot;sbert_jsl_medium_rxnorm_uncased&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;sbert_embeddings&quot;) ... Printing Validation and Test Logs in MedicalNerApproach and AssertionDLApproach Now we can check validation loss and test loss for each epoch in the logs created during trainings of MedicalNerApproach and AssertionDLApproach. Epoch 15/15 started, lr: 9.345794E-4, dataset size: 1330 Epoch 15/15 - 56.65s - loss: 37.58828 - avg training loss: 1.7899181 - batches: 21 Quality on validation dataset (20.0%), validation examples = 266 time to finish evaluation: 8.11s Total validation loss: 15.1930 Avg validation loss: 2.5322 label tp fp fn prec rec f1 I-Disease 707 72 121 0.9075738 0.8538647 0.8799004 B-Disease 657 81 60 0.8902439 0.916318 0.90309274 tp: 1364 fp: 153 fn: 181 labels: 2 Macro-average prec: 0.89890885, rec: 0.88509136, f1: 0.8919466 Micro-average prec: 0.89914304, rec: 0.8828479, f1: 0.89092094 Quality on test dataset: time to finish evaluation: 9.11s Total test loss: 17.7705 Avg test loss: 1.6155 label tp fp fn prec rec f1 I-Disease 663 113 126 0.85438144 0.8403042 0.8472843 B-Disease 631 122 77 0.8379814 0.8912429 0.86379194 tp: 1294 fp: 235 fn: 203 labels: 2 Macro-average prec: 0.8461814, rec: 0.86577356, f1: 0.85586536 Micro-average prec: 0.8463048, rec: 0.86439544, f1: 0.8552544 Filter Only the Regex Entities Feature in Deidentification Annotator The setBlackList() method will be able to filter just the detected Regex Entities. Before this change we filtered the chunks and the regex entities. Add .setMaskingPolicy Parameter in Deidentification Annotator Now we can have three modes to mask the entities in the Deidentification annotator. You can select the modes using the .setMaskingPolicy(&quot;entity_labels&quot;). The methods are the followings: “entity_labels”: Mask with the entity type of that chunk. (default) “same_length_chars”: Mask the deid entities with same length of asterix (*) with brackets ([,]) on both end. “fixed_length_chars”: Mask the deid entities with a fixed length of asterix (*). The length is setting up using the setFixedMaskLength(4) method. Given the following sentence John Snow is a good guy. the result will be: “entity_labels”: &lt;NAME&gt; is a good guy. “same_length_chars”: [*******] is a good guy. “fixed_length_chars”: **** is a good guy. Example Masked with entity labels DATE &lt;DATE&gt;, &lt;DOCTOR&gt;, The driver&#39;s license &lt;DLN&gt;. Masked with chars DATE [**********], [***********], The driver&#39;s license [*********]. Masked with fixed length chars DATE ****, ****, The driver&#39;s license ****. Obfuscated DATE 07-04-1981, Dr Vivian Irving, The driver&#39;s license K272344712994. Add .cache_folder Parameter in UpdateModels.updateCacheModels() This parameter lets user to define custom local paths for the folder on which pretrained models are saved (rather than using default cached_pretrained folder). This cache_folder must be a path (“hdfs:..”,”file:…”). UpdateModels.updateCacheModels(&quot;file:/home/jsl/cache_pretrained_2&quot;) UpdateModels.updateModels(&quot;12/01/2021&quot;,&quot;file:/home/jsl/cache_pretrained_2&quot;) The cache folder used by default is the folder loaded in the spark configuration ` spark.jsl.settings.pretrained.cache_folder.The default value for that property is ~/cache_pretrained` S3 Access Credentials No Longer Shipped Along Licenses S3 access credentials are no longer being shipped with licenses. Going forward, we’ll use temporal S3 access credentials which will be periodically refreshed. All this will happen automatically and will be transparent to the user. Still, for those users who would need to perform manual tasks involving access to S3, there’s a mechanism to get access to the set of credentials being used by the library at any given time. from sparknlp_jsl import get_credentials get_credentials(spark) Enhanced Security for the Library and log4shell Update On top of periodical security checks on the library code, 3rd party dependencies were analyzed, and some dependencies reported as containing vulnerabilities were replaced by more secure options. Also, the library was analyzed in the context of the recently discovered threat(CVE-2021-45105) on the log4j library. Spark NLP for Healthcare does not depend on the log4j library by itself, but the library gets loaded through some of its dependencies. It’s worth noting that the version of log4j dependency that will be in the classpath when running Spark NLP for Healthcare is 1.x, which would make the system vulnerable to CVE-2021-4104, instead of CVE-2021-45105. CVE-2021-4104 is related to the JMSAppender. Spark NLP for Healthcare does not provide any log4j configuration, so it’s up to the user to follow the recommendation of avoiding the use of the JMSAppender. New Peer-Reviewed Conference Paper on Clinical Relation Extraction We publish a new peer-reviewed conference paper titled Deeper Clinical Document Understanding Using Relation Extraction explaining the applications of Relation Extraction in a text mining framework comprising of Named Entity Recognition (NER) and Relation Extraction (RE) models. The paper is accepted to SDU (Scientific Document Understanding) workshop at AAAI-2022 conference and claims new SOTA scores on 5 out of 7 Biomedical &amp; Clinical Relation Extraction (RE) tasks. Dataset FCNN BioBERT Curr-SOTA i2b2-Temporal 68.7 73.6 72.41 i2b2-Clinical 60.4 69.1 67.97 DDI 69.2 72.1 84.1 CPI 65.8 74.3 88.9 PGR 81.2 87.9 79.4 ADE Corpus 89.2 90.0 83.7 Posology 87.8 96.7 96.1 Macro-averaged F1 scores of both RE models on public datasets. FCNN refers to the Speed-Optimized FCNN architecture, while BioBERT refers to the AccuracyOptimized BioBERT architecture. The SOTA metrics are obtained from (Guan et al. 2020), (Ningthoujam et al. 2019), (Asada, Miwa, and Sasaki 2020), (Phan et al. 2021), (Sousa and Couto 2020), (Crone 2020), and (Yang et al. 2021) respectively. New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction We publish a new peer-reviewed conference paper titled Mining Adverse Drug Reactions from Unstructured Mediums at Scale proposing an end-to-end Adverse Drug Event mining solution using Classification, NER, and Relation Extraction Models. The paper is accepted to W3PHIAI (INTERNATIONAL WORKSHOP ON HEALTH INTELLIGENCE) workshop at AAAI-2022 conference, and claims new SOTA scores on 1 benchmark dataset for Classification, 3 benchmark datasets for NER, and 1 benchmark dataset for Relation Extraction. Task Dataset Spark NLP Curr-SOTA Classification ADE 85.96 87.0 Classification CADEC 86.69 81.5 Entity Recognition ADE 91.75 91.3 Entity Recognition CADEC 78.36 71.9 Entity Recognition SMM4H 76.73 67.81 Relation Extraction ADE 90.0 83.7 All F1 scores are Macro-averaged New and Updated Notebooks We have two new Notebooks: Chunk Sentence Splitter Notebook that involves usage of ChunkSentenceSplitter annotator. Clinical Relation Extraction Spark NLP Paper Reproduce Notebook that can be used for reproducing the results in Deeper Clinical Document Understanding Using Relation Extraction paper. We have updated our existing notebooks by adding new features and functionalities. Here are updated notebooks: Clinical Named Entity Recognition Model Clinical Entity Resolver Models Clinical DeIdentification Clinical NER Chunk Merger Pretrained Clinical Pipelines Healthcare Code Mapping Improved Entity Resolvers in Spark NLP with sBert To see more, please check : Spark NLP Healthcare Workshop Repo Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_0"
  },
  "1426": {
    "id": "1426",
    "title": "Annotation Lab Release Notes 3.4.0",
    "content": "3.4.0 Release date: 01-08-2022 We are very excited to release Annotation Lab v3.4.0 with support for Visual NER Automated Preannotation and Model Training. Spark NLP and Spark NLP for Healthcare libraries are upgraded to version 4.0. As always known security and bug fixes are also included with it. Here are the highlights of this release: Highlights Visual NER Training support. Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. Floating or airgap licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Visual NER Preannotation. For running preannotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Preannotate button from the upper right side of the Tasks Page. The minimal required preannotation configuration is 32 GB RAM, 2 Core CPU for Visual NER Model. Spark NLP and Spark NLP for Healthcare upgrades. Annotation Lab 3.4.0 uses Spark NLP 4.0.0, Spark NLP for Healthcare 4.0.2 and Spark OCR 3.13.0. Confusion Matrix for Classification Projects. A checkbox is now added on the training page to enable the generation of confusion matrix for classification projects. The confusion matrix is visible in the live training logs as well as in the downloaded training logs. Project Import Improvements. The name of the imported project is set according to the name of the imported zip file. Users can now make changes in the content of the exported zip and then zip it back for import into Annotation Lab. Task Pagination in Labeling page. Tasks are paginated based on the number of characters they contain. Confidence filter slider is now visible only for preannotations. Previously the confidence filter was applied to both predictions and completions. Since all manual annotations have a confidence score of 1, we decided to only show and apply the confidence filter when the prediction widget is selected. Swagger Docs Changes. API docs have been restructured for an easier use and new methods have been added to mirror the new functionalities offered via the UI. Confidence score for Rules preannotations. Confidence of rule-based preannotations is now visible on the Labeling screen, the same as that of model-based preannotation. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_0"
  },
  "1427": {
    "id": "1427",
    "title": "Spark NLP for Healthcare Release Notes 3.4.1",
    "content": "3.4.1 We are glad to announce that Spark NLP Healthcare 3.4.1 has been released! Highlights Brand new Spanish deidentification NER models Brand new Spanish deidentification pretrained pipeline New clinical NER model to detect supplements New RxNorm sentence entity resolver model New EntityChunkEmbeddings annotator New MedicalBertForSequenceClassification annotator New MedicalDistilBertForSequenceClassification annotator New MedicalDistilBertForSequenceClassification and MedicalBertForSequenceClassification models Redesign of the ContextualParserApproach annotator getClasses method in RelationExtractionModel and RelationExtractionDLModel annotators Label customization feature for RelationExtractionModel and RelationExtractionDL models useBestModel parameter in MedicalNerApproach annotator Early stopping feature in MedicalNerApproach annotator Multi-Language support for faker and regex lists of Deidentification annotator Spark 3.2.0 compatibility for the entire library Saving visualization feature in spark-nlp-display library Deploying a custom Spark NLP image (for opensource, healthcare, and Spark OCR) to an enterprise version of Kubernetes: OpenShift New speed benchmarks table on databricks New &amp; Updated Notebooks List of recently updated or added models Brand New Spanish Deidentification NER Models We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Spanish. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. Both also are available for using Roberta Spanish Clinical Embeddings and sciwiki 300d. ner_deid_generic : Detects 7 PHI entities in Spanish (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 13 PHI sub-entities in Spanish (PATIENT, HOSPITAL, DATE, ORGANIZATION, E-MAIL, USERNAME, LOCATION, ZIP, MEDICALRECORD, PROFESSION, PHONE, DOCTOR, AGE). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_sciwiki_300d&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Antonio Pérez Juan, nacido en Cadiz, España. Aún no estaba vacunado, se infectó con Covid-19 el dia 14/03/2020 y tuvo que ir al Hospital. Fue tratado con anticuerpos monoclonales en la Clinica San Carlos..&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |--||--| | Antonio Pérez Juan | NAME | PATIENT | | Cádiz | LOCATION | LOCATION | | España | LOCATION | LOCATION | | 14/03/2022 | DATE | DATE | | Clínica San Carlos | LOCATION | HOSPITAL | Brand New Spanish Deidentification Pretrained Pipeline We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from Spanish medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask, fake or obfuscate the following entities: AGE, DATE, PROFESSION, E-MAIL, USERNAME, LOCATION, DOCTOR, HOSPITAL, PATIENT, URL, IP, MEDICALRECORD, IDNUM, ORGANIZATION, PHONE, ZIP, ACCOUNT, SSN, PLATE, SEX and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;es&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;Datos del paciente. Nombre: Jose . Apellidos: Aranda Martinez. NHC: 2748903. NASS: 26 37482910.&quot;&quot;&quot; result = deid_pipe.annotate(text) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Results: Masked with entity labels Datos del paciente. Nombre: &lt;PATIENT&gt; . Apellidos: &lt;PATIENT&gt;. NHC: &lt;SSN&gt;. NASS: &lt;SSN&gt; &lt;SSN&gt; Masked with chars Datos del paciente. Nombre: [**] . Apellidos: [*************]. NHC: [*****]. NASS: [**] [******] Masked with fixed length chars Datos del paciente. Nombre: **** . Apellidos: ****. NHC: ****. NASS: **** **** Obfuscated Datos del paciente. Nombre: Sr. Lerma . Apellidos: Aristides Gonzalez Gelabert. NHC: BBBBBBBBQR648597. NASS: 041010000011 RZRM020101906017 04. New Clinical NER Model to Detect Supplements We are releasing ner_supplement_clinical model that can extract benefits of using drugs for certain conditions. It can label detected entities as CONDITION and BENEFIT. Also this model is trained on the dataset that is released by Spacy in their HealthSea product. Here is the benchmark comparison of both versions: Entity Spark NLP Spacy-HealthSea BENEFIT 0.8729641 0.8330684 CONDITION 0.8339274 0.8333333 Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_supplement_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;Excellent!. The state of health improves, nervousness disappears, and night sleep improves. It also promotes hair and nail growth.&quot;]], [&quot;text&quot;])) Results : +++ | chunk | ner_label | +++ | nervousness | CONDITION | | night sleep improves | BENEFIT | | hair | BENEFIT | | nail | BENEFIT | +++ New RxNorm Sentence Entity Resolver Model sbiobertresolve_rxnorm_augmented_re : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes without specifying the relations between the entities (relations are calculated on the fly inside the annotator) using sbiobert_base_cased_mli Sentence Bert Embeddings (EntityChunkEmbeddings). Example : ... rxnorm_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_rxnorm_augmented_re&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;entity_chunk_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... New EntityChunkEmbeddings Annotator We have a new EntityChunkEmbeddings annotator to compute a weighted average vector representing entity-related vectors. The model’s input usually consists of chunks of recognized named entities produced by MedicalNerModel. We can specify relations between the entities by the setTargetEntities() parameter, and the internal Relation Extraction model finds related entities and creates a chunk. Embedding for the chunk is calculated according to the weights specified in the setEntityWeights() parameter. For instance, the chunk warfarin sodium 5 MG Oral Tablet has DRUG, STRENGTH, ROUTE, and FORM entity types. Since DRUG label is the most prominent label for resolver models, now we can assign weight to prioritize DRUG label (i.e {&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;ROUTE&quot;: 0.2, &quot;FORM&quot;: 0.2} as shown below). In other words, embeddings of these labels are multipled by the assigned weights such as DRUG by 0.8. For more details and examples, please check Sentence Entity Resolvers with EntityChunkEmbeddings Notebook in the Spark NLP workshop repo. Example : ... drug_chunk_embeddings = EntityChunkEmbeddings() .pretrained(&quot;sbiobert_base_cased_mli&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;drug_chunk_embeddings&quot;) .setMaxSyntacticDistance(3) .setTargetEntities({&quot;DRUG&quot;: [&quot;STRENGTH&quot;, &quot;ROUTE&quot;, &quot;FORM&quot;]}) .setEntityWeights({&quot;DRUG&quot;: 0.8, &quot;STRENGTH&quot;: 0.2, &quot;ROUTE&quot;: 0.2, &quot;FORM&quot;: 0.2}) rxnorm_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_rxnorm_augmented_re&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;drug_chunk_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) rxnorm_weighted_pipeline_re = Pipeline( stages = [ documenter, sentence_detector, tokenizer, embeddings, posology_ner_model, ner_converter, pos_tager, dependency_parser, drug_chunk_embeddings, rxnorm_resolver]) sampleText = [&quot;The patient was given metformin 500 mg, 2.5 mg of coumadin and then ibuprofen.&quot;, &quot;The patient was given metformin 400 mg, coumadin 5 mg, coumadin, amlodipine 10 MG&quot;] data_df = spark.createDataFrame(sample_df) results = rxnorm_weighted_pipeline_re.fit(data_df).transform(data_df) The internal relation extraction creates the chunks here, and the embedding is computed according to the weights. Results : +--+-+--+--+ |index| chunk|rxnorm_code_weighted_08_re| Concept_Name| +--+-+--+--+ | 0|metformin 500 mg| 860974|metformin hydrochloride 500 MG:::metformin 500 ...| | 0| 2.5 mg coumadin| 855313|warfarin sodium 2.5 MG [Coumadin]:::warfarin so...| | 0| ibuprofen| 1747293|ibuprofen Injection:::ibuprofen Pill:::ibuprofe...| | 1|metformin 400 mg| 332809|metformin 400 MG:::metformin 250 MG Oral Tablet...| | 1| coumadin 5 mg| 855333|warfarin sodium 5 MG [Coumadin]:::warfarin sodi...| | 1| coumadin| 202421|Coumadin:::warfarin sodium 2 MG/ML Injectable S...| | 1|amlodipine 10 MG| 308135|amlodipine 10 MG Oral Tablet:::amlodipine 10 MG...| +--+-+--+--+ New MedicalBertForSequenceClassification Annotator We developed a new annotator called MedicalBertForSequenceClassification. It can load BERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. New MedicalDistilBertForSequenceClassification Annotator We developed a new annotator called MedicalDistilBertForSequenceClassification. It can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. New MedicalDistilBertForSequenceClassification and MedicalBertForSequenceClassification Models We are releasing a new MedicalDistilBertForSequenceClassification model and three new MedicalBertForSequenceClassification models. bert_sequence_classifier_ade_biobert: a classifier for detecting if a sentence is talking about a possible ADE (TRUE, FALSE) bert_sequence_classifier_gender_biobert: a classifier for detecting the gender of the main subject of the sentence (MALE, FEMALE, UNKNOWN) bert_sequence_classifier_pico_biobert: a classifier for detecting the class of a sentence according to PICO framework (CONCLUSIONS, DESIGN_SETTING,INTERVENTION, PARTICIPANTS, FINDINGS, MEASUREMENTS, AIMS) Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_pico&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text = &quot;To compare the results of recording enamel opacities using the TF and modified DDE indices.&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-+--+ |text |label| +-+--+ |To compare the results of recording enamel opacities using the TF and modified DDE indices.|AIMS | +-+--+ distilbert_sequence_classifier_ade : This model is a DistilBertForSequenceClassification model for classifying clinical texts whether they contain ADE (TRUE, FALSE). Example : ... sequenceClassifier = MedicalDistilBertForSequenceClassification .pretrained(&#39;distilbert_sequence_classifier_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&#39;token&#39;, &#39;document&#39;]) .setOutputCol(&#39;class&#39;) ... sample_text = &quot;I felt a bit drowsy and had blurred vision after taking Aspirin.&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : +-+--+ |text |label| +-+--+ |I felt a bit drowsy and had blurred vision after taking Aspirin.| True| +-+--+ Redesign of the ContextualParserApproach Annotator We’ve dropped the annotator’s contextMatch parameter and removed the need for a context field when feeding a JSON configuration file to the annotator. Context information can now be fully defined using the prefix, suffix and contextLength fields in the JSON configuration file. We’ve also fixed issues with the contextException field in the JSON configuration file - it was mismatching values in documents with several sentences and ignoring exceptions situated to the right of a word/token. The ruleScope field in the JSON configuration file can now be set to document instead of sentence. This allows you to match multi-word entities like “New York” or “Salt Lake City”. You can do this by setting &quot;ruleScope&quot; : &quot;document&quot; in the JSON configuration file and feeding a dictionary (csv or tsv) to the annotator with its setDictionary parameter. These changes also mean that we’ve dropped the updateTokenizer parameter since the new capabilities of ruleScope improve the user experience for matching multi-word entities. You can now feed in a dictionary in your chosen format - either vertical or horizontal. You can set that with the following parameter: setDictionary(&quot;dictionary.csv&quot;, options={&quot;orientation&quot;:&quot;vertical&quot;}) Lastly, there was an improvement made to the confidence value calculation process to better measure successful hits. For more explanation and examples, please check this Contextual Parser medium article and Contextual Parser Notebook. getClasses Method in RelationExtractionModel and RelationExtractionDLModel Annotators Now you can use getClasses() method for checking the relation labels of RE models (RelationExtractionModel and RelationExtractionDLModel) like MedicalNerModel(). Example : clinical_re_Model = RelationExtractionModel() .pretrained(&quot;re_temporal_events_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) clinical_re_Model.getClasses() Output : [&#39;OVERLAP&#39;, &#39;BEFORE&#39;, &#39;AFTER&#39;] Label Customization Feature for RelationExtractionModel and RelationExtractionDL Models We are releasing label customization feature for Relation Extraction and Relation Extraction DL models by using .setCustomLabels() parameter. Example : ... reModel = RelationExtractionModel.pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setMaxSyntacticDistance(10) .setRelationPairs([&quot;drug-ade, ade-drug&quot;]) .setCustomLabels({&quot;1&quot;: &quot;is_related&quot;, &quot;0&quot;: &quot;not_related&quot;}) redl_model = RelationExtractionDLModel.pretrained(&#39;redl_ade_biobert&#39;, &#39;en&#39;, &quot;clinical/models&quot;) .setPredictionThreshold(0.5) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setCustomLabels({&quot;1&quot;: &quot;is_related&quot;, &quot;0&quot;: &quot;not_related&quot;}) ... sample_text = &quot;I experienced fatigue and muscle cramps after taking Lipitor but no more adverse after passing Zocor.&quot; result = model.transform(spark.createDataFrame([[sample_text]]).toDF(&#39;text&#39;)) Results : +--+-+-+-+-+-+ | relation|entity1| chunk1|entity2| chunk2|confidence| +--+-+-+-+-+-+ | is_related| ADE| fatigue| DRUG|Lipitor| 0.9999825| |not_related| ADE| fatigue| DRUG| Zocor| 0.9960077| | is_related| ADE|muscle cramps| DRUG|Lipitor| 1.0| |not_related| ADE|muscle cramps| DRUG| Zocor| 0.94971| +--+-+-+-+-+-+ useBestModel Parameter in MedicalNerApproach Annotator Introducing useBestModel param in MedicalNerApproach annotator. This param preserves and restores the model that has achieved the best performance at the end of the training. The priority is metrics from testDataset (micro F1), metrics from validationSplit (micro F1), and if none is set it will keep track of loss during the training. Example : med_ner = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... ... .setUseBestModel(True) Early Stopping Feature in MedicalNerApproach Annotator Introducing earlyStopping feature for MedicalNerApproach(). You can stop training at the point when the perforfmance on test/validation dataset starts to degrage. Two params are added to MedicalNerApproach() in order to use this feature: earlyStoppingCriterion : (float) This is used set the minimal improvement of the test metric to terminate training. The metric monitored is the same as the metrics used in useBestModel (macro F1 when using test/validation set, loss otherwise). Default is 0 which means no early stopping is applied. earlyStoppingPatience: (int), the number of epoch without improvement which will be tolerated. Default is 0, which means that early stopping will occur at the first time when performance in the current epoch is no better than in the previous epoch. Example : med_ner = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... ... .setTestDataset(test_data_parquet_path) .setEarlyStoppingCriterion(0.01) .setEarlyStoppingPatience(3) Multi-Language Support for Faker and Regex Lists of Deidentification Annotator We have a new .setLanguage() parameter in order to use internal Faker and Regex list for multi-language texts. When you are working with German and Spanish texts for a Deidentification, you can set this parameter to de for German and es for Spanish. Default value of this parameter is en. Example : deid_obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;de&#39;) .setObfuscateRefSource(&quot;faker&quot;) Spark 3.2.0 Compatibility for the Entire Library Now we can use the Spark 3.2.0 version for Spark NLP for Healthcare by setting spark32=True in sparknlp_jsl.start() function. ! pip install --ignore-installed -q pyspark==3.2.0 import sparknlp_jsl spark = sparknlp_jsl.start(SECRET, spark32=True) Saving Visualization Feature in spark-nlp-display Library We have a new save_path parameter in spark-nlp-display library for saving any visualization results in Spark NLP. Example : from sparknlp_display import NerVisualizer visualiser = NerVisualizer() visualiser.display(light_result[0], label_col=&#39;ner_chunk&#39;, document_col=&#39;document&#39;, save_path=&quot;display_result.html&quot;) Deploying a Custom Spark NLP Image (for opensource, healthcare, and Spark OCR) to an Enterprise Version of Kubernetes: OpenShift Spark NLP for opensource, healthcare, and SPARK OCR is now available for Openshift - enterprise version of Kubernetes. For deployment, please refer to: Github Link: https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/platforms/openshift Youtube: https://www.youtube.com/watch?v=FBes-6ylFrM&amp;ab_channel=JohnSnowLabs New Speed Benchmarks Table on Databricks We prepared a speed benchmark table by running a clinical BERT For Token Classification model pipeline on various number of repartitioning and writing the results to parquet or delta formats. You can find the details here : Clinical Bert For Token Classification Benchmark Experiment. New &amp; Updated Notebooks We have updated our existing workshop notebooks with v3.4.0 by adding new features and functionalities. You can find the workshop notebooks updated with previous versions in the branches named with the relevant version. We have updated the ContextualParser Notebook with the new updates in this version. We have a new Sentence Entity Resolvers with EntityChunkEmbeddings Notebook for the new EntityChunkEmbeddings annotator. To see more, please check : Spark NLP Healthcare Workshop Repo List of Recently Updated or Added Models bert_sequence_classifier_ade_en bert_sequence_classifier_gender_biobert_en bert_sequence_classifier_pico_biobert_en distilbert_sequence_classifier_ade_en bert_token_classifier_ner_supplement_en deid_pipeline_es ner_deid_generic_es ner_deid_generic_roberta_es ner_deid_subentity_es ner_deid_subentity_roberta_es ner_nature_nero_clinical_en ner_supplement_clinical_en sbiobertresolve_clinical_abbreviation_acronym_en sbiobertresolve_rxnorm_augmented_re For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_1"
  },
  "1428": {
    "id": "1428",
    "title": "Annotation Lab Release Notes 3.4.1",
    "content": "3.4.1 Release date: 05-08-2022 Annotation Lab v3.4.1 has beed released and it includes Models Hub and Visual NER bug fixes. Here are the highlights of this release: Highlights Confidence score of labels predicted by Visual NER model is now displayed in the labeling page. Missing image issues that appeared when deleting a task in Visual NER project has been fixed. Jumpy screen on annotating Visual NER tasks is resolved. Addition of new models supported in Spark NLP 4.0.0 Upgrade TensorFlow to 2.7.1 and PySpark to 3.2.0 Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_4_1"
  },
  "1429": {
    "id": "1429",
    "title": "Spark NLP for Healthcare Release Notes 3.4.2",
    "content": "3.4.2 We are glad to announce that Spark NLP Healthcare 3.4.2 has been released! Highlights New RCT Classifier, NER models and pipeline (Deidentification) Setting the scope window (target area) dynamically in Assertion Status detection models Reading JSON files (exported from ALAB) from HDFS with AnnotationJsonReader Allow users to write Tensorflow graphs to HDFS Serving Spark NLP on APIs Updated documentation on installing Spark NLP for Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop) New series of notebooks to reproduce the academic papers published by our colleagues PySpark tutorial notebooks to let non-Spark users get started with Apache Spark ecosystem in Python New &amp; updated notebooks List of recently updated or added models New RCT Classifier, NER Models and Pipeline (Deidentification) We are releasing a new bert_sequence_classifier_rct_biobert model, four new Spanish deidentification NER models (ner_deid_generic_augmented, ner_deid_subentity_augmented, ner_deid_generic_roberta_augmented, ner_deid_subentity_roberta_augmented) and a pipeline (clinical_deidentification_augmented). bert_sequence_classifier_rct_biobert: This model can classify the sections within abstract of scientific articles regarding randomized clinical trials (RCT) (BACKGROUND, CONCLUSIONS, METHODS, OBJECTIVE, RESULTS). Example : ... sequenceClassifier_model = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_rct_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&#39;token&#39;]) .setOutputCol(&quot;class&quot;) ... sample_text = &quot;Previous attempts to prevent all the unwanted postoperative responses to major surgery with an epidural hydrophilic opioid , morphine , have not succeeded . The authors &#39; hypothesis was that the lipophilic opioid fentanyl , infused epidurally close to the spinal-cord opioid receptors corresponding to the dermatome of the surgical incision , gives equal pain relief but attenuates postoperative hormonal and metabolic responses more effectively than does systemic fentanyl .&quot; result = sequence_clf_model.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) &gt;&gt; class: &#39;BACKGROUND&#39; ner_deid_generic_augmented, ner_deid_subentity_augmented, ner_deid_generic_roberta_augmented, ner_deid_subentity_roberta_augmented models and clinical_deidentification_augmented pipeline : You can use either sciwi-embeddings (300 dimensions) or the Roberta Clinical Embeddings (infix _roberta_) with these NER models. These models and pipeline are different to their non-augmented versions in the following: They are trained with more data, now including an in-house annotated deidentification dataset; New SEX tag is available for all of them. This tag is now included in the NER and has been improved with more rules in the ContextualParsers of the pipeline, resulting in having a bigger recall to detect the sex of the patient. New STREET, CITY and COUNTRY entities are added to subentity versions. For more details and examples, please check Clinical Deidentification in Spanish notebook. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_sciwiki_300d&quot;,&quot;es&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic_augmented&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_augmented&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... Results : chunk entity_subentity entity_generic -- - Antonio Miguel Martínez PATIENT NAME un varón SEX SEX 35 AGE AGE auxiliar de enfermería PROFESSION PROFESSION Cadiz CITY LOCATION España COUNTRY LOCATION Clinica San Carlos HOSPITAL LOCATION Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format [X,Y] being X the number of tokens to consider on the left of the chunk, and Y the max number of tokens to consider on the right. Let’s take a look at what different windows mean: By default, the window is [-1,-1] which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in setMaxSentLen()). [0,0] means “don’t pay attention to any token except the ner_chunk”, what basically is not considering any context for the Assertion resolution. [9,15] is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status. Check this scope window tuning assertion status detection notebook that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them. Example : assertion_status = AssertionDLApproach() .setGraphFolder(&quot;assertion_dl/&quot;) .setInputCols(&quot;sentence&quot;, &quot;chunk&quot;, &quot;embeddings&quot;) .setOutputCol(&quot;assertion&quot;) ... ... .setScopeWindow([9, 15]) # NEW! Scope Window! Reading JSON Files (Exported from ALAB) From HDFS with AnnotationJsonReader Now we can read the dataframe from a HDFS that we read the files from in our cluster. Example : filename = &quot;hdfs:///user/livy/import.json&quot; reader = AnnotationToolJsonReader(assertion_labels = [&#39;AsPresent&#39;, &#39;AsAbsent&#39;, &#39;AsConditional&#39;, &#39;AsHypothetical&#39;, &#39;Family&#39;, &#39;AsPossible&#39;, &#39;AsElse&#39;]) df = reader.readDataset(spark, filename) Allow Users Write Tensorflow Graphs to HDFS Now we can save custom Tensorflow graphs to the HDFS that mainly being used in a cluster environment. tf_graph.build(&quot;ner_dl&quot;, build_params={&quot;embeddings_dim&quot;: 200, &quot;nchars&quot;: 128, &quot;ntags&quot;: 12, &quot;is_medical&quot;: 1}, model_location=&quot;hdfs:///user/livy&quot;, model_filename=&quot;auto&quot;) Serving Spark NLP on APIs Two new notebooks and a series of blog posts / Medium articles have been created to guide Spark NLP users to serve Spark NLP on a RestAPI. The notebooks can be found here. The articles can be found in the Technical Documentation of Spark NLP, available here and also in Medium: Serving Spark NLP via API (1/3): Microsoft’s Synapse ML Serving Spark NLP via API (2/3): FastAPI and LightPipelines Serving Spark NLP via API (3/3): Databricks Jobs and MLFlow Serve APIs The difference between both approaches are the following: SynapseML is a Microsoft Azure Open Source library used to carry out ML at scale. In this case, we use the Spark Serving feature, that leverages Spark Streaming and adds a web server with a Load Balancer, allowing concurrent processing of Spark NLP calls. Best approach if you look for scalability with Load Balancing. FastAPI + LightPipelines: A solution to run Spark NLP using a FastAPI webserver. It uses LightPipelines, what means having a very good performance but not leveraging Spark Clusters. Also, no Load Balancer is available in the suggestion, but you can create your own. Best approach if you look for performance. Databricks and MLFlow: Using MLFlow Serve or Databricks Jobs APIs to serve for inference Spark NLP pipelines from within Databricks. Best approach if you look for scalability within Databricks. Updated Documentation on Installing Spark NLP For Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop) Ready-to-go Spark NLP for Healthcare environment in AWS EMR. Full instructions are here. New Series of Notebooks to Reproduce the Academic Papers Published by Our Colleagues You can find all these notebooks here PySpark Tutorial Notebooks to Let Non-Spark Users to Get Started with Apache Spark Ecosystem in Python John Snow Labs has created a series of 8 notebooks to go over PySpark from zero to hero. Notebooks cover PySpark essentials, DataFrame creation, querying, importing data from different formats, functions / udfs, Spark MLLib examples (regression, classification, clustering) and Spark NLP best practises (usage of parquet, repartition, coalesce, custom annotators, etc). You can find all these notebooks here. New &amp; Updated Notebooks Series of academic notebooks : A new series of academic paper notebooks, available here Clinical_Deidentification_in_Spanish.ipynb: A notebook showcasing Clinical Deidentification in Spanish, available here. Clinical_Deidentification_Comparison.ipynb: A new series of comparisons between different Deidentification libraries. So far, it contains Spark NLP for Healthcare and ScrubaDub with Spacy Transformers. Available here. Scope_window_tuning_assertion_status_detection.ipynb: How to finetune Assertion Status using the Scope Window. Available here Clinical_Longformer_vs_BertSentence_&amp;_USE.ipynb: A Comparison of how Clinical Longformer embeddings, averaged by the Sentence Embeddings annotator, performs compared to BioBert and UniversalSentenceEncoding. Link here. Serving_SparkNLP_with_Synapse.ipynb: Serving SparkNLP for production purposes using Synapse ML. Available here Serving_SparkNLP_with_FastAPI_and_LP.ipynb: Serving SparkNLP for production purposes using FastAPI, RestAPI and LightPipelines. Available here Series of PySpark tutorial notebooks: Available here List of Recently Updated or Added Models sbiobertresolve_hcpcs bert_sequence_classifier_rct_biobert ner_deid_generic_augmented_es ner_deid_subentity_augmented_es ner_deid_generic_roberta_augmented_es ner_deid_subentity_roberta_augmented_es clinical_deidentification_augmented_es For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_4_2"
  },
  "1430": {
    "id": "1430",
    "title": "Spark NLP release notes 3.5.0",
    "content": "3.5.0 Release date: 15-07-2021 Overview Improve table detection and table recognition. More details please read in Extract Tabular Data from PDF in Spark OCR New Features Added new method to ImageTableCellDetector which support borderless tables and combined tables. Added Wolf and Singh adaptive binarization methods to the ImageAdaptiveThresholding. Enhancements Added possibility to use different type of images as input for ImageTableDetector. Added display_pdf and display_images_horizontal util functions. New notebooks Tables Recognition from PDF Pdf de-identification on Databricks Dicom de-identification on Databricks Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_5_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_5_0"
  },
  "1431": {
    "id": "1431",
    "title": "Spark NLP for Healthcare Release Notes 3.5.0",
    "content": "3.5.0 We are glad to announce that Spark NLP Healthcare 3.5.0 has been released! Highlights Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset Deidentification: New French Deidentification NER models and pipeline New Italian Deidentification NER models and pipeline Check our reference table for French and Italian deidentification metrics Added French support to the “fake” generation of data (aka data obfuscation) in the Deidentification annotator Deidentification benchmark: Spark NLP vs Cloud Providers (AWS, Azure, GCP) Graph generation: ChunkMapperApproach to augment NER chunks extracted by Spark NLP with a custom graph-like dictionary of relationships New Relation Extraction features: Configuration of case sensitivity in the name of the relations in Relation Extraction Models Models and Demos: We have reached 600 clinical models and pipelines, what sums up to 5000+ overall models in Models Hub! Check our new live demos including multilanguage deidentification to anonymize clinical notes in 5 different languages Generate Dataframes to train Assertion Status models using JSON Files exported from Annotation Lab (ALAB) Guide about how to scale from PoC to Production using Spark NLP for Healthcare in our new Medium Article, available here Core improvements: Contextual Parser (our Rule-based NER annotator) is now much more performant! Bug fixing and compatibility additions affecting and improving some behaviours of AssertionDL, BertSentenceChunkEmbeddings, AssertionFilterer and EntityRulerApproach New notebooks: zero-shot relation extraction and Deidentification benchmark vs Cloud Providers Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset This release includes a zero-shot relation extraction model that leverages BertForSequenceClassificaiton to return, based on a predefined set of relation candidates (including no-relation / O), which one has the higher probability to be linking two entities. The dataset will be a csv which contains the following columns: sentence, chunk1, firstCharEnt1, lastCharEnt1, label1, chunk2, firstCharEnt2, lastCharEnt2, label2, rel. For example, let’s take a look at this dataset (columns chunk1, rel, chunk2 and sentence): +-+-+-+--+ | chunk1 | rel | chunk2 | sentence | |-+-+-+--| | light-headedness | PIP | diaphoresis | She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea . | | respiratory rate | O | saturation | VITAL SIGNS - Temp 98.8 , pulse 60 , BP 150/94 , respiratory rate 18 , and saturation 96% on room air . | | lotions | TrNAP | incisions | No lotions , creams or powders to incisions . | | abdominal ultrasound | TeRP | gallbladder sludge | Abdominal ultrasound on 2/23/00 - This study revealed gallbladder sludge but no cholelithiasis . | | ir placement of a drainage catheter | TrAP | his abdominopelvic fluid collection | At that time he was made NPO with IVF , placed on Ampicillin / Levofloxacin / Flagyl and underwent IR placement of a drainage catheter for his abdominopelvic fluid collection | +-+-+-+--+ The relation types (TeRP, TrAP, PIP, TrNAP, etc…) are described here Let’s take a look at the first sentence! She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea As we see in the table, the sentences includes a PIP relationship (Medical problem indicates medical problem), meaning that in that sentence, chunk1 (light-headedness) indicates chunk2 (diaphoresis). We set a list of candidates tags ([PIP, TrAP, TrNAP, TrWP, O]) and candidate sentences ([light-headedness caused diaphoresis, light-headedness was administered for diaphoresis, light-headedness was not given for diaphoresis, light-headedness worsened diaphoresis]), meaning that: PIP is expressed by light-headedness caused diaphoresis TrAP is expressed by light-headedness was administered for diaphoresis TrNAP is expressed by light-headedness was not given for diaphoresis TrWP is expressed by light-headedness worsened diaphoresis or something generic, like O is expressed by light-headedness and diaphoresis… We will get that the biggest probability of is PIP, since it’s phrase light-headedness caused diaphoresis is the most similar relationship expressing the meaning in the original sentence (light-headnedness is often associated with ... and diaphoresis) The example code is the following: ... re_ner_chunk_filter = sparknlp_jsl.annotator.RENerChunksFilter() .setRelationPairs([&quot;problem-test&quot;,&quot;problem-treatment&quot;]) .setMaxSyntacticDistance(4) .setDocLevelRelations(False) .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;re_ner_chunks&quot;) # The relations are defined by a map- keys are relation label, values are lists of predicated statements. The variables in curly brackets are NER entities, there could be more than one, e.g. &quot; improves &quot; re_model = sparknlp_jsl.annotator.ZeroShotRelationExtractionModel .pretrained(&quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setRelationalCategories({ &quot;CURE&quot;: [&quot; cures .&quot;], &quot;IMPROVE&quot;: [&quot; improves .&quot;, &quot; cures .&quot;], &quot;REVEAL&quot;: [&quot; reveals .&quot;]}) .setMultiLabel(False) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) pipeline = sparknlp.base.Pipeline() .setStages([documenter, tokenizer, sentencer, words_embedder, pos_tagger, ner_tagger, ner_converter, dependency_parser, re_ner_chunk_filter, re_model]) data = spark.createDataFrame( [[&quot;Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer.&quot;]] ).toDF(&quot;text&quot;) model = pipeline.fit(data) results = model.transform(data) results .selectExpr(&quot;explode(relations) as relation&quot;) .show(truncate=False) Results: +-+ |relation | +-+ |{category, 534, 613, REVEAL, {entity1_begin -&gt; 48, relation -&gt; REVEAL, hypothesis -&gt; An MRI test reveals cancer., confidence -&gt; 0.9760039, nli_prediction -&gt; entail, entity1 -&gt; TEST, syntactic_distance -&gt; 4, chunk2 -&gt; cancer, entity2_end -&gt; 85, entity1_end -&gt; 58, entity2_begin -&gt; 80, entity2 -&gt; PROBLEM, chunk1 -&gt; An MRI test, sentence -&gt; 1}, []} | |{category, 267, 357, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves sickness., confidence -&gt; 0.98819494, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 3, chunk2 -&gt; sickness, entity2_end -&gt; 45, entity1_end -&gt; 10, entity2_begin -&gt; 38, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []}| |{category, 0, 90, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves headache., confidence -&gt; 0.9929625, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 2, chunk2 -&gt; headache, entity2_end -&gt; 33, entity1_end -&gt; 10, entity2_begin -&gt; 26, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []} | +-+ Take a look at the example notebook here. Stay tuned for the few-shot Annotator to be release soon! New French Deidentification NER models and pipeline We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in French. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 7 PHI entities in French (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID). ner_deid_subentity : Detects 15 PHI sub-entities in French (PATIENT, HOSPITAL, DATE, ORGANIZATION, E-MAIL, USERNAME, ZIP, MEDICALRECORD, PROFESSION, PHONE, DOCTOR, AGE, STREET, CITY, COUNTRY). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;fr&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;J&#39;ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant de Mars 2015.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |-||--| | Michel Martinez | NAME | PATIENT | | 49 ans | AGE | AGE | | Centre Hospitalier De Plaisir | LOCATION | HOSPITAL | | Mars 2015 | DATE | DATE | We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from French medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, E-MAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, ACCOUNT, PLATE, USERNAME, URL, and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;fr&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;PRENOM : Jean NOM : Dubois NUMÉRO DE SÉCURITÉ SOCIALE : 1780160471058 ADRESSE : 18 Avenue Matabiau VILLE : Grenoble CODE POSTAL : 38000&quot;&quot;&quot; result = deid_pipeline.annotate(text) Results: Masked with entity labels PRENOM : &lt;PATIENT&gt; NOM : &lt;PATIENT&gt; NUMÉRO DE SÉCURITÉ SOCIALE : &lt;SSN&gt; ADRESSE : &lt;STREET&gt; VILLE : &lt;CITY&gt; CODE POSTAL : &lt;ZIP&gt; Masked with chars PRENOM : [**] NOM : [****] NUMÉRO DE SÉCURITÉ SOCIALE : [***********] ADRESSE : [****************] VILLE : [******] CODE POSTAL : [***] Masked with fixed length chars PRENOM : **** NOM : **** NUMÉRO DE SÉCURITÉ SOCIALE : **** ADRESSE : **** VILLE : **** CODE POSTAL : **** Obfuscated PRENOM : Mme Olivier NOM : Mme Traore NUMÉRO DE SÉCURITÉ SOCIALE : 164033818514436 ADRESSE : 731, boulevard de Legrand VILLE : Sainte Antoine CODE POSTAL : 37443 New Italian Deidentification NER models and pipeline We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Italian. ner_deid_generic and ner_deid_subentity models are trained with in-house annotations. ner_deid_generic : Detects 8 PHI entities in Italian (DATE, NAME, LOCATION, PROFESSION, CONTACT, AGE, ID, SEX). ner_deid_subentity : Detects 19 PHI sub-entities in Italian (DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, EMAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, USERNAME, URL). Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;it&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) deid_ner = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;it&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) deid_sub_entity_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;it&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_sub_entity&quot;) ... text = &quot;&quot;&quot;Ho visto Gastone Montanariello (49 anni) riferito all&#39; Ospedale San Camillo per diabete mal controllato con sintomi risalenti a marzo 2015.&quot;&quot;&quot; result = model.transform(spark.createDataFrame([[text]], [&quot;text&quot;])) Results : | chunk | ner_deid_generic_chunk | ner_deid_subentity_chunk | |-||--| | Gastone Montanariello| NAME | PATIENT | | 49 | AGE | AGE | | Ospedale San Camillo | LOCATION | HOSPITAL | | marzo 2015 | DATE | DATE | We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from Italian medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: DATE, AGE, SEX, PROFESSION, ORGANIZATION, PHONE, E-MAIL, ZIP, STREET, CITY, COUNTRY, PATIENT, DOCTOR, HOSPITAL, MEDICALRECORD, SSN, IDNUM, ACCOUNT, PLATE, USERNAME, URL, and IPADDR. from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;it&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;NOME: Stefano Montanariello CODICE FISCALE: YXYGXN51C61Y662I INDIRIZZO: Viale Burcardo 7 CODICE POSTALE: 80139&quot;&quot;&quot; result = deid_pipeline.annotate(sample_text) Results: Masked with entity labels NOME: &lt;PATIENT&gt; CODICE FISCALE: &lt;SSN&gt; INDIRIZZO: &lt;STREET&gt; CODICE POSTALE: &lt;ZIP&gt; Masked with chars NOME: [*******************] CODICE FISCALE: [**************] INDIRIZZO: [**************] CODICE POSTALE: [***] Masked with fixed length chars NOME: **** CODICE FISCALE: **** INDIRIZZO: **** CODICE POSTALE: **** Obfuscated NOME: Stefania Gregori CODICE FISCALE: UIWSUS86M04J604B INDIRIZZO: Viale Orlando 808 CODICE POSTALE: 53581 Check our reference table for French and Italian deidentification metrics Please find this reference table with metrics comparing F1 score for the available entities in French and Italian clinical pipelines: |Entity Label |Italian|French| |-|-|| |PATIENT |0.9069 |0.9382| |DOCTOR |0.9171 |0.9912| |HOSPITAL |0.8968 |0.9375| |DATE |0.9835 |0.9849| |AGE |0.9832 |0.8575| |PROFESSION |0.8864 |0.8147| |ORGANIZATION |0.7385 |0.7697| |STREET |0.9754 |0.8986| |CITY |0.9678 |0.8643| |COUNTRY |0.9262 |0.8983| |PHONE |0.9815 |0.9785| |USERNAME |0.9091 |0.9239| |ZIP |0.9867 |1.0 | |E-MAIL |1 |1.0 | |MEDICALRECORD|0.8085 |0.939 | |SSN |0.9286 |N/A | |URL |1 |N/A | |SEX |0.9697 |N/A | |IDNUM |0.9576 |N/A | Added French support in Deidentification Annotator for data obfuscation Our Deidentificator annotator is now able to obfuscate entities (coming from a deid NER model) with fake data in French language. Example: Example code: ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;fr&quot;).setInputCols([&quot;sentence&quot;, &quot;token&quot;]).setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;fr&quot;, &quot;clinical/models&quot;).setInputCols([&quot;sentence&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]).setOutputCol(&quot;ner&quot;) ner_converter = NerConverter().setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]).setOutputCol(&quot;ner_chunk&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setRefSep(&quot;#&quot;) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;fr&quot;) .setObfuscateRefSource(&#39;faker&#39;) pipeline = Pipeline() .setStages([ documentAssembler, sentenceDetector, tokenizer, embeddings, clinical_ner, ner_converter, de_identification ]) sentences = [ [&quot;&quot;&quot;J&#39;ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant&quot;&quot;&quot;] ] my_input_df = spark.createDataFrame(sentences).toDF(&quot;text&quot;) output = pipeline.fit(my_input_df).transform(my_input_df) ... Entities detected: ++-+ |token |entity | ++-+ |J&#39;ai |O | |vu |O | |en |O | |consultation|O | |Michel |B-PATIENT | |Martinez |I-PATIENT | |( |O | |49 |B-AGE | |ans |O | |) |O | |adressé |O | |au |O | |Centre |B-HOSPITAL| |Hospitalier |I-HOSPITAL| |De |I-HOSPITAL| |Plaisir |I-HOSPITAL| |pour |O | |un |O | |diabète |O | |mal |O | ++-+ Obfuscated sentence: +--+ |result | +--+ |[J&#39;ai vu en consultation Sacrispeyre Ligniez (86 ans) adressé au Centre Hospitalier Pierre Futin pour un diabète mal contrôlé avec des symptômes datant]| +--+ Deidentification benchmark: Spark NLP vs Cloud Providers (AWS, Azure, GCP) We have published a new notebook with a benchmark and the reproduceable code, comparing Spark NLP for Healthcare Deidentification capabilities of one of our English pipelines (clinical_deidentification_glove_augmented) versus: AWS Comprehend Medical Azure Cognitive Services GCP Data Loss Prevention The notebook is available here, and the results are the following: SPARK NLP AWS AZURE GCP AGE 1 0.96 0.93 0.9 DATE 1 0.99 0.9 0.96 DOCTOR 0.98 0.96 0.7 0.6 HOSPITAL 0.92 0.89 0.72 0.72 LOCATION 0.9 0.81 0.87 0.73 PATIENT 0.96 0.95 0.78 0.48 PHONE 1 1 0.8 0.97 ID 0.93 0.93 - - ChunkMapperApproach: mapping extracted entities to an ontology (Json dictionary) with relations We have released a new annotator, called ChunkMapperApproach(), that receives a ner_chunk and a Json with a mapping of NER entities and relations, and returns the ner_chunk augmented with the relations from the Json ontology. Example of a small ontology with relations: Giving the map with entities and relationships stored in mapper.json, we will use an NER to detect entities in a text and, in case any of them is found, the ChunkMapper will augment the output with the relationships from this dictionary: {&quot;mappings&quot;: [{ &quot;key&quot;: &quot;metformin&quot;, &quot;relations&quot;: [{ &quot;key&quot;: &quot;action&quot;, &quot;values&quot; : [&quot;hypoglycemic&quot;, &quot;Drugs Used In Diabets&quot;] },{ &quot;key&quot;: &quot;treatment&quot;, &quot;values&quot; : [&quot;diabetes&quot;, &quot;t2dm&quot;] }] }] text = [&quot;&quot;&quot;The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also given 1 unit of Metformin daily. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day.&quot;&quot;&quot;] ... nerconverter = NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperApproach() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;relations&quot;) .setDictionary(&quot;mapper.json&quot;) .setRel(&quot;action&quot;) pipeline = Pipeline().setStages([document_assembler,sentence_detector,tokenizer, ner, nerconverter, chunkerMapper]) res = pipeline.fit(test_data).transform(test_data) res.select(F.explode(&#39;ner_chunk.result&#39;).alias(&quot;chunks&quot;)).show(truncate=False) Entities: +-+ |chunks | +-+ |Metformin | |insulin glargine| |insulin lispro | |metformin | |mg | |times | +-+ Checking the relations: ... pd_df = res.select(F.explode(&#39;relations&#39;).alias(&#39;res&#39;)).select(&#39;res.result&#39;, &#39;res.metadata&#39;).toPandas() ... Results: Entity: metformin Main relation: hypoglycemic Other relations (included in metadata): Drugs Used In Diabets Configuration of case sensitivity in the name of the relations in Relation Extraction Models We have added a new parameter, called ‘relationPairsCaseSensitive’, which affects the way setRelationPairs works. If relationPairsCaseSensitive is True, then the pairs of entities in the dataset should match the pairs in setRelationPairs in their specific case (case sensitive). By default it’s set to False, meaning that the match of those relation names is case insensitive. Before 3.5.0, .setRelationPairs([&quot;dosage-drug&quot;]) would not return relations if it was trained with a relation called DOSAGE-DRUG (different casing). Now, setting .setRelationPairs([&quot;dosage-drug&quot;])and relationPairsCaseSensitive(False) or just leaving it by default, it will return any dosage-drug or DOSAGE-DRUG relationship. Example of usage in Python: ... reModel = RelationExtractionModel() .pretrained(&quot;posology_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setMaxSyntacticDistance(4) .setRelationPairs([&quot;dosage-drug&quot;]) .setRelationPairsCaseSensitive(False) .setOutputCol(&quot;relations_case_insensitive&quot;) ... This will return relations named dosage-drug, DOSAGE-DRUG, etc. We have reached the milestone of 600 clinical models (and 5000+ models overall) ! 🥳 This release added to Spark NLP Models Hub 100+ pretrained clinical pipelines, available to use as one-liners, including some of the most used NER models, namely: ner_deid_generic_pipeline_de: German deidentification pipeline with aggregated (generic) labels ner_deid_subentity_pipeline_de: German deidentification pipeline with specific (subentity) labels ner_clinical_biobert_pipeline_en: A pretrained pipeline based on ner_clinical_biobert to carry out NER on BioBERT embeddings ner_abbreviation_clinical_pipeline_en: A pretrained pipeline based on ner_abbreviation_clinical that detects medical acronyms and abbreviations ner_ade_biobert_pipeline_en: A pretrained pipeline based on ner_ade_biobert to carry out Adverse Drug Events NER recognition using BioBERT embeddings ner_ade_clinical_pipeline_en: Similar to the previous one, but using clinical_embeddings ner_radiology_pipeline_en: A pretrained pipeline to detect Radiology entities (coming from ner_radiology_wip model) ner_events_clinical_pipeline_en: A pretrained pipeline to extract Clinical Events related entities (leveraging ner_events_clinical) ner_anatomy_biobert_pipeline_en: A pretrained pipeline to extract Anamoty entities (from ner_anamoty_biobert) …100 more Here is how you can use any of the pipelines with one line of code: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;explain_clinical_doc_medication&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;The patient is a 30-year-old female with a long history of insulin dependent diabetes, type 2. She received a course of Bactrim for 14 days for UTI. She was prescribed 5000 units of Fragmin subcutaneously daily, and along with Lantus 40 units subcutaneously at bedtime.&quot;&quot;&quot;)[0] Results: +-+-++ | | chunks | entities | |:|:|:--| | 0 | insulin | DRUG | | 1 | Bactrim | DRUG | | 2 | for 14 days | DURATION | | 3 | 5000 units | DOSAGE | | 4 | Fragmin | DRUG | | 5 | subcutaneously | ROUTE | | 6 | daily | FREQUENCY | | 7 | Lantus | DRUG | | 8 | 40 units | DOSAGE | | 9 | subcutaneously | ROUTE | | 10 | at bedtime | FREQUENCY | +-+-++ +-+-++-+ | | chunks | entities | assertion | |:|:|:--|:| | 0 | insulin | DRUG | Present | | 1 | Bactrim | DRUG | Past | | 2 | Fragmin | DRUG | Planned | | 3 | Lantus | DRUG | Planned | +-+-++-+ +-+--++--+-+ | relation | entity1 | chunk1 | entity2 | chunk2 | |:|:-|:--|:-|:| | DRUG-DURATION | DRUG | Bactrim | DURATION | for 14 days | | DOSAGE-DRUG | DOSAGE | 5000 units | DRUG | Fragmin | | DRUG-ROUTE | DRUG | Fragmin | ROUTE | subcutaneously | | DRUG-FREQUENCY | DRUG | Fragmin | FREQUENCY | daily | | DRUG-DOSAGE | DRUG | Lantus | DOSAGE | 40 units | | DRUG-ROUTE | DRUG | Lantus | ROUTE | subcutaneously | | DRUG-FREQUENCY | DRUG | Lantus | FREQUENCY | at bedtime | +-+--++--+-+ We have updated our 11.Pretrained_Clinical_Pipelines.ipynb notebook to properly show this addition. Don’t forget to check it out! All of our scalable, production-ready Spark NLP Clinical Models and Pipelines can be found in our Models Hub Finally, we have added two new entityMapper models: drug_ontology and section_mapper For all Spark NLP for healthcare models, please check our Models Hub webpage Have you checked our demo page? New several demos were created, available at https://nlp.johnsnowlabs.com/demos In this release we feature the Multilingual deidentification, showcasing how to deidentify clinical texts in English, Spanish, German, French and Italian. This demo is available here For the rest of the demos, please visit Models Hub Demos Page Generate Dataframes to train Assertion Status Models using JSON files exported from Annotation Lab (ALAB) Now we can generate a dataframe that can be used to train an AssertionDLModel by using the output of AnnotationToolJsonReader.generatePlainAssertionTrainSet(). The dataframe contains all the columns that you need for training. Example : filename = &quot;../json_import.json&quot; reader = AnnotationToolJsonReader(assertion_labels = [&#39;AsPresent&#39;, &#39;AsAbsent&#39;, &#39;AsConditional&#39;, &#39;AsHypothetical&#39;, &#39;AsFamily&#39;, &#39;AsPossible&#39;, &#39;AsElse&#39;]) df = reader.readDataset(spark, filename) reader.generatePlainAssertionTrainSet(df).show(truncate=False) Results : +-+--+--++--++ |task_id|sentence |begin|end|ner |assertion| +-+--+--++--++ |1 |Patient has a headache for the last 2 weeks |2 |3 |a headache |AsPresent| +-+--+--++--++ Understand how to scale from a PoC to Production using Spark NLP for Healthcare in our new Medium Article, available here We receive many questions about how Spark work distribution is carried out, what specially becomes important before making the leap from a PoC to a big scalable, production-ready cluster. This article helps you understand: How many different ways to create a cluster are available, as well as their advantages and disadvantages; How to scale all of them; How to take advantage of autoscalability and autotermination policy in Cloud Providers; Which are the steps to take depending on your infrastructure, to make the leap to production; If you need further assistance, please reach our Support team at support@johnsnowlabs.com Contextual Parser (our Rule-based NER annotator) is now much more performant! Contextual Parser has been improved in terms of performance. These are the metrics comparing 3.4.2 and 3.5.0 4 cores and 30 GB RAM ===================== 10 MB 20 MB 30MB 50MB 3.4.2 349 786 982 1633 3.5.0 142 243 352 556 8 cores and 60 GB RAM ===================== 10 MB 20 MB 30MB 50MB 3.4.2 197 373 554 876 3.5.0 79 136 197 294 We have reached the milestone of 600 clinical demos! During this release, we included: More than 100+ recently created clinical models and pipelines, including NER, NER+RE, NER+Assertion+RE, etc. Added two new entityMapper models: drug_action_treatment_mapper and normalized_section_header_mapper For all Spark NLP for healthcare models, please check : Models Hub Page Bug fixing and compatibility additions This is the list of fixed issues and bugs, as well as one compatibility addition between EntityRuler and AssertionFiltered: Error in AssertionDLApproach and AssertionLogRegApproach: an error was being triggered wthen the dataset contained long (64bits) instead of 32 bits integers for the start / end columns. Now this bug is fixed. Error in BertSentenceChunkEmbeddings: loading a model after downloading it with pretrained() was triggering an error. Now you can load any model after downloading it with pretrained(). Adding setIncludeConfidence to AssertionDL Python version, where it was missing. Now, it’s included in both Python and Scala, as described here Making EntityRuler and AssertionFiltered compatible: AssertionFilterer annotator that is being used to filter the entities based on entity labels now can be used by EntityRulerApproach, a rule based entity extractor: Path(&quot;test_file.jsonl&quot;).write_text(json.dumps({&quot;id&quot;:&quot;cough&quot;,&quot;label&quot;:&quot;COUGH&quot;,&quot;patterns&quot;:[&quot;cough&quot;,&quot;coughing&quot;]})) ... entityRuler = EntityRulerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;ner_chunk&quot;) .setPatternsResource(&quot;test_file.jsonl&quot;, ReadAs.TEXT, {&quot;format&quot;: &quot;jsonl&quot;}) clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_dl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setWhiteList([&quot;present&quot;]) ... empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) ruler_model = rulerPipeline.fit(empty_data) text = &quot;I have a cough but no fatigue or chills.&quot; ruler_light_model = LightPipeline(ruler_model).fullAnnotate(text)[0][&#39;assertion_filtered&#39;] Result: Annotation(chunk, 9, 13, cough, {&#39;entity&#39;: &#39;COUGH&#39;, &#39;id&#39;: &#39;cough&#39;, &#39;sentence&#39;: &#39;0&#39;})] New notebooks: zero-shot relation extraction and Deidentification benchmark (Spark NLP and Cloud Providers) Check these recently notebooks created by our Healthcare team and available in our Spark NLP Workshop git repo, where you can find many more. Zero-shot Relation Extraction, available here. Deidentification benchmark (SparkNLP and Cloud Providers), available here Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_0"
  },
  "1432": {
    "id": "1432",
    "title": "Annotation Lab Release Notes 3.5.0",
    "content": "3.5.0 Release date: 25-08-2022 Annotation Lab 3.5.0 add support for out-of-the-box usage of Multilingual Models as well as support for some of the European Language Models: Romanian, Portuguese, Danish and Italian. It also provides support for split dataset using Test/Train tags in classification project and allows NER pretrained models evaluation with floating license. The release also includes fixes for known security vulnerabilities and for some bug reported by our user community. Here are the highlights of this release: Highlights Support for Multilingual Models. Previously, only multilingual embeddings were available in Models Hub page. A new language filter has been added to the Models hub page to make searching for all available multilingual models and embeddings more efficient. User can select the target language and then explore the set of relevant multilingual models and embeddings. Expended Support for European Language Models. Annotation Lab now offers support for four new European languages Romanian, Portuguese, Italian, and Danish, on top of English, Spanish, and German, already supported in previous versions. Many pretrained models in those languages are now available to download from the NLP Models Hub and easily use to preannotate documents on the Annotation Lab. Use Test/Train Tags for Classification Training Experiments. The Test/Train split of annotated tasks can be used when training classification models. When this option is checked on the Training Settings, all tasks that have the Test tag are used as test datasets. All tasks tagged as Train together with all other non Test tasks will be used as a training dataset. NER Model Evaluation available for Floating License. Project Owner and/or Manager can evaluate pretrained NER models against a set of annotated tasks in the presence of floating licenses. Earlier, this feature was only available in the presence of airgap licenses. Chunks preannotation in VisualNER. Annotation Lab 3.4.0 which first published the visual NER preannotation and visual NER model training could only create token level preannotations. With version 3.5.0, individual tokens are combined into one chunk entity and shown as merged to the user. Benchmarking Information for Models Trained with Annotation Lab. With version 3.5.0 benchmarking information is available for models trained within Annotation Lab. User can go to the Available Models Tab of the Models Hub page and view the benchmarking data by clicking the small graph icon next to the model. Configuration for Annotation Lab Deployment. The resources allocated to Annotation Lab deployment can be configured via the resource values in the annotationlab-updater.sh. The instruction to change the parameters are available in the instruction.md file. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_3_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_3_5_0"
  },
  "1433": {
    "id": "1433",
    "title": "Spark NLP for Healthcare Release Notes 3.5.1",
    "content": "3.5.1 We are glad to announce that 3.5.1 version of Spark NLP for Healthcare has been released! Highlights Deidentification: New Portuguese Deidentification NER models and pretrained pipeline. This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese). New pretrained models and pipelines: New RxNorm Sentence Entity Resolver model to map and extract pharmaceutical actions (e.g. analgesic, hypoglycemic) as well as treatments (e.g. backache, diabetes) along with the RxNorm code resolved (sbiobertresolve_rxnorm_action_treatment) New RCT classification models and pretrained pipelines to classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT). (rct_binary_classifier_use, rct_binary_classifier_biobert, bert_sequence_classifier_binary_rct_biobert, rct_binary_classifier_use_pipeline, rct_binary_classifier_biobert_pipeline, bert_sequence_classifier_binary_rct_biobert_pipeline) New features: Add getClasses() attribute for MedicalBertForTokenClassifier and MedicalBertForSequenceClassification to find out the entity classes of the models Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before) New functionality to download and extract clinical models from S3 via direct zip url. Core improvements: Fixing the confidence scores in MedicalNerModel when setIncludeAllConfidenceScores is true Graph_builder relation_extraction model file name extension problem with auto parameter. List of recently updated or added models Portuguese Deidentification Models This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese). This version includes two Portuguese deidentification models to mask or obfuscate Protected Health Information in the Portuguese language. The models are the following: ner_deid_generic: extracts Name, Profession, Age, Date, Contact (Telephone numbers, Email addresses), Location (Address, City, Postal code, Hospital Name, Organization), ID (Social Security numbers, Medical record numbers) and Sex entities. See Model Hub Page for details. ner_deid_subentity: Patient (name), Hospital (name), Date, Organization, City, ID, Street, Sex, Email, ZIP, Profession, Phone, Country, Doctor (name) and Age See Model Hub Page for details. You will use the w2v_cc_300d Portuguese Embeddings with these models. The pipeline should look as follows: ... word_embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;, &quot;pt&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_subentity = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner_deid_subentity&quot;) ner_converter_subentity = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_deid_subentity&quot;]) .setOutputCol(&quot;ner_chunk_subentity&quot;) ner_generic = MedicalNerModel.pretrained(&quot;ner_deid_generic&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner_deid_generic&quot;) ner_converter_generic = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner_deid_generic&quot;]) .setOutputCol(&quot;ner_chunk_generic&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentencerDL, tokenizer, word_embeddings, ner_subentity, ner_converter_subentity, ner_generic, ner_converter_generic, ]) text = &quot;&quot;&quot;Detalhes do paciente. Nome do paciente: Pedro Gonçalves NHC: 2569870. Endereço: Rua Das Flores 23. Código Postal: 21754-987. Dados de cuidados. Data de nascimento: 10/10/1963. Idade: 53 anos Data de admissão: 17/06/2016. Doutora: Maria Santos&quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) results = nlpPipeline.fit(data).transform(data) Results: +--+-+ |chunk |ner_generic_label|ner_subentity_label| +--+-+ |Pedro Gonçalves | NAME | PATIENT | |2569870 | ID | ID | |Rua Das Flores 23| LOCATION | STREET | |21754-987 | LOCATION | ZIP | |10/10/1963 | DATE | DATE | |53 | AGE | AGE | |17/06/2016 | DATE | DATE | |Maria Santos | NAME | DOCTOR | +--+-+ We also include a Clinical Deidentification Pipeline for Portuguese that uses ner_deid_subentity NER model and also several ContextualParsers for rule based contextual Named Entity Recognition tasks. It’s available to be used as follows: from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;pt&quot;, &quot;clinical/models&quot;) The pretrained pipeline comes with Deidentification and Obfuscation capabilities as shows the following example: text = &quot;&quot;&quot;RELAÇÃO HOSPITALAR NOME: Pedro Gonçalves NHC: MVANSK92F09W408A ENDEREÇO: Rua Burcardo 7 CÓDIGO POSTAL: 80139 DATA DE NASCIMENTO: 03/03/1946 IDADE: 70 anos SEXO: Homens E-MAIL: pgon21@tim.pt DATA DE ADMISSÃO: 12/12/2016 DOUTORA: Eva Andrade RELATO CLÍNICO: 70 anos, aposentado, sem alergia a medicamentos conhecida, com a seguinte história: ex-acidente de trabalho com fratura de vértebras e costelas; operado de doença de Dupuytren na mão direita e ponte ílio-femoral esquerda; diabetes tipo II, hipercolesterolemia e hiperuricemia; alcoolismo ativo, fuma 20 cigarros/dia. Ele foi encaminhado a nós por apresentar hematúria macroscópica pós-evacuação em uma ocasião e microhematúria persistente posteriormente, com evacuação normal. O exame físico mostrou bom estado geral, com abdome e genitais normais; o toque retal foi compatível com adenoma de próstata grau I/IV. A urinálise mostrou 4 hemácias/campo e 0-5 leucócitos/campo; o resto do sedimento era normal. O hemograma é normal; a bioquímica mostrou uma glicemia de 169 mg/dl e triglicerídeos 456 mg/dl; função hepática e renal são normais. PSA de 1,16 ng/ml. DIRIGIDA A: Dr. Eva Andrade - Centro Hospitalar do Medio Ave - Avenida Dos Aliados, 56 E-MAIL: evandrade@poste.pt &quot;&quot;&quot; result = deid_pipeline.annotate(text) Results: | | Sentence | Masked | Masked with Chars | Masked with Fixed Chars | Obfuscated | |:|:-|:|:-|:--|:-| | 0 | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | RELAÇÃO HOSPITALAR | | | NOME: Pedro Gonçalves | NOME: &lt;DOCTOR&gt; | NOME: [*************] | NOME: **** | NOME: Isabel Magalhães | | 1 | NHC: MVANSK92F09W408A | NHC: &lt;ID&gt; | NHC: [**************] | NHC: **** | NHC: 124 445 311 | | 2 | ENDEREÇO: Rua Burcardo 7 | ENDEREÇO: &lt;STREET&gt; | ENDEREÇO: [************] | ENDEREÇO: **** | ENDEREÇO: Rua de Santa María, 100 | | 3 | CÓDIGO POSTAL: 80139 | CÓDIGO POSTAL: &lt;ZIP&gt; | CÓDIGO POSTAL: [***] | CÓDIGO POSTAL: **** | CÓDIGO POSTAL: 1000-306 | | | DATA DE NASCIMENTO: 03/03/1946 | DATA DE NASCIMENTO: &lt;DATE&gt; | DATA DE NASCIMENTO: [********] | DATA DE NASCIMENTO: **** | DATA DE NASCIMENTO: 04/04/1946 | | 4 | IDADE: 70 anos | IDADE: &lt;AGE&gt; anos | IDADE: ** anos | IDADE: **** anos | IDADE: 46 anos | | 5 | SEXO: Homens | SEXO: &lt;SEX&gt; | SEXO: [****] | SEXO: **** | SEXO: Mulher | | 6 | E-MAIL: pgon21@tim.pt | E-MAIL: &lt;EMAIL&gt; | E-MAIL: [***********] | E-MAIL: **** | E-MAIL: eric.shannon@geegle.com | | | DATA DE ADMISSÃO: 12/12/2016 | DATA DE ADMISSÃO: &lt;DATE&gt; | DATA DE ADMISSÃO: [********] | DATA DE ADMISSÃO: **** | DATA DE ADMISSÃO: 23/12/2016 | | 7 | DOUTORA: Eva Andrade | DOUTORA: &lt;DOCTOR&gt; | DOUTORA: [*********] | DOUTORA: **** | DOUTORA: Isabel Magalhães | See Model Hub Page for details. Check Spark NLP Portuguese capabilities in 4.7.Clinical_Deidentification_in_Portuguese.ipynb notebook we have prepared for you. New RxNorm Sentence Entity Resolver Model (sbiobertresolve_rxnorm_action_treatment) We are releasing sbiobertresolve_rxnorm_action_treatment model that maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using sbiobert_base_cased_mli Sentence Bert Embeddings. This resolver model maps and extracts pharmaceutical actions (e.g analgesic, hypoglycemic) as well as treatments (e.g backache, diabetes) along with the RxNorm code resolved. Actions and treatments of the drugs are returned in all_k_aux_labels column. See Model Card for details. Example : documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;ner_chunk&quot;) sbert_embedder = BertSentenceEmbeddings.pretrained(&#39;sbiobert_base_cased_mli&#39;, &#39;en&#39;,&#39;clinical/models&#39;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;sentence_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_action_treatment&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;rxnorm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver]) lp_model = LightPipeline(pipelineModel) text = [&quot;Zita 200 mg&quot;, &quot;coumadin 5 mg&quot;, &#39;avandia 4 mg&#39;] result= lp_model.annotate(text) Results* : | | ner_chunk | rxnorm_code | action | treatment | |:|:--|--:|:-|| | 0 | Zita 200 mg | 104080 | [&#39;Analgesic&#39;, &#39;Antacid&#39;, &#39;Antipyretic&#39;] | [&#39;Backache&#39;, &#39;Pain&#39;, &#39;Sore Throat&#39;]| | 1 | coumadin 5 mg | 855333 | [&#39;Anticoagulant&#39;] | [&#39;Cerebrovascular Accident&#39;] | | 2 | avandia 4 mg | 261242 | [&#39;Drugs Used In Diabets&#39;,&#39;Hypoglycemic&#39;]| [&#39;Diabetes Mellitus&#39;, ...] | | New RCT Classification Models and Pretrained Pipelines We are releasing new Randomized Clinical Trial (RCT) classification models and pretrained pipelines that can classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT). Classification Models: rct_binary_classifier_use (Models Hub page) rct_binary_classifier_biobert (Models Hub page) bert_sequence_classifier_binary_rct_biobert (Models Hub page) Pretrained Pipelines: rct_binary_classifier_use_pipeline (Models Hub page) rct_binary_classifier_biobert_pipeline (Models Hub page) bert_sequence_classifier_binary_rct_biobert_pipeline (Models Hub page) Classification Model Example : ... use = UniversalSentenceEncoder.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence_embeddings&quot;) classifier_dl = ClassifierDLModel.pretrained(&#39;rct_binary_classifier_use&#39;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;class&quot;) use_clf_pipeline = Pipeline( stages = [ document_assembler, use, classifier_dl ]) sample_text = &quot;&quot;&quot;Abstract:Based on the American Society of Anesthesiologists&#39; Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants&#39; perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants&#39; guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. &quot;&quot;&quot; result = use_clf_pipeline.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : &gt;&gt; class: True Pretrained Pipeline Example : from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;rct_binary_classifier_use_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;Abstract:Based on the American Society of Anesthesiologists&#39; Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants&#39; perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants&#39; guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. &quot;&quot;&quot; result = pipeline.annotate(text) Results : &gt;&gt; class: True New Features Add getClasses() attribute to MedicalBertForTokenClassifier and MedicalBertForSequenceClassification Now you can use getClasses() method for checking the entity labels of MedicalBertForTokenClassifier and MedicalBertForSequenceClassification like MedicalNerModel. tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_ade&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) .setMaxSentenceLength(512) tokenClassifier.getClasses() [&#39;B-DRUG&#39;, &#39;I-ADE&#39;, &#39;I-DRUG&#39;, &#39;O&#39;, &#39;B-ADE&#39;] Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version Now we download the private models using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before). New functionality to download and extract clinical models from S3 via direct link. Now, you can download clinical models from S3 via direct link directly by downloadModelDirectly method. See the Models Hub Page to find out the download url of each model. from sparknlp.pretrained import ResourceDownloader #The first argument is the path to the zip file and the second one is the folder. ResourceDownloader.downloadModelDirectly(&quot;clinical/models/assertion_dl_en_2.0.2_2.4_1556655581078.zip&quot;, &quot;clinical/models&quot;) Core improvements: Fix MedicalNerModel confidence scores when setIncludeAllConfidenceScores is True A mismatch problem between the tag with the highest confidence score and the predicted tag in MedicalNerModel is resolved. Graph_builder relation_extraction model file name extension problem with auto param A naming problem which occurs while generating a graph for Relation Extraction via graph builder was resolved. Now, the TF graph is generated with the correct extension (.pb). List of Recently Updated or Added Models ner_deid_generic_pt ner_deid_subentity_pt clinical_deidentification_pt sbiobertresolve_rxnorm_action_treatment rct_binary_classifier_use rct_binary_classifier_biobert bert_sequence_classifier_binary_rct_biobert rct_binary_classifier_use_pipeline rct_binary_classifier_biobert_pipeline bert_sequence_classifier_binary_rct_biobert_pipeline sbiobertresolve_ndc Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_1"
  },
  "1434": {
    "id": "1434",
    "title": "Spark NLP for Healthcare Release Notes 3.5.2",
    "content": "3.5.2 Highlights TFGraphBuilder annotator to create graphs for training NER, Assertion, Relation Extraction, and Generic Classifier models Default TF graphs added for AssertionDLApproach to let users train models without custom graphs New functionalities in ContextualParserApproach Printing the list of clinical pretrained models and pipelines with one-liner New clinical models Clinical NER model (ner_biomedical_bc2gm) Clinical ChunkMapper models (abbreviation_mapper, rxnorm_ndc_mapper, drug_brandname_ndc_mapper, rxnorm_action_treatment_mapper) Bug fixes New and updated notebooks List of recently updated or added models TFGraphBuilder annotator to create graphs for Training NER, Assertion, Relation Extraction, and Generic Classifier Models We have a new annotator used to create graphs in the model training pipeline. TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (&lt;= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach. You can use this builder with MedicalNerApproach, RelationExtractionApproach, AssertionDLApproach, and GenericClassifierApproach Example: graph_folder_path = &quot;./medical_graphs&quot; med_ner_graph_builder = TFGraphBuilder() .setModelName(&quot;ner_dl&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFile(&quot;auto&quot;) .setHiddenUnitsNumber(20) .setGraphFolder(graph_folder_path) med_ner = MedicalNerApproach() ... .setGraphFolder(graph_folder) medner_pipeline = Pipeline()([ ..., med_ner_graph_builder, med_ner ]) For more examples, please check TFGraph Builder Notebook. Default TF graphs added for AssertionDLApproach to let users train models without custom graphs We added default TF graphs for the AssertionDLApproach to let users train assertion models without specifying any custom TF graph. Default Graph Features: Feature Sizes: 100, 200, 768 Number of Classes: 2, 4, 8 New Functionalities in ContextualParserApproach Added .setOptionalContextRules parameter that allows to output regex matches regardless of context match (prefix, suffix configuration). Allows sending a JSON string of the configuration file to setJsonPath parameter. Confidence Value Scenarios: When there is regex match only, the confidence value will be 0.5. When there are regex and prefix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the prefix. When there are regex and suffix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the suffix. When there are regex, prefix, and suffix matches all together, the confidence value will be &gt; than the other scenarios. Example: jsonString = { &quot;entity&quot;: &quot;CarId&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;false&quot;, &quot;regex&quot;: &quot; d+&quot;, &quot;prefix&quot;: [&quot;red&quot;], &quot;contextLength&quot;: 100 } with open(&quot;jsonString.json&quot;, &quot;w&quot;) as f: json.dump(jsonString, f) contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;jsonString.json&quot;) .setCaseSensitive(True) .setOptionalContextRules(True) Printing the List of Clinical Pretrained Models and Pipelines with One-Liner Now we can check what the clinical model names are of a specific annotator and the names of clinical pretrained pipelines in a language. Listing Clinical Model Names: Example: from sparknlp_jsl.pretrained import InternalResourceDownloader InternalResourceDownloader.showPrivateModels(&quot;AssertionDLModel&quot;) Results: +--+++ | Model | lang | version | +--+++ | assertion_ml | en | 2.0.2 | | assertion_dl | en | 2.0.2 | | assertion_dl_healthcare | en | 2.7.2 | | assertion_dl_biobert | en | 2.7.2 | | assertion_dl | en | 2.7.2 | | assertion_dl_radiology | en | 2.7.4 | | assertion_jsl_large | en | 3.1.2 | | assertion_jsl | en | 3.1.2 | | assertion_dl_scope_L10R10 | en | 3.4.2 | | assertion_dl_biobert_scope_L10R10 | en | 3.4.2 | +--+++ Listing Clinical Pretrained Pipelines: from sparknlp_jsl.pretrained import InternalResourceDownloader InternalResourceDownloader.showPrivatePipelines(&quot;en&quot;) +--+++ | Pipeline | lang | version | +--+++ | clinical_analysis | en | 2.4.0 | | clinical_ner_assertion | en | 2.4.0 | | clinical_deidentification | en | 2.4.0 | | clinical_analysis | en | 2.4.0 | | explain_clinical_doc_ade | en | 2.7.3 | | icd10cm_snomed_mapping | en | 2.7.5 | | recognize_entities_posology | en | 3.0.0 | | explain_clinical_doc_carp | en | 3.0.0 | | recognize_entities_posology | en | 3.0.0 | | explain_clinical_doc_ade | en | 3.0.0 | | explain_clinical_doc_era | en | 3.0.0 | | icd10cm_snomed_mapping | en | 3.0.2 | | snomed_icd10cm_mapping | en | 3.0.2 | | icd10cm_umls_mapping | en | 3.0.2 | | snomed_umls_mapping | en | 3.0.2 | | ... | ... | ... | +--+++ New ner_biomedical_bc2gm NER Model This model has been trained to extract genes/proteins from a medical text. See Model Card for more details. Example : ... ner = MedicalNerModel.pretrained(&quot;ner_biomedical_bc2gm&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... text = spark.createDataFrame([[&quot;Immunohistochemical staining was positive for S-100 in all 9 cases stained, positive for HMB-45 in 9 (90%) of 10, and negative for cytokeratin in all 9 cases in which myxoid melanoma remained in the block after previous sections.&quot;]]).toDF(&quot;text&quot;) result = model.transform(text) Results : +--++ |chunk |ner_label | +--++ |S-100 |GENE_PROTEIN| |HMB-45 |GENE_PROTEIN| |cytokeratin|GENE_PROTEIN| +--++ New Clinical ChunkMapper Models We have 4 new ChunkMapper models and a new Chunk Mapping Notebook for showing their examples. drug_brandname_ndc_mapper: This model maps drug brand names to corresponding National Drug Codes (NDC). Product NDCs for each strength are returned in result and metadata. See Model Card for more details. Example : document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;drug_brandname_ndc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;ndc&quot;) .setRel(&quot;Strength_NDC&quot;) model = PipelineModel(stages=[document_assembler, chunkerMapper]) light_model = LightPipeline(model) res = light_model.fullAnnotate([&quot;zytiga&quot;, &quot;ZYVOX&quot;, &quot;ZYTIGA&quot;]) Results : +-+--+--+ | Brandname | Strenth_NDC | Other_NDSs | +-+--+--+ | zytiga | 500 mg/1 | 57894-195 | [&#39;250 mg/1 | 57894-150&#39;] | | ZYVOX | 600 mg/300mL | 0009-4992 | [&#39;600 mg/300mL | 66298-7807&#39;, &#39;600 mg/300mL | 0009-7807&#39;] | | ZYTIGA | 500 mg/1 | 57894-195 | [&#39;250 mg/1 | 57894-150&#39;] | +-+--+--+ abbreviation_mapper: This model maps abbreviations and acronyms of medical regulatory activities with their definitions. See Model Card for details. Example: input = [&quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LABORATORY DATA: Laboratory tests include a CBC which is normal. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] &gt;&gt; output: ++-+ |Abbreviation|Definition | ++-+ |CBC |complete blood count | |HIV |human immunodeficiency virus| ++-+ rxnorm_action_treatment_mapper: RxNorm and RxNorm Extension codes with their corresponding action and treatment. Action refers to the function of the drug in various body systems; treatment refers to which disease the drug is used to treat. See Model Card for more details. Example: input = [&#39;Sinequan 150 MG&#39;, &#39;Zonalon 50 mg&#39;] &gt;&gt; output: ++++ |chunk |rxnorm_code |Action | ++++ |Sinequan 150 MG|1000067 |Antidepressant | |Zonalon 50 mg |103971 |Analgesic | ++++ rxnorm_ndc_mapper: This pretrained model maps RxNorm and RxNorm Extension codes with corresponding National Drug Codes (NDC). See Model Card for more details. Example: input = [&#39;doxepin hydrochloride 50 MG/ML&#39;, &#39;macadamia nut 100 MG/ML&#39;] &gt;&gt; output: ++++ |chunk |rxnorm_code |Product NDC | ++++ |doxepin hydrochloride 50 MG/ML|1000091 |00378-8117 | |macadamia nut 100 MG/ML |212433 |00064-2120 | ++++ Bug Fixes We fixed some issues in DrugNormalizer, DateNormalizer and ContextualParserApproach annotators. DateNormalizer : We fixed some relative date issues and also DateNormalizer takes account the Leap years now. DrugNormalizer : Fixed some formats. ContextualParserApproach : Computing the right distance for prefix. Extracting the right content for suffix. Handling special characters in prefix and suffix. New and Updated Notebooks We prepared Spark NLP for Healthcare 3hr Notebook to cover mostly used components of Spark NLP in ODSC East 2022-3 hours hands-on workshop on ‘Modular Approach to Solve Problems at Scale in Healthcare NLP’. You can also find its Databricks version here. New Chunk Mapping Notebook for showing the examples of Chunk Mapper models. Updated healthcare tutorial notebooks for Databricks with sparknlp_jsl v3.5.1 We have a new Databricks healthcare tutorials folder in which you can find all Spark NLP for Healthcare Databricks tutorial notebooks. Updated Graph Builder Notebook by adding the examples of new TFGraphBuilder annotator. List of Recently Updated or Added Models sbiobertresolve_rxnorm_action_treatment ner_biomedical_bc2gm abbreviation_mapper rxnorm_ndc_mapper drug_brandname_ndc_mapper sbiobertresolve_cpt_procedures_measurements_augmented sbiobertresolve_icd10cm_slim_billable_hcc sbiobertresolve_icd10cm_slim_normalized For all Spark NLP for healthcare models, please check : Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_2"
  },
  "1435": {
    "id": "1435",
    "title": "Spark NLP for Healthcare Release Notes 3.5.3",
    "content": "3.5.3 Highlights New rxnorm_mapper model New ChunkMapperFilterer annotator to filter ChunkMapperModel results New features Add the setReplaceLabels parameter that allows replacing the non-conventional labels without using an external source file in the NerConverterInternal(). Case sensitivity can be set in ChunkMapperApproach and ChunkMapperModel through setLowerCase() parameter. Return multiple relations at a time in ChunkMapperModel models via setRels() parameter. Filter the multi-token chunks separated with whitespace in ChunkMapperApproach by setAllowMultiTokenChunk() parameter. New license validation policy in License Validator. Bug fixes Updated notebooks List of recently updated or added models New rxnorm_mapper Model We are releasing rxnorm_mapper model that maps clinical entities and concepts to corresponding rxnorm codes. See Model Hub Page for details. Example : ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRel(&quot;rxnorm_code&quot;) ... sample_text = &quot;The patient was given Zyrtec 10 MG, Adapin 10 MG Oral Capsule, Septi-Soothe 0.5 Topical Spray&quot; Results : +++ |chunk |rxnorm_mappings| +++ |Zyrtec 10 MG |1011483 | |Adapin 10 MG Oral Capsule |1000050 | |Septi-Soothe 0.5 Topical Spray|1000046 | +++ New ChunkMapperFilterer Annotator to Filter ChunkMapperModel Results ChunkMapperFilterer annotator allows filtering of the chunks that were passed through the ChunkMapperModel. If setReturnCriteria() is set as &quot;success&quot;, only the chunks which are mapped by ChunkMapperModel are returned. Otherwise, if setReturnCriteria() is set as &quot;fail&quot;, only the chunks which are not mapped by ChunkMapperModel are returned. Example : ... cfModel = ChunkMapperFilterer() .setInputCols([&quot;ner_chunk&quot;,&quot;mappings&quot;]) .setOutputCol(&quot;chunks_filtered&quot;) .setReturnCriteria(&quot;success&quot;) #or &quot;fail&quot; ... sample_text = &quot;The patient was given Warfarina Lusa and amlodipine 10 mg. Also, he was given Aspagin, coumadin 5 mg and metformin&quot; .setReturnCriteria(&quot;success&quot;) Results : +--++--+--+ |begin|end| entity| mappings| +--++--+--+ | 22| 35| DRUG|Warfarina Lusa| +--++--+--+ .setReturnCriteria(&quot;fail&quot;) Results : +--++--++ |begin|end| entity| not mapped| +--++--++ | 41| 50| DRUG| amlodipine| | 80| 86| DRUG| Aspagin| | 89| 96| DRUG| coumadin| | 115|123| DRUG| metformin| +--++--++ New Features: Add setReplaceLabels Parameter That Allows Replacing the Non-Conventional Labels Without Using an External Source File in the NerConverterInternal(). Now you can replace the labels in NER models with custom labels by using .setReplaceLabels parameter with NerConverterInternal annotator. In this way, you will not need to use any other external source file to replace the labels with custom ones. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;, &quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ner_converter_original = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;original_label&quot;) ner_converter_replaced = NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) .setOutputCol(&quot;replaced_label&quot;) .setReplaceLabels({&quot;Drug_Ingredient&quot; : &quot;Drug&quot;,&#39;Drug_BrandName&#39;:&#39;Drug&#39;}) ... sample_text = &quot;The patient was given Warfarina Lusa and amlodipine 10 mg. Also, he was given Aspagin, coumadin 5 mg, and metformin&quot; Results : +--+--+++--+ |chunk |begin|end|original_label |replaced_label| +--+--+++--+ |Warfarina Lusa|22 |35 |Drug_BrandName |Drug | |amlodipine |41 |50 |Drug_Ingredient|Drug | |10 mg |52 |56 |Strength |Strength | |he |65 |66 |Gender |Gender | |Aspagin |78 |84 |Drug_BrandName |Drug | |coumadin |87 |94 |Drug_Ingredient|Drug | |5 mg |96 |99 |Strength |Strength | |metformin |106 |114|Drug_Ingredient|Drug | +--+--+++--+ Case Sensitivity in ChunkMapperApproach and ChunkMapperModel Through setLowerCase() Parameter The case status of ChunkMapperApproach and ChunkMapperModel can be set by using setLowerCase() parameter. Example : ... chunkerMapperapproach = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setRel(&quot;action&quot;) .setLowerCase(True) #or False ... sentences = [[&quot;&quot;&quot;The patient was given Warfarina lusa and amlodipine 10 mg, coumadin 5 mg. The patient was given Coumadin&quot;&quot;&quot;]] setLowerCase(True) Results : ++--+ |chunk |mapped | ++--+ |Warfarina lusa |540228 | |amlodipine |329526 | |coumadin |202421 | |Coumadin |202421 | ++--+ setLowerCase(False) Results : ++--+ |chunk |mapped | ++--+ |Warfarina lusa |NONE | |amlodipine |329526 | |coumadin |NONE | |Coumadin |202421 | ++--+ Return Multiple Relations At a Time In ChunkMapper Models Via setRels() Parameter Multiple relations for the same chunk can be set with the setRels() parameter in both ChunkMapperApproach and ChunkMapperModel. Example : ... chunkerMapperapproach = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setRels([&quot;action&quot;,&quot;treatment&quot;]) .setLowerCase(True) ... sample_text = &quot;The patient was given Warfarina Lusa.&quot; Results : +--++--+-++ |begin|end| entity| mappings| relation| +--++--+-++ | 22| 35|Warfarina Lusa|Anticoagulant| action| | 22| 35|Warfarina Lusa|Heart Disease|treatment| +--++--+-++ Filter the Multi-Token Chunks Separated With Whitespace in ChunkMapperApproach and ChunkMapperModel by setAllowMultiTokenChunk() Parameter The chunks that include multi-tokens separated by a whitespace, can be filtered by using setAllowMultiTokenChunk() parameter. Example : ... chunkerMapper = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(False) ... sample_text = &quot;The patient was given Warfarina Lusa&quot; setAllowMultiTokenChunk(False) Results : +--++--+--+--+ |begin|end| chunk|mappings|relation| +--++--+--+--+ | 22| 35|Warfarina Lusa| NONE| null| +--++--+--+--+ setAllowMultiTokenChunk(True) Results : +--++--+-++ |begin|end| chunk| mappings| relation| +--++--+-++ | 22| 35|Warfarina Lusa|Anticoagulant| action| | 22| 35|Warfarina Lusa|Heart Disease|treatment| +--++--+-++ New License Validation Policies in License Validator A new version of the License Validator has been included in Spark NLP for Healthcare. This License Validator checks the compatibility between the type of your license and the environment you are using, allowing the license to be used only for the environment it was requested (single-node, cluster, databricks, etc) and the number of concurrent sessions (floating or not-floating). You can check which type of license you have in my.johnsnowlabs.com -&gt; My Subscriptions. If your license stopped working, please contact support@johnsnowlabs.com so that it can be checked the difference between the environment your license was requested for and the one it’s currently being used. Bug Fixes We fixed some issues in AnnotationToolJsonReader tool, DrugNormalizer and ContextualParserApproach annotators. DrugNormalizer : Fixed some issues that affect the performance. ContextualParserApproach : Fixed the issue in the computation of indices for documents with more than one sentence while defining the rule-scope field as a document. AnnotationToolJsonReader : Fixed an issue where relation labels were not being extracted from the Annotation Lab json file export. Updated Notebooks Clinical Named Entity Recognition Notebook .setReplaceLabels parameter example was added. Chunk Mapping Notebook New case sensitivity, selecting multiple relations, filtering multi-token chunks and ChunkMapperFilterer features were added. List of Recently Updated Models sbiobertresolve_icdo_augmented rxnorm_mapper For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_3_5_3"
  },
  "1436": {
    "id": "1436",
    "title": "Spark NLP release notes 3.6.0",
    "content": "3.6.0 Release date: 05-08-2021 Overview Handwritten detection and visualization improvement. New Features Added ImageHandwrittenDetector for detecting ‘signature’, ‘date’, ‘name’, ‘title’, ‘address’ and others handwritten text. Added rendering labels and scores in ImageDrawRegions. Added possibility to scale image to fixed size in ImageScaler with keeping original ratio. Enhancements Support new version of pip for installing python package Added support string labels for detectors Added an auto inferencing of the input shape for detector models New license validator Bugfixes Fixed display BGR images in display functions New and updated notebooks Image Signature Detection example Image Handwritten Detection example Image Scaler example Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_6_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_6_0"
  },
  "1437": {
    "id": "1437",
    "title": "Spark NLP release notes 3.7.0",
    "content": "3.7.0 Release date: 30-08-2021 Overview Improve table recognition and render OCR results to the PDF with original image New Features Added ImageToTextPdf transformer for storing recognized text to the searchable PDF with original image Added PdfAssembler for assembling multipage PDF document from single page PDF documents Enhancements Added support dbfs for store models. This allow to use models on Databricks. Improved ImageTableCellDetector algorithms Added params for tuning ImageTableCellDetector algorithms Added possibility to render detected lines to the original image in ImageTableCellDetector Added support to store recognized results to CSV in ImageCellsToTextTable Added display_table and display_tables functions Added display_pdf_file function for displaying pdf in embedded pdf viewer Updated license validator New and updated notebooks Process multiple page scanned PDF (New) Image Table Detection example Image Cell Recognition example Image Table Recognition Tables Recognition from PDF Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_7_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_7_0"
  },
  "1438": {
    "id": "1438",
    "title": "Spark NLP release notes 3.8.0",
    "content": "3.8.0 Release date: 14-09-2021 Overview Support Microsoft PPT and PPTX documents. New Features Added PptToPdf transformer for converting PPT and PPTX slides to the PDF document. Added PptToTextTable transformer for extracting tables from PPT and PPTX slides. New and updated notebooks Convert PPT to PDF (New) Extract tables from PPT (New) Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_8_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_8_0"
  },
  "1439": {
    "id": "1439",
    "title": "Spark NLP release notes 3.9.0",
    "content": "3.9.0 Release date: 20-10-2021 Overview Improve visualization and support Spark NLP. New Features Added HocrTokenizer Added HocrDocumentAssembler Added ImageDrawAnnotations Added support Arabic language in ImageToText and ImageToHocr Enhancements Added postprocessing to the ImageTableDetector Added Spark NLP by default to spark session in start function Changed default value for ignoreResolution param in ImageToText Updated license-validator. Added support floating license and set AWS keys from license. Added ‘whiteList’ param to the VisualDocumentNER New and updated notebooks Spark OCR HOCR Visual Document NER Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_9_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_9_0"
  },
  "1440": {
    "id": "1440",
    "title": "Spark NLP release notes 3.9.1",
    "content": "3.9.1 Release date: 02-11-2021 Overview Added preserving of original file formatting Enhancements Added keepLayout param to the ImageToText New and updated notebooks Preserve Original Formatting Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_3_9_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_3_9_1"
  },
  "1441": {
    "id": "1441",
    "title": "Spark NLP release notes 4.0.0",
    "content": "4.0.0 Release date: 16-07-2022 Overview We are very glad to announce that Spark OCR 4.0.0 has been released! This release comes with new models, new functionality, bug fixes, and compatibility with 4.0.0 versions of Spark NLP and Spark NLP for Healthcare. New Features New DicomMetadataDeidentifier class to help deidentifying metadata of dicom files. Example Notebook. New helper function display_dicom() to help displaying DICOM files in notebooks. New DicomDrawRegions that can clean burned pixels for removing PHI. Improved support for DICOM files containing 12bit images. Bug Fixes Fixes on the Visual NER Finetuning process including VisualDocumentNERv2 and AlabReader. Improved exception handling for VisualDocumentClassifier models. New Models New LayoutLMv3 based Visual Document NER: layoutlmv3_finetuned_funsd. Improved handwritten detection ocr_base_handwritten_v2. VisualDocumentClassifierV2: layoutlmv2_rvl_cdip_40k. This model adds more data compared to layoutlmv2_rvl_cdip_1500, and achieves an accuracy of 88%. Compatibility Updates Deprecated Spark 2.3 and Spark 2.4 support. Tested compatibility with Spark-NLP and Spark NLP for Healthcare 4.0.0. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_0_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_0_0"
  },
  "1442": {
    "id": "1442",
    "title": "Spark NLP for Healthcare Release Notes 4.0.0",
    "content": "4.0.0 Highlights 8 new chunk mapper models and 9 new pretrained chunk mapper pipelines to convert one medical terminology to another (Snomed to ICD10, RxNorm to UMLS etc.) 2 new medical NER models (ner_clinical_trials_abstracts and ner_pathogen) and pretrained NER pipelines 20 new biomedical NER models based on the LivingNER corpus in 8 languages (English, Spanish, French, Italian, Portuguese, Romanian, Catalan and Galician) 2 new medical NER models for Romanian language (ner_clinical, ner_clinical_bert) Deidentification support for Romanian language (ner_deid_subentity, ner_deid_subentity_bert and a pretrained deidentification pipeline) The first public health model: Emotional stress classifier (bert_sequence_classifier_stress) ResolverMerger annotator to merge the results of ChunkMapperModel and SentenceEntityResolverModel annotators New Shortest Context Match and Token Index Features in ContextualParserApproach Prettified relational categories in ZeroShotRelationExtractionModel annotator Create graphs for open source NerDLApproach with the TFGraphBuilder Spark NLP for Healthcare library installation with Poetry (dependency management and packaging tool) Bug fixes Updated notebooks List of recently updated or added models (50+ new medical models and pipelines) 8 New Chunk Mapper Models and 9 New Pretrained Chunk Mapper Pipelines to Convert One Medical Terminology to Another (Snomed to ICD10, RxNorm to UMLS etc.) We are releasing 8 new ChunkMapperModel models and 9 new pretrained pipelines for mapping clinical codes with their corresponding. Mapper Models: Mapper Name Source Target snomed_icd10cm_mapper SNOMED CT ICD-10-CM icd10cm_snomed_mapper ICD-10-CM SNOMED CT snomed_icdo_mapper SNOMED CT ICD-O icdo_snomed_mapper ICD-O SNOMED CT rxnorm_umls_mapper RxNorm UMLS icd10cm_umls_mapper ICD-10-CM UMLS mesh_umls_mapper MeSH UMLS snomed_umls_mapper SNOMED CT UMLS Example: ... snomed_resolver = SentenceEntityResolverModel.pretrained(&quot;sbertresolve_snomed_conditions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;snomed_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;snomed_icd10cm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;snomed_code&quot;]) .setOutputCol(&quot;icd10cm_mappings&quot;) .setRels([&quot;icd10cm_code&quot;]) pipeline = PipelineModel( stages = [ documentAssembler, sbert_embedder, snomed_resolver, chunkerMapper ]) light_pipeline= LightPipeline(pipeline) result = light_pipeline.fullAnnotate(&quot;Radiating chest pain&quot;) Results : | | ner_chunk | snomed_code | icd10cm_mappings | |:|:|--:|:-| | 0 | Radiating chest pain | 10000006 | R07.9 | Pretrained Pipelines: Pipeline Name Source Target icd10cm_snomed_mapping ICD-10-CM SNOMED CT snomed_icd10cm_mapping SNOMED CT ICD-10-CM icdo_snomed_mapping ICD-O SNOMED CT snomed_icdo_mapping SNOMED CT ICD-O rxnorm_ndc_mapping RxNorm NDC icd10cm_umls_mapping ICD-10-CM UMLS mesh_umls_mapping MeSH UMLS rxnorm_umls_mapping RxNorm UMLS snomed_umls_mapping SOMED CT UMLS Example: from sparknlp.pretrained import PretrainedPipeline pipeline= PretrainedPipeline(&quot;rxnorm_umls_mapping&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result= pipeline.annotate(&quot;1161611 315677&quot;) Results : {&#39;document&#39;: [&#39;1161611 315677&#39;], &#39;rxnorm_code&#39;: [&#39;1161611&#39;, &#39;315677&#39;], &#39;umls_code&#39;: [&#39;C3215948&#39;, &#39;C0984912&#39;]} 2 New Medical NER Models (ner_clinical_trials_abstracts and ner_pathogene) and Pretrained NER Pipelines ner_clinical_trials_abstracts: This model can extract concepts related to clinical trial design, diseases, drugs, population, statistics and publication. It can detect Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_trials_abstracts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... sample_text = &quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot; bert_token_classifier_ner_clinical_trials_abstracts: This model is the BERT-based version of ner_clinical_trials_abstracts model and it can detect Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_clinical_trials_abstracts&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... sample_text = &quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot; ner_clinical_trials_abstracts_pipeline: This pretrained pipeline is build upon the ner_clinical_trials_abstracts model and it can extract Age, AllocationRatio, Author, BioAndMedicalUnit, CTAnalysisApproach, CTDesign, Confidence, Country, DisorderOrSyndrome, DoseValue, Drug, DrugTime, Duration, Journal, NumberPatients, PMID, PValue, PercentagePatients, PublicationYear, TimePoint, Value entities. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_clinical_trials_abstracts_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;A one-year, randomised, multicentre trial comparing insulin glargine with NPH insulin in combination with oral agents in patients with type 2 diabetes.&quot;) Results : +-++ | chunk| ner_label| +-++ | randomised| CTDesign| | multicentre| CTDesign| |insulin glargine| Drug| | NPH insulin| Drug| | type 2 diabetes|DisorderOrSyndrome| +-++ ner_pathogen: This model is trained for detecting medical conditions (influenza, headache, malaria, etc), medicine (aspirin, penicillin, methotrexate) and pathogenes (Corona Virus, Zika Virus, E. Coli, etc) in clinical texts. It can extract Pathogen, MedicalCondition, Medicine entities. See Model Hub Page for details. Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_pathogen&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&quot; ner_pathogen_pipeline: This pretrained pipeline is build upon the ner_pathogen model and it can extract Pathogen, MedicalCondition, Medicine entities. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_pathogen_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;Racecadotril is an antisecretory medication and it has better tolerability than loperamide. Diarrhea is the condition of having loose, liquid or watery bowel movements each day. Signs of dehydration often begin with loss of the normal stretchiness of the skin. While it has been speculated that rabies virus, Lyssavirus and Ephemerovirus could be transmitted through aerosols, studies have concluded that this is only feasible in limited conditions.&quot;) Results : ++-+ |chunk |ner_label | ++-+ |Racecadotril |Medicine | |loperamide |Medicine | |Diarrhea |MedicalCondition| |dehydration |MedicalCondition| |rabies virus |Pathogen | |Lyssavirus |Pathogen | |Ephemerovirus |Pathogen | ++-+ ner_biomedical_bc2gm_pipeline : This pretrained pipeline can extract genes/proteins from medical texts by labelling them as GENE_PROTEIN. See Model Hub Page for details. Example : pipeline = PretrainedPipeline(&quot;ner_biomedical_bc2gm_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;Immunohistochemical staining was positive for S-100 in all 9 cases stained, positive for HMB-45 in 9 (90%) of 10, and negative for cytokeratin in all 9 cases in which myxoid melanoma remained in the block after previous sections.&quot;&quot;&quot;) Results : +--++ |chunk |ner_label | +--++ |S-100 |GENE_PROTEIN| |HMB-45 |GENE_PROTEIN| |cytokeratin|GENE_PROTEIN| +--++ 20 New Biomedical NER Models Based on the [LivingNER corpus] in 8 Languages We are releasing 20 new NER and MedicalBertForTokenClassifier models for *English, French, Italian, Portuguese, Romanian, Catalan and Galician languages that are trained on the LivingNER multilingual corpus and for Spanish that is trained on LivingNER corpus is composed of clinical case reports extracted from miscellaneous medical specialties including COVID, oncology, infectious diseases, tropical medicine, urology, pediatrics, and others. These models can detect living species as HUMAN and SPECIES entities in clinical texts. Here is the list of model names and their embeddings used while training: Language Annotator Embeddings Model Name es MedicalBertForTokenClassification   bert_token_classifier_ner_living_species es MedicalNerModel bert_base_cased_es ner_living_species_bert es MedicalNerModel roberta_base_biomedical_es ner_living_species_roberta es MedicalNerModel embeddings_scielo_300d_es ner_living_species_300 es MedicalNerModel w2v_cc_300d_es ner_living_species en MedicalBertForTokenClassification   bert_token_classifier_ner_living_species en MedicalNerModel embeddings_clinical_en ner_living_species en MedicalNerModel biobert_pubmed_base_cased_en ner_living_species_biobert fr MedicalNerModel w2v_cc_300d_fr ner_living_species fr MedicalNerModel bert_embeddings_bert_base_fr_cased ner_living_species_bert pt MedicalBertForTokenClassification   bert_token_classifier_ner_living_species pt MedicalNerModel w2v_cc_300d_pt ner_living_species pt MedicalNerModel roberta_embeddings_BR_BERTo_pt ner_living_species_roberta pt MedicalNerModel biobert_embeddings_biomedical_pt ner_living_species_bert it MedicalBertForTokenClassification   bert_token_classifier_ner_living_species it MedicalNerModel bert_base_italian_xxl_cased_it ner_living_species_bert it MedicalNerModel w2v_cc_300d_it ner_living_species ro MedicalNerModel bert_base_cased_ro ner_living_species_bert cat MedicalNerModel w2v_cc_300d_cat ner_living_species gal MedicalNerModel w2v_cc_300d_gal ner_living_species Example : ... clinical_ner = MedicalNerModel.pretrained(&quot;ner_living_species&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner_tags&quot;) ... results = ner_model.transform(spark.createDataFrame([[&quot;&quot;&quot;Patient aged 61 years; no known drug allergies, smoker of 63 packs/year, significant active alcoholism, recently diagnosed hypertension. He came to the emergency department approximately 4 days ago with a frontal headache coinciding with a diagnosis of hypertension, for which he was started on antihypertensive treatment. The family reported that they found him &quot;slower&quot; accompanied by behavioural alterations; with no other accompanying symptoms.Physical examination: Glasgow Glasgow 15; neurological examination without focality except for bradypsychia and disorientation in time, person and space. Afebrile. BP: 159/92; heart rate 70 and O2 Sat: 93%; abdominal examination revealed hepatomegaly of two finger widths with no other noteworthy findings. CBC: Legionella antigen and pneumococcus in urine negative.&quot;&quot;&quot;]], [&quot;text&quot;])) Results : ++-+ |ner_chunk |label | ++-+ |Patient |HUMAN | |family |HUMAN | |person |HUMAN | |Legionella |SPECIES| |pneumococcus|SPECIES| ++-+ 2 New Medical NER Models for Romanian Language We trained ner_clinical and ner_clinical_bert models that can detect Measurements, Form, Symptom, Route, Procedure, Disease_Syndrome_Disorder, Score, Drug_Ingredient, Pulse, Frequency, Date, Body_Part, Drug_Brand_Name, Time, Direction, Dosage, Medical_Device, Imaging_Technique, Test, Imaging_Findings, Imaging_Test, Test_Result, Weight, Clinical_Dept and Units entities in Romanian clinical texts. ner_clinical: This model is trained with w2v_cc_300d embeddings model. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Aorta ascendenta inlocuita cu proteza de Dacron de la nivelul anulusului pana pe segmentul ascendent distal pe o lungime aproximativa de 75 mm.&quot; ner_clinical_bert: This model is trained with bert_base_cased embeddings model. Example : ... embeddings = BertEmbeddings.pretrained(&quot;bert_base_cased&quot;, &quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_bert&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;Aorta ascendenta inlocuita cu proteza de Dacron de la nivelul anulusului pana pe segmentul ascendent distal pe o lungime aproximativa de 75 mm.&quot; Results : +-+--+ | chunks| entities| +-+--+ | Aorta ascendenta| Body_Part| | proteza de Dacron|Medical_Device| | anulusului| Body_Part| |segmentul ascendent| Body_Part| | distal| Direction| | 75| Measurements| | mm| Units| +-+--+ Deidentification Support for Romanian Language (ner_deid_subentity, ner_deid_subentity_bert and a Pretrained Deidentification Pipeline) We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in Romanian. ner_deid_subentity and ner_deid_subentity_bert models are trained with in-house annotations and can detect 17 different entities (AGE, CITY, COUNTRY, DATE, DOCTOR, EMAIL, FAX, HOSPITAL, IDNUM, LOCATION-OTHER, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, ZIP). ner_deid_subentity: This model is trained with w2v_cc_300d embeddings model. See Model Hub Page for details. Example : ... embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;&quot;&quot; Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui, 737405 România Tel: +40(235)413773 Data setului de analize: 25 May 2022 15:36:00 Nume si Prenume : BUREAN MARIA, Varsta: 77 Medic : Agota Evelyn Tımar C.N.P : 2450502264401&quot;&quot;&quot; ner_deid_subentity_bert: This model is trained with bert_base_cased embeddings model. See Model Hub Page for details. Example : ... embeddings = BertEmbeddings.pretrained(&quot;bert_base_cased&quot;, &quot;ro&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;word_embeddings&quot;) clinical_ner = MedicalNerModel.pretrained(&quot;ner_deid_subentity_bert&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;word_embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... text = &quot;&quot;&quot; Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui, 737405 România Tel: +40(235)413773 Data setului de analize: 25 May 2022 15:36:00 Nume si Prenume : BUREAN MARIA, Varsta: 77 Medic : Agota Evelyn Tımar C.N.P : 2450502264401&quot;&quot;&quot; Results : +-++ |chunk |ner_label| +-++ |Spitalul Pentru Ochi de Deal|HOSPITAL | |Drumul Oprea Nr |STREET | |Vaslui |CITY | |737405 |ZIP | |+40(235)413773 |PHONE | |25 May 2022 |DATE | |BUREAN MARIA |PATIENT | |77 |AGE | |Agota Evelyn Tımar |DOCTOR | |2450502264401 |IDNUM | +-++ clinical_deidentification: This pretrained pipeline that can be used to deidentify PHI information from Romanian medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate ACCOUNT, PLATE, LICENSE, AGE, CITY, COUNTRY, DATE, DOCTOR, EMAIL, FAX, HOSPITAL, IDNUM, LOCATION-OTHER, MEDICALRECORD, ORGANIZATION, PATIENT, PHONE, PROFESSION, STREET, ZIP entities. See Model Hub Page for details. Example : from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;ro&quot;, &quot;clinical/models&quot;) text = &quot;Varsta : 77, Nume si Prenume : BUREAN MARIA, Data setului de analize: 25 May 2022, Licență : B004256985M, Înmatriculare : CD205113, Cont : FXHZ7170951927104999&quot; result = deid_pipeline.annotate(text) print(&quot; nMasked with entity labels&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked&#39;])) print(&quot; nMasked with chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_with_chars&#39;])) print(&quot; nMasked with fixed length chars&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;masked_fixed_length_chars&#39;])) print(&quot; nObfuscated&quot;) print(&quot;-&quot;*30) print(&quot; n&quot;.join(result[&#39;obfuscated&#39;])) Results : Masked with entity labels Varsta : &lt;AGE&gt;, Nume si Prenume : &lt;PATIENT&gt;, Data setului de analize: &lt;DATE&gt;, Licență : &lt;LICENSE&gt;, Înmatriculare : &lt;PLATE&gt;, Cont : &lt;ACCOUNT&gt; Masked with chars Varsta : **, Nume si Prenume : [**********], Data setului de analize: [*********], Licență : [*********], Înmatriculare : [******], Cont : [******************] Masked with fixed length chars Varsta : ****, Nume si Prenume : ****, Data setului de analize: ****, Licență : ****, Înmatriculare : ****, Cont : **** Obfuscated Varsta : 91, Nume si Prenume : Dragomir Emilia, Data setului de analize: 01-04-2001, Licență : T003485962M, Înmatriculare : AR-65-UPQ, Cont : KHHO5029180812813651 The First Public Health Model: Emotional Stress Classifier We are releasing a new bert_sequence_classifier_stress model that can classify whether the content of a text expresses emotional stress. It is a PHS-BERT-based model and trained with the Dreaddit dataset. Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_stress&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) sample_text = &quot;No place in my city has shelter space for us, and I won&#39;t put my baby on the literal street. What cities have good shelter programs for homeless mothers and children?&quot; Results : +-+--+ |text | class| +-+--+ |No place in my city has shelter space for us, and I won&#39;t put my baby on the literal street. What cities have good shelter programs for homeless mothers and children?|[stress]| +-+--+ ResolverMerger Annotator to Merge the Results of ChunkMapperModel and SentenceEntityResolverModel Annotators ResolverMerger annotator allows to merge the results of ChunkMapperModel and SentenceEntityResolverModel annotators. You can detect your results that fail by ChunkMapperModel with ChunkMapperFilterer and then merge your resolver and mapper results with ResolverMerger. Example : ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;chunk&quot;]) .setOutputCol(&quot;RxNorm_Mapper&quot;) .setRel(&quot;rxnorm_code&quot;) cfModel = ChunkMapperFilterer() .setInputCols([&quot;chunk&quot;, &quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;chunks_fail&quot;) .setReturnCriteria(&quot;fail&quot;) ... resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;resolver_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolverMerger = ResolverMerger() .setInputCols([&quot;resolver_code&quot;,&quot;RxNorm_Mapper&quot;]) .setOutputCol(&quot;RxNorm&quot;) ... Results : +--+--++-+-+ |chunk |RxNorm_Mapper |chunks_fail |resolver_code|RxNorm | +--+--++-+-+ |[Adapin 10 MG, coumadin 5 mg] |[1000049, NONE] |[coumadin 5 mg]|[855333] |[1000049, 855333] | |[Avandia 4 mg, Tegretol, zytiga]|[NONE, 203029, 1100076]|[Avandia 4 mg] |[261242] |[261242, 203029, 1100076]| +--+--++-+-+ New Shortest Context Match and Token Index Features in ContextualParserApproach We have new functionalities in ContextualParserApproach to make it more performant. setShortestContextMatch() parameter will allow stop looking for matches in the text when a token defined as a suffix is found. Also it will keep tracking of the last mathced prefix and subsequent mathches with suffix. Now the index of the matched token can be found in metadata. Example : ... contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;entity&quot;) .setJsonPath(&quot;cities.json&quot;) .setCaseSensitive(True) .setDictionary(&#39;cities.tsv&#39;, options={&quot;orientation&quot;:&quot;vertical&quot;}) .setShortestContextMatch(True) ... sample_text = &quot;Peter Parker is a nice guy and lives in Chicago.&quot; Results : +-++-+ |chunk |ner_label|tokenIndex| +-++-+ |Chicago|City |9 | +-++-+ Prettified relational categories in ZeroShotRelationExtractionModel annotator Now you can setRelationalCategories() between the entity labels by using a single {} instead of two. Example : re_model = ZeroShotRelationExtractionModel.pretrained(&quot;re_zeroshot_biobert&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentences&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationalCategories({&quot;ADE&quot;: [&quot;{DRUG} causes {PROBLEM}.&quot;]}) Create Graphs for Open Source NerDLApproach with the TFGraphBuilder Now you can create graphs for model training with NerDLApproach by using the new setIsMedical() parameter of TFGraphBuilder annotator. If setIsMedical(True), the model can be trained with MedicalNerApproach, but if it is setIsMedical(False) it can be used with NerDLApproach for training non-medical models. graph_folder_path = &quot;./graphs&quot; ner_graph_builder = TFGraphBuilder() .setModelName(&quot;ner_dl&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFile(&quot;auto&quot;) .setHiddenUnitsNumber(20) .setGraphFolder(graph_folder_path) .setIsMedical(False) ner = NerDLApproach() ... .setGraphFolder(graph_folder_path) ner_pipeline = Pipeline()([ ..., ner_graph_builder, ner ]) Spark NLP for Healthcare Library Installation with Poetry Documentation (dependency management and packaging tool). We have a new documentation page for showing Spark NLP for Healthcare installation with Poetry. You can find it here. Bug fixes ContextualParserApproach: Fixed the bug using a dictionary and document rule scope in JSON config file. RENerChunksFilter: Preparing a pretrained pipeline with RENerChunksFilter annotator issue is fixed. Updated Notebooks ZeroShot Clinical Relation Extraction Notebook: Added new features, visualization and new examples. Clinical_Entity_Resolvers Notebook: Added an example of ResolverMerger. Chunk Mapping Notebook: Added new models into the model list and an example of mapper pretrained pipelines. Healthcare Code Mapping Notebook: Added all mapper pretrained pipeline examples. List of Recently Updated and Added Models ner_pathogene ner_pathogen_pipeline ner_clinical_trials_abstracts bert_token_classifier_ner_clinical_trials_abstracts ner_clinical_trials_abstracts_pipeline ner_biomedical_bc2gm_pipeline bert_sequence_classifier_stress icd10cm_snomed_mapper snomed_icd10cm_mapper snomed_icdo_mapper icdo_snomed_mapper rxnorm_umls_mapper icd10cm_umls_mapper mesh_umls_mapper snomed_umls_mapper icd10cm_snomed_mapping snomed_icd10cm_mapping icdo_snomed_mapping snomed_icdo_mapping rxnorm_ndc_mapping icd10cm_umls_mapping mesh_umls_mapping rxnorm_umls_mapping snomed_umls_mapping drug_action_tretment_mapper normalized_section_header_mapper drug_brandname_ndc_mapper abbreviation_mapper rxnorm_ndc_mapper rxnorm_action_treatment_mapper rxnorm_mapper ner_deid_subentity -&gt; ro ner_deid_subentity_bert -&gt; ro clinical_deidentification -&gt; ro ner_clinical -&gt; ro ner_clinical_bert -&gt; ro bert_token_classifier_ner_living_species -&gt; es ner_living_species_bert -&gt; es ner_living_species_roberta -&gt; es ner_living_species_300 -&gt; es ner_living_species -&gt; es bert_token_classifier_ner_living_species -&gt; en ner_living_species -&gt; en ner_living_species_biobert -&gt; en ner_living_species -&gt; fr ner_living_species_bert -&gt; fr bert_token_classifier_ner_living_species -&gt; pt ner_living_species -&gt; pt ner_living_species_roberta -&gt; pt ner_living_species_bert -&gt; pt bert_token_classifier_ner_living_species -&gt; it ner_living_species_bert -&gt; it ner_living_species -&gt; pt ner_living_species_bert -&gt; ro ner_living_species -&gt; ro ner_living_species -&gt; gal For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_0"
  },
  "1443": {
    "id": "1443",
    "title": "Spark NLP release notes 4.0.2",
    "content": "4.0.2 Release date: 12-09-2022 Overview We are glad to announce that Spark OCR 4.0.2 has been released! This release comes with new features, fixes and more!. New Features VisualDocumentClassifierV2 is now trainable! Continuing with the effort to make all the most useful models easily trainable, we added training capabilities to this annotator. Added support for Simplified Chinese. Added new ‘PdfToForm’ annotator, capable of extracting forms from digital PDFs. This is different from previously introduced VisualDocumentNER annotator in that this new annotator works only on digital documents, as opposite to the scanned forms handled by VisualDocumentNER. PdfToForm is complementary to VisualDocumentNER. Improvements Support for multi-frame dicom has been added. Added the missing load()​ method in ImageToTextV2. New Notebooks We added two new notebooks for VisualDocumentClassifierV2, a preprocessing notebook, useful when you’re dealing with large datasets, and a fine-tuning notebook. We added a new sample notebook showing how to extract forms from digital PDF documents. We added a new sample notebook explaining how to use Simplified Chinese OCR. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_0_2",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_0_2"
  },
  "1444": {
    "id": "1444",
    "title": "Spark NLP for Healthcare Release Notes 4.0.2",
    "content": "4.0.2 Highlights 16 new text classification models for English and Spanish social media text related to public health topics (stress, domestic violence, vaccine status, drug reviews etc.) Pretrained medication NER pipeline to augment posology NER models with Drugbank dataset Pretrained medication resolver pipeline to extract RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments. New disease NER model for Spanish language 5 new chunk mapper models to convert clinical entities to relevant medical terminology (UMLS) 5 new pretrained resolver pipelines to convert clinical entities to relevant medical terminology (UMLS) New Relation Extraction model to detect Drug and ADE relations New module for converting Annotation Lab (ALAB) exports into formats suitable for training new models Updated De-identification pretrained pipelines New setBlackList() parameter in ChunkFilterer() annotator New Doc2ChunkInternal() annotator Listing clinical pretrained models and pipelines with one-liner Bug fixes New and updated notebooks List of recently updated or added models (40+ new models and pipelines) 16 New Classification Models for English and Spanish Social Media Texts Related to Public Health Topics (Stress, Domestic Violence, Vaccine Status, Drug Reviews etc.) We are releasing 11 new MedicalBertForSequenceClassification models to classify text from social media data for English and Spanish languages. model name description predicted entities bert_sequence_classifier_ade_augmented this model classify tweets reporting ADEs (Adverse Drug Events). ADE noADE bert_sequence_classifier_health_mandates_stance_tweet this model classifies stance in tweets about health mandates. FAVOR AGAINST NONE bert_sequence_classifier_health_mandates_premise_tweet this model classifies premise in tweets about health mandates. has_premse has_no_premse bert_sequence_classifier_treatement_changes_sentiment_tweet this model classifies treatment changes reviews in tweets as negative and positive. positive negative bert_sequence_classifier_drug_reviews_webmd this model classifies drug reviews from WebMD as negative and positive. positive negative bert_sequence_classifier_self_reported_age_tweet this model classifies if there is a self-reported age in social media data. self_report_age no_report bert_sequence_classifier_self_reported_symptoms_tweet this model classifies self-reported COVID-19 symptoms in Spanish language tweets. Lit-News_mentions Self_reports non_personal_reports bert_sequence_classifier_self_reported_vaccine_status_tweet this model classifies self-reported COVID-19 vaccination status in tweets. Vaccine_chatter Self_reports bert_sequence_classifier_self_reported_partner_violence_tweet this model classifies self-reported Intimate partner violence (IPV) in tweets. intimate_partner_violence non_intimate_partner_violence bert_sequence_classifier_exact_age_reddit this model classifies if there is a self-reported age in social media forum posts (Reddit). self_report_age no_report bert_sequence_classifier_self_reported_stress_tweet this model classifies stress in social media (Twitter) posts in the self-disclosure category. stressed not-stressed Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_exact_age_reddit&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;, &quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text = [&quot;Is it bad for a 19 year old it&#39;s been getting worser.&quot;, &quot;I was about 10. So not quite as young as you but young.&quot;] Results : +-+--+ |text |class | +-+--+ |Is it bad for a 19 year old its been getting worser. |[self_report_age]| |I was about 10. So not quite as young as you but young.|[no_report] | +-+--+ We are releasing 5 new public health classification models. model name description predicted entities bert_sequence_classifier_health_mentions This model can classify public health mentions in social media text figurative_mention other_mention health_mention classifierdl_health_mentions This model can classify public health mentions in social media text figurative_mention other_mention health_mention bert_sequence_classifier_vaccine_sentiment This model can extract information from COVID-19 Vaccine-related tweets neutral positive negative classifierdl_vaccine_sentiment This model can extract information from COVID-19 Vaccine-related tweets neutral positive negative bert_sequence_classifier_stressor This model can classify source of emotional stress in text. Family_Issues Financial_Problem Health_Fatigue_or_Physical Pain Other School Work Social_Relationships Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_health_mentions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) ... sample_text =[&quot;Another uncle of mine had a heart attack and passed away. Will be cremated Saturday I think I ve gone numb again RIP Uncle Mike&quot;, &quot;I don&#39;t wanna fall in love. If I ever did that, I think I&#39;d have a heart attack&quot;, &quot;Aluminum is a light metal that causes dementia and Alzheimer&#39;s disease. You should never put aluminum into your body (including deodorants).&quot;] Results : +--+--+ |text |result | +--+--+ |Another uncle of mine had a heart attack and passed away. Will be cremated Saturday I think I ve gone numb again RIP Uncle Mike |[health_mention] | |I don&#39;t wanna fall in love. If I ever did that, I think I&#39;d have a heart attack |[figurative_mention]| |Aluminum is a light metal that causes dementia and Alzheimer&#39;s disease. You should never put aluminum into your body (including deodorants).|[other_mention] | +--+--+ Pretrained Medication NER Pipeline to Augmented Posology NER Models with Drugbank Dataset We are releasing a medication NER pretrained pipeline to extract medications in clinical text. It’s an augmented version of posology NER model with Drugbank datasets and can retun all the medications with a single line of code without building a pipeline with models. ner_medication_pipeline: This pretrained pipeline can detect medication entities and label them as DRUG in clinical text. See Models Hub Page for more details. Example : from sparknlp.pretrained import PretrainedPipeline medication_pipeline = PretrainedPipeline(&quot;ner_medication_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;The patient was prescribed metformin 1000 MG, and glipizide 2.5 MG. The other patient was given Fragmin 5000 units, Xenaderm to wounds topically b.i.d. and OxyContin 30 mg.&quot;&quot;&quot; Results : |--|--| | chunk | ner_label | |--|--| | metformin 1000 MG | DRUG | | glipizide 2.5 MG | DRUG | | Fragmin 5000 units | DRUG | | Xenaderm | DRUG | | OxyContin 30 mg | DRUG | |--|--| Pretrained Medication Resolver Pipeline to Extract RxNorm, UMLS, NDC , SNOMED CT Codes and Action/Treatments We are releasing a medication resolver pipeline to extract medications and and resolve RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text. You can get those codes if available with a single line of code without building a pipeline with models. medication_resolver_pipeline: This pretrained pipeline can detect medication entities and resolve codes if available. Example : from sparknlp.pretrained import PretrainedPipeline medication_pipeline = PretrainedPipeline(&quot;medication_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;&quot;&quot;The patient was prescribed Mycobutn 150 MG, Salagen 5 MG oral tablet, The other patient is given Lescol 40 MG and Lidoderm 0.05 MG/MG, triazolam 0.125 MG Oral Tablet, metformin hydrochloride 1000 MG Oral Tablet&quot;&quot;&quot; Results : ||-||--|-|-|||-| | ner_chunk | RxNorm_Chunk | Action | Treatment | UMLS | SNOMED_CT | NDC_Product | NDC_Package | entity | ||-||--|-|-|||-| | Mycobutn 150 MG | 103899 | Antimiycobacterials | Infection | C0353536 | - | 00013-5301 | 00013-5301-17 | DRUG | | Salagen 5 MG oral tablet | 1000915 | Antiglaucomatous | Cancer | C0361693 | - | 59212-0705 | 59212-0705-10 | DRUG | | Lescol 40 MG | 103919 | Hypocholesterolemic | Heterozygous Familial Hypercholesterolemia | C0353573 | - | 00078-0234 | 00078-0234-05 | DRUG | | Lidoderm 0.05 MG/MG | 1011705 | Anesthetic | Pain | C0875706 | - | 00247-2129 | 00247-2129-30 | DRUG | | triazolam 0.125 MG Oral Tablet | 198317 | - | - | C0690642 | 373981005 | 00054-4858 | 00054-4858-25 | DRUG | | metformin hydrochloride 1000 MG Oral Tablet | 861004 | - | - | C0978482 | 376701008 | 00093-7214 | 00185-0221-01 | DRUG | ||-||--|-|-|||-| New Disease NER Model for Spanish Language We are releasing a new MedicalBertForTokenClassifier model to extract disease entities from social media text in Spanish. bert_token_classifier_disease_mentions_tweet: This model can extract disease entities in Spanish tweets and label them as ENFERMEDAD (disease). See Models Hub Page for more details. Example : ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_disease_mentions_tweet&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;sentence&quot;) .setOutputCol(&quot;label&quot;) .setCaseSensitive(True) ... example_text = &quot;&quot;&quot;El diagnóstico fueron varios. Principal: Neumonía en el pulmón derecho. Sinusitis de caballo, Faringitis aguda e infección de orina, también elevada. Gripe No. Estuvo hablando conmigo, sin exagerar, mas de media hora, dándome ánimo y fuerza y que sabe, porque ha visto&quot;&quot;&quot; Results : ++-+ |chunk |ner_label | ++-+ |Neumonía en el pulmón|ENFERMEDAD| |Sinusitis |ENFERMEDAD| |Faringitis aguda |ENFERMEDAD| |infección de orina |ENFERMEDAD| |Gripe |ENFERMEDAD| ++-+ 5 new Chunk Mapper Models to Convert Clinical Entities to Relevant Medical Terminology (UMLS) We are releasing 5 new ChunkMapperModel models to map clinical entities with their corresponding UMLS CUI codes. Mapper Name Source Target umls_clinical_drugs_mapper Drugs UMLS CUI umls_clinical_findings_mapper Clinical Findings UMLS CUI umls_disease_syndrome_mapper Disease and Syndromes UMLS CUI umls_major_concepts_mapper Clinical Major Concepts UMLS CUI umls_drug_substance_mapper Drug Substances UMLS CUI Example : ... ner_model = MedicalNerModel.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;clinical_ner&quot;) ner_model_converter = NerConverterInternal() .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;clinical_ner&quot;) .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;umls_drug_substance_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;umls_code&quot;]) .setLowerCase(True) ... example_text = &quot;&quot;&quot;The patient was given metformin, lenvatinib and lavender 700 ml/ml&quot;&quot;&quot; Results : ++++ | ner_chunk|ner_label|umls_code| ++++ | metformin| DRUG| C0025598| | lenvatinib| DRUG| C2986924| |lavender 700 ml/ml| DRUG| C0772360| ++++ 5 new Pretrained Resolver Pipelines to Convert Clinical Entities to Relevant Medical Terminology (UMLS) We now have 5 new resolver PretrainedPipeline to convert clinical entities to their UMLS CUI codes. You just need to feed your text and it will return the corresponding UMLS codes. Pipeline Name Entity Target umls_drug_resolver_pipeline Drugs UMLS CUI umls_clinical_findings_resolver_pipeline Clinical Findings UMLS CUI umls_disease_syndrome_resolver_pipeline Disease and Syndromes UMLS CUI umls_major_concepts_resolver_pipeline Clinical Major Concepts UMLS CUI umls_drug_substance_resolver_pipeline Drug Substances UMLS CUI Example : from sparknlp.pretrained import PretrainedPipeline pipeline= PretrainedPipeline(&quot;umls_clinical_findings_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;HTG-induced pancreatitis associated with an acute hepatitis, and obesity&quot; Results : +-+++ |chunk |ner_label|umls_code| +-+++ |HTG-induced pancreatitis |PROBLEM |C1963198 | |an acute hepatitis |PROBLEM |C4750596 | |obesity |PROBLEM |C1963185 | +-+++ New Relation Extraction Model to Detect Drug and ADE relations We are releasing new re_ade_conversational model that can extract relations between DRUG and ADE entities from conversational texts and tag the relations as is_related and not_related. See Models Hub Page for more details. Example : ... re_model = RelationExtractionModel().pretrained(&quot;re_ade_conversational&quot;, &quot;en&quot;, &#39;clinical/models&#39;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;ade-drug&quot;, &quot;drug-ade&quot;]) ... sample_text = &quot;E19.32 day 20 rivaroxaban diary. still residual aches and pains; only had 4 paracetamol today.&quot; Results : |--|-|-||-| | chunk1 | entitiy1 | chunk2 | entity2 | relation | |--|-|-||-| | residual aches and pains | ADE | rivaroxaban | DRUG | is_related | | residual aches and pains | ADE | paracetamol | DRUG | not_related | |--|-|-||-| New Module for Converting Annotation Lab (ALAB) Exports Into Suitable Formats for Training New Models We have a new sparknlp_jsl.alab module with functions for converting ALAB JSON exports into suitable formats for training NER, Assertion and Relation Extraction models. Example : from sparknlp_jsl.alab import get_conll_data, get_assertion_data, get_relation_extraction_data get_conll_data(spark=spark, input_json_path=&quot;alab_demo.json&quot;, output_name=&quot;conll_demo&quot;) assertion_df = get_assertion_data(spark=spark, input_json_path = &#39;alab_demo.json&#39;, assertion_labels = [&#39;ABSENT&#39;], relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;]) relation_df = get_relation_extraction_data(spark=spark, input_json_path=&#39;alab_demo.json&#39;) These functions contain over 10 arguments each which give you all the flexibility you need to convert your annotations to trainable formats. These include parameters controlling tokenization, ground truth selections, negative annotations, negative annotation weights, task exclusions, and many more. To find out how to make best use of these functions, head over to this repository. Updated De-identification Pretrained Pipelines We have updated de-identification pretrained pipelines to provide better performance than ever before. This includes an update to the clinical_deidentification pretrained pipeline and a new light-weight version clinical_deidentification_slim. Example : from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification&quot;, &quot;en&quot;, &quot;clinical/models&quot;) slim_deid_pipeline = PretrainedPipeline(&quot;clinical_deidentification_slim&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;Name : Hendrickson, Ora, Record date: 2093-01-13, # 719435&quot; Results : Name : &lt;PATIENT&gt;, Record date: &lt;DATE&gt;, &lt;MEDICALRECORD&gt; Name : [**************], Record date: [********], [****] Name : ****, Record date: ****, **** Name : Alexia Mcgill, Record date: 2093-02-19, Y138038 New setBlackList() Parameter in ChunkFilterer() Annotator We are releasing a new setBlackList() parameter in the ChunkFilterer() annotator. ChunkFilterer() lets through every chunk except those that match the list of phrases or regex rules in the setBlackList() parameter. Example : ... chunk_filterer = ChunkFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;) .setOutputCol(&quot;chunk_filtered&quot;) .setCriteria(&quot;isin&quot;) .setBlackList([&#39;severe fever&#39;, &#39;severe cough&#39;]) ... example_text= &quot;&quot;&quot;Patient with severe fever, severe cough, sore throat, stomach pain, and a headache.&quot;&quot;&quot; Results : +-++ |ner_chunk |chunk_filtered | +-++ |[severe fever, severe cough, sore throat, stomach pain, a headache]|[sore throat, stomach pain, a headache]| +-++ New Doc2ChunkInternal() Annotator We are releasing a Doc2ChunkInternal() annotator. This is a licensed version of the open source Doc2Chunk() annotator. You can now customize the tokenization step within Doc2Chunk(). This will be quite handy when it comes to training custom assertion models. Example : ... doc2ChunkInternal = Doc2ChunkInternal() .setInputCols(&quot;document&quot;,&quot;token&quot;) .setStartCol(&quot;start&quot;) .setChunkCol(&quot;target&quot;) .setOutputCol(&quot;doc2chunkInternal&quot;) ... df= spark.createDataFrame([ [&quot;The mass measures 4 x 3.5cm in size more.&quot;,8,&quot;size&quot;], [&quot;The mass measures 4 x 3.5cm in size more.&quot;,9,&quot;size&quot;]]).toDF(&quot;sentence&quot;,&quot;start&quot;, &quot;target&quot;) Results : +--+--++--+--+ | sentence|start|target| doc2chunkInternal| doc2chunk| +--+--++--+--+ |The mass measures 4 x 3.5cm in size more.| 8| size|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}]|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}] | |The mass measures 4 x 3.5cm in size more.| 9| size| []|[{chunk, 31, 34, size, {sentence -&gt; 0, chunk -&gt; 0}, []}] | +--+--++--+--+ Listing Pretrained Clinical Models and Pipelines with One-Liner We have new returnPrivatePipelines() and returnPrivateModels() features under InternalResourceDownloader package to return licensed models and pretrained pipelines as a list. Example : from sparknlp_jsl.pretrained import InternalResourceDownloader # pipelines = InternalResourceDownloader.returnPrivatePipelines() assertion_models = InternalResourceDownloader.returnPrivateModels(&quot;AssertionDLModel&quot;) Results : [[&#39;assertion_ml&#39;, &#39;en&#39;, &#39;2.0.2&#39;], [&#39;assertion_dl&#39;, &#39;en&#39;, &#39;2.0.2&#39;], [&#39;assertion_dl_healthcare&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl_biobert&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl&#39;, &#39;en&#39;, &#39;2.7.2&#39;], [&#39;assertion_dl_radiology&#39;, &#39;en&#39;, &#39;2.7.4&#39;], [&#39;assertion_jsl_large&#39;, &#39;en&#39;, &#39;3.1.2&#39;], [&#39;assertion_jsl&#39;, &#39;en&#39;, &#39;3.1.2&#39;], [&#39;assertion_dl_scope_L10R10&#39;, &#39;en&#39;, &#39;3.4.2&#39;], [&#39;assertion_dl_biobert_scope_L10R10&#39;, &#39;en&#39;, &#39;3.4.2&#39;], [&#39;assertion_oncology_treatment_binary_wip&#39;, &#39;en&#39;, &#39;3.5.0&#39;]] Bug Fixes ZeroShotRelationExtractionModel: Fixed the issue that blocks the use of this annotator. AnnotationToolJsonReader: Fixed the issue with custom pipeline usage in this annotator. RelationExtractionApproach: Fixed issues related to training logs and inference. New and Updated Notebooks Clinical Named Entity Recognition Notebook: Added new getPrivateModel() feature Clinical Entity Resolvers Notebook: Added an example of reseolver pretrained pipelines Pretrained Clinical Pipelines Notebook: Pipeline list updated and examples of resolver pretrained pipelines were added Chunk Mapping Notebook: New mapper models added into model list All certification notebooks updated with v4.0.0. List of Recently Updated and Added Models and Pretrained Pipelines bert_token_classifier_ner_anatem bert_token_classifier_ner_bc2gm_gene bert_token_classifier_ner_bc4chemd_chemicals bert_token_classifier_ner_bc5cdr_chemicals bert_token_classifier_ner_bc5cdr_disease bert_token_classifier_ner_jnlpba_cellular bert_token_classifier_ner_linnaeus_species bert_token_classifier_ner_ncbi_disease bert_token_classifier_ner_species bert_sequence_classifier_ade_augmented bert_sequence_classifier_health_mandates_stance_tweet bert_sequence_classifier_health_mandates_premise_tweet bert_sequence_classifier_treatement_changes_sentiment_tweet bert_sequence_classifier_drug_reviews_webmd bert_sequence_classifier_self_reported_age_tweet bert_sequence_classifier_self_reported_symptoms_tweet =&gt; es bert_sequence_classifier_self_reported_vaccine_status_tweet bert_sequence_classifier_self_reported_partner_violence_tweet bert_sequence_classifier_exact_age_reddit bert_sequence_classifier_self_reported_stress_tweet bert_token_classifier_disease_mentions_tweet =&gt; es bert_token_classifier_ner_ade_tweet_binary bert_token_classifier_ner_pathogen clinical_deidentification clinical_deidentification_slim umls_clinical_drugs_mapper umls_clinical_findings_mapper umls_disease_syndrome_mapper umls_major_concepts_mapper umls_drug_substance_mapper umls_drug_resolver_pipeline umls_clinical_findings_resolver_pipeline umls_disease_syndrome_resolver_pipeline umls_major_concepts_resolver_pipeline umls_drug_substance_resolver_pipeline classifierdl_health_mentions bert_sequence_classifier_health_mentions ner_medication_pipeline bert_sequence_classifier_vaccine_sentiment classifierdl_vaccine_sentiment bert_sequence_classifier_stressor re_ade_conversational medication_resolver_pipeline Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_0_2"
  },
  "1445": {
    "id": "1445",
    "title": "Spark NLP release notes 4.1.0",
    "content": "4.1.0 Release date: 22-09-2022 Overview We are glad to announce that Spark OCR 4.1.0 has been released! This release comes with new features, enhancements, fixes and more!. New Features DicomSplitter: new annotator that helps to distribute and split Dicom files into multiple frames. It supports multiple strategies, similar to our PdfToImage annotator. It enables parallel processing of different frames and keeps memory utilization bounded. For big datasets, or memory constrained environments, it enables Streaming Mode to process frames 1-by-1, resulting in very low memory requirements. DicomToImageV2: new annotator that supports loading images from Dicom files/frames, without loading Dicom files into memory. Targeted to datasets containing big Dicom files. This is an example on how to use the two above mentioned annotators to process images, coming from your big Dicom files in a memory constrained setting, splitter = DicomSplitter() splitter.setInputCol(&quot;path&quot;) splitter.setOutputCol(&quot;frames&quot;) splitter.setSplitNumBatch(2) splitter.setPartitionNum(2) dicom = DicomToImageV2() dicom.setInputCols([&quot;path&quot;, &quot;frames&quot;]) dicom.setOutputCol(&quot;image&quot;) pipeline = PipelineModel(stages=[ splitter, dicom ]) New image pre-processing annotators: ImageHomogenizeLight, ImageRemoveBackground, ImageEnhanceContrast, ImageRemoveGlare. For examples on how to use them, and their amazing results check this notebook: SparkOcrImagePreprocessing.ipynb. Improvements VisualDocumentClassifierV2 training has been improved for more efficient memory utilization. Library dependencies have been updated to remove security vulnerabilities. Bug Fixes The infamous “ImportError: No module named resource” bug that was affecting Windows users has been fixed. Some issues while loading images using AlabReader have been fixed. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_1_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_1_0"
  },
  "1446": {
    "id": "1446",
    "title": "Spark NLP for Healthcare Release Notes 4.1.0",
    "content": "4.1.0 Highlights Zero-Shot NER model to extract entities with no training dataset 7 new clinical NER models in Spanish 8 new clinical classification models in English and German related to public health topics (depression, covid sentiment, health mentions) New pretrained chunk mapper model (drug_ade_mapper) to map drugs with their corresponding adverse drug events A new pretrained resolver pipeline (medication_resolver_pipeline) to extract medications and resolve their adverse reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text with a single line of code. Updated NER profiling pretrained pipelines with new NER models to allow running 64 clinical NER models at once Core improvements and bug fixes New and updated notebooks 20+ new clinical models and pipelines added &amp; updated in total Zero-Shot NER model to Extract Entities With No Training Dataset We are releasing the first of its kind Zero-Shot NER model that can detect any named entities without using any annotated dataset to train a model. It allows extracting entities by crafting appropriate prompts to query any RoBERTa Question Answering model. See Models Hub Page for more details. Example : ... zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions( { &quot;PROBLEM&quot;: [&quot;What is the disease?&quot;, &quot;What is his symptom?&quot;, &quot;What is her disease?&quot;, &quot;What is his disease?&quot;, &quot;What is the problem?&quot; ,&quot;What does a patient suffer&quot;, &#39;What was the reason that the patient is admitted to the clinic?&#39;], &quot;DRUG&quot;: [&quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;, &quot;Which drug does he use?&quot;, &quot;Which drug does she use?&quot;, &quot;Which drug do I use?&quot;, &quot;Which drug is prescribed for a symptom?&quot;], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [&quot;How old is the patient?&quot;,&#39;What is the age of the patient?&#39;] }) ... sample_text = [&quot;The doctor pescribed Majezik for my severe headache.&quot;, &quot;The patient was admitted to the hospital for his colon cancer.&quot;, &quot;27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis.&quot;] Results : ++--+-+ | chunk| ner_label|confidence| ++--+-+ | Majezik| DRUG|0.64671576| | severe headache| PROBLEM| 0.5526346| | colon cancer| PROBLEM| 0.8898498| | 27 years old| PATIENT_AGE| 0.6943085| | Sep 1st|ADMISSION_DATE|0.95646095| |a right-sided pleural effusion for thoracentesis| PROBLEM|0.50026613| ++--+-+ 7 New Clinical NER Models in Spanish We are releasing 4 new MedicalNerModel and 3 new MedicalBertForTokenClassifier NER models in Spanish. model name description predicted entities ner_negation_uncertainty This model detects relevant entities from Spanish medical texts NEG UNC USCO NSCO disease_mentions_tweet This model detects disease mentions in Spanish tweets ENFERMEDAD ner_clinical_trials_abstracts This model detects relevant entities from Spanish clinical trial abstracts CHEM DISO PROC ner_pharmacology This model detects pharmacological entities from Spanish medical texts PROTEINAS NORMALIZABLES bert_token_classifier_ner_clinical_trials_abstracts This model detects relevant entities from Spanish clinical trial abstracts CHEM DISO PROC bert_token_classifier_negation_uncertainty This model detects relevant entities from Spanish medical texts NEG NSCO UNC USCO bert_token_classifier_pharmacology This model detects pharmacological entities from Spanish medical texts PROTEINAS NORMALIZABLES Example : ... ner = MedicalNerModel.pretrained(&#39;ner_clinical_trials_abstracts&#39;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) example_text= &quot;&quot;&quot;&quot;Efecto de la suplementación con ácido fólico sobre los niveles de homocisteína total en pacientes en hemodiálisis. La hiperhomocisteinemia es un marcador de riesgo independiente de morbimortalidad cardiovascular. Hemos prospectivamente reducir los niveles de homocisteína total (tHcy) mediante suplemento con ácido fólico y vitamina B6 (pp), valorando su posible correlación con dosis de diálisis, función residual y parámetros nutricionales.&quot;&quot;&quot;&quot; Results : +--++ |chunk |ner_label| +--++ |suplementación |PROC | |ácido fólico |CHEM | |niveles de homocisteína |PROC | |hemodiálisis |PROC | |hiperhomocisteinemia |DISO | |niveles de homocisteína total|PROC | |tHcy |PROC | |ácido fólico |CHEM | |vitamina B6 |CHEM | |pp |CHEM | |diálisis |PROC | |función residual |PROC | +--++ 8 New Clinical Classification Models in English and German Related to Public Health Topics (Depression, Covid Sentiment, Health Mentions) We are releasing 8 new MedicalBertForSequenceClassification models to classify text from social media data in English and German related to public health topics (depression, covid sentiment, health mentions) model name description predicted entities bert_sequence_classifier_depression_binary This model classifies whether a social media text expresses depression or not. no-depression depression bert_sequence_classifier_health_mentions_gbert_large This GBERT-large based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_medbert This German-MedBERT based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_gbert This GBERT-large based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_health_mentions_bert This bert-base-german based model classifies public health mentions in German social media text. non-health health-related bert_sequence_classifier_depression_twitter This PHS-BERT based model classifies whether tweets contain depressive text or not. depression no-depression bert_sequence_classifier_depression This PHS-BERT based model classifies depression level of social media text into three levels. no-depression minimum high-depression bert_sequence_classifier_covid_sentiment This BioBERT based sentiment analysis model classifies whether a tweet contains positive, negative, or neutral sentiments about COVID-19 pandemic. neutral positive negative Example : ... sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_depression_twitter&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) example_text = [&quot;Do what makes you happy, be with who makes you smile, laugh as much as you breathe, and love as long as you live!&quot;, &quot;Everything is a lie, everyone is fake, I&#39;m so tired of living&quot;] Results : +++ |text |result | +--++ |Do what makes you happy, be with who makes you smile, laugh as much as you breathe, and love as long as you live!|[no-depression]| |Everything is a lie, everyone is fake, I am so tired of living. |[depression] | +--++ New Pretrained Chunk Mapper Model (drug_ade_mapper) to Map Drugs With Their Corresponding Adverse Drug Events We are releasing new drug_ade_mapper pretrained chunk mapper model to map drugs with their corresponding adverse drug events. See Models Hub Page for more details. Example : ... chunkMapper = ChunkMapperModel.pretrained(&quot;drug_ade_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;ADE&quot;]) ... sample_text = &quot;The patient was prescribed 1000 mg fish oil and multivitamins. She was discharged on zopiclone and ambrisentan.&quot; Results : +-++-+ |ner_chunk |ade_mappings|all_relations | +-++-+ |1000 mg fish oil|Dizziness |Myocardial infarction:::Nausea | |multivitamins |Erythema |Acne:::Dry skin:::Skin burning sensation:::Inappropriate schedule of product administration| |zopiclone |Vomiting |Malaise:::Drug interaction:::Asthenia:::Hyponatraemia | |ambrisentan |Dyspnoea |Therapy interrupted:::Death:::Dizziness:::Drug ineffective | +-++-+ A New Pretrained Resolver Pipeline (medication_resolver_pipeline) to Extract Medications and Resolve Their Adverse Reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT Codes and Action/Treatments in Clinical Text. We are releasing the medication_resolver_pipeline pretrained pipeline to extract medications and resolve their adverse reactions (ADE), RxNorm, UMLS, NDC, SNOMED CT codes and action/treatments in clinical text with a single line of code. Also, you can use medication_resolver_transform_pipeline to use transform method of Spark. See Models Hub Page for more details. Example : from sparknlp.pretrained import PretrainedPipeline sample_text = &quot;&quot;&quot;The patient was prescribed Amlodopine Vallarta 10-320mg, Eviplera. The other patient is given Lescol 40 MG and Everolimus 1.5 mg tablet.&quot;&quot;&quot; med_pipeline = PretrainedPipeline(&quot;medication_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) med_pipeline.annotate(sample_text) med_transform_pipeline = PretrainedPipeline(&quot;medication_resolver_transform_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) med_transform_pipeline.transform(spark.createDataFrame([[sample_text]]).toDF(&quot;text&quot;)) Results : | chunk | ner_label | ADE | RxNorm | Action | Treatment | UMLS | SNOMED_CT | NDC_Product | NDC_Package | |:--|:|:-|:|:|:-|:|:|:--|:--| | Amlodopine Vallarta 10-320mg | DRUG | Gynaecomastia | 722131 | NONE | NONE | C1949334 | 425838008 | 00093-7693 | 00093-7693-56 | | Eviplera | DRUG | Anxiety | 217010 | Inhibitory Bone Resorption | Osteoporosis | C0720318 | NONE | NONE | NONE | | Lescol 40 MG | DRUG | NONE | 103919 | Hypocholesterolemic | Heterozygous Familial Hypercholesterolemia | C0353573 | NONE | 00078-0234 | 00078-0234-05 | | Everolimus 1.5 mg tablet | DRUG | Acute myocardial infarction | 2056895 | NONE | NONE | C4723581 | NONE | 00054-0604 | 00054-0604-21 | Updated NER Profiling Pretrained Pipelines With New NER Models to Allow Running 64 Clinical NER Models at Once We have upadated ner_profiling_clinical and ner_profiling_biobert pretrained pipelines with the new NER models. When you run these pipelines over your text, now you will end up with the predictions coming out of 64 clinical NER models in ner_profiling_clinical and 22 clinical NER models in ner_profiling_biobert results. You can check ner_profiling_clinical and ner_profiling_biobert Models Hub pages for more details and the NER model lists that these pipelines include. Core Improvements and Bug Fixes Updated HCC module (from sparknlp_jsl.functions import profile) with the new changes in HCC score calculation functions. AnnotationToolJsonReader, NerDLMetrics and StructuredDeidentification: These annotators can be used on Spark 3.0 now. NerDLMetrics: Added case_sensitive parameter and case sensitivity issue in tokens is solved. Added drop_o parameter to computeMetricsFromDF method and dropO parameter in NerDLMetrics class is deprecated. MedicalNerModel: Inconsistent NER model results between different versions issue is solved. AssertionDLModel: Unindexed chunks will be ignored by the AssertionDLModel instead of raising an exception. ContextualParserApproach: These two issues are solved when using ruleScope: &quot;document&quot; configuration: Wrong index computations of chunks after matching sub-tokens. Including sub-token matches even though completeMatchRegex: &quot;true&quot;. New and Updated Notebooks We have a new Zero-Shot Clinical NER Notebook to show how to use zero-shot NER model. We have updated Medicare Risk Adjustment Score Calculation Notebook with the new changes in HCC score calculation functions. We have updated these notebooks with the new updates in NER profiling pretrained pipelines: Clinical Named Entity Recognition Model Notebook Pretrained Clinical Pipelines Notebook Pretrained NER Profiling Pipelines Notebook We have updated Clinical Assertion Model Notebook according to the bug fix in the training section. We moved all Azure/AWS/Databricks notebooks to products folder in spark-nlp-worksop repo. 20+ New Clinical Models and Pipelines Added &amp; Updated in Total zero_shot_ner_roberta medication_resolver_pipeline medication_resolver_transform_pipeline ner_profiling_clinical ner_profiling_biobert drug_ade_mapper ner_negation_uncertainty disease_mentions_tweet ner_clinical_trials_abstracts ner_pharmacology bert_token_classifier_ner_clinical_trials_abstracts bert_token_classifier_negation_uncertainty bert_token_classifier_pharmacology bert_sequence_classifier_depression_binary bert_sequence_classifier_health_mentions_gbert_large bert_sequence_classifier_health_mentions_medbert bert_sequence_classifier_health_mentions_gbert bert_sequence_classifier_health_mentions_bert bert_sequence_classifier_depression_twitter bert_sequence_classifier_depression bert_sequence_classifier_covid_sentiment Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_1_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_1_0"
  },
  "1447": {
    "id": "1447",
    "title": "Annotation Lab Release Notes 4.1.0",
    "content": "4.1.0 Release date: 30-09-2022 Here are the highlights of this release: Highlights Updated login page. This release of Annotation Lab has an updated Login View. Unlike a plain old form, we have an aesthetically pleasing Login Page with a section highlighting the key features of Annotation Lab. Now the Sign-In page highlights the new features we add to the Annotation Lab with animated GIFs. Project Dashboard. The Projects dashboard has a new structure with visually pleasing project cards. For each project, details like description, tasks count, groups, team members, etc. are now available on the main dashboard so users can quickly identify the projects they need to work on, without navigating to the Project Details page. Projects can also be sorted by name or date of creation. Categorize Projects with Groups. Projects can be organized in custom groups, and each project card will inherit the group color so that the users can visually distinguish the projects easily in a large cluster of projects. Also, the new color picker for the group is much more user-friendly and customizable, unlike the random color generator in the previous versions of Annotation Lab. Project Filters. The filters associated with the Projects dashboard are clear, simple, and precise to make the users more productive and efficient while working with a large number of projects. Project Creation Wizard. A project creation wizard is now available and will guide users through each step of the project creation and configuration. Two navigation buttons Back and Next were added to the Team page. The Back button navigates to the Project’s Details page and the Next button to navigates to the Configuration page. Optimized Task page. The newly redesigned task page incorporates all the Task Related operations that a user needs to perform, such as Import, Export, Labeling, Pre-Annotation, etc., in a single page without having to navigate between different pages. Support for multiple comments. Previously a comment could be pinned to a task from the Task List Page where anyone could leave a note for peer contributors. With this release, multiple comments can be added to any task. The users can have a to and fro communication in the comment section resulting in the improved efficiency of the annotation process. New Import page. The new Import Page contains detailed information on the supported file formats with sample files attached to them. Users can refer to the samples and create their files/tasks to import with minimum help. New Export page. The new Export page simplifies the experience while exporting annotations in different formats. The Annotation page. The annotation page has been reorganized and optimized as annotators spend most of their time on this page. The Side Column now separates Annotation, Versions, and Progress into separate tabs. The Regions/Labels UI is migrated into a collapsible structure that inherits the Label color defined in the project configuration to make it easy for users to identify annotations in case of a large number of Regions or Labels. The role switcher is now more visible on the upper right side, and the choice is persisted when navigating to other pages of the same project. New Train page. The Train page is now part of the Project Menu, for improved accessibility. It has been revised to improve the experience and guide users on each step. Users can now follow a step-wise wizard view or a synthesis view for initiating the training of a model. During the training, a progress bar is shown to give users basic information on the status of the training process. New Models HUB page. This version comes with brightened and improved Models HUB page. The cards for models, embeddings, and rules are visually pleasing and highlight their source. The displayed information is much more compact and easy to read. The cards are visually separable just by looking at the colors and the card types. New License page. The License Page now has a tabbed view. The first tab allows importing of the JSL license in the preferred method. The second tab displays the already existing license on a full page with corresponding details and actions. The page provides detailed instructions on how to import licenses and how to get a trial license. New Users page. The Users page is redesigned to make the operations regarding users’ information more time efficient and less confusing. The Personal Info, Role, and Credential sections are merged into a single page so that users do not have to click around to add/update. New Analytics Request page. The Swagger and Secrets Page have been merged into one single API Integration page. The users can find everything needed on that page without having to click around for the needed information regarding the APIs. New Clusters page. The Servers page has been redesigned and renamed into the Clusters page. The page now shows more details like License type/scope and Server usage of all the spawned instances at a given time. A license information banner is now available on the Clusters and License pages. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_1_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_1_0"
  },
  "1448": {
    "id": "1448",
    "title": "Spark NLP release notes 4.2.0",
    "content": "4.2.0 Release date: 31-10-2022 We are glad to announce that Spark OCR 4.2.0 has been released. This is mostly a compatibility release to ensure compatibility of Spark OCR against Spark NLP 4.2.1, and Spark NLP Healthcare 4.2.1. Improvements Improved memory consumption and performance in the training of Visual NER models. New Features PdfToForm new param: useFullyQualifiedName, added capability to return fully qualified key names. New or Updated Notebooks SparkOcrProcessMultiplepageScannedPDF.ipynb has been added to show how to serve a multi-page document processing pipeline. SparkOcrDigitalFormRecognition.ipynb has been updated to show utilization of useFullyQualifiedName parameter. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_0"
  },
  "1449": {
    "id": "1449",
    "title": "Spark NLP for Healthcare Release Notes 4.2.0",
    "content": "4.2.0 Highlights Introducing 46 new Oncology specific pretrained models (12 NER, 12 BERT-based token classification, 14 relation extraction, 8 assertion status models) Brand new NerQuestionGenerator annotator for automated prompt generation for a QA-based Zero-Shot NER model Updated ALAB (Annotation Lab) module becoming a fullfledged suite to manage activities on ALAB via its API remotely New pretrained assertion status detection model (assertion_jsl_augmented) to classify the negativity &amp; assertion scope of medical concepts New chunk mapper models and pretrained pipeline to map entities (phrases) to their corresponding ICD-9, ICD-10-CM and RxNorm codes New ICD-9-CM sentence entity resolver model and pretrained pipeline New shifting days feature in DeIdentification by using the new DocumentHashCoder annotator Updated NER model finder pretrained pipeline to help users find the most appropriate NER model for their use case in one-liner Medicare risk adjustment score calculation module updated to support different version and year combinations Core improvements and bug fixes New and updated notebooks 50+ new clinical models and pipelines added &amp; updated in total Introducing 46 New Oncology Specific Pretrained Models (12 NER, 12 BERT-Based Token Classification, 14 Relation Extraction, 8 Assertion Status Models) These models will be the first versions (wip - work in progress) of Oncology models. See Oncology Model Notebook for examples. New Oncological NER and BERT-Based Token Classification Models We have 12 new oncological NER and their BERT-based token classification models. NER model name (MedicalNerModel) BERT-Based model name (MedicalBertForTokenClassifier) description predicted entities ner_oncology_therapy_wip bert_token_classifier_ner_oncology_therapy_wip This model extracts entities related to cancer therapies, including posology entities and response to treatment, using granular labels. Response_To_Treatment, Line_Of_Therapy, Cancer_Surgery, Radiotherapy, Immunotherapy, Targeted_Therapy, Hormonal_Therapy, Chemotherapy, Unspecific_Therapy, Route, Duration, Cycle_Count, Dosage, Frequency, Cycle_Number, Cycle_Day, Radiation_Dose ner_oncology_diagnosis_wip bert_token_classifier_ner_oncology_diagnosis_wip This model extracts entities related to cancer diagnosis, including the presence of metastasis. Grade, Staging, Tumor_Size, Adenopathy, Pathology_Result, Histological_Type, Metastasis, Cancer_Score, Cancer_Dx, Invasion, Tumor_Finding, Performance_Status ner_oncology_wip bert_token_classifier_ner_oncology_wip This model extracts more than 40 oncology-related entities. Histological_Type, Direction, Staging, Cancer_Score, Imaging_Test, Cycle_Number, Tumor_Finding, Site_Lymph_Node, Invasion, Response_To_Treatment, Smoking_Status, Tumor_Size, Cycle_Count, Adenopathy, Age, Biomarker_Result, Unspecific_Therapy, Site_Breast, Chemotherapy, Targeted_Therapy, Radiotherapy, Performance_Status, Pathology_Test, Site_Other_Body_Part, Cancer_Surgery, Line_Of_Therapy, Pathology_Result, Hormonal_Therapy, Site_Bone, Biomarker, Immunotherapy, Cycle_Day, Frequency, Route, Duration, Death_Entity, Metastasis, Site_Liver, Cancer_Dx, Grade, Date, Site_Lung, Site_Brain, Relative_Date, Race_Ethnicity, Gender, Oncogene, Dosage, Radiation_Dose ner_oncology_tnm_wip bert_token_classifier_ner_oncology_tnm_wip This model extracts mentions related to TNM staging. Lymph_Node, Staging, Lymph_Node_Modifier, Tumor_Description, Tumor, Metastasis, Cancer_Dx ner_oncology_anatomy_general_wip bert_token_classifier_ner_oncology_anatomy_general_wip This model extracts anatomical entities. Anatomical_Site, Direction ner_oncology_demographics_wip bert_token_classifier_ner_oncology_demographics_wip This model extracts demographic information, including smoking status. Age, Gender, Smoking_Status, Race_Ethnicity ner_oncology_test_wip bert_token_classifier_ner_oncology_test_wip This model extracts mentions of oncology-related tests. Oncogene, Biomarker, Biomarker_Result, Imaging_Test, Pathology_Test ner_oncology_unspecific_posology_wip bert_token_classifier_ner_oncology_unspecific_posology_wip This model extracts any mention of cancer therapies and posology information using general labels Cancer_Therapy, Posology_Information ner_oncology_anatomy_granular_wip bert_token_classifier_ner_oncology_anatomy_granular_wip This model extracts anatomical entities using granular labels. Direction, Site_Lymph_Node, Site_Breast, Site_Other_Body_Part, Site_Bone, Site_Liver, Site_Lung, Site_Brain ner_oncology_response_to_treatment_wip bert_token_classifier_ner_oncology_response_to_treatment_wip This model extracts entities related to the patient’s response to cancer treatment. Response_To_Treatment, Size_Trend, Line_Of_Therapy ner_oncology_biomarker_wip bert_token_classifier_ner_oncology_biomarker_wip This model extracts biomarkers and their results. Biomarker, Biomarker_Result ner_oncology_posology_wip bert_token_classifier_ner_oncology_posology_wip This model extracts oncology specific posology information and cancer therapies. Cycle_Number, Cycle_Count, Radiotherapy, Cancer_Surgery, Cycle_Day, Frequency, Route, Cancer_Therapy, Duration, Dosage, Radiation_Dose F1 Scores: label f1 label f1 label f1 label f1 label f1 Adenopathy 0.73 Cycle_Day 0.83 Histological_Type 0.71 Posology_Information 0.88 Site_Lymph_Node 0.91 Age 0.97 Cycle_Number 0.79 Hormonal_Therapy 0.90 Race_Ethnicity 0.86 Smoking_Status 0.82 Anatomical_Site 0.83 Date 0.97 Imaging_Test 0.90 Radiation_Dose 0.87 Staging 0.85 Biomarker 0.89 Death_Entity 0.82 Invasion 0.80 Radiotherapy 0.90 Targeted_Therapy 0.87 Biomarker_Result 0.82 Direction 0.82 Line_Of_Therapy 0.91 Relative_Date 0.79 Tumor 0.91 Cancer_Dx 0.92 Dosage 0.91 Lymph_Node 0.86 Route 0.84 Tumor_Description 0.81 Cancer_Surgery 0.85 Duration 0.77 Lymph_Node_Modifier 0.75 Site_Bone 0.80 Tumor_Finding 0.92 Cancer_Therapy 0.90 Frequency 0.88 Metastasis 0.95 Site_Brain 0.78 Tumor_Size 0.88 Chemotherapy 0.90 Gender 0.99 Oncogene 0.77 Site_Breast 0.88     Cycle_Count 0.81 Grade 0.81 Pathology_Test 0.79 Site_Lung 0.79     NER Model Example: ... medical_ner = MedicalNerModel.pretrained(&quot;ner_oncology_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) ... sample_text = &quot;The had previously undergone a left mastectomy and an axillary lymph node dissection for a left breast cancer twenty years ago. The tumor was positive for ER. Postoperatively, radiotherapy was administered to her breast.&quot; BERT-Based Token Classification Model Example: ... tokenClassifier = MedicalBertForTokenClassifier.pretrained(&quot;bert_token_classifier_ner_oncology_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;, &quot;document&quot;) .setOutputCol(&quot;ner&quot;) .setCaseSensitive(True) ... sample_text = &quot;The had previously undergone a left mastectomy and an axillary lymph node dissection for a left breast cancer twenty years ago. The tumor was positive for ER. Postoperatively, radiotherapy was administered to her breast.&quot; Results: +++ |chunk |ner_label | +++ |left |Direction | |mastectomy |Cancer_Surgery | |axillary lymph node dissection|Cancer_Surgery | |left |Direction | |breast cancer |Cancer_Dx | |twenty years ago |Relative_Date | |tumor |Tumor_Finding | |positive |Biomarker_Result | |ER |Biomarker | |radiotherapy |Radiotherapy | |her |Gender | |breast |Site_Breast | +++ New Oncological Assertion Status Models We have 8 new oncological assertion status detection models. model name description predicted entities assertion_oncology_wip This model identifies the assertion status of different oncology-related entities. Medical_History, Family_History, Possible, Hypothetical_Or_Absent assertion_oncology_problem_wip This assertion model identifies the status of Cancer_Dx extractions and other problem entities. Present, Possible, Hypothetical, Absent, Family assertion_oncology_treatment_wip This model identifies the assertion status of treatments mentioned in text. Present, Planned, Past, Hypothetical, Absent assertion_oncology_response_to_treatment_wip This assertion model identifies if the response to treatment mentioned in text actually happened, or if it mentioned as something absent or hypothetical. Present_Or_Past, Hypothetical_Or_Absent assertion_oncology_test_binary_wip This assertion model identifies if a test mentioned in text actually was used, or if it mentioned as something absent or hypothetical. Present_Or_Past, Hypothetical_Or_Absent assertion_oncology_smoking_status_wip This assertion model is used to classify the smoking status of the patient. Absent, Past, Present assertion_oncology_family_history_wip This assertion model identifies if an entity refers to a family member. Family_History, Other assertion_oncology_demographic_binary_wip This assertion model identifies if the demographic entities refer to the patient or to someone else. Patient, Someone_Else Example: ... assertion = AssertionDLModel.pretrained(&quot;assertion_oncology_problem_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &#39;ner_chunk&#39;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) ... sample_text = &quot;Considering the findings, the patient may have a breast cancer. There are no signs of metastasis. Family history positive for breast cancer in her maternal grandmother.&quot; Results: +-+-++ | chunk| ner_label|assertion| +-+-++ |breast cancer| Cancer_Dx| Possible| | metastasis|Metastasis| Absent| |breast cancer| Cancer_Dx| Family| +-+-++ New Oncological Relation Extraction Models We are releasing 7 new RelationExtractionModel and 7 new RelationExtractionDLModel models to extract relations between various oncological concepts. model name description predicted entities re_oncology_size_wip This model links Tumor_Size extractions to their corresponding Tumor_Finding extractions. is_size_of, O re_oncology_biomarker_result_wip This model links Biomarker and Oncogene extractions to their corresponding Biomarker_Result extractions. is_finding_of, O re_oncology_granular_wip This model can be identified four relation types is_size_of, is_finding_of, is_date_of, is_location_of, O re_oncology_location_wip This model links extractions from anatomical entities (such as Site_Breast or Site_Lung) to other clinical entities (such as Tumor_Finding or Cancer_Surgery). is_location_of, O re_oncology_temporal_wip This model links Date and Relative_Date extractions to clinical entities such as Test or Cancer_Dx. is_date_of, O re_oncology_test_result_wip This model links test extractions to their corresponding results. is_finding_of, O re_oncology_wip This model link between dates and other clinical entities, between tumor mentions and their size, between anatomical entities and other clinical entities, and between tests and their results. is_related_to, O redl_oncology_size_biobert_wip This model links Tumor_Size extractions to their corresponding Tumor_Finding extractions. is_size_of, O redl_oncology_biomarker_result_biobert_wip This model links Biomarker and Oncogene extractions to their corresponding Biomarker_Result extractions. is_finding_of, O redl_oncology_location_biobert_wip This model links extractions from anatomical entities (such as Site_Breast or Site_Lung) to other clinical entities (such as Tumor_Finding or Cancer_Surgery). is_location_of, O redl_oncology_temporal_biobert_wip This model links Date and Relative_Date extractions to clinical entities such as Test or Cancer_Dx. is_date_of, O redl_oncology_test_result_biobert_wip This model links test extractions to their corresponding results. is_finding_of, O redl_oncology_biobert_wip This model identifies relations between dates and other clinical entities, between tumor mentions and their size, between anatomical entities and other clinical entities, and between tests and their results. is_related_to redl_oncology_granular_biobert_wip This model can be identified four relation types is_date_of, is_finding_of, is_location_of, is_size_of, O F1 Scores and Samples: label F1 Score sample_text results is_finding_of 0.95 “Immunohistochemistry was negative for thyroid transcription factor-1 and napsin A.” negative - thyroid transcription factor-1, negative - napsin is_date_of 0.81 “A mastectomy was performed two months ago.” mastectomy-two months ago is_location_of 0.92 “In April 2011, she first noticed a lump in her right breast.” lump - breast is_size_of 0.86 “The patient presented a 2 cm mass in her left breast.” 2 cm - mass is_related_to 0.87 A mastectomy was performed two months ago.” mastectomy - two months ago Example: ... re_model = RelationExtractionModel.pretrained(&quot;re_oncology_size_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunk&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;Tumor_Finding-Tumor_Size&quot;, &quot;Tumor_Size-Tumor_Finding&quot;]) .setMaxSyntacticDistance(10) ... sample_text = &quot;The patient presented a 2 cm mass in her left breast, and the tumor in her other breast was 3 cm long.&quot; Results: +-+-++-++-+ | relation| entity1|chunk1| entity2|chunk2|confidence| +-+-++-++-+ |is_size_of| Tumor_Size| 2 cm|Tumor_Finding| mass| 0.8532705| |is_size_of|Tumor_Finding| tumor| Tumor_Size| 3 cm| 0.8156226| +-+-++-++-+ Brand New NerQuestionGenerator Annotator For Automated Prompt Generation For A QA-based Zero-Shot NER Model. This annotators helps you build questions on the fly using 2 entities from different labels (preferably a subject and a verb). For example, let’s suppose you have an NER model, able to detect PATIENTand ADMISSION in the following text: John Smith was admitted Sep 3rd to Mayo Clinic PATIENT: John Smith ADMISSION: was admitted You can add the following annotator to construct questions using PATIENT and ADMISSION: # setEntities1 says which entity from NER goes first in the question # setEntities2 says which entity from NER goes second in the question # setQuestionMark to True adds a &#39;?&#39; at the end of the sentence (after entity 2) # To sum up, the pattern is [QUESTIONPRONOUN] [ENTITY1] [ENTITY2] [QUESTIONMARK] qagenerator = NerQuestionGenerator() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;question&quot;) .setQuestionMark(True) .setQuestionPronoun(&quot;When&quot;) .setStrategyType(&quot;Paired&quot;) .setEntities1([&quot;PATIENT&quot;]) .setEntities2([&quot;ADMISSION&quot;]) In the column question you will find: When John Smith was admitted?. Likewise you could have Where or any other question pronoun you may need. You can use those questions in a QuestionAnsweringModel or ZeroShotNER (any model which requires a question as an input. Let’s see the case of QA. qa = BertForQuestionAnswering.pretrained(&quot;bert_qa_spanbert_finetuned_squadv1&quot;,&quot;en&quot;) .setInputCols([&quot;question&quot;, &quot;document&quot;]) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(True) The result will be: +--+--+ |question |answer | +--+--+ |[{document, 0, 25, When John Smith was admitted ? ...}] |[{chunk, 0, 8, Sep 3rd ...}] | +--+--+ Strategies: Paired: First chunk of Entity 1 will be grouped with first chunk of Entity 2, second with second, third with third, etc (one-vs-one) Combined: A more flexible strategy to be used in case the number of chukns in Entity 1 is not aligned with the number of chunks in Entityt 2. The first chunk from Entity 1 will be grouped with all chunks in Entity 2, the second chunk in Entity 1 with again be grouped with all the chunks in Entity 2, etc (one-vs-all). Updated ALAB (Annotation Lab) Module Becoming a Fullfledged Suite to Manage Activities on ALAB Via Its API Remotely We are release a new module for interacting with Annotation Lab with minimal code. Users can now create/edit/delete projects and their tasks. Also, they can upload preannotations, and export annotations and generate training data for various models. Complete documentation and tutorial is available at Spark NLP Workshop. Following is a comprehensive list of supported tasks: Getting details of all projects in the Annotation Lab instance. Creating New Projects. Deleting Projects. Setting &amp; editing configuration of projects. Accessing/getting configuration of any existing project. Upload tasks to a project. Deleting tasks of a project. Generating Preannotations for a project using custom Spark NLP pipelines. Uploading Preannotations to a project. Generating dataset for training Classification models. Generating dataset for training NER models. Generating dataset for training Assertion models. Generating dataset for training Relation Extraction models. Using Annotation Lab Module: from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() alab.set_credentials(username=username, password=password, client_secret=client_secret, annotationlab_url=annotationlab_url) # create a new project alab.create_project(&#39;alab_demo&#39;) # assign ner labels to the project alab.set_project_config(&#39;alab_demo&#39;, ner_labels=[&#39;Age&#39;, &#39;Gender&#39;]) # upload tasks alab.upload_tasks(&#39;alab_demo&#39;, task_list=[txt1, txt2...]) # export tasks alab.get_annotations(&#39;alab_demo&#39;) New Pretrained Assertion Status Detection Model (assertion_jsl_augmented) to Classify The Negativity &amp; Assertion Scope of Medical Concepts We are releasing new assertion_jsl_augmented model to classify the assertion status of the clinical entities with Present, Absent, Possible, Planned, Past, Family, Hypothetical and SomeoneElse labels. See Models Hub Page for more details. Example: ... clinical_assertion = AssertionDLModel.pretrained(&quot;assertion_jsl_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;assertion&quot;) ... sample_text = &quot;&quot;&quot;Patient had a headache for the last 2 weeks, and appears anxious when she walks fast. No alopecia noted. She denies pain. Her father is paralyzed and it is a stressor for her. She was bullied by her boss and got antidepressant. We prescribed sleeping pills for her current insomnia&quot;&quot;&quot; Results: +--+--++-+--++ |ner_chunk |begin|end|ner_label |sentence_id|assertion| +--+--++-+--++ |headache |14 |21 |Symptom |0 |Past | |anxious |57 |63 |Symptom |0 |Possible | |alopecia |89 |96 |Disease_Syndrome_Disorder|1 |Absent | |pain |116 |119|Symptom |2 |Absent | |paralyzed |136 |144|Symptom |3 |Family | |antidepressant|212 |225|Drug_Ingredient |4 |Past | |sleeping pills|242 |255|Drug_Ingredient |5 |Planned | |insomnia |273 |280|Symptom |5 |Present | +--+--++-+--++ New Chunk Mapper models and Pretrained Pipeline to map entities (phrases) to their corresponding ICD-9, ICD-10-CM and RxNorm codes We are releasing 4 new chunk mapper models that can map entities to their corresponding ICD-9, ICD-10-CM and RxNorm codes. model name description rxnorm_normalized_mapper Mapping drug entities (phrases) with the corresponding RxNorm codes and normalized resolutions. icd9_mapper Mapping entities with their corresponding ICD-9-CM codes. icd10_icd9_mapper Mapping ICD-10-CM codes with their corresponding ICD-9-CM codes. icd9_icd10_mapper Mapping ICD-9-CM codes with their corresponding ICD-10-CM codes. icd10_icd9_mapping (Pipeline) This pretrained pipeline maps ICD-10-CM codes to ICD-9-CM codes without using any text data. Model Example: ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_normalized_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_code&quot;, &quot;normalized_name&quot;]) ... sample_text = &quot;The patient was given Zyrtec 10 MG, Adapin 10 MG Oral Capsule, Septi-Soothe 0.5 Topical Spray&quot; Results: ++--+--+ |ner_chunk |rxnorm_code|normalized_name | ++--+--+ |Zyrtec 10 MG |1011483 |cetirizine hydrochloride 10 MG [Zyrtec] | |Adapin 10 MG Oral Capsule |1000050 |doxepin hydrochloride 10 MG Oral Capsule [Adapin] | |Septi-Soothe 0.5 Topical Spray|1000046 |chlorhexidine diacetate 0.5 MG/ML Topical Spray [Septi-Soothe]| ++--+--+ Pipeline Example: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline( &quot;icd10_icd9_mapping&quot;,&quot;en&quot;,&quot;clinical/models&quot;) pipeline.annotate(&quot;Z833 A0100 A000&quot;) Results: | icd10_code | icd9_code | |:--|:-| | Z833 - A0100 - A000 | V180 - 0020 - 0010 | New ICD-9-CM Sentence Entity Resolver Model and Pretrained Pipeline sbiobertresolve_icd9 : This model maps extracted medical entities to their corresponding ICD-9-CM codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Example: ... icd10_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd9&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) ... sample_text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2.&quot; Results: +-+-+++-+ | ner_chunk| entity|icd9_code| resolution| all_codes| +-+-+++-+ | gestational diabetes mellitus|PROBLEM| V12.21|[Personal history of gestational diabetes, Ne...|[V12.21, 775.1, 249, 250, 249.7, 249.71, 249.9, 249.61,...| |subsequent type two diabetes mellitus|PROBLEM| 249|[Secondary diabetes mellitus, Diabetes mellit...|[249, 250, 249.9, 249.7, 775.1, 249.6, 249.8, V12.21, 2...| | an acute hepatitis|PROBLEM| 571.1|[Acute alcoholic hepatitis, Viral hepatitis, ...|[571.1, 070, 571.42, 902.22, 279.51, 571.4, 091.62, 572...| | obesity|PROBLEM| 278.0|[Overweight and obesity, Morbid obesity, Over...|[278.0, 278.01, 278.02, V77.8, 278, 278.00, 272.2, 783....| | a body mass index|PROBLEM| V85|[Body mass index [BMI], Human bite, Localized...|[V85, E928.3, 278.1, 993, E008.4, V61.5, 747.63, V85.5,...| +-+-+++-+ icd9_resolver_pipeline : This pretrained pipeline maps entities with their corresponding ICD-9-CM codes. You’ll just feed your text and it will return the corresponding ICD-9-CM codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;icd9_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years and anisakiasis. Also, it was reported that fetal and neonatal hemorrhage&quot;&quot;&quot; result = resolver_pipeline.fullAnnotate(sample_text) Results: +--+++ |chunk |ner_chunk|icd9_code| +--+++ |gestational diabetes mellitus|PROBLEM |V12.21 | |anisakiasis |PROBLEM |127.1 | |fetal and neonatal hemorrhage|PROBLEM |772 | +--+++ New Shifting Days Feature in Deidentification by Using the New DocumentHashCoder Annotator Now we can shift dates in the documents rather than obfuscating randomly. We have a new DocumentHashCoder() annotator to determine shifting days. This annotator gets the hash of the specified column and creates a new document column containing day shift information. And then, the DeIdentification annotator deidentifies this new doc. We can use the seed parameter to hash consistently. Example: documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setPatientIdColumn(&quot;patientID&quot;) .setRangeDays(100) .setNewDateShift(&quot;shift_days&quot;) .setSeed(100) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) Results: output.select(&#39;patientID&#39;,&#39;text&#39;, &#39;deid_text.result&#39;).show(truncate = False) ++-++ |patientID|text |result | ++-++ |A001 |Chris Brown was discharged on 10/02/2022|[Glorious Mc was discharged on 27/03/2022] | |A001 |Mark White was discharged on 10/04/2022 |[Kimberlee Bair was discharged on 25/05/2022]| |A003 |John was discharged on 15/03/2022 |[Monia Richmond was discharged on 17/05/2022]| |A003 |John Moore was discharged on 15/12/2022 |[Veleta Pollard was discharged on 16/02/2023]| ++-++ Instead of shifting days according to ID column, we can specify shifting values with another column. Example: documentHasher = DocumentHashCoder() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;document2&quot;) .setDateShiftColumn(&quot;dateshift&quot;) de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setDateTag(&quot;DATE&quot;) .setLanguage(&quot;en&quot;) .setObfuscateRefSource(&#39;faker&#39;) .setUseShifDays(True) Results: +-+++ |text |dateshift|result | +-+++ |Chris Brown was discharged on 10/02/2022|10 |[Levorn Powers was discharged on 20/02/2022] | |Mark White was discharged on 10/04/2022 |10 |[Hall Jointer was discharged on 20/04/2022] | |John was discharged on 15/03/2022 |30 |[Jared Gains was discharged on 14/04/2022] | |John Moore was discharged on 15/12/2022 |30 |[Frederic Seitz was discharged on 14/01/2023]| +-+++ You can check Clinical Deidentification Notebook for more examples. Updated NER Model Finder Pretrained Pipeline to Help Users Find The Most Appropriate NER Model For Their Use Case In One-Liner We have updated ner_model_finder pretrained pipeline and sbertresolve_ner_model_finder resolver model with 70 clinical NER models and their labels. See Models Hub Page for more details and the Pretrained Clinical Pipelines Notebook for the examples. Support Different Version and Year Combinations on Medicare Risk Adjustment Score Calculation Module Now, you can calculate CMS-HCC risk score with different version and year combinations by importing one of the following function calculate the score. - profileV2217 - profileV2318 - profileV2417 - profileV2218 - profileV2319 - profileV2418 - profileV2219 - profileV2419 - profileV2220 - profileV2420 - profileV2221 - profileV2421 - profileV2222 - profileV2422 from sparknlp_jsl.functions import profileV24Y20 See the notebook for more details. Core Improvements and Bug Fixes ContextualParserApproach: New parameter completeContextMatch. This parameter let the user define whether to do an exact match of prefix and suffix. Deidentification: Enhanced default regex rules in French deidentification for DATE entity extraction. ZeroShotRelationExtractionModel: Fixed the issue that setting some parameters together and no need to setRelationalCategories after downloading the model. New and Updated Notebooks New MedicalBertForSequenceClassification Notebook to show how to use MedicalBertForSequenceClassification models. New ALAB Module Notebook to show all features of ALAB Module. New Oncology Models Notebook to show the examples of the new Oncology models. Updated Medicare Risk Adjustment Score Calculation Notebook with the new changes in HCC score calculation functions. Updated Clinical DeIdentification Notebook by adding how not to deidentify a part of an entity section and showing examples of shifting days feature with the new DocumentHashCoder. Updated Pretrained Clinical Pipelines Notebook with the updated ner_model_finder results. 50+ New Clinical Models and Pipelines Added &amp; Updated in Total assertion_jsl_augmented rxnorm_normalized_mapper ner_model_finder sbertresolve_ner_model_finder sbiobertresolve_icd9 icd9_resolver_pipeline rxnorm_normalized_mapper icd9_mapper icd10_icd9_mapper icd9_icd10_mapper icd10_icd9_mapping bert_qa_spanbert_finetuned_squadv1 ner_oncology_therapy_wip ner_oncology_diagnosis_wip ner_oncology_wip ner_oncology_tnm_wip ner_oncology_anatomy_general_wip ner_oncology_demographics_wip ner_oncology_test_wip ner_oncology_unspecific_posology_wip ner_oncology_anatomy_granular_wip ner_oncology_response_to_treatment_wip ner_oncology_biomarker_wip ner_oncology_posology_wip bert_token_classifier_ner_oncology_therapy_wip bert_token_classifier_ner_oncology_diagnosis_wip bert_token_classifier_ner_oncology_wip bert_token_classifier_ner_oncology_tnm_wip bert_token_classifier_ner_oncology_anatomy_general_wip bert_token_classifier_ner_oncology_demographics_wip bert_token_classifier_ner_oncology_test_wip bert_token_classifier_ner_oncology_unspecific_posology_wip bert_token_classifier_ner_oncology_anatomy_granular_wip bert_token_classifier_ner_oncology_response_to_treatment_wip bert_token_classifier_ner_oncology_biomarker_wip bert_token_classifier_ner_oncology_posology_wip assertion_oncology_wip assertion_oncology_problem_wip assertion_oncology_treatment_wip assertion_oncology_response_to_treatment_wip assertion_oncology_test_binary_wip assertion_oncology_smoking_status_wip assertion_oncology_family_history_wip assertion_oncology_demographic_binary_wip re_oncology_size_wip re_oncology_biomarker_result_wip re_oncology_granular_wip re_oncology_location_wip re_oncology_temporal_wip re_oncology_test_result_wip re_oncology_wip redl_oncology_size_biobert_wip redl_oncology_biomarker_result_biobert_wip redl_oncology_location_biobert_wip redl_oncology_temporal_biobert_wip redl_oncology_test_result_biobert_wip redl_oncology_biobert_wip redl_oncology_granular_biobert_wip Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_0"
  },
  "1450": {
    "id": "1450",
    "title": "Annotation Lab Release Notes 4.2.0",
    "content": "4.2.0 Release date: 02-11-2022 Annotation Lab 4.2.0 supports projects combining models trained with multiple embeddings for preannotation as well as predefined Demo projects that can be imported with the click of a button for easy experimentations and features testing. The Project Configuration page now has a new “View” step to configure the layout of the Labeling page. The release also includes stabilization and fixes bugs reported by our user community. Here are the highlights of this release: Highlights Projects can reuse and combine models trained with different embeddings for pre-annotation. Now, it is easily possible to use models with different embeddings and deploy them as part of the same pre-annotation server. In the customize configuration page all the added models and their embeddings are listed. The list makes it easier for the user to delete the labels of a specific model. Demo Projects can be imported for experiments. To allow users access and experiment with already configured and populated projects we have added the option to import predefined Demo projects. This is for helping users understand the various features offered by the Annotation Lab. The user can import demo projects from the Import Project window, by clicking on the Import Demo Project option. Visual Update of the Annotation Screen Layout from the View Tab. A new tab - “View” - has been added to the project setup wizard after the “Content Type” selection tab. This gives users the ability to set different layouts based on their needs and preferences. Support for Granular License Scopes. This versions brings support for more granular license scopes such as Healthcare: Inference, Healthcare: Training, OCR: Inference or OCR: Training. This is in line with the latest developments of the John Snow Labs licenses. Easy Reuse and Editing of Pre-annotations. For an improved usability, when pre-annotations are available for a task, those will be shown by default when accessing the labeling screen. Users can filter them based on the confidence score and the either accept the visible annotations as a new submitted completion or start editing those as part of a new completion. Easy Export of Large Visual NER Projects. From version 4.2.0 users will be able to export large NER/ Visual NER projects with a size bigger than 500 MB. Smaller Project Tiles on the Projects Dashboard. The size of a project tile was compacted in this version in order to increase the number of project cards that could be displayed on the screen at one time. Confusion Matrix in Training Logs for NER projects. With the addition of confusion matrix it will be easier to understand the performance of the model and judge whether the model is underfitting or overfitting. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_2_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_2_0"
  },
  "1451": {
    "id": "1451",
    "title": "Visual NLP(Spark OCR) release notes 4.2.1",
    "content": "4.2.1 Release date: 11-28-2022 We’re glad to announce that Spark-OCR 4.2.1 has been released! This release is almost completely about LightPipelines. LightPipeline added to Spark-OCR Originally introduced by Spark-NLP, this has been one of the most celebrated features by our users. In a nutshell, LightPipelines allow you switching your pipeline from distributed processing to local mode, in a single line of code. Also, results are much easier to post-process as they come in plain Python data structures. Now, LightPipelines are available in Spark-OCR as well! This is an initial implementation only covering three of our most popular annotators: ImageToText, PdfToImage, and BinaryToImage. Although not all the annotators from Spark-OCR are included in this initial release, a number of interesting features are being delivered: Latency has been dramatically reduced for small input dataset sizes. Interoperability with Spark-NLP and Spark-NLP healthcare: you can mix any NLP annotator with supported OCR annotators on the same LightPipeline. Following is a chart comparing performance of different techniques on batches of different page counts: 8, 16, 24, 32, 40, 48, and 80 pages. For the 8 pages case, on the left side of the chart, LightPipelines average 1.25s per page vs. 4s per page that were scored by a similar Pytesseract implementation. That makes LightPipelines a great candidate to achieve low latency on small sized batches, while still leveraging parallelism. Korean Support You can start using Korean language by just passing the ‘KOR’ option to ImageToText, ... # Run OCR ocr = ImageToText() # Set Korean language ocr.setLanguage(Language.KOR) # Download model from JSL S3 ocr.setDownloadModelData(True) Bug Fixes AlabReader has been updated to handle the new structure present in Annotation Lab’s exported annotations. New Notebooks Check how to use LightPipelines in this notebook: SparkOcrLightPipelines.ipynb Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_1"
  },
  "1452": {
    "id": "1452",
    "title": "Spark NLP for Healthcare Release Notes 4.2.1",
    "content": "4.2.1 Highlights Creating new chunks with NerConverterInternal by merging chunks by skipping stopwords in between. Adding relation direction to RelationExtraction models to make the relations direction-aware. Using proper regional date formats in the DeIdentification module. Being able to play with different date formats in DateNormalizer output. New Replacer annotator to replace chunks with their normalized versions (`DateNormalizer’) in documents. New ModelTracer helper class to generate and add model UID and timestamps of the stages in a pipeline Added entity source and labels to the AssertionFilterer metadata New chunk mapper and sentence entity resolver models and a pipeline for CVX Updated clinical NER models with new labels New Certification Training notebooks for the johnsnowlabs library New and updated notebooks 6 new clinical models and pipelines added &amp; updated in total Creating New Chunks with NerConverterInternal by Merging Chunks by Skipping Stopwords in Between. NerConverterInternal’s new setIgnoreStopWords parameter allows merging between chunks with the same label, ignoring stopwords and punctuations. txt = &quot;&quot;&quot; The qualified manufacturers for this starting material are: Alpha Chemicals Pvt LTD 17, R K Industry House, Walbhat Rd, Goregaon – 400063 Mumbai, Maharashtra, India Beta Chemical Co., Ltd Huan Cheng Xi Lu 3111hao Hai Guan Da Ting Shanghai, China &quot;&quot;&quot; Example for default: NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_deid&quot;]) .setOutputCol(&quot;chunk_deid&quot;) .setGreedyMode(True) .setWhiteList([&#39;LOCATION&#39;]) Results: | chunks | entities | begin | end | |:-|:|:|-:| | R K Industry House | LOCATION | 90 | 107 | | Walbhat | LOCATION | 110 | 116 | | Mumbai | LOCATION | 141 | 146 | | Maharashtra | LOCATION | 149 | 159 | | India | LOCATION | 162 | 166 | | Huan Cheng Xi Lu 3111hao | LOCATION | 191 | 214 | | Shanghai | LOCATION | 234 | 241 | | China | LOCATION | 244 | 248 | Example for setting setIgnoreStopWords parameter: NerConverterInternal() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_deid&quot;]) .setOutputCol(&quot;chunk_deid&quot;) .setGreedyMode(True) .setWhiteList([&#39;LOCATION&#39;]) .setIgnoreStopWords([&#39; n&#39;, &#39;,&#39;, &quot;and&quot;, &#39;or&#39;, &#39;.&#39;]) Results: | chunks | entities | begin | end | |:|:|:|-:| | R K Industry House Walbhat | LOCATION | 90 | 116 | | Mumbai Maharashtra India | LOCATION | 141 | 166 | | Huan Cheng Xi Lu 3111hao | LOCATION | 191 | 214 | | Shanghai China | LOCATION | 234 | 248 | Adding Relation Direction to RelationExtraction Models to Make the Relations Direction-aware. We have a new setRelationDirectionCol parameter that is used during training with a new separate column that specified relationship directions. The column should contain one of the following values: rightwards: The first entity in the text is also the first argument of the relation (as well as the second entity in the text is the second argument). In other words, the relation arguments are ordered left to right in the text. leftwards: The first entity in the text is the second argument of the relation (and the second entity in the text is the first argument). both: Order doesn’t matter (relation is symmetric). In our test cases, it was observed that the accuracy increased significantly when we just add setRelationDirectionCol parameter by keeping the other parameter as they are. Example: +--+++--+-+-+ | chunk1| label1| label2| chunk2| rel| rel_dir| +--+++--+-+-+ |expected long ter...|treatment|treatment| a picc line| O| both| | light-headedness| problem| problem| diaphoresis| PIP|rightwards| | po pain medications|treatment| problem| his pain|TrAP| leftwards| |bilateral pleural...| problem| problem|increased work of...| PIP|rightwards| | her urine output| test| problem| decreased|TeRP|rightwards| |his psychiatric i...| problem| problem|his neurologic in...| PIP|rightwards| | white blood cells| test| test| red blood cells| O| both| | chloride| test| test| bun| O| both| | further work-up| test| problem|his neurologic co...|TeCP|rightwards| | four liters|treatment| test| blood pressure| O| both| +--+++--+-+-+ re_approach_with_dir = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setRelationDirectionCol(&quot;rel_dir&quot;) Using Proper Regional date Formats in DeIdentification Module You can specify the format for date entities that will be shifted to the new date or converted to a year. de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;sentence&quot;]) .setOutputCol(&quot;dei_id&quot;) .setRegion(&#39;us&#39;) # &#39;eu&#39; for Europe Being Able to Play With Different Date Formats in DateNormalizer Output Now we can customize the normalized date formats in the output of DateNormalizer by using the new setOutputDateformat parameter. There are two options to do that; us for MM/DD/YYYY, eu for DD/MM/YYYY formats. Example: date_normalizer_us = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_us&#39;) .setOutputDateformat(&#39;us&#39;) date_normalizer_eu = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_eu&#39;) .setOutputDateformat(&#39;eu&#39;) sample_text = [&#39;She was last seen in the clinic on Jan 30, 2018, by Dr. Y.&#39;, &#39;Chris Brown was discharged on 12Mar2021&#39;, &#39;We reviewed the pathology obtained on 13.04.1999.&#39;] Results: +-++++ |text |date_chunk |normalized_date_eu|normalized_date_us| +-++++ |She was last seen in the clinic on Jan 30, 2018, by Dr. Y.|Jan 30, 2018|30/01/2018 |01/30/2018 | |Chris Brown was discharged on 12Mar2021 |12Mar2021 |12/03/2021 |03/20/2021 | |We reviewed the pathology obtained on 13.04.1999. |13.04.1999 |13/04/1999 |04/13/1999 | +-++++ New Replacer Annotator To Replace Chunks With Their Normalized Versions (DateNormalizer) In Documents We have a new Replacer annotator that returns the original document by replacing it with the normalized version of the original chunks. Example: date_normalizer = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date&#39;) replacer = Replacer() .setInputCols([&quot;normalized_date&quot;,&quot;document&quot;]) .setOutputCol(&quot;replaced_document&quot;) sample_text = [&#39;She was last seen in the clinic on Jan 30, 2018, by Dr. Y.&#39;, &#39;Chris Brown was discharged on 12Mar2021&#39;, &#39;We reviewed the pathology obtained on 13.04.1999.&#39;] Results: +-++--+ |text |normalized_date|replaced_document | +-++--+ |She was last seen in the clinic on Jan 30, 2018, by Dr. Y.|2018/01/30 |She was last seen in the clinic on 2018/01/30, by Dr. Y.| |Chris Brown was discharged on 12Mar2021 |2021/03/12 |Chris Brown was discharged on 2021/03/12 | |We reviewed the pathology obtained on 13.04.1999. |1999/04/13 |We reviewed the pathology obtained on 1999/04/13. | +-++--+ New ModelTracer Helper Class to Generate and Add Model UID and Timestamps of the Stages in a Pipeline ModelTracer allows to track the UIDs and timestamps of each stage of a pipeline. Example: from sparknlp_jsl.modelTracer import ModelTracer ... pipeline = Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, ]) df = pipeline.fit(data).transform(data) result = ModelTracer().addUidCols(pipeline = pipeline, df = df) result.show(truncate=False) Results: +-+--+--++-+--+-+ |text|document|token|ner|documentassembler_model_uid |tokenizer_model_uid |bert_for_token_classification_model_uid | +-+--+--++-+--+-+ |... |... |... |...|{uid -&gt; DocumentAssembler_a666efd1d789, timestamp -&gt; 2022-10-21_11:34}|{uid -&gt; Tokenizer_01fbad79f069, timestamp -&gt; 2022-10-21_11:34}|{uid -&gt; BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89, timestamp -&gt; 2022-10-21_11:34}| +-+--+--++-+--+-+ Added Entity Source and Labels to the AssertionFilterer Metadata Now the AssertionFilterer annotator returns the entity source and assertion labels in the metadata. Example: assertionFilterer = AssertionFilterer() .setInputCols([&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;]) .setOutputCol(&quot;filtered&quot;) .setCriteria(&quot;assertion&quot;) .setWhiteList([&quot;Absent&quot;]) text = &quot;Patient has a headache for the last 2 weeks, no alopecia noted.&quot; Results: # before v4.2.1 +--+ |filtered | +--+ |[{chunk, 48, 55, alopecia, {entity -&gt; PROBLEM, sentence -&gt; 0, chunk -&gt; 1, confidence -&gt; 0.9988}, []}]| +--+ # v4.2.1 ++ |filtered | ++ |[{chunk, 48, 55, alopecia, {chunk -&gt; 1, confidence -&gt; 0.9987, ner_source -&gt; ner_chunk, assertion -&gt; Absent, entity -&gt; PROBLEM, sentence -&gt; 0}, []}]| ++ New Chunk Mapper and Sentence Entity Resolver Models And A Pipeline for CVX We are releasing 2 new chunk mapper models to map entities to their corresponding CVX codes, vaccine names and CPT codes. There are 3 types of vaccine names mapped; short_name, full_name and trade_name model name description cvx_name_mapper Mapping vaccine products to their corresponding CVX codes, vaccine names and CPT codes. cvx_code_mapper Mapping CVX codes to their corresponding vaccine names and CPT codes. Example: chunkerMapper = ChunkMapperModel .pretrained(&quot;cvx_name_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;cvx_code&quot;, &quot;short_name&quot;, &quot;full_name&quot;, &quot;trade_name&quot;, &quot;cpt_code&quot;]) data = spark.createDataFrame([[&#39;DTaP&#39;], [&#39;MYCOBAX&#39;], [&#39;cholera, live attenuated&#39;]]).toDF(&#39;text&#39;) Results: +--+--+--+-++--+ |chunk |cvx_code|short_name |full_name |trade_name |cpt_code| +--+--+--+-++--+ |[DTaP] |[20] |[DTaP] |[diphtheria, tetanus toxoids and acellular pertussis vaccine]|[ACEL-IMUNE]|[90700] | |[MYCOBAX] |[19] |[BCG] |[Bacillus Calmette-Guerin vaccine] |[MYCOBAX] |[90585] | |[cholera, live attenuated]|[174] |[cholera, live attenuated]|[cholera, live attenuated] |[VAXCHORA] |[90625] | +--+--+--+-++--+ sbiobertresolve_cvx: This sentence entity resolver model maps vaccine entities to CVX codes using sbiobert_base_cased_mli Sentence Bert Embeddings. Additionally, this model returns status of the vaccine (Active/Inactive/Pending/Non-US) in all_k_aux_labels column. Example: cvx_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_cvx&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;cvx_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) result = light_model.fullAnnotate([&quot;Sinovac&quot;, &quot;Moderna&quot;, &quot;BIOTHRAX&quot;]) Results: +-+--+-+--+ |ner_chunk |cvx_code|resolved_text |Status | +-+--+-+--+ |Sinovac |511 |COVID-19 IV Non-US Vaccine (CoronaVac, Sinovac) |Non-US | |Moderna |227 |COVID-19, mRNA, LNP-S, PF, pediatric 50 mcg/0.5 mL dose|Inactive| |BIOTHRAX |24 |anthrax |Active | +-+--+-+--+ cvx_resolver_pipeline: This pretrained pipeline maps entities with their corresponding CVX codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;cvx_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text= &quot;The patient has a history of influenza vaccine, tetanus and DTaP&quot; result = resolver_pipeline.fullAnnotate(text) Results: +--++--+ |chunk |ner_chunk|cvx_code| +--++--+ |influenza vaccine|Vaccine |160 | |tetanus |Vaccine |35 | |DTaP |Vaccine |20 | +--++--+ Updated Clinical NER Models With New Labels ner_jsl and ner_covid_trials models were updated with the new label called “Vaccine_Name”. Example: ... jsl_ner = MedicalNerModel.pretrained(&quot;ner_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;jsl_ner&quot;) ... sample_text= &quot;&quot;&quot;The patient is a 21-day-old Caucasian male here for 2 days, there is no side effect observed after the influenza vaccine&quot;&quot;&quot; Results: |chunks | begin | end | entities | ||--:|:|:| |21-day-old | 18 | 27 | Age | |Caucasian | 29 | 37 | Race_Ethnicity | |male | 39 | 42 | Gender | |for 2 days | 49 | 58 | Duration | |influenza vaccine | 100 | 116 | Vaccine_Name | New Certification Training Notebooks for the johnsnowlabs Library Now we have 46 new Healtcare Certification Training notebooks for the users who want to use the new johnsnowlabs library. New and Updated Notebooks New Coreference Resolution notebook to find other references of clinical entities in a document. Updated Clinical Name Entity Recognition Model notebook with the new feature setIgnoreStopWords parameter and ModelTracer module. Updated Clinical Assertion Model notebook with the new changes in AssertionFilterer improvement. Updated Clinical Deidentification notebook with the new setRegion parameter in DeIdentification. Updated Clinical Relation Extraction notebook with the new setRelationDirectionCol parameter in RelationExtractionApproach. Updated Date Normalizer notebook with the new setOutputDateformat parameter in DateNormalizer and Replacer annotator. Updated 25 Certification Training Public notebooks and 47 Certification Training Healthcare notebooks with the latest updates in the libraries. Updated 6 Databricks Public notebooks and 14 Databricks Healthcare notebooks with the latest updates in the libraries and 4 new Databricks notebooks created. 6 New Clinical Models and Pipelines Added &amp; Updated in Total cvx_code_mapper cvx_name_mapper sbiobertresolve_cvx cvx_resolver_pipeline ner_jsl ner_covid_trials Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_1"
  },
  "1453": {
    "id": "1453",
    "title": "Spark NLP for Healthcare Release Notes 4.2.2",
    "content": "4.2.2 Highlights Fine-tuning Relation Extraction models with your data Added Romanian support in deidentification annotator for data obfuscation New SDOH (Social Determinants of Health) ner model Improved oncology models and 4 pretrained pipelines New chunk mapper models to map entities (phrases) to their corresponding ICD-10-CM codes as well as clinical abbreviations to their definitions New ICD-10-PCS sentence entity resolver model and ICD-10-CM resolver pipeline New utility &amp; helper modules documentation page New and updated notebooks 22 new clinical models and pipelines added &amp; updated in total Fine-Tuning Relation Extraction Models With Your Data Instead of starting from scratch when training a new Relation Extraction model, you can train a new model by adding your new data to the pretrained model. There are two new params in RelationExtractionApproach which allows you to initialize your model with the data from the pretrained model: setPretrainedModelPath: This parameter allows you to point the training process to an existing model. setОverrideExistingLabels: This parameter overrides the existing labels in the original model that are assigned the same output nodes in the new model. Default is True, when it is set to False the RelationExtractionApproach uses the existing labels and if it finds new ones it tries to assign them to unused output nodes. Example: reApproach_finetune = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setFromEntity(&quot;begin1i&quot;, &quot;end1i&quot;, &quot;label1&quot;) .setToEntity(&quot;begin2i&quot;, &quot;end2i&quot;, &quot;label2&quot;) .setPretrainedModelPath(&quot;existing_RE_MODEL_path&quot;) .setOverrideExistingLabels(False) You can check Resume RelationExtractionApproach Training Notebook for more examples. Added Romanian Support in Deidentification Annotator For Data Obfuscation Deidentification annotator is now able to obfuscate entities (coming from a deid NER model) with fake data in Romanian language. Example: deid_obfuscated_faker = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;ro&#39;) .setObfuscateDate(True) .setObfuscateRefSource(&#39;faker&#39;) text = &quot;&quot;&quot;Nume si Prenume : BUREAN MARIA, Varsta: 77 ,Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui&quot;&quot;&quot; Result: Sentence Masked with entity Masked with Chars Masked with Fixed Chars Obfuscated Nume si Prenume : BUREAN MARIA, Varsta: 77 ,Spitalul Pentru Ochi de Deal, Drumul Oprea Nr. 972 Vaslui Nume si Prenume : &lt; PATIENT&gt;, Varsta: &lt; AGE&gt; ,&lt; HOSPITAL&gt;, &lt; STREET&gt; &lt; CITY&gt; Nume si Prenume : ****, Varsta: ** ,********, ****** ** Nume si Prenume : **, Varsta: ** , **, ** ** Nume si Prenume : Claudia Crumble, Varsta: 18 ,LOS ANGELES AMBULATORY CARE CENTER, 706 north parrish avenue Piscataway New SDOH (Social Determinants of Health) NER Model Social Determinants of Health(SDOH) are the socioeconomic factors under which people live, learn, work, worship, and play that determine their health outcomes.The World Health Organization also provides a definition of social determinants of health. Social determinants of health as the conditions in which people are born, grow, live, work and age. These circumstances are shaped by the distribution of money, power, and resources at global, national, and local levels. Social determinants of health (SDOH) have a major impact on people’s health, well-being, and quality of life. SDOH include lots of factors, also contribute to wide health disparities and inequities. In this project We have tried to define well these factors. The goal of this project is to train models for natural language processing focused on extracting terminology related to social determinants of health from various kinds of biomedical documents. This first model is Named Entity Recognition (NER) task. The project is still ongoing and will mature over time and the number of sdoh factors (entities) will also be enriched. It will include other tasks as well. Example: ner_model = MedicalNerModel.pretrained(&quot;sdoh_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot; Mother states that he does smoke, there is a family hx of alcohol on both maternal and paternal sides of the family, maternal grandfather who died of alcohol related complications and paternal grandmother with severe alcoholism. Pts own drinking began at age 16, living in LA, had a DUI at age 17 after totaling a new car that his mother bought for him, he was married. &quot;&quot;&quot; Result: +-+-+ | token| ner_label| +-+-+ | Mother| B-Family_Member| | he| B-Gender| | smoke| B-Smoking| | alcohol| B-Alcohol| | maternal| B-Family_Member| | paternal| B-Family_Member| | maternal| B-Family_Member| | grandfather| B-Family_Member| | alcohol| B-Alcohol| | paternal| B-Family_Member| | grandmother| B-Family_Member| | severe| B-Alcohol| | alcoholism| I-Alcohol| | drinking| B-Alcohol| | age| B-Age| | 16| I-Age| | LA|B-Geographic_Entity| | age| B-Age| | 17| I-Age| | his| B-Gender| | mother| B-Family_Member| | him| B-Gender| | he| B-Gender| | married| B-Marital_Status| +-+-+ Improved Oncology NER Models And 4 New Pretrained Pipelines We are releasing the improved version of Oncological NER models (_wip) and 4 new pretrained oncological pipelines which are able to detect assertion status and relations between the extracted oncological entities. NER model name (MedicalNerModel) description predicted entities ner_oncology_anatomy_general Extracting anatomical entities. Anatomical_Site, Direction ner_oncology_anatomy_granular Extracting anatomical entities using granular labels. Direction, Site_Lymph_Node, Site_Breast, Site_Other_Body_Part, Site_Bone, Site_Liver, Site_Lung, Site_Brain ner_oncology_biomarker Extracting biomarkers and their results. Biomarker, Biomarker_Result ner_oncology_demographics Extracting demographic information, including smoking status. Age, Gender, Smoking_Status, Race_Ethnicity ner_oncology_diagnosis Extracting entities related to cancer diagnosis, including the presence of metastasis. Grade, Staging, Tumor_Size, Adenopathy, Pathology_Result, Histological_Type, Metastasis, Cancer_Score, Cancer_Dx, Invasion, Tumor_Finding, Performance_Status ner_oncology Extracting more than 40 oncology-related entities. Histological_Type, Direction, Staging, Cancer_Score, Imaging_Test, Cycle_Number, Tumor_Finding, Site_Lymph_Node, Invasion, Response_To_Treatment, Smoking_Status, Tumor_Size, Cycle_Count, Adenopathy, Age, Biomarker_Result, Unspecific_Therapy, Site_Breast, Chemotherapy, Targeted_Therapy, Radiotherapy, Performance_Status, Pathology_Test, Site_Other_Body_Part, Cancer_Surgery, Line_Of_Therapy, Pathology_Result, Hormonal_Therapy, Site_Bone, Biomarker, Immunotherapy, Cycle_Day, Frequency, Route, Duration, Death_Entity, Metastasis, Site_Liver, Cancer_Dx, Grade, Date, Site_Lung, Site_Brain, Relative_Date, Race_Ethnicity, Gender, Oncogene, Dosage, Radiation_Dose ner_oncology_posology This model extracts oncology specific posology information and cancer therapies. Cycle_Number, Cycle_Count, Radiotherapy, Cancer_Surgery, Cycle_Day, Frequency, Route, Cancer_Therapy, Duration, Dosage, Radiation_Dose ner_oncology_unspecific_posology Extracting any mention of cancer therapies and posology information using general labels Cancer_Therapy, Posology_Information ner_oncology_response_to_treatment_wip Extracting entities related to the patient’s response to cancer treatment. Response_To_Treatment, Size_Trend, Line_Of_Therapy ner_oncology_therapy Extracting entities related to cancer therapies, including posology entities and response to treatment, using granular labels. Response_To_Treatment, Line_Of_Therapy, Cancer_Surgery, Radiotherapy, Immunotherapy, Targeted_Therapy, Hormonal_Therapy, Chemotherapy, Unspecific_Therapy, Route, Duration, Cycle_Count, Dosage, Frequency, Cycle_Number, Cycle_Day, Radiation_Dose ner_oncology_test Extracting mentions of oncology-related tests. Oncogene, Biomarker, Biomarker_Result, Imaging_Test, Pathology_Test ner_oncology_tnm Extracting mentions related to TNM staging. Lymph_Node, Staging, Lymph_Node_Modifier, Tumor_Description, Tumor, Metastasis, Cancer_Dx Oncological Pipeline (PretrainedPipeline) Description oncology_general_pipeline Includes Named-Entity Recognition, Assertion Status and Relation Extraction models to extract information from oncology texts. This pipeline extracts diagnoses, treatments, tests, anatomical references and demographic entities. oncology_biomarker_pipeline Includes Named-Entity Recognition, Assertion Status and Relation Extraction models to extract information from oncology texts. This pipeline focuses on entities related to biomarkers oncology_diagnosis_pipeline Includes Named-Entity Recognition, Assertion Status, Relation Extraction and Entity Resolution models to extract information from oncology texts. This pipeline focuses on entities related to oncological diagnosis. oncology_therapy_pipeline Includes Named-Entity Recognition and Assertion Status models to extract information from oncology texts. This pipeline focuses on entities related to therapies. Example: from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;oncology_general_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;The patient underwent a left mastectomy for a left breast cancer two months ago. The tumor is positive for ER and PR.&quot; Result: **** ner_oncology_wip results **** | chunk | ner_label | |:|:--| | left | Direction | | mastectomy | Cancer_Surgery | | left | Direction | | breast cancer | Cancer_Dx | | two months ago | Relative_Date | | tumor | Tumor_Finding | | positive | Biomarker_Result | | ER | Biomarker | | PR | Biomarker | **** assertion_oncology_wip results **** | chunk | ner_label | assertion | |:--|:|:| | mastectomy | Cancer_Surgery | Past | | breast cancer | Cancer_Dx | Present | | tumor | Tumor_Finding | Present | | ER | Biomarker | Present | | PR | Biomarker | Present | **** re_oncology_wip results **** | chunk1 | entity1 | chunk2 | entity2 | relation | |:--|:--|:|:--|:--| | mastectomy | Cancer_Surgery | two months ago | Relative_Date | is_related_to | | breast cancer | Cancer_Dx | two months ago | Relative_Date | is_related_to | | tumor | Tumor_Finding | ER | Biomarker | O | | tumor | Tumor_Finding | PR | Biomarker | O | | positive | Biomarker_Result | ER | Biomarker | is_related_to | | positive | Biomarker_Result | PR | Biomarker | is_related_to | New Chunk Mapper Models to Map Entities (phrases) to Their Corresponding ICD-10-CM Codes As Well As Clinical Abbreviations to Their Definitions We have 2 new chunk mapper models: abbreviation_mapper_augmented is an augmented version of the existing abbreviation_mapper model. It maps abbreviations and acronyms of medical regulatory activities to their definitions. icd10cm_mapper maps entities to corresponding ICD-10-CM codes. Example: chunkerMapper = ChunkMapperModel .pretrained(&quot;icd10cm_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;icd10cm_code&quot;]) text = &quot;&quot;&quot;A 35-year-old male with a history of primary leiomyosarcoma of neck, gestational diabetes mellitus diagnosed eight years prior to presentation and presented with a one-week history of polydipsia, poor appetite, and vomiting.&quot;&quot;&quot; Result: ++-++ |ner_chunk |entity |icd10cm_code| ++-++ |primary leiomyosarcoma of neck|PROBLEM|C49.0 | |gestational diabetes mellitus |PROBLEM|O24.919 | |polydipsia |PROBLEM|R63.1 | |poor appetite |PROBLEM|R63.0 | |vomiting |PROBLEM|R11.10 | ++-++ New ICD-10-PCS Sentence Entity Resolver Model and ICD-10-CM Resolver Pipeline We are releasing new ICD-10-PCS resolver model and ICD-10-CM resolver pipeline: sbiobertresolve_icd10pcs_augmented model maps extracted medical entities to ICD-10-PCS codes using sbiobert_base_cased_mli sentence bert embeddings. It trained on the augmented version of the dataset which is used in previous ICD-10-PCS resolver model. Example: icd10pcs_resolver = SentenceEntityResolverModel .pretrained(&quot;sbiobertresolve_icd10pcs_augmented&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;, &quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) text = &quot;Given the severity of her abdominal examination and her persistence of her symptoms, it is detected that need for laparoscopic appendectomy and possible open appendectomy as well as pyeloplasty. We recommend performing a mediastinoscopy&quot; Result: +-++-++--+ | ner_chunk| entity|icd10pcs_code| resolutions| all_codes| +-++-++--+ | abdominal examination| Test| 2W63XZZ|[traction of abdominal wall [trac...|[2W63XZZ, BW40ZZZ...| |laparoscopic appendectomy|Procedure| 0DTJ8ZZ|[resection of appendix, endo [res...|[0DTJ8ZZ, 0DT84ZZ...| | open appendectomy|Procedure| 0DBJ0ZZ|[excision of appendix, open appro...|[0DBJ0ZZ, 0DTJ0ZZ...| | pyeloplasty|Procedure| 0TS84ZZ|[reposition bilateral ureters, pe...|[0TS84ZZ, 0TS74ZZ...| | mediastinoscopy|Procedure| BB1CZZZ|[fluoroscopy of mediastinum [fluo...|[BB1CZZZ, 0WJC4ZZ...| +-++-++--+ icd10cm_resolver_pipeline pretrained pipeline maps entities with their corresponding ICD-10-CM codes. You’ll just feed your text and it will return the corresponding ICD-10-CM codes. Example: from sparknlp.pretrained import PretrainedPipeline resolver_pipeline = PretrainedPipeline(&quot;icd10cm_resolver_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) text = &quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years and anisakiasis. Also, it was reported that fetal and neonatal hemorrhage&quot; Result: +--+++ |chunk |ner_chunk|icd10cm_code| +--+++ |gestational diabetes mellitus|PROBLEM |O24.919 | |anisakiasis |PROBLEM |B81.0 | |fetal and neonatal hemorrhage|PROBLEM |P545 | +--+++ New Utility &amp; Helper Modules Documentation Page We have a new utility &amp; helper modules documentation page that you can find the documentations of Spark NLP for Healthcare modules with examples. New and Updated Notebooks New Resume RelationExtractionApproach Training notebook train a model already trained on a different dataset. Updated Clinical Deidentification notebook with day shifting feature in DeIdentification. Updated Clinical Multi Language Deidentification notebook with new Romanian obfuscation and faker improvement. Updated Adverse Drug Event ADE NER and Classifier notebook with the new models and improvement. 22 New Clinical Models and Pipelines Added &amp; Updated in Total abbreviation_mapper_augmented icd10cm_mapper sbiobertresolve_icd10pcs_augmented icd10cm_resolver_pipeline oncology_biomarker_pipeline oncology_diagnosis_pipeline oncology_therapy_pipeline oncology_general_pipeline ner_oncology_anatomy_general ner_oncology_anatomy_granular ner_oncology_biomarker ner_oncology_demographics ner_oncology_diagnosis ner_oncology ner_oncology_posology ner_oncology_response_to_treatment ner_oncology_test ner_oncology_therapy ner_oncology_tnm ner_oncology_unspecific_posology sdoh_slim_wip t5_base_pubmedqa For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_2"
  },
  "1454": {
    "id": "1454",
    "title": "Spark NLP for Healthcare Release Notes 4.2.3",
    "content": "4.2.3 Highlights 3 new chunk mapper models to mapping Drugs and Diseases from the KEGG Database as well as mapping abbreviations to their categories New utility &amp; helper Relation Extraction modules to handle preprocess New utility &amp; helper OCR modules to handle annotate New utility &amp; helper NER log parser Adding flexibility chunk merger prioritization Core improvements and bug fixes New and updated notebooks 3 new clinical models and pipelines added &amp; updated in total 3 New Hhunk Mapper Models to Mapping Drugs and Diseases from the KEGG Database as well as Mapping Abbreviations to Their Categories kegg_disease_mapper: This pretrained model maps diseases with their corresponding category, description, icd10_code, icd11_code, mesh_code, and hierarchical brite_code. This model was trained with the data from the KEGG database. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;kegg_disease_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;description&quot;, &quot;category&quot;, &quot;icd10_code&quot;, &quot;icd11_code&quot;, &quot;mesh_code&quot;, &quot;brite_code&quot;]) text= &quot;A 55-year-old female with a history of myopia, kniest dysplasia and prostate cancer. She was on glipizide , and dapagliflozin for congenital nephrogenic diabetes insipidus.&quot; Result: +--+--+--+-+-++--+ | ner_chunk| description| category|icd10_code|icd11_code|mesh_code| brite_code| +--+--+--+-+-++--+ | myopia|Myopia is the most common ocular disorder world...| Nervous system disease| H52.1| 9D00.0| D009216| 08402,08403| | kniest dysplasia|Kniest dysplasia is an autosomal dominant chond...|Congenital malformation| Q77.7| LD24.3| C537207| 08402,08403| | prostate cancer|Prostate cancer constitutes a major health prob...| Cancer| C61| 2C82| NONE|08402,08403,08442,08441| |congenital nephrogenic diabetes insipidus|Nephrogenic diabetes insipidus (NDI) is charact...| Urinary system disease| N25.1| GB90.4A| D018500| 08402,08403| +--+--+--+-+-++--+ kegg_drug_mapper: This pretrained model maps drugs with their corresponding efficacy, molecular_weight as well as CAS, PubChem, ChEBI, LigandBox, NIKKAJI, PDB-CCD codes. This model was trained with the data from the KEGG database. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;kegg_drug_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;efficacy&quot;, &quot;molecular_weight&quot;, &quot;CAS&quot;, &quot;PubChem&quot;, &quot;ChEBI&quot;, &quot;LigandBox&quot;, &quot;NIKKAJI&quot;, &quot;PDB-CCD&quot;]) text= &quot;She is given OxyContin, folic acid, levothyroxine, Norvasc, aspirin, Neurontin&quot; Result: +-+--+-+-+--+-+++-+ | ner_chunk| efficacy|molecular_weight| CAS| PubChem| ChEBI|LigandBox| NIKKAJI|PDB-CCD| +-+--+-+-+--+-+++-+ | OxyContin| Analgesic (narcotic), Opioid receptor agonist| 351.8246| 124-90-3| 7847912.0| 7859.0| D00847|J281.239H| NONE| | folic acid|Anti-anemic, Hematopoietic, Supplement (folic a...| 441.3975| 59-30-3| 7847138.0|27470.0| D00070| J1.392G| FOL| |levothyroxine| Replenisher (thyroid hormone)| 776.87| 51-48-9|9.6024815E7|18332.0| D08125| J4.118A| T44| | Norvasc|Antihypertensive, Vasodilator, Calcium channel ...| 408.8759|88150-42-9|5.1091781E7| 2668.0| D07450| J33.383B| NONE| | aspirin|Analgesic, Anti-inflammatory, Antipyretic, Anti...| 180.1574| 50-78-2| 7847177.0|15365.0| D00109| J2.300K| AIN| | Neurontin| Anticonvulsant, Antiepileptic| 171.2368|60142-96-3| 7847398.0|42797.0| D00332| J39.388F| GBN| +-+--+-+-+--+-+++-+ abbreviation_category_mapper: This pretrained model maps abbreviations and acronyms of medical regulatory activities with their definitions and categories. Predicted categories: general, problem, test, treatment, medical_condition, clinical_dept, drug, nursing, internal_organ_or_component, hospital_unit, drug_frequency, employment, procedure. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;abbreviation_category_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;abbr_ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;definition&quot;, &quot;category&quot;]) text = [&quot;&quot;&quot;Gravid with estimated fetal weight of 6-6/12 pounds. LABORATORY DATA: Laboratory tests include a CBC which is normal. VDRL: Nonreactive HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.&quot;&quot;&quot;] Result: | chunk | category | definition | |:--|:|:| | CBC | general | complete blood count | | VDRL | clinical_dept | Venereal Disease Research Laboratories | | HIV | medical_condition | Human immunodeficiency virus | New Utility &amp; Helper Relation Extraction Modules to Handle Preprocess This process is standard and training column should be same in all RE trainings. We can simplify this process with helper class. With proposed changes it can be done as follows: Example: from sparknlp_jsl.training import REDatasetHelper # map entity columns to dataset columns column_map = { &quot;begin1&quot;: &quot;firstCharEnt1&quot;, &quot;end1&quot;: &quot;lastCharEnt1&quot;, &quot;begin2&quot;: &quot;firstCharEnt2&quot;, &quot;end2&quot;: &quot;lastCharEnt2&quot;, &quot;chunk1&quot;: &quot;chunk1&quot;, &quot;chunk2&quot;: &quot;chunk2&quot;, &quot;label1&quot;: &quot;label1&quot;, &quot;label2&quot;: &quot;label2&quot; } # apply preprocess function to dataframe data = REDatasetHelper(data).create_annotation_column( column_map, ner_column_name=&quot;train_ner_chunks&quot; # optional, default train_ner_chunks ) New Utility &amp; Helper OCR Modules to Handle Annotations This modeule can generates an annotated PDF file using input PDF files. style: PDF file proccess style that has 3 options; black_band: Black bands over the chunks detected by NER pipeline. bounding_box: Colorful bounding boxes around the chunks detected by NER pipeline. Each color represents a different NER label. highlight: Colorful highlights over the chunks detected by NER pipeline. Each color represents a different NER label. You can check Spark OCR Utility Module notebook for more examples. Example: from sparknlp_jsl.utils.ocr_nlp_processor import ocr_entity_processor path=&#39;/*.pdf&#39; box = &quot;bounding_box&quot; ocr_entity_processor(spark=spark,file_path=path,ner_pipeline = nlp_model,chunk_col = &quot;merged_chunk&quot;, black_list = [&quot;AGE&quot;, &quot;DATA&quot;, &quot;PATIENT&quot;], style = box, save_dir = &quot;colored_box&quot;,label= True, label_color = &quot;red&quot;,color_chart_path = &quot;label_colors.png&quot;, display_result=True) box = &quot;highlight&quot; ocr_entity_processor(spark=spark,file_path=path, ner_pipeline = nlp_model, chunk_col = &quot;merged_chunk&quot;, black_list = [&quot;AGE&quot;, &quot;DATE&quot;, &quot;PATIENT&quot;], style = box, save_dir = &quot;colored_box&quot;, label= True, label_color = &quot;red&quot;, color_chart_path = &quot;label_colors.png&quot;, display_result=True) box = &quot;black_band&quot; ocr_entity_processor(spark=spark,file_path=path, ner_pipeline = nlp_modelchunk_col = &quot;merged_chunk&quot;, style = box, save_dir = &quot;black_band&quot;,label= True, label_color = &quot;red&quot;, display_result = True) Results: Bounding box with labels and black list Highlight with labels and black_list black_band with labels New Utility &amp; Helper NER Log Parser ner_utils: This new module is used after NER training to calculate mertic chunkbase and plot training logs. Example: nerTagger = NerDLApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setOutputCol(&quot;ner&quot;) ... .setOutputLogsPath(&#39;ner_logs&#39;) ner_pipeline = Pipeline(stages=[glove_embeddings, graph_builder, nerTagger]) ner_model = ner_pipeline.fit(training_data) evaluate: if verbose, returns overall performance, as well as performance per chunk type; otherwise, simply returns overall precision, recall, f1 scores Example: from sparknlp_jsl.utils.ner_utils import evaluate metrics = evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) Result: processed 14133 tokens with 1758 phrases; found: 1779 phrases; correct: 1475. accuracy: 83.45%; (non-O) accuracy: 96.67%; precision: 82.91%; recall: 83.90%; FB1: 83.40 LOC: precision: 91.41%; recall: 85.69%; FB1: 88.46 524 MISC: precision: 78.15%; recall: 62.11%; FB1: 69.21 151 ORG: precision: 61.86%; recall: 74.93%; FB1: 67.77 430 PER: precision: 90.80%; recall: 93.58%; FB1: 92.17 674 loss_plot: Plots the figure of loss vs epochs Example: from sparknlp_jsl.utils.ner_utils import loss_plot loss_plot(&#39;./ner_logs/&#39;+log_files[0]) Results: get_charts : Plots the figures of metrics ( precision, recall, f1) vs epochs Example: from sparknlp_jsl.utils.ner_utils import get_charts get_charts(&#39;./ner_logs/&#39;+log_files[0]) Results: Adding Flexibility Chunk Merger Prioritization orderingFeatures: Array of strings specifying the ordering features to use for overlapping entities. Possible values are ChunkBegin, ChunkLength, ChunkPrecedence, ChunkConfidence selectionStrategy: Whether to select annotations sequentially based on annotation order Sequential or using any other available strategy, currently only DiverseLonger are available. defaultConfidence: When ChunkConfidence ordering feature is included and a given annotation does not have any confidence the value of this param will be used. chunkPrecedence: When ChunkPrecedence ordering feature is used this param contains the comma separated fields in metadata that drive prioritization of overlapping annotations. When used by itself (empty chunkPrecedenceValuePrioritization) annotations will be prioritized based on number of metadata fields present. When used together with chunkPrecedenceValuePrioritization param it will prioritize based on the order of its values. chunkPrecedenceValuePrioritization: When ChunkPrecedence ordering feature is used this param contains an Array of comma separated values representing the desired order of prioritization for the VALUES in the metadata fields included from chunkPrecedence. Example: text = &quot;&quot;&quot;A 63 years old man presents to the hospital with a history of recurrent infections that include cellulitis, pneumonias, and upper respiratory tract infections...&quot;&quot;&quot; +-+ |ner_deid_chunk | +-+ |[{chunk, 2, 3, 63, {entity -&gt; AGE, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.9997}}]| +-+ +-+ |jsl_ner_chunk | +-+ |[{chunk, 2, 13, 63 years old, {entity -&gt; Age, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.85873336}}]| +-+ Merging overlapped chunks by considering their lenght If we set setOrderingFeatures([&quot;ChunkLength&quot;]) and setSelectionStrategy(&quot;DiverseLonger&quot;) parameters, the longest chunk will be prioritized in case of overlapping. Example: chunk_merger = ChunkMergeApproach() .setInputCols(&#39;ner_deid_chunk&#39;, &quot;jsl_ner_chunk&quot;) .setOutputCol(&#39;merged_ner_chunk&#39;) .setOrderingFeatures([&quot;ChunkLength&quot;]) .setSelectionStrategy(&quot;DiverseLonger&quot;) Results: |begin|end| chunk| entity| +--++-++ | 2| 13| 63 years old| Age| | 15| 17| man| Gender| | 35| 42| hospital| Clinical_Dept| Merging overlapped chunks by considering custom values that we set setChunkPrecedence() parameter contains an Array of comma separated values representing the desired order of prioritization for the VALUES in the metadata fields included from setOrderingFeatures([&quot;chunkPrecedence&quot;]). Example: chunk_merger = ChunkMergeApproach() .setInputCols(&#39;ner_deid_chunk&#39;, &quot;jsl_ner_chunk&quot;) .setOutputCol(&#39;merged_ner_chunk&#39;) .setMergeOverlapping(True) .setOrderingFeatures([&quot;ChunkPrecedence&quot;]) .setChunkPrecedence(&#39;ner_deid_chunk,AGE&#39;) # .setChunkPrecedenceValuePrioritization([&quot;ner_deid_chunk,AGE&quot;, &quot;jsl_ner_chunk,Age&quot;]) Results: |begin|end| chunk| entity| +--++-++ | 2| 3| 63| AGE| | 15| 17| man| Gender| | 35| 42| hospital| Clinical_Dept| You can check NER Chunk Merger notebook for more examples. Core improvements and bug fixes AssertionDL IncludeConfidence() parameters default value set by True Fixed NaN outputs in RelationExtraction Fixed loadSavedModel method that we use for importing transformers into Spark NLP Fixed replacer with setUseReplacement(True) parameter Added overall confidence score to MedicalNerModel when setIncludeAllConfidenceScore is True Fixed in InternalResourceDownloader showAvailableAnnotators New and Updated Notebooks New Spark OCR Utility Module notebook to help handle OCR process. Updated Clinical Entity Resolvers notebook with Assertion Filterer example. Updated NER Chunk Merger notebook with flexibility chunk merger prioritization example. Updated Clinical Relation Extraction notebook with new REDatasetHelper module. Updated ALab Module SparkNLP JSL notebook with new updates. 3 New Clinical Models and Pipelines Added &amp; Updated in Total kegg_disease_mapper kegg_drug_mapper abbreviation_category_mapper For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_3",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_3"
  },
  "1455": {
    "id": "1455",
    "title": "Visual NLP(Spark OCR) release notes 4.2.4",
    "content": "4.2.4 We are glad to announce that Spark OCR 4.2.4⚡has been released!! This release includes new optimized ImageToTextV2 models, more support on annotators in LightPipelines, a new PdfToHocr annotator, enhancements, and more! New Features New annotators supported in LightPipelines: PdfToText and most Image transformations. Check sample notebook for details. Handling of PDFs with broken headers: some PDFs may contain incorrect header information causing the pipelines to fail to process them, now PDF processing annotators support handling these documents. New Annotators New ImageToTextV2 Transformers based OCR annotator, Intended to become a full replacement of original ImageToTextV2. Speed ups of up to 2x compared to original model. It doesn’t require GPU, it works with CPU only environments. Preliminary experiments show similar character error rate compared to original model. Optimized versions take less space(about a half) and are faster to store and download. Full JVM implementation. Limitations: currently the new ImageToTextV2 doesn’t support Hocr output. To start using it, follow this example, ... from sparkocr.optimized import ImageToTextV2 ocr = ImageToTextV2.pretrained(&quot;ocr_base_printed_v2_opt&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) New PdfToHocr: this new annotator allows to produce HOCR output from digital PDFs. This is not only useful for integrating into existing annotators that already consume HOCR, but for new pipelines that will be released in the future. Stay tuned for new releases. New Models ocr_base_printed_v2 ocr_base_handwritten_v2 ocr_base_printed_v2_opt (quantized version) ocr_base_handwritten_v2_opt (quantized version) New Notebooks New supported transformers in LightPipelines in action, SparkOcrLightPipelinesPdf.ipynb PdfToHocr, SparkOCRPdfToHocr.ipynb This release is compatible with Spark NLP 4.2.4, and Spark NLP for Healthcare 4.2.3. Versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_2_4",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_2_4"
  },
  "1456": {
    "id": "1456",
    "title": "Spark NLP for Healthcare Release Notes 4.2.4",
    "content": "4.2.4 Highlights New chunk mapper model for matching drugs by categories as well as other brands and names 4 new NER and classification models for Social Determinant of Health Allow fuzzy matching in the ChunkMapper annotator New NameChunkObfuscatorApproach annotator to obfuscate doctor and patient names using a custom external list (consistent name obfuscation) New AssertionChunkConverter annotator to prepare assertion model training dataset from chunk indices New training_log_parser module to parse NER and Assertion Status Detection model training log files Obfuscation of age entities by age groups in Deidentification Controlling the behaviour of unnormalized dates while shifting the days in Deidentification (setUnnormalizedDateMode parameter) Setting default day, months or years for partial dates via DateNormalizer Setting label case sensitivity in AssertionFilterer getClasses method for Zero Shot NER and Zero Shot Relation Extraction models Setting max syntactic distance parameter in RelationExtractionApproach Generic Relation Extraction Model (generic_re) to extract relations between any named entities using syntactic distances Core improvements and bug fixes New and updated notebooks New and updated demos MEDICAL QUESTION ANSWERING SMOKING STATUS MENTAL HEALTH DEPRESSION 5 new clinical models and pipelines added &amp; updated in total New Chunk Mapper Model For Matching Drugs by Categories As Well As Other Brands and Names We have a new drug_category_mapper chunk mapper model that maps drugs to their categories, other brands and names. It has two categories called main category and subcategory. Example: chunkerMapper = ChunkMapperModel.pretrained(&quot;drug_category_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;main_category&quot;, &quot;sub_category&quot;, &quot;other_name&quot;]) sample_text= &quot;She is given OxyContin, folic acid, levothyroxine, Norvasc, aspirin, Neurontin.&quot; Result: +-++--+--+ | ner_chunk| main_category| sub_category|other_names| +-++--+--+ | OxyContin| Pain Management| Opioid Analgesics| Oxaydo| | folic acid| Nutritionals| Vitamins, Water-Soluble| Folvite| |levothyroxine|Metabolic &amp; Endocrine| Thyroid Products| Levo T| | Norvasc| Cardiovascular| Antianginal Agents| Katerzia| | aspirin| Cardiovascular|Antiplatelet Agents, Cardiovascular| ASA| | Neurontin| Neurologics| GABA Analogs| Gralise| +-++--+--+ 4 New NER and Classification Models for Social Determinant of Health We are releasing 4 new NER and Classification models for Social Determinant of Health. ner_sdoh_mentions: Detecting Social Determinants of Health mentions in clinical notes. Predicted entities: sdoh_community, sdoh_economics, sdoh_education, sdoh_environment, behavior_tobacco, behavior_alcohol, behavior_drug. Example: ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_mentions&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;Mr. John Smith is a pleasant, cooperative gentleman with a long standing history (20 years) of diverticulitis. He is married and has 3 children. He works in a bank. He denies any alcohol or intravenous drug use. He has been smoking for many years.&quot;&quot;&quot; Result: +-+-+ |chunk |ner_label | +-+-+ |married |sdoh_community | |children |sdoh_community | |works |sdoh_economics | |alcohol |behavior_alcohol| |intravenous drug|behavior_drug | |smoking |behavior_tobacco| +-+-+ MedicalBertForSequenceClassification models that can be used in Social Determinant of Health related classification tasks: model name description predicted entities bert_sequence_classifier_sdoh_community_absent_status Classifies the clinical texts related to the loss of social support such as a family member or friend in the clinical documents. A discharge summary was classified True for Community-Absent if the discharge summary had passages related to the loss of social support and False if such passages were not found in the discharge summary. True False bert_sequence_classifier_sdoh_community_present_status Classifies the clinical texts related to social support such as a family member or friend in the clinical documents. A discharge summary was classified True for Community-Present if the discharge summary had passages related to active social support and False if such passages were not found in the discharge summary. True False bert_sequence_classifier_sdoh_environment_status Classifies the clinical texts related to environment situation such as any indication of housing, homeless or no related passage. A discharge summary was classified as True for the SDOH Environment if there was any indication of housing, False if the patient was homeless and None if there was no related passage. True False None Example: sequenceClassifier = MedicalBertForSequenceClassification.pretrained(&quot;bert_sequence_classifier_sdoh_community_present_status&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;document&quot;,&quot;token&quot;]) .setOutputCol(&quot;class&quot;) sample_text = [&quot;Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair 2137. Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. Name (NI) past or present smoking hx, no EtOH.&quot;, &quot;Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep Apnea. Denies tobacco and ETOH. Works as cafeteria worker.&quot;] Result: +-+-+ | text| result| +-+-+ |Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair...| [True]| |Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep...|[False]| +-+-+ Allow Fuzzy Matching in the ChunkMapper Annotator There are multiple options to achieve fuzzy matching using the ChunkMapper annotation: Partial Token NGram Fingerprinting: Useful to combine two frequent usecases; when there are noisy non informative tokens at the beginning / end of the chunk and the order of the chunk is not absolutely relevant. i.e. stomach acute pain –&gt; acute pain stomach ; metformin 100 mg –&gt; metformin. Char NGram Fingerprinting: Useful in usecases that involve typos or different spacing patterns for chunks. i.e. head ache / ache head –&gt; headache ; metformini / metformoni / metformni –&gt; metformin Fuzzy Distance (Slow): Useful when the mapping can be defined in terms of edit distance thresholds using functions like char based like Levenshtein, Hamming, LongestCommonSubsequence or token based like Cosine, Jaccard. The mapping logic will be run in the previous order also ordering by longest key inside each option as an intuitive way to minimize false positives. Basic Mapper Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) text = &quot;&quot;&quot;The patient was given Lusa Warfarina 5mg and amlodipine 10 MG. The patient was given Aspaginaspa, coumadin 5 mg, coumadin, and he has metamorfin&quot;&quot;&quot; # Since mappers only match one-to-one | ner_chunk | fixed_chunk | action | treatment | |:-|:|:-|:-| | Aspaginaspa | nan | nan | nan | | Lusa Warfarina 5mg | nan | nan | nan | | amlodipine 10 | nan | nan | nan | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | nan | nan | nan | | metamorfin | nan | nan | nan | Since mappers only match one-to-one, we see that only 1 chunk has action and teatment in the table above. Token Fingerprinting Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) Result: | ner_chunk | fixed_chunk | action | treatment | |:--|:-|:--|:-| | Aspaginaspa | nan | nan | nan | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | nan | nan | nan | Token and Char Fingerprinting Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setLowerCase(True) .setRels([&quot;action&quot;, &quot;treatment&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) .setEnableCharFingerprintMatching(True) .setMinCharNgramFingerprint(1) .setMaxCharNgramFingerprint(3) Result: | ner_chunk | fixed_chunk | action | treatment | |:--|:|:|:-| | Aspaginaspa | aspagin | Cycooxygenase Inhibitor | arthritis | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | nan | nan | nan | Token and Char Fingerprinting With Fuzzy Distance Calculation Example: cm = ChunkMapperApproach() .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setDictionary(&quot;mappings.json&quot;) .setLowerCase(True) .setRels([&quot;action&quot;]) .setAllowMultiTokenChunk(True) .setEnableTokenFingerprintMatching(True) .setMinTokenNgramFingerprint(1) .setMaxTokenNgramFingerprint(3) .setMaxTokenNgramDroppingCharsRatio(0.5) .setEnableCharFingerprintMatching(True) .setMinCharNgramFingerprint(1) .setMaxCharNgramFingerprint(3) .setEnableFuzzyMatching(True) .setFuzzyMatchingDistanceThresholds(0.31) Result: | ner_chunk | fixed_chunk | action | treatment | |:-|:|:|:-| | Aspaginaspa | aspagin | Cycooxygenase Inhibitor | arthritis | | Lusa Warfarina 5mg | Warfarina lusa | Analgesic | diabetes | | amlodipine 10 | amlodipine | Calcium Ions Inhibitor | hypertension | | coumadin | coumadin | Coagulation Inhibitor | hypertension | | coumadin 5 mg | coumadin | Coagulation Inhibitor | hypertension | | metamorfin | metformin | hypoglycemic | diabetes | You can check Chunk_Mapping notebook for more examples. New NameChunkObfuscatorApproach Annotator to Obfuscate Doctor and Patient Names Using a Custom External List (consistent name obfuscation) We have a new NameChunkObfuscatorApproach annotator that can be used in deidentification tasks for replacing doctor and patient names with fake names using a reference document. Example: names = &quot;&quot;&quot;Mitchell#NAME Jackson#NAME Leonard#NAME Bowman#NAME Fitzpatrick#NAME Melody#NAME&quot;&quot;&quot; with open(&#39;names_test.txt&#39;, &#39;w&#39;) as file: file.write(names) nameChunkObfuscator = NameChunkObfuscatorApproach() .setInputCols(&quot;ner_chunk&quot;) .setOutputCol(&quot;replacement&quot;) .setRefFileFormat(&quot;csv&quot;) .setObfuscateRefFile(&quot;names_test.txt&quot;) .setRefSep(&quot;#&quot;) text = &#39;&#39;&#39;John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment. &#39;&#39;&#39; Result: Original text : John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment. Obfuscated text : Fitzpatrick is a &lt;AGE&gt; y.o. patient admitted. Mr. Bowman was seen by attending physician Dr. Melody and was scheduled for emergency assessment. You can check Clinical DeIdentification notebook for more examples. New AssertionChunkConverter Annotator to Prepare Assertion Model Training Dataset From Chunk Indices In some cases, there may be issues while creating the chunk column by using token indices and losing some data while training and testing the assertion status model if there are issues in these token indices. So we developed a new AssertionChunkConverter annotator that takes begin and end indices of the chunks as input and creates an extended chunk column with metadata that can be used for assertion status detection model training. Example: ... converter = AssertionChunkConverter() .setInputCols(&quot;tokens&quot;) .setChunkTextCol(&quot;target&quot;) .setChunkBeginCol(&quot;char_begin&quot;) .setChunkEndCol(&quot;char_end&quot;) .setOutputTokenBeginCol(&quot;token_begin&quot;) .setOutputTokenEndCol(&quot;token_end&quot;) .setOutputCol(&quot;chunk&quot;) sample_data = spark.createDataFrame([[&quot;An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.&quot;, &quot;Minnie&quot;, 57, 63], [&quot;After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation &quot;, &quot;PCP&quot;, 31, 34]]) .toDF(&quot;text&quot;, &quot;target&quot;, &quot;char_begin&quot;, &quot;char_end&quot;) Result: ++-+--+--++--+++-+ |target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk | ++-+--+--++--+++-+ |Minnie|57 |62 |10 |10 |Minnie |Minnie |Minnie|[{chunk, 57, 63, Minnie, {sentence -&gt; 0}, []}]| |PCP |31 |34 |5 |5 |PCP |PCP |PCP |[{chunk, 31, 33, PCP, {sentence -&gt; 0}, []}] | ++-+--+--++--+++-+ New training_log_parser Module to Parse Training Log Files of NER And Assertion Status Detection Models We are releasing a new training_log_parser module that helps to parse NER and Assertion Status Detection model training log files using a single module. Here are the methods and their descriptions:   Description ner_log_parser assertion_log_parser How to import You can import this module for NER and Assertion as shown here from sparknlp_jsl.utils.training_log_parser import ner_log_parser from sparknlp_jsl.utils.training_log_parser import assertion_log_parser get_charts Plots the figures of metrics ( precision, recall, f1) vs epochs ner_log_parser.get_charts(log_file, threshold) assertion_log_parser.get_charts(log_file, labels, threshold) loss_plot Plots the figures of validation and test loss values vs epochs. ner_log_parser.loss_plot(path) assertion_log_parser.loss_plot(path) get_best_f1_scores Returns the best Micro and Macro F1 Scores on test set ner_log_parser.get_best_f1_scores(path) assertion_log_parser.get_best_f1_scores(path) parse_logfile Returns the parsed log file in pandas dataframe format with the order of label-score dataframe, epoch-metrics dataframe and graph file used in tranining. ner_log_parser.parse_logfile(path) assertion_log_parser.parse_logfile(path, labels) evaluate if verbose, returns overall performance, as well as performance per chunk type; otherwise, simply returns overall precision, recall, f1 scores. Ground truth and predictions should be provided in pandas dataframe. ner_log_parser.evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) - Import from sparknlp_jsl.utils.training_log_parser import ner_log_parser, assertion_log_parser ner_parser = ner_log_parser() assertion_parser = assertion_log_parser() Example for NER loss_plot method: ner_parser.loss_plot(&#39;NER_training_log_file.log&#39;) Result: Example for NER evaluate method: metrics = ner_parser.evaluate(preds_df[&#39;ground_truth&#39;].values, preds_df[&#39;prediction&#39;].values) Result: Example for Assertion get_best_f1_scores method: assertion_parser.get_best_f1_scores(&#39;Assertion_training_log_file.log&#39;, [&#39;Absent&#39;, &#39;Present&#39;]) Result: Obfuscation of Age Entities by Age Groups in Deidentification We have a new setAgeRanges() parameter in Deidentification annotator that provides the ability to set a custom range for obfuscation of AGE entities by another age within that age group (range). Default age groups list is [1, 4, 12, 20, 40, 60] and users can set any range. Infant = 0-1 year. Toddler = 2-4 yrs. Child = 5-12 yrs. Teen = 13-19 yrs. Adult = 20-39 yrs. Middle Age Adult = 40-59 yrs. Senior Adult = 60+ Example: deidentification = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;age_chunk&quot;]) .setOutputCol(&quot;obfuscation&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setObfuscateRefSource(&quot;faker&quot;) .setAgeRanges([1, 4, 12, 20, 40, 60, 80]) Result: +--++--+ |text |age_chunk|obfuscation | +--++--+ |1 year old baby |1 |2 year old baby | |4 year old kids |4 |6 year old kids | |A 15 year old female with |15 |A 12 year old female with | |Record date: 2093-01-13, Age: 25|25 |Record date: 2093-03-01, Age: 30| |Patient is 45 years-old |45 |Patient is 44 years-old | |He is 65 years-old male |65 |He is 75 years-old male | +--++--+ Controlling the behaviour of unnormalized dates while shifting the days in Deidentification (setUnnormalizedDateMode parameter) Two alternatives can be used when deidentification in unnormalized date formats, these are mask and obfuscation. setUnnormalizedDateMode(&#39;mask&#39;) parameter is used to mask the DATE entities that can not be normalized. setUnnormalizedDateMode(&#39;obfuscate&#39;) parameter is used to obfuscate the DATE entities that can not be normalized. Example: de_identification = DeIdentification() .setInputCols([&quot;ner_chunk&quot;, &quot;token&quot;, &quot;document2&quot;]) .setOutputCol(&quot;deid_text&quot;) .setMode(&quot;obfuscate&quot;) ... .setUnnormalizedDateMode(&quot;mask&quot;) # or obfuscation Result: +--++++ |text |dateshift| mask | obfuscation| +--++++ |04/19/2018 |-5 | 04/14/2018 | 04/14/2018 | |04-19-2018 |-2 | 04-17-2018 | 04-17-2018 | |19 Apr 2018|10 | &lt;DATE&gt; | 10-10-1975 | |04-19-18 |20 | &lt;DATE&gt; | 03-23-2001 | +--++++ Setting Default Day, Months or Years for Partial Dates via DateNormalizer We have 3 new parameters to make DateNormalizer more flexible with date replacing. If any of the day, month and year information is missing in the date format, the following default values will be added. setDefaultReplacementDay: default value is 15 setDefaultReplacementMonth: default value is July or 6 setDefaultReplacementYear: default value is 2020 Example: date_normalizer_us = DateNormalizer() .setInputCols(&#39;date_chunk&#39;) .setOutputCol(&#39;normalized_date_us&#39;) .setOutputDateformat(&#39;us&#39;) .setDefaultReplacementDay(&quot;15&quot;) .setDefaultReplacementMonth(&quot;6&quot;) .setDefaultReplacementYear(&quot;2020&quot;) Result: ++++ |text |date_chunk |normalized_date_us| ++++ |08/02/2018 |08/02/2018 |08/02/2018 | |3 April 2020|3 April 2020|04/03/2020 | |03/2021 |03/2021 |03/15/2021 | |05 Jan |05 Jan |01/05/2020 | |01/05 |01/05 |01/05/2020 | |2022 |2022 |06/15/2022 | ++++ You can check Date Normalizer notebook for more examples Setting Label Case Sensitivity in AssertionFilterer We have case sensitive filtering flexibility for labels by setting new setCaseSensitive(True) in AssertionFilterer annotator. Example: assertion_filterer = AssertionFilterer() .setInputCols(&quot;sentence&quot;,&quot;ner_chunk&quot;,&quot;assertion&quot;) .setOutputCol(&quot;assertion_filtered&quot;) .setCaseSensitive(False) .setWhiteList([&quot;ABsent&quot;]) sample_text = &quot;The patient was admitted 2 weeks ago with a headache. No alopecia was noted.&quot; Result: | chunks | entities | assertion | confidence | | -- | - | | - | | Alopecia | Disease_Syndrome_Disorder | Absent | 1 | getClasses Method to Zero Shot NER and Zero Shot Relation Extraction Models The predicted entities of ZeroShotNerModel and ZeroShotRelationExtractionModels can be extracted with getClasses methods just like NER annotators. Example: zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setEntityDefinitions({ &quot;PROBLEM&quot;: [&quot;What is the disease?&quot;, &quot;What is the problem?&quot; ,&quot;What does a patient suffer&quot;], &quot;DRUG&quot;: [&quot;Which drug?&quot;, &quot;Which is the drug?&quot;, &quot;What is the drug?&quot;], &quot;ADMISSION_DATE&quot;: [&quot;When did patient admitted to a clinic?&quot;], &quot;PATIENT_AGE&quot;: [&quot;How old is the patient?&quot;,&#39;What is the gae of the patient?&#39;] }) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;zero_shot_ner&quot;) zero_shot_ner.getClasses() Result: [&#39;DRUG&#39;, &#39;PATIENT_AGE&#39;, &#39;ADMISSION_DATE&#39;, &#39;PROBLEM&#39;] Setting Max Syntactic Distance Flexibility In RelationExtractionApproach Now we are able to set maximal syntactic distance as threshold in RelationExtractionApproach while training relation extraction models. reApproach = RelationExtractionApproach() .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;train_ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setLabelColumn(&quot;rel&quot;) ... .setMaxSyntacticDistance(10) Generic Relation Extraction Model (generic_re) to extract relations between any named entities using syntactic distances We already have more than 80 relation extraction (RE) models that can extract relations between certain named entities. Nevertheless, there are some rare entities or cases that you may not find the right RE or the one you find may not work as expected due to nature of your dataset. In order to ease this burden, we are releasing a generic RE model (generic_re) that can be used between any named entities using the syntactic distances, POS tags and dependency tree between the entities. You can tune this model by using the setMaxSyntacticDistance param. Example: reModel = RelationExtractionModel() .pretrained(&quot;generic_re&quot;) .setInputCols([&quot;embeddings&quot;, &quot;pos_tags&quot;, &quot;ner_chunks&quot;, &quot;dependencies&quot;]) .setOutputCol(&quot;relations&quot;) .setRelationPairs([&quot;Biomarker-Biomarker_Result&quot;, &quot;Biomarker_Result-Biomarker&quot;, &quot;Oncogene-Biomarker_Result&quot;, &quot;Biomarker_Result-Oncogene&quot;, &quot;Pathology_Test-Pathology_Result&quot;, &quot;Pathology_Result-Pathology_Test&quot;]) .setMaxSyntacticDistance(4) text = &quot;&quot;&quot;Pathology showed tumor cells, which were positive for estrogen and progesterone receptors.&quot;&quot;&quot; Result: |sentence |entity1_begin |entity1_end | chunk1 | entity1 |entity2_begin |entity2_end | chunk2 | entity2 | relation |confidence| |--:|-:|--:|:-|:--|-:|--:|:--|:--|:--|-| | 0 | 1 | 9 | Pathology | Pathology_Test | 18 | 28 | tumor cells | Pathology_Result | Pathology_Test-Pathology_Result | 1| | 0 | 42 | 49 | positive | Biomarker_Result | 55 | 62 | estrogen | Biomarker | Biomarker_Result-Biomarker | 1| | 0 | 42 | 49 | positive | Biomarker_Result | 68 | 89 | progesterone receptors | Biomarker | Biomarker_Result-Biomarker | 1| Core improvements and bug fixes Fixed obfuscated addresses capitalized word style Added more patterns for Date Obfuscation Improve speed of get_conll_data() method in alab module Fixed serialization Issue with MLFlow ContextualParser Renamed TFGraphBuilder.setIsMedical to TFGraphBuilder.setIsLicensed New and Updated Notebooks Updated ZeroShot Clinical NER Notebook with getClasses method for zero shot NER models. Updated Clinical Assertion Notebook with AssertionChunkConverter, AssertionFilterer and TFGraphBuilder.setIsLicensed examples. Updated Clinical Entity Resolvers Notebook with AssertionFilterer example. Updated Clinical DeIdentification Notebook with setUnnormalizedDateMode and NameChunkObfuscatorApproach example. Updated ZeroShot Clinical Relation Extraction Notebook with getClasses and setMaxSyntacticDistance method for Relation Extraction models. Updated Date Normalizer notebook with DateNormalizer for dynamic date replace values. Updated Chunk Mapping notebook with fuzzy matching flexibility examples. New and Updated Demos MEDICAL QUESTION ANSWERING SMOKING STATUS MENTAL HEALTH DEPRESSION 5 New Clinical Models and Pipelines Added &amp; Updated in Total drug_category_mapper ner_sdoh_mentions bert_sequence_classifier_sdoh_community_absent_status bert_sequence_classifier_sdoh_community_present_status bert_sequence_classifier_sdoh_environment_status For all Spark NLP for healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_4",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_4"
  },
  "1457": {
    "id": "1457",
    "title": "Spark NLP for Healthcare Release Notes 4.2.8",
    "content": "4.2.8 Highlights 4 new clinical named entity recognition models (3 oncology, 1 others) 5 new Social Determenant of Health text classification models New DocumentMLClassifierApproach annotator for training text classification models using SVM and Logistic Regression using TfIdf New Resolution2Chunk annotator to map entity resolver outputs (terminology codes) to other clinical terminologies New DocMapperModel annotator allows to use any mapper model in DOCUMENT type Option to return Deidentification output as a single document Inter-Annotator Agreement (IAA) metrics module that works with NLP Lab seamlessly Assertion dataset preparation module now supports chunk start and end indices, rather than token indices Added ner_source in the ChunkConverter metadata Core improvements and bug fixes Added chunk confidence score in the RelationExtractionModel metadata Added confidence score in the DocumentLogRegClassifierApproach metadata Fixed non-deterministic Relation Extraction DL Models (30+ models updated in the model hub) Fixed incompatible PretrainedPipelines with PySpark v3.2.x and v3.3.x Fixed ZIP label issue on faker mode with setZipCodeTag parameter in Deidentification Fixed obfuscated numbers have the same number of chars as the original ones Fixed name obfuscation hashes in Deidentification for romanian language Fixed LightPipeline validation parameter for internal annotators LightPipeline support for GenericClassifier (FeatureAssembler) New and updated notebooks New Clinical Text Classification with Spark_NLP Notebook New Clinical Text Classification with DocumentMLClassifier Notebook Updated ALAB Notebook New and updated demos SOCIAL DETERMINANT demo 9 new clinical models and pipelines added &amp; updated in total 4 New Clinical Named Entity Recognition Models (3 Oncology, 1 Others) We are releasing 3 new oncological NER models that were trained by using embeddings_healthcare_100d embeddings model. model name description predicted entities ner_oncology_anatomy_general_healthcare Extracts anatomical entities using an unspecific label Anatomical_Site Direction ner_oncology_biomarker_healthcare Extracts mentions of biomarkers and biomarker results in oncological texts. Biomarker_Result Biomarker ner_oncology_unspecific_posology_healthcare Extracts mentions of treatments and posology information using unspecific labels (low granularity). Posology_Information Cancer_Therapy Example: ... word_embeddings = WordEmbeddingsModel() .pretrained(&quot;embeddings_healthcare_100d&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel .pretrained(&quot;ner_oncology_anatomy_general_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;The patient presented a mass in her left breast, and a possible metastasis in her lungs and in her liver.&quot; Result: ++-+ |chunk |ner_label | ++-+ |left |Direction | |breast |Anatomical_Site | |lungs |Anatomical_Site | |liver |Anatomical_Site | ++-+ We are releasing new oncological NER models that used for model training is provided by European Clinical Case Corpus (E3C), a project aimed at offering a freely available multilingual corpus of semantically annotated clinical narratives. Example: ... ner = MedicalNerModel.pretrained(&#39;ner_eu_clinical_case&#39;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) text = &quot;&quot;&quot;A 3-year-old boy with autistic disorder on hospital of pediatric ward A at university hospital. He has no family history of illness or autistic spectrum disorder.&quot;&quot;&quot; Result: +++ |chunk |ner_label | +++ |A 3-year-old boy |patient | |autistic disorder |clinical_condition| |He |patient | |illness |clinical_event | |autistic spectrum disorder |clinical_condition| +++ 5 New Social Determinant of Health Text Classification Models We are releasing 5 new models that can be used in Social Determinant of Health related classification tasks. model name description predicted entities genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli This model is intended for detecting alcohol use in clinical notes and trained by using GenericClassifierApproach annotator. Present Past Never None genericclassifier_sdoh_alcohol_usage_binary_sbiobert_cased_mli This model is intended for detecting alcohol use in clinical notes and trained by using GenericClassifierApproach annotator. Present Never None genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli This model is intended for detecting tobacco use in clinical notes and trained by using GenericClassifierApproach annotator Present Past Never None genericclassifier_sdoh_economics_binary_sbiobert_cased_mli This model classifies related to social economics status in the clinical documents and trained by using GenericClassifierApproach annotator. True False genericclassifier_sdoh_substance_usage_binary_sbiobert_cased_mli This model is intended for detecting substance use in clinical notes and trained by using GenericClassifierApproach annotator. Present None Example: ... features_asm = FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;features&quot;) generic_classifier_tobacco = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class_tobacco&quot;) generic_classifier_alcohol = GenericClassifierModel.pretrained(&quot;genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli&quot;, &#39;en&#39;, &#39;clinical/models&#39;) .setInputCols([&quot;features&quot;]) .setOutputCol(&quot;class_alcohol&quot;) text = [&quot;Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. He uses alcohol and cigarettes&quot;, &quot;The patient quit smoking approximately two years ago with an approximately a 40 pack year history, mostly cigar use.&quot;, &quot;The patient denies any history of smoking or alcohol abuse. She lives with her one daughter.&quot;, &quot;She was previously employed as a hairdresser, though says she hasnt worked in 4 years. Not reported by patient, but there is apparently a history of alochol abuse.&quot; ] Result: +-+++ | text| tobacco| alcohol| +-+++ |Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 2...|[Present]|[Present]| |The patient quit smoking approximately two years ago with an approximately a 40 pack year history...| [Past]| [None]| | The patient denies any history of smoking or alcohol abuse. She lives with her one daughter.| [Never]| [Never]| |She was previously employed as a hairdresser, though says she hasnt worked in 4 years. Not report...| [None]| [Past]| +-+++ New DocumentMLClassifierApproach Annotator For Training Text Classification Models Using SVM And Logistic Regression Using TfIdf We have a new DocumentMLClassifierApproach that can be used for training text classification models with Logistic Regression and SVM algorithms. Training data requires “text” and their “label” columns only and the trained model will be a DocumentMLClassifierModel(). Input types: TOKEN Output type: CATEGORY Parameters Description labels array to output the label in the original form. labelCol column with the value result we are trying to predict. maxIter maximum number of iterations. tol convergence tolerance after each iteration. fitIntercept whether to fit an intercept term, default is true. maxTokenNgram the max number of tokens for Ngrams minTokenNgram the min number of tokens for Ngrams vectorizationModelPath specify the vectorization model if it has been already trained. classificationModelPath specify the classification model if it has been already trained. classificationModelClass specify the SparkML classification class; possible values are logreg, svm Example: ... classifier_svm= DocumentMLClassifierApproach() .setInputCols(&quot;token&quot;) .setLabelCol(&quot;category&quot;) .setOutputCol(&quot;prediction&quot;) .setMaxTokenNgram(1) .setClassificationModelClass(&quot;svm&quot;) #or &quot;logreg&quot; model_svm = Pipeline(stages=[document, token, classifier_svm]).fit(trainingData) text = [ [&quot;This 1-year-old child had a gastrostomy placed due to feeding difficulties.&quot;], [&quot;He is a pleasant young man who has a diagnosis of bulbar cerebral palsy and hypotonia.&quot;], [&quot;The patient is a 45-year-old female whose symptoms are pain in the left shoulder and some neck pain.&quot;], [&quot;The patient is a 61-year-old female with history of recurrent uroseptic stones.&quot;] ] Result: +-+-+ |text |prediction | +-+-+ |He is a pleasant young man who has a diagnosis of bulbar cerebral palsy and hypotonia. |Neurology | |This 1-year-old child had a gastrostomy placed due to feeding difficulties. |Gastroenterology| |The patient is a 61-year-old female with history of recurrent uroseptic stones. |Urology | |The patient is a 45-year-old female whose symptoms are pain in the left shoulder and some neck pain.|Orthopedic | +-+-+ Option To Return Deidentification Output As a Single Document We can return Deidentification() output as a single document by setting new setOutputAsDocument as True. If it is False, the outputs will be list of sentences as it is used to be. Example: deid_obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk_subentity&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setObfuscateDate(True) .setObfuscateRefFile(&#39;obfuscate.txt&#39;) .setObfuscateRefSource(&quot;file&quot;) .setUnnormalizedDateMode(&quot;obfuscate&quot;) .setOutputAsDocument(True) # or False for sentence level result text =&#39;&#39;&#39; Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR # 7194334 Date : 01/13/93 . Patient : Oliveira, 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street &#39;&#39;&#39; Result of .setOutputAsDocument(True): &#39;obfuscated&#39;: [&#39;Record date : 2093-01-14 , Beer-Karge , M.D . , Name : Hasan Jacobi Jäckel MR # &lt;MEDICALRECORD&gt; Date : 01-31-1991 . Patient : Herr Anselm Trüb, 51 years-old , Record date : 2080-01-08 . Klinik St. Hedwig . &lt;MEDICALRECORD&gt; Keats Street&#39;] Result of .setOutputAsDocument(False): &#39;obfuscated&#39;: [&#39;Record date : 2093-02-19 , Kaul , M.D . , Name : Frauke Oestrovsky MR # &lt;MEDICALRECORD&gt; Date : 05-08-1971 .&#39;, &#39;Patient : Lars Bloch, 33 years-old , Record date : 2079-11-11 .&#39;, &#39;University Hospital of Düsseldorf . &lt;MEDICALRECORD&gt; Keats Street&#39;] New Resolution2Chunk Annotator To Map Entity Resolver Outputs (terminology codes) To Other Clinical Terminologies We have a new Resolution2Chunk annotator that maps the entity resolver outputs to other clinical terminologies. Example: icd_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_icd10cm_augmented_billable_hcc&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;icd10cm_code&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver2chunk = Resolution2Chunk() .setInputCols([&quot;icd10cm_code&quot;]) .setOutputCol(&quot;resolver2chunk&quot;) chunkerMapper = ChunkMapperModel.pretrained(&quot;icd10cm_snomed_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;resolver2chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;snomed_code&quot;]) sample_text = &quot;&quot;&quot;Diabetes Mellitus&quot;&quot;&quot; Result: +--+--++--+ |text |ner_chunk |icd10cm_code|snomed_code| +--+--++--+ |Diabetes Mellitus|Diabetes Mellitus|E109 |170756003 | +--+--++--+ New DocMapperModel Annotator Allows To Use With Any Mapper Model In DOCUMENT Type Any ChunkMapperModel can be used with this new annotator called DocMapperModel and as its name suggests, it is used to map short strings via DocumentAssembler without using any other annotator between to convert strings to Chunk type that ChunkMapperModel expects. Example: documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) model = DocMapperModel.pretrained(&quot;drug_brandname_ndc_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;mappings&quot;) sample_text = &quot;ZYVOX&quot; Result: | Brand_Name | Strenth_NDC | |:-|:-| | ZYVOX | 600 mg/300mL | 0009-4992 | Inter-Annotator Agreement (IAA) metrics module that works with NLP Lab seamlessly We added a new get_IAA_metrics() method to ALAB module. This method allows you to compare and evaluate the annotations in the seed corpus that all annotators annotated the same documents at the begining of an annotation project. It returns all the results in CSV files. Here are the parameters; spark : SparkSession. conll_dir (str): path to the folder that conll files in. annotator_names (list): list of annotator names. set_ref_annotator (str): reference annotator name. If present, all comparisons made with respect to it, if it is None all annotators will be compared by each other. Default is None. return_NerDLMetrics (boolean): If True, we get the full_chunk and - partial_chunk_per_token IAA metrics by using NerDLMetrics. If False, we get the chunk based metrics using evaluate method of training_log_parser module and the token based metrics using classification reports, then write the results in “eval_metric_files” folder. Default is False. save_dir (str): path to save the token based results dataframes, default is “results_token_based”. For more details and examples, please check ALAB Notebook. Example: alab.get_IAA_metrics(spark, conll_dir = path_to_conll_folder, annotator_names = [&quot;annotator_1&quot;,&quot;annotator_2&quot;,&quot;annotator_3&quot;,&quot;annotator_4&quot;], set_ref_annotator = &quot;annotator_1&quot;, return_NerDLMetrics = False, save_dir = &quot;./token_based_results&quot;) Assertion dataset preparation module now supports chunk start and end indices, rather than token indices. Here are the new features in get_assertion_data(); Now it returns the char_begin and char_end indices of the chunks. These columns can be used in AssertionDLApproach() annotator instead of token_begin and token_end columns for training an Assertion Status Detection model. Added included_task_ids parameter that allows you to prepare the assertion model training dataframe with only the included tasks. Default is None. Added seed parameter that allows you to get the same training dataframe at each time when you set unannotated_label_strategy. Default is None. For more details and examples, please check ALAB Notebook. Added ner_source in the ChunkConverter Metadata We added ner_source in the metadata of ChunkConverter output. In this way, the sources of the chunks can be seen if there are multiple components that have the same NER label in the same pipeline. Example: ... age_contextual_parser = ContextualParserApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;age_cp&quot;) .setJsonPath(&quot;age.json&quot;) .setCaseSensitive(False) .setPrefixAndSuffixMatch(False) chunks_age = ChunkConverter() .setInputCols(&quot;age_cp&quot;) .setOutputCol(&quot;age_chunk&quot;) ... sample_text = &quot;&quot;&quot;The patient is a 28 years old female with a history of gestational diabetes mellitus was diagnosed in April 2002 in County Baptist Hospital .&quot;&quot;&quot; Result: [Annotation(chunk, 17, 18, 28, {&#39;tokenIndex&#39;: &#39;4&#39;, &#39;entity&#39;: &#39;Age&#39;, &#39;field&#39;: &#39;Age&#39;, &#39;ner_source&#39;: &#39;age_chunk&#39;, &#39;chunk&#39;: &#39;0&#39;, &#39;normalized&#39;: &#39;&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;confidenceValue&#39;: &#39;0.74&#39;})] Core Improvements and Bug Fixes Added chunk confidence score in the RelationExtractionModel metadata Added confidence score in the DocumentLogRegClassifierApproach metadata Fixed non-deterministic Relation Extraction DL Models (30+ models updated in the model hub) Fixed incompatible PretrainedPipelines with PySpark v3.2.x and v3.3.x Fixed ZIP label issue on faker mode with setZipCodeTag parameter in Deidentification Fixed obfuscated numbers have the same number of chars as the original ones Fixed name obfuscation hashes in Deidentification for romanian language Fixed LightPipeline validation parameter for internal annotators LightPipeline support for GenericClassifier (FeatureAssembler) New and Updated Notebooks New Clinical Text Classification with Spark_NLP Notebook show how can use medical text with ClassifierDL, MultiClassifierDL, GenericClassifier, and DocumentLogRegClassifier New Clinical Text Classification with DocumentMLClassifier Notebook show how can use medical text with DocumentMLClassifier Updated ALAB Notebook with the changes in get_assertion_data() and the new get_IAA_metrics() method. New and Updated Demos SOCIAL DETERMINANT demo 9 New Clinical Models and Pipelines Added &amp; Updated in Total ner_oncology_anatomy_general_healthcare ner_oncology_biomarker_healthcare ner_oncology_unspecific_posology_healthcare ner_eu_clinical_case genericclassifier_sdoh_economics_binary_sbiobert_cased_mli genericclassifier_sdoh_substance_usage_binary_sbiobert_cased_mli genericclassifier_sdoh_tobacco_usage_sbiobert_cased_mli genericclassifier_sdoh_alcohol_usage_sbiobert_cased_mli genericclassifier_sdoh_alcohol_usage_binary_sbiobert_cased_mli For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_8",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_2_8"
  },
  "1458": {
    "id": "1458",
    "title": "Visual NLP(Spark OCR) release notes 4.3.0",
    "content": "4.3.0 Release date: 2023-01-13 We are glad to announce that Spark OCR 4.3.0 has been released!! This big release comes with improvements in Dicom Processing, Visual Question Answering, new Table Extraction annotators, and much more!. New Features PositionFinder now works in LightPipelines. New annotator HocrToTextTable to work together with PdfToHocr that allows table extraction from digital PDFs. This allows to extract tables using a mixed pipeline in which tables are detected using visual features, but the text is pulled directly from the digital layer of the PDF yielding near to perfect results, and removing OCR overhead. New Dicom Processing improvements, Added support of Dicom documents to BinaryFile Datasource: this allows to write Dicom documents from Spark Dataframes to all data storages supported by Spark, in batch and streaming mode. Added possibility to specify name of the files in BinaryFile Datasource: now we can store images, PDFs, Dicom files directly using Spark capabilities with names of our choice, overcoming the limitation imposed by Spark of naming files according to partitions. Added DicomToMetadata Transformer: it allows to extract metadata from the Dicom documents. This allows to analyze Dicom metadata using Spark capabilities. For example, collect statistic about color schema, number of frames, compression of the images. This is useful for estimating needed resources and time before starting to process a big dataset. Added DicomToImageV3 based on Pydicom with better support of different color schemas. Added support YBR_FULL_422, YBR_FULL images. Also fixed handling pixel data with different pixel size for RGB and Monochrome images. Added support for compression after update pixel data in DicomDrawRegions. This reduces size of output Dicom files by applying JPEGBaseline8Bit compression to the pixel data. Added support for different color schemas in DicomDrawRegions. Added support YBR_FULL_422, YBR_FULL images. Added support for coordinates with rotated bounding box in DicomDrawRegions for compatibility with ImageTextDetectorV2. Fixed ImageTextDetectorV2 for images without text. New Donut based VisualQuestionAnswering annotator. Supports two modes of operation: it can receive an array of questions in the same row as the input image; in this way, each input image can be queried by an arbitrary set of user-defined questions, and also questions can be defined globally outside the Dataframe. This will cause that all images will be queried by the same set of questions. Running time is about a half the time per question when compared to the open-source version. Optimized model is smaller(about a half) of the original open-source version, making it easier to download and distribute in a cluster. Two models available: docvqa_donut_base and docvqa_donut_base_opt(quantized). LightPipelines support. Bug Fixes Empty tables now handled properly in ImageCellsToTextTable. Pretrained models for VisualDocumentNerV21 are now accessible. New/updated Notebooks SparkOcrVisualQuestionAnswering.ipynb, this notebook shows examples on how to use Donut based visual question answering in Spark-OCR. SparkOCRPdfToTable.ipynb, this notebook shows how PdfToHocr and HocrToTextTable can be put together to do table extraction without OCR, by just relying on the digital layer of text in the PDF. Still, existent well tested table detection models, continue to be used for finding the tables. SparkOcrImageTableRecognitionWHOCR.ipynb, this notebook shows table detection, and the HocrToTextTable in action. Compared to previous implementations, now the OCR method is external, and it can be replaced by different implementations(even handwritten!). This release is compatible with Spark NLP for Healthcare 4.2.4, and Spark NLP 4.2.4. Previous versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_0",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_0"
  },
  "1459": {
    "id": "1459",
    "title": "Spark NLP for Healthcare Release Notes 4.3.0",
    "content": "4.3.0 Highlights 12 new clinical models and pipelines added &amp; updated (8 new clinical named entity recognition models including 4 social determinants of health models) New Chunk Mapper model for mapping RxNorm codes to drug brand names New text classification annotators (architectures) for training text classification models using SVM and Logistic Regression with sentence embeddings One-liner clinical deidentification module Certification_Training notebooks (written in johnsnowlabs library) moved to parent workshop folder Different validation split per epoch in MedicalNerApproach Core improvements and bug fixes New read_conll method for reading conll files as Conll.readDataset does but it returns pandas dataframe with document(task) ids. Updated documentation Allow using FeatureAssembler in pretrained pipelines. Fixed RelationExtractionModel running in LightPipeline Fixed get_conll_data method issue New and updated notebooks New Clinical Deidentification Utility Module Notebook. Updated Clinical_Named_Entity_Recognition_Model with Conll.readDataset examples. Updated Clinical Text Classification with Spark NLP with new GenericLogRegClassifierApproach and GenericSVMClassifierApproach examples. New and updated demos SOCIAL DETERMINANT NER demo SOCIAL DETERMINANT CLASSIFICATION demo SOCIAL DETERMINANT GENERIC CLASSIFICATION demo 13 new clinical models and pipelines added &amp; updated in total 12 New Clinical Models And Pipelines Added &amp; Updated (8 New Clinical Named Entity Recognition Models Including 4 Social Determinants of Health Models) We are releasing 4 new SDOH NER models that were trained by using embeddings_clinical embeddings model. model name description predicted entities ner_sdoh_wip Extracts terminology related to Social Determinants of Health from various kinds of biomedical documents. Other_SDoH_Keywords Education Population_Group Quality_Of_Life Housing Substance_Frequency Smoking Eating_Disorder Obesity Healthcare_Institution Financial_Status Age Chidhood_Event Exercise Communicable_Disease Hypertension Other_Disease Violence_Or_Abuse Spiritual_Beliefs Employment Social_Exclusion Access_To_Care Marital_Status Diet Social_Support Disability Mental_Health Alcohol Insurance_Status Substance_Quantity Hyperlipidemia Family_Member Legal_Issues Race_Ethnicity Gender Geographic_Entity Sexual_Orientation Transportation Sexual_Activity Language Substance_Use ner_sdoh_social_environment_wip Extracts social environment terminologies related to Social Determinants of Health from various kinds of biomedical documents. Social_Support Chidhood_Event Social_Exclusion Violence_Abuse_Legal ner_sdoh_demographics_wip Extracts demographic information related to Social Determinants of Health from various kinds of biomedical documents. Family_Member Age Gender Geographic_Entity Race_Ethnicity Language Spiritual_Beliefs ner_sdoh_income_social_status_wip Extracts income and social status information related to Social Determinants of Health from various kinds of biomedical documents. Education Marital_Status Financial_Status Population_Group Employment Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts =&quot;Smith is a 55 years old, divorced Mexcian American woman with financial problems. She speaks spanish. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. She has a son student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reprots having her catholic faith as a means of support as well. She has long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI back in April and was due to be in court this week.&quot; Result: ++--++-+ |chunk |begin|end|ner_label | ++--++-+ |55 years old |11 |22 |Age | |divorced |25 |32 |Marital_Status | |Mexcian American |34 |49 |Race_Ethnicity | |financial problems|62 |79 |Financial_Status | |spanish |93 |99 |Language | |apartment |118 |126|Housing | |diabetes |158 |165|Other_Disease | |cleaning assistant|307 |324|Employment | |health insurance |354 |369|Insurance_Status | |son |401 |403|Family_Member | |student |405 |411|Education | |college |416 |422|Education | |depression |454 |463|Mental_Health | |rehab |489 |493|Access_To_Care | |catholic faith |518 |531|Spiritual_Beliefs | |support |547 |553|Social_Support | |etoh abuse |589 |598|Alcohol | |teens |618 |622|Age | |drinker |658 |664|Alcohol | |drinking beer |694 |706|Alcohol | |daily |708 |712|Substance_Frequency| |smokes |719 |724|Smoking | |a pack |726 |731|Substance_Quantity | |cigarettes |736 |745|Smoking | |a day |747 |751|Substance_Frequency| |DUI |762 |764|Legal_Issues | ++--++-+ We are releasing 8 new NER models which are trained by European Clinical Case Corpus (E3C), a project aimed at offering a freely available multilingual corpus of semantically annotated clinical narratives. ner_eu_clinical_case: This model extracts 6 different clinical entities based on medical taxonomies. ner_eu_clinical_condition: This model extracts one entity – clinical / medical conditions. model name lang predicted entities ner_eu_clinical_case es clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_case fr clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_case eu clinical_condition clinical_event bodypart units_measurements patient date_time ner_eu_clinical_condition en clinical_condition ner_eu_clinical_condition es clinical_condition ner_eu_clinical_condition eu clinical_condition ner_eu_clinical_condition fr clinical_condition ner_eu_clinical_condition it clinical_condition Example: word_embeddings = WordEmbeddingsModel.pretrained(&quot;w2v_cc_300d&quot;,&quot;es&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner = MedicalNerModel.pretrained(&quot;ner_eu_clinical_case&quot;, &quot;es&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_text = &quot;&quot;&quot;Paciente de 59 años que refiere dificultad para caminar desde hace un mes aproximadamente. Presenta debilidad y dolor en los miembros inferiores, que mejora tras detenerse, acompañándose en ocasiones de lumbalgia no irradiada. En la exploración neurológica presenta habla hipofónica, facial centrado. Debido a la mala perfusión secundaria a la sepsis aparecieron lesiones necróticas en extremidades superiores y principalmente inferiores distales. Motilidad ocular interna y externa normal.&quot;&quot;&quot; Result: +++ |chunk |ner_label | +++ |Paciente de 59 años |patient | |refiere |clinical_event | |dificultad para caminar |clinical_event | |hace un mes aproximadamente|date_time | |debilidad |clinical_event | |dolor |clinical_event | |los miembros inferiores |bodypart | |mejora |clinical_event | |detenerse |clinical_event | |lumbalgia |clinical_event | |irradiada |clinical_event | |exploración |clinical_event | |habla |clinical_event | |hipofónica |clinical_event | |perfusión |clinical_event | |sepsis |clinical_event | |lesiones |clinical_event | |extremidades superiores |bodypart | |inferiores distales |bodypart | |Motilidad |clinical_event | |normal |units_measurements| +++ New Chunk Mapper Model for Mapping RxNorm Codes to Drug Brand Names We are releasing rxnorm_drug_brandname_mapper pretrained model that maps RxNorm and RxNorm Extension codes with their corresponding drug brand names. It returns 2 types of brand names called rxnorm_brandname and rxnorm_extension_brandname for the corresponding RxNorm or RxNorm Extension code. Example: ... chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;rxnorm_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;]) sample_text= [&#39;metformin&#39;, &#39;advil&#39;] Result: +--+-+--+--+ | drug_name|rxnorm_result| mapping_result| relation | +--+-+--+--+ | metformin| 6809|Actoplus Met (metformin):::Avandamet (metformin...| rxnorm_brandname| | metformin| 6809|A FORMIN (metformin):::ABERIN MAX (metformin)::...|rxnorm_extension_brandname| | advil| 153010| Advil (Advil)| rxnorm_brandname| | advil| 153010| NONE|rxnorm_extension_brandname| +--+-+--+--+ New Text Classification Annotators (Architectures) For Training Text Classification Models Using SVM and Logistic Regression With Sentence Embeddings We have a new text classification architecture called GenericLogRegClassifierApproach that implements a multinomial Logistic Regression with sentence embeddings. This is a single layer neural network with the logistic function at the output. The input to the model is FeatureVector (from any sentence embeddings) and the output is Category annotations with labels and corresponding confidence scores. Training data requires “text” and their “label” columns only and the trained model will be a GenericLogRegClassifierModel(). We have another text classification architecture called GenericSVMClassifierApproach that implements SVM (Support Vector Machine) classification. The input to the model is FeatureVector (from any sentence embeddings) and the output is Category annotations with labels and corresponding confidence scores. Taining data requires “text” and their “label” columns only and the trained model will be a GenericSVMClassifierModel(). Input types: FEATURE_VECTOR Output type: CATEGORY Example: features_asm = sparknlp_jsl.base.FeaturesAssembler() .setInputCols([&quot;sentence_embeddings&quot;]) .setOutputCol(&quot;feature_vector&quot;) gcf_graph_builder = sparknlp_jsl.annotators.TFGraphBuilder() .setModelName(&quot;logreg_classifier&quot;) .setInputCols([&quot;feature_vector&quot;]) .setLabelColumn(&quot;label&quot;) .setGraphFolder(&quot;/tmp/&quot;) .setGraphFile(&quot;log_reg_graph.pb&quot;) log_reg_approach = sparknlp_jsl.annotators.GenericLogRegClassifierApproach() .setLabelColumn(&quot;label&quot;) .setInputCols([&quot;feature_vector&quot;]) .setOutputCol(&quot;prediction&quot;) .setModelFile(f&quot;/tmp/log_reg_graph.pb&quot;) .setEpochsNumber(10) .setBatchSize(1) .setLearningRate(0.001) One-Liner Clinical Deidentification Module Spark NLP for Healthcare provides functionality to apply Deidentification using one-liner module called Deid. The Deid module is a tool for deidentifying Protected Health Information (PHI) from data in a file path. It can be used with or without ant Spark NLP NER pipelines. It can apply deidentification and obfuscation on different columns at the same time. It returns the deidentification &amp; obfuscation results as a spark dataframe as well as a csv or json file saved locally. The module also includes functionality for applying Structured Deidentification task to data from a file path. The function, deidentify(), can be used with a custom pipeline or without defining any custom pipeline. structured_deidentifier() function can be used for the Structured Deidentification task. Please see this notebook for the detailed usage and explanation of all parameters. Check here for the documentation of the module. Deidentification with a custom pipeline Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A custom pipeline model to be used for deidentification. If not specified, the default is None. custom_pipeline=nlpModel, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text_column_1&quot;: &quot;text_column_1_deidentified&quot;, &quot;text_column_2&quot;: &quot;text_column_2_deidentified&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;fixed_length_chars&quot;, #optional: The fixed mask length. Default is 4. fixed_mask_length=4) Result: ++-+-+-+-+ | ID| text_column_1| text_column_1_deidentified| text_column_2| text_column_2_deidentified| ++-+-+-+-+ | 0|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : ** , ** , M.D . , Name : ** MR .|Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-...|Date : 10-16-1991 PCP : Alveda Castles , 26 years-old , Record date...| ++-+-+-+-+ Deidentification with no custom pipeline Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;entity_labels&quot;) Result: ++-+-+ | ID| text_original| text_deid| ++-+-+ | 0| &quot;| &quot;| | 1|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : &lt;DATE&gt; , &lt;DOCTOR&gt; , M.D . , Name : &lt;PATIENT&gt; , MR # &lt;...| | 2| &quot;| &quot;| ++-+-+ Structured Deidentification Example: from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.structured_deidentifier( #required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A dictionary that contains the column names and the tags that should be used for deidentification. Default is {&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;} columns_dict= {&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, #optional: The seed value for the random number generator. Default is {&quot;NAME&quot;: 23, &quot;AGE&quot;: 23} columns_seed= {&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, #optional: The source of the reference file. Default is faker. ref_source=&quot;faker&quot;, #optional: The number of days to be shifted. Default is None shift_days=5) Result: +-++--++-+ | NAME| DOB| ADDRESS|SBP| TEL| +-++--++-+ |[N2649912]|[18/02/1977]| 711 Nulla St.|140| 673 431234| | [W466004]|[28/02/1977]| 1 Green Avenue.|140|+23 (673) 431234| | [M403810]|[16/04/1900]|Calle del Liberta...|100| 912 345623| +-++--++-+ Different Validation Split Per Epoch In MedicalNerApproach The validation splits in MedicalNerApproach used to be static and same for every epoch. Now we can control with behaviour with a new parameter called setRandomValidationSplitPerEpoch(bool) and allow users to set random validation splits per epoch. Certification_Training Notebooks (Written In Johnsnowlabs Library) Moved to Parent Workshop Folder re-organize and re-locate open-source-nlp folder re-organize and re-locate healthcare-nlp folder Core Improvements and Bug Fixes New read_conll method for reading conll files as Conll.readDataset does but it returns dataframe with document(task) ids. Updated documentation Allow using FeatureAssembler in pretrained pipelines. Fixed RelationExtractionModel running in LightPipeline Fixed get_conll_data method issue New and Updated Notebooks New Clinical Deidentification Utility Module Notebook. Updated Clinical_Named_Entity_Recognition_Model with Conll.readDataset examples. Updated Clinical Text Classification with Spark NLP with new GenericLogRegClassifierApproach and GenericSVMClassifierApproach examples. New and Updated Demos SOCIAL DETERMINANT NER demo SOCIAL DETERMINANT CLASSIFICATION demo SOCIAL DETERMINANT GENERIC CLASSIFICATION demo 12 New Clinical Models and Pipelines Added &amp; Updated in Total ner_eu_clinical_case-&gt; es ner_eu_clinical_case-&gt; fr ner_eu_clinical_case-&gt; eu ner_eu_clinical_condition-&gt; en ner_eu_clinical_condition-&gt; es ner_eu_clinical_condition-&gt; fr ner_eu_clinical_condition-&gt; eu ner_eu_clinical_condition-&gt; it ner_sdoh_demographics_wip ner_sdoh_income_social_status_wip ner_sdoh_social_environment_wip ner_sdoh_wip rxnorm_drug_brandname_mapper For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_0",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_0"
  },
  "1460": {
    "id": "1460",
    "title": "Annotation Lab Release Notes 4.3.0",
    "content": "4.3.0 Release date: 25-11-2022 Annotation Lab 4.3.0 adds support for Finance and Legal NLP Libraries, Finance and Legal License Scopes, and access to pre-trained Visual NER models on the Models Hub. It also allows easy task import directly from S3 and keeps the complete history of training logs. The release also includes stabilization and fixes for several issues reported by our user community. Here are the highlights of this release: Highlights Support for Finance NLP and Legal NLP. Annotation Labs now includes a full-fledged integration with two new NLP libraries: Finance NLP and Legal NLP. Pretrained models for the Finance and Legal verticals are now available on the Models Hub page, covering tasks such as Entity Recognition, Assertion Status, and Text Classification. Searching models on Models Hub. A new filter named Edition was added to the Models Hub. It includes all supported NLP editions: Healthcare, Opensource, Legal, Finance, and Visual. It will ease search for models specific to an Edition, which can then easily be downloaded and used within Annotation Lab projects. Support for Finance and Legal Licenses. Annotation Lab now supports import of licenses with legal and/or finance scopes. It can be uploaded from the Licenses page. Similar to Healthcare and Visual licenses, they unlock access to optimized annotators, models, embeddings, and rules. Pre-annotations using Finance and Legal models. Finance and Legal models downloaded from the Models Hub can be used for pre-annotation in NER, assertion status, and classification projects. Train Finance and Legal models. Two new options: Legal and Finance libraries were added for selection when training a new NER model in Annotation Lab. The new options are only available when at least one valid license with the corresponding scope is added to the License page. Import tasks from S3. Annotation Lab now supports importing tasks/documents stored on Amazon S3. In the Import Page, a new section was added which allows users to define S3 connection details. All documents in the specified path will then be imported as tasks in the current project. Project level history of the Trained Models. It is now possible to keep track of all previous training activities executed for a project. When pressing the History button from the Train page, users are presented with a list of all trainings triggered for the current project. Easier page navigation. Users can now right-click on the available links and select “Open in new tab” to open the link in a new tab without losing the current work context. Optimized user editing UI. All the checkboxes on the Users Edit page now have the same style. The “UserAdmins” group was renamed to “Admins” and the description of groups is more detailed and easier to understand. Also, a new error message is shown when an invalid email address is used. Improved page navigation for Visual NER projects. For Visual NER projects, users can jump to a specific page in any multi-page task instead of passing through all pages to reach a target section of a PDF document. Visual configuration options for Visual NER project. Users are now able to add custom labels and choices in the project configuration from the Visual tab for Visual NER projects as well as for the text projects. Visual NER Models available on the Models Hub page. Visual NER models can now be filtered, downloaded from the NLP Models Hub, and used for pre-annotating image-based documents. Lower CPU and Memory resources allocated to the license server. In this version, the resources allocated to the license server were decreased to CPU: 1000m (1 core) and Memory: 1GB. Simplify Training and Pre-annotation configurations. Now the user only need to adjust “Memory limit” and “CPU limit” in the Infrastructure page. “Spark Drive Memory” is calculated as 85% of Memory Limit where are “Spark Kryo Buff Max” and “Spark Driver Max Result Size” are constants with values “2000 MB” and “4096 MB” respectively. Auto-close user settings. The user settings menu is closed automatically when a user clicks on any other settings options. Preserve task filters. From version 4.3.0, all defined filters in the task page remain preserved when the user navigates back and forth between the labeling page and the task page. Optimized Alert Messages. All the alert notification shows clear errors, warnings, information, and success messages. Zoom in/out features in Visual NER projects with Sticky Left Column view. In various views of Visual NER, zoom-controlling features are now available by default. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_3_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_3_0"
  },
  "1461": {
    "id": "1461",
    "title": "Visual NLP(Spark OCR) release notes 4.3.1",
    "content": "4.3.1 Release date: 17-02-2023 We’re glad to announce that Visual NLP 😎 4.3.1 has been released. Highlights ImageTextCleaner &amp; ImageTableDetector have improved memory consumption. New Annotators supported in LightPipelines. Table extraction from Digital PDFs pipeline now entirely supported as a LightPipeline. ImageTextCleaner &amp; ImageTableDetector improved memory consumption ImageTextCleaner &amp; ImageTableDetector improved memory consumption: we reduced about 30% the memory consumption for this annotator making it more memory friendly and enabling running on memory constrained environments like Colab. New Annotators supported in LightPipelines Now the following annotators are supported in LightPipelines, PdfToHocr, HocrTokenizer, ImageTableDetector, ImageScaler, HocrToTextTable, Table extraction from Digital PDFs pipeline now entirely supported as a LightPipeline. Our Table Extraction from digital PDFs pipeline now supports running as a LightPipeline, check the updated notebook: SparkOCRPdfToTable.ipynb This release is compatible with Spark NLP for Healthcare 4.3.0, and Spark NLP 4.3.0. Previous versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_1",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_1"
  },
  "1462": {
    "id": "1462",
    "title": "Spark NLP for Healthcare Release Notes 4.3.1",
    "content": "4.3.1 Highlights The first Voice of Patients (VOP) named entity recognition model New Social Determinants of Health (SDOH) named entity recognition models New entity resolution model for mapping Rxnorm codes according to the National Institute of Health (NIH) Database New Chunk Mapper models for mapping NDC codes to drug brand names as well as clinical entities (like drugs/ingredients) to Rxnorm codes Format consistency for formatted entity obfuscation in Deidentification module New parameters for controlling the validation set while training a NER model with MedicalNerApproach Whitelisting the entities while merging multiple entities in ChunkMergeApproach Core improvements and bug fixes New and updated notebooks New and updated demos 8 new clinical models and pipelines added &amp; updated in total The First Voice of Patients (VOP) Named Entity Recognition Model We are releasing a new VOP NER model that was trained on the conversations gathered from patients forums. model name description predicted entities ner_vop_slim_wip This model extracts healthcare-related terms from the documents transferred from the patient’s own sentences. AdmissionDischarge Age BodyPart ClinicalDept DateTime Disease Dosage_Strength Drug Duration Employment Form Frequency Gender Laterality Procedure PsychologicalCondition RelationshipStatus Route Symptom Test Vaccine VitalTest Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts = [&quot;Hello,I&#39;m 20 year old girl. I&#39;m diagnosed with hyperthyroid 1 month ago. I was feeling weak, poor digestion, depression, left chest pain, increased heart rate from 4 months. Also i have b12 deficiency so I&#39;m taking weekly supplement of 1000 mcg b12 daily.&quot;] Result: chunk begin end ner_label 20 year old 10 20 Age girl 22 25 Gender hyperthyroid 47 58 Disease 1 month ago 60 70 DateTime weak 87 90 Symptom depression 137 146 PsychologicalCondition left 149 152 Laterality chest 154 158 BodyPart pain 160 163 Symptom heart rate 176 185 VitalTest 4 months 215 222 Duration b12 deficiency 613 626 Disease weekly 667 672 Frequency supplement 674 683 Drug 1000 mcg 702 709 Dosage_Strength b12 711 713 Drug daily 715 719 Frequency New Social Determinants of Health (SDOH) Named Entity Recognition Models We are releasing 4 new SDOH NER models with various entity combinations. model name description predicted entities ner_sdoh_substance_usage_wip This model extracts substance usage information related to Social Determinants of Health from various kinds of biomedical documents. Smoking Substance_Duration Substance_Use Substance_Quantity Substance_Frequency Alcohol ner_sdoh_access_to_healthcare_wip This model extracts access to healthcare information related to Social Determinants of Health from various kinds of biomedical documents. Insurance_Status Healthcare_Institution Access_To_Care ner_sdoh_community_condition_wip This model extracts community condition information related to Social Determinants of Health from various kinds of biomedical documents. Transportation Community_Living_Conditions Housing Food_Insecurity ner_sdoh_health_behaviours_problems_wip This model extracts health and behaviours problems related to Social Determinants of Health from various kinds of biomedical documents. Diet Mental_Health Obesity Eating_Disorder Sexual_Activity Disability Quality_Of_Life Other_Disease Exercise Communicable_Disease Hyperlipidemia Hypertension ner_sdoh_substance_usage_wip Example: ... clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) sample_texts = [&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;, &quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;] Result: chunk begin end ner_label drink 8 12 Alcohol occasional 14 23 Substance_Frequency alcohol 25 31 Alcohol 5 to 6 47 52 Substance_Quantity alcoholic drinks 54 69 Alcohol per month 71 79 Substance_Frequency smoke 16 20 Smoking one pack 22 29 Substance_Quantity cigarettes 34 43 Smoking daily 45 49 Substance_Frequency past 28 years 70 82 Substance_Duration ner_sdoh_access_to_healthcare_wip Example: ... sample_texts = [&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;, &quot;He also reported food insecurityduring his childhood and lack of access to adequate healthcare.&quot;, &quot;She used to work as a unit clerk at XYZ Medical Center.&quot;] Result: chunk begin end ner_label private health insurance 22 45 Insurance_Status access to adequate healthcare 65 93 Access_To_Care XYZ Medical Center 36 53 Healthcare_Institution ner_sdoh_community_condition_wip Example: ... sample_texts = [&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;, &quot;Patient reports difficulty affording healthy food, and relies oncheaper, processed options.&quot;, &quot;She reports her husband and sons provide transportation top medical apptsand do her grocery shopping.&quot;] Result: chunk begin end ner_label small apartment 87 101 Housing green spaces 154 165 Community_Living_Conditions outdoor recreational activities 171 201 Community_Living_Conditions healthy food 37 48 Food_Insecurity transportation 41 54 Transportation ner_sdoh_health_behaviours_problems_wip Example: ... sample_texts = [&quot;She has not been getting regular exercise and not followed diet for approximately two years due to chronic sciatic pain.&quot;, &quot;Medical History: The patient is a 32-year-old female who presents with a history of anxiety, depression, bulimia nervosa, elevated cholesterol, and substance abuse.&quot;, &quot;Pt was intubated atthe scene &amp; currently sedated due to high BP. Also, he is currently on social security disability.&quot;] Result: chunk begin end ner_label regular exercise 25 40 Exercise diet 59 62 Diet chronic sciatic pain 99 118 Other_Disease anxiety 84 90 Mental_Health depression 93 102 Mental_Health bulimia nervosa 105 119 Eating_Disorder elevated cholesterol 122 141 Hyperlipidemia high BP 56 62 Hypertension disability 106 115 Disability New Entity Resolver Model for Mapping Rxnorm Codes According To the National Institute of Health (NIH) Database We are releasing sbiobertresolve_rxnorm_nih pretrained model to map clinical entities and concepts (like drugs/ingredients) to RxNorm codes according to the National Institute of Health (NIH) database using sbiobert_base_cased_mli Sentence Bert Embeddings. Example: ... rxnorm_resolver = SentenceEntityResolverModel.pretrained(&quot;sbiobertresolve_rxnorm_nih&quot;,&quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;sbert_embeddings&quot;]) .setOutputCol(&quot;resolution&quot;) .setDistanceFunction(&quot;EUCLIDEAN&quot;) text= &quot;She is given folic acid 1 mg daily , levothyroxine 0.1 mg and aspirin 81 mg daily .&quot; Result: | ner_chunk | entity |rxnorm_code | all_codes | resolutions | |:|:-|--:|:-|:| | folic acid 1 mg | DRUG | 12281181 | [&#39;12281181&#39;, &#39;12283696&#39;, &#39;12270292&#39;, ...| [&#39;folic acid 1 MG [folic acid 1 MG]&#39;, &#39;folic acid 1.1 MG [folic acid 1.1 MG]&#39;,...| | levothyroxine 0.1 mg | DRUG | 12275630 | [&#39;12275630&#39;, &#39;12275646&#39;, &#39;12301585&#39;, ...| [&#39;levothyroxine sodium 0.1 MG [levothyroxine sodium 0.1 MG]&#39;, &#39;levothyroxine ...| | aspirin 81 mg | DRUG | 12278696 | [&#39;12278696&#39;, &#39;12299811&#39;, &#39;12298729&#39;, ...| [&#39;aspirin 81 MG [aspirin 81 MG]&#39;, &#39;aspirin 81 MG [YSP Aspirin] [aspirin 81 MG ...| New Chunk Mapper Models For Mapping NDC Codes to Drug Brand Names As Well As Clinical Entities (like drugs/ingredients) to Rxnorm Codes We have two new chunk mapper models. ndc_drug_brandname_mapper model maps NDC codes with their corresponding drug brand names as well as RxNorm Codes according to National Institute of Health (NIH). Example: ... mapper = ChunkMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;drug_brand_name&quot;]) text= [&quot;0009-4992&quot;, &quot;57894-150&quot;] Result:   ndc_code drug_brand_name 0 0009-4992 ZYVOX 1 57894-150 ZYTIGA rxnorm_nih_mapper model maps entities with their corresponding RxNorm codes according to the National Institute of Health (NIH) database. It returns Rxnorm codes along with their NIH Rxnorm Term Types within a parenthesis. Example: ... chunkerMapper = ChunkMapperModel .pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols([&quot;ner_chunk&quot;]) .setOutputCol(&quot;mappings&quot;) .setRels([&quot;rxnorm_code&quot;]) Result: ner_chunk mappings relation Adapin 10 MG Oral Capsule 1911002 (SY) rxnorm_code acetohexamide 12250421 (IN) rxnorm_code Parlodel 829 (BN) rxnorm_code Format Consistency For Formatted Entity Obfuscation In Deidentification Module We have added a new setSameLengthFormattedEntities parameter that obfuscates the formatted entities like PHONE, FAX, ID, IDNUM, BIOID, MEDICALRECORD, ZIP, VIN, SSN, DLN, PLATE and LICENSE with the fake ones in the same format. Default is an empty list ([]). Example: obfuscated = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;deid_ner_chunk&quot;]) .setOutputCol(&quot;obfuscated&quot;) .setMode(&quot;obfuscate&quot;) .setLanguage(&#39;en&#39;) .setObfuscateDate(True) .setObfuscateRefSource(&#39;faker&#39;) .setSameLengthFormattedEntities([&quot;PHONE&quot;,&quot;MEDICALRECORD&quot;, &quot;IDNUM&quot;]) sample_text = &quot;&quot;&quot;Record date: 2003-01-13 Name : Hendrickson, Ora, Age: 25 MR: #7194334 ID: 1231511863 Phone: (302) 786-5227&quot;&quot;&quot; Result: sentence masking obfuscation Record date: 2003-01-13 Record date: &lt;DATE&gt; Record date: 2003-03-07 Name : Hendrickson, Ora, Age: 25 Name : &lt;PATIENT&gt;, Age: &lt;AGE&gt; Name : Manya Horsfall, Age: 20 MR: #7194334 MR: &lt;MEDICALRECORD&gt; MR: #4868080 ID: 1231511863 ID: &lt;IDNUM&gt; ID: 2174658035 Phone: (302) 786-5227 Phone:&lt;PHONE&gt; Phone: (467) 302-9509 New Parameters For Controlling The Validation Set While Training a NER Model With MedicalNerApproach We added a new parameter to MedicalNerApproach for controlling the validation set while training. setRandomValidationSplitPerEpoch: If it is True, the validation set is randomly splitted for each epoch; and if it is False, the split is done only once before training (the same validation split used after each epoch). Default is False. Example: nerTagger = MedicalNerApproach() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) .setLabelColumn(&quot;label&quot;) .setValidationSplit(0.2) .setRandomValidationSplitPerEpoch(True) .setRandomSeed(42) ... Whitelisting The Entities While Merging Multiple Entities In ChunkMergeApproach We have added setWhiteList parameter to ChunkMergeApproach annotator that you can whitelist detected entities while merging. Example: chunk_merge = ChunkMergeApproach() .setInputCols(&quot;deid_chunk_1&quot;, &quot;deid_chunk_2&quot;) .setOutputCol(&quot;merged_chunk&quot;) .setMergeOverlapping(True) #.setWhiteList([&quot;AGE&quot;,&quot;DATE&quot;]) sample_text = &quot;Mr. ABC is a 25 years old with a nonproductive cough that started last week. He has a history of pericarditis in May 2006 and developed cough with right-sided chest pain, and admitted to Beverley Count Hospital.&quot; Result for without WhiteList: index ner_chunk entity 0 John Smith PATIENT 1 25 AGE 2 May 2006 DATE 3 Beverley Count Hospital HOSPITAL Result for with WhiteList([&quot;AGE&quot;,&quot;DATE&quot;]): index ner_chunk entity 0 25 AGE 1 May 2006 DATE Core Improvements and Bug Fixes Fixed the bug in get_assertion_data method issue in ALAB module Updated documentation pages with corrections and additions. New and Updated Notebooks Updated Spark NLP for Healthcare Workshop in 3 hr with latest examples. New and Updated Demos SOCIAL_DETERMINANT_ALCOHOL demo SOCIAL_DETERMINANT_TOBACCO demo 8 New Clinical Models and Pipelines Added &amp; Updated in Total ner_sdoh_substance_usage_wip ner_sdoh_access_to_healthcare_wip ner_sdoh_community_condition_wip ner_sdoh_health_behaviours_problems_wip ner_vop_slim_wip sbiobertresolve_rxnorm_nih ndc_drug_brandname_mapper rxnorm_nih_mapper For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_1",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_1"
  },
  "1463": {
    "id": "1463",
    "title": "Spark NLP for Healthcare Release Notes 4.3.2",
    "content": "4.3.2 Highlights Welcoming BioGPT (Generative pre-trained transformer for biomedical text generation and mining) to Spark NLP, with a faster inference and better memory management. New MedicalQuestionAnswering annotator based on BioGPT to answer questions from PubMed abstracts Crossing 1000+ healthcare specific pretrained models &amp; pipelines in the Model hub Running obfuscation and deidentification at the same time, based on selected entities in one pass Core improvements and bug fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Added new sub-module to the ALAB module for reviewing annotations and spotting label errors easily Added ner_jsl model label definitions to the model cards More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and updated notebooks New and updated demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New blogposts 30+ new clinical models and pipelines added &amp; updated in total Welcoming BioGPT (Generative Pre-Trained Transformer For Biomedical Text Generation and Mining) to Spark NLP BioGPT is a domain-specific generative pre-trained Transformer language model for biomedical text generation and mining. BioGPT follows the Transformer language model backbone, and is pre-trained on 15M PubMed abstracts from scratch. Experiments demonstrate that BioGPT achieves better performance compared with baseline methods and other well-performing methods across all the tasks. Read more at the official paper. We ported BioGPT (BioGPT-QA-PubMedQA-BioGPT) into Spark NLP for Healthcare with better inference speed and memory optimization. New MedicalQuestionAnswering Annotator Based On BioGPT To Answer Questions From PubMed Abstracts New medical_qa_biogpt model is based on the original BioGPT-QA-PubMedQA-BioGPT model (trained with Pubmed abstracts) can generate two types of answers, short and long. The first type of question is &quot;short&quot; and is designed to elicit a simple, concise answer that is typically one of three options: yes, no, or maybe. The second type of question is &quot;long&quot; and intended to prompt a more detailed response. Unlike the short questions, which are generally answerable with a single word, long questions require a more thoughtful and comprehensive response. Overall, the distinction between short and long questions is based on the complexity of the answers they are meant to elicit. Short questions are used when a quick and simple answer is sufficient, while long questions are used when a more detailed and nuanced response is required. med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) .setOutputCol(&quot;answer&quot;) .setMaxNewTokens(30) .setTopK(1) .setQuestionType(&quot;long&quot;) # &quot;short&quot; pipeline = Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65–97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus–stimulus and stimulus–response spatial compatibility.&quot; Result for long answer: Question [&quot;What is the effect of directing attention on memory?&quot;] Answer [&quot;the results of the present study suggest that the visual indexing theory does not fully explain the effects of spatial attention on memory performance.&quot;] Result for short answer: Question [&quot;Does directing attention improve memory for items?&quot;] Answer [&quot;no&quot;] You can check the Medical Question Answering Notebook for more examples and see the Medical Question Answering demo. Crossing 1000+ Healthcare Specific Pretrained Models &amp; Pipelines In Models Hub We just crossed 1000+ healthcare specific pretrained models &amp; pipelines in the Models Hub Page! Running Obfuscation and Deidentification At The Same Time, Based On Selected Entities In One Pass The DeIdentification() annotator has been enhanced with the inclusion of multi-mode functionality. Users are required to define a dictionary that contains the policies which will be applied to the labels and save it as a JSON file. Then multi-mode functionality can be utilized in the de-identification process by providing the path of the JSON file to the setSelectiveObfuscationModes() parameter. If the entities are not provided in the JSON file, they will be deidentified according to the setMode() as default. Example JSON file : sample_deid = { &quot;obfuscate&quot;: [&quot;PHONE&quot;], &quot;mask_entity_labels&quot;: [&quot;ID&quot;], &quot;skip&quot;: [&quot;DATE&quot;], &quot;mask_same_length_chars&quot;: [&quot;NAME&quot;], &quot;mask_fixed_length_chars&quot;: [&quot;ZIP&quot;, &quot;LOCATION&quot;] } Description of possible modes to enable multi-mode deidentification: obfuscate: Replace the values with random values. mask_same_length_chars: Replace the name with the minus two same lengths asterisk, plus one bracket on both ends. mask_entity_labels: Replace the values with the entity labels. mask_fixed_length_chars: Replace the name with the asterisk with fixed length. You can also invoke setFixedMaskLength(). skip: Skip the entities (intact). Example: ... deid = DeIdentification() .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner_chunk&quot;]) .setOutputCol(&quot;deidentified&quot;) .setMode(&quot;obfuscate&quot;) .setSelectiveObfuscationModesPath(&quot;sample_deid.json&quot;) .setSameLengthFormattedEntities([&quot;PHONE&quot;]) text = &quot;Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora , M.R # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .&quot; Result: [Record date : 2093-01-13 , [********] , M.D . , Name : [*************] , M.R # &lt;ID&gt;, Date : 01/13/93 . PCP : [******] , &lt;AGE&gt; years-old , Record date : 2079-11-09 . ******* , ******* , Phone 98-496-9970 ] DATE entities were skipped: 2093-01-13 =&gt; 2093-01-13, 01/13/93=&gt; 01/13/93 PHONE entity was obfuscated with fake phone number: 55-555-5555 =&gt; 98-496-9970 ID entity was masked with ID tag: 7194334 =&gt; &lt;ID&gt; NAME entities were masked with same original lenght: David Hale = &gt; [********], Hendrickson Ora =&gt; [*************] LOCATION entities were masked with fixed lenght: Cocke County Baptist Hospital =&gt; ******* , 0295 Keats Street =&gt; ******* Core Improvements and Bug Fixes New features added to NameChunkObfuscation module More flexibility for setAgeRanges in DeIdentification Adding new sub-module to the ALAB module to review annotation and spot label errors easily Added ner_jsl model label definitions to the model card More flexibility in ocr_nlp_processor with new parameters for the OCR pipeline, please see Spark OCR Utility Module Updated 120+ clinical pipelines to make them compatible with all PySpark versions New and Updated Notebooks New Medical Question Answering Notebook for showing how medical question answering can be used with new MedicalQuestionAnswering annotator. Updated Clinical DeIdentification Notebook with latest updates. New and Updated Demos Medical Question Answering demo Social Determinants of Health Behaviour Problems demo Social Determinants of Health Access Status demo Voice of The Patients demo New Blogposts Extract Social Determinants of Health Entities From Clinical Text with Spark NLP Extract Clinical Entities From Patient Forums with Healthcare NLP Mapping Rxnorm and NDC Codes to the National Institute of Health (NIH) Drug Brand Names with Spark NLP Format Consistency For Entity Obfuscation In De-Identification with Spark NLP 30+ New Clinical Models and Pipelines Added &amp; Updated in Total biogpt_pubmed_qa 30+ new clinical ner pipelines For all Spark NLP for Healthcare models, please check: Models Hub Page Versions Version Version Version 4.3.2 4.3.1 4.3.0 4.2.8 4.2.4 4.2.3 4.2.2 4.2.1 4.2.0 4.1.0 4.0.2 4.0.0 3.5.3 3.5.2 3.5.1 3.5.0 3.4.2 3.4.1 3.4.0 3.3.4 3.3.2 3.3.1 3.3.0 3.2.3 3.2.2 3.2.1 3.2.0 3.1.3 3.1.2 3.1.1 3.1.0 3.0.3 3.0.2 3.0.1 3.0.0 2.7.6 2.7.5 2.7.4 2.7.3 2.7.2 2.7.1 2.7.0 2.6.2 2.6.0 2.5.5 2.5.3 2.5.2 2.5.0 2.4.6 2.4.5 2.4.2 2.4.1 2.4.0",
    "url": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_2",
    "relUrl": "/docs/en/spark_nlp_healthcare_versions/release_notes_4_3_2"
  },
  "1464": {
    "id": "1464",
    "title": "Spark OCR release notes",
    "content": "4.3.3 Release date: 14-03-2023 We’re glad to announce that Visual NLP 😎 4.3.3 has been released. Highlights New parameter keepOriginalEncoding in PdfToHocr. New Yolo-based table and form detector. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved. Fixes in AlabReader Fixes in HocrToTextTable. New parameter keepOriginalEncoding in PdfToHocr Now you can choose to make PdfToHocr return an ASCII normalized version of the characters present in the PDF(keepOriginalEncoding=False) or to return the original Unicode character(keepOriginalEncoding=True). Source PDF, Keeping the encoding, Not keeping it, New Yolo-based Table and Form detector This new model allows to distinguish between forms and tables, so you can apply different downstream processing afterwards. Check a full example of utilization in this notebook. Memory consumption in VisualQuestionAnswering and ImageTableDetector models has been improved Memory utilization has been improved to make it more GC friendly. The practical result is that big jobs are more stable, and less likely to get restarted because of exhausting resources. Fixes in AlabReader AlabReader has been improved to fix some bugs, and to improve the performance. Fixes in HocrToTextTable HocrToTextTable has been improved in order to better handle some corner cases in which the last rows of tables were being missed. This release of Visual NLP is compatible with version 4.3.1 of Spark-NLP and version 4.3.1 of Spark NLP for Healthcare. Previous versions 4.3.3 4.3.1 4.3.0 4.2.4 4.2.1 4.1.0 4.0.2 4.0.0 3.14.0 3.13.0 3.12.0 3.11.0 3.10.0 3.9.1 3.9.0 3.8.0 3.7.0 3.6.0 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 1.11.0 1.10.0 1.9.0 1.8.0 1.7.0 1.6.0 1.5.0 1.4.0 1.3.0 1.2.0 1.1.2 1.1.1 1.1.0 1.0.0",
    "url": "/docs/en/spark_ocr_versions/release_notes_4_3_3",
    "relUrl": "/docs/en/spark_ocr_versions/release_notes_4_3_3"
  },
  "1465": {
    "id": "1465",
    "title": "Annotation Lab Release Notes 4.4.0",
    "content": "4.4.0 Release date: 05-12-2022 Annotation Lab 4.4.0 brings performance matrix and benchmarking information for NER and classification models - both imported from NLP Models Hub and/or trained locally. Furthermore, with this release, tasks can be explicitly assigned to Project Owners for annotators and/or reviewers. The release also includes several improvements and fixes for issues reported by our users. Here are the highlights of this release: Highlights Benchmarking information for Classification models. Benchmarking information is now available for Classification models. It includes the confusion matrix in the training logs and is also available on the models on the Models page, which is accessible by clicking on the benchmarking icon. Task Assignment for Project Owners. Project Owners can now be explicitly assigned as annotators and/or reviewers for tasks. It is useful when working in a small team and when the Project Owners are also involved in the annotation process. A new option “Only Assigned” checkbox is now available on the labeling page that allows Project Owners to filter the tasks explicitly assigned to them when clicking the Next button. New Role available on the Team Page. On the Team Setup page, the project creator is now clearly identified by the “Owner” role. Rules Available in the Finance and Legal Editions. Rules can now be deployed and used for pre-annotation using the Legal and Finance licenses. UX Improvement for Completion. The action icons are now available on the completions, and users can directly execute the appropriate action without having to select the completion first. IAA chart improvements. NER labels and Assertion Status labels are now handled separately in the IAA charts on the Analytics page. The filter for selecting the label type is added on the respective charts. Import tasks with title field. Users can now import the tasks with title information pre-defined in the JSON/CSV. The title field was also added to the sample task file that can be downloaded from the Import page. Rename Models Hub page. The name Models HUB on the left navigation panel has been changed to Hub. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_0"
  },
  "1466": {
    "id": "1466",
    "title": "Annotation Lab Release Notes 4.4.1",
    "content": "4.4.1 Release date: 07-12-2022 Annotation Lab 4.4.1 hotfix has beed released and it includes few features, enhancements, and bug fixes. Here are the highlights of this release: Highlights Users can now delete the relations using the backspace key (on windows) or delete key (on mac) or using the delete action icon on Relations widget. Unsupported Legal and Finance models are now hidden on the Models Hub Issue when deploying pre-annotation server for some assertion models have been fixed. The “Only Assigned” checkbox state is preserved when user moves to the next task. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_4_1"
  },
  "1467": {
    "id": "1467",
    "title": "Annotation Lab Release Notes 4.5.0",
    "content": "4.5.0 Release date: 01-01-2023 Over the last year, Annotation Lab has grown to be much more than a document annotation tool. It became a full-fledged AI system, capable of testing pre-trained models and rules, applying them to new datasets, training, and tuning models, and exporting them to be deployed in production. All those features together with the new Playground concept presented in the current release notes contributed to the transformation of the Annotation Lab into the NLP Lab. A new Playground feature is released as part of the NLP Lab’s Hub that allows users to quickly test any model and/or rule on a snippet of text without the need to create a project and import tasks. NLP Lab also supports the training of Legal and Finance models and Model evaluation for classification projects. As always the release includes some stabilization and bug fixes for issues reported by our user community. Below are the details of what has been included in this release. NLP Lab’s Playground NLP Lab introduces the Playground feature where users can directly deploy and test models and/or rules. In previous versions, the pre-annotation servers could only be deployed from within a given project. With the addition of the Playground, models can easily be deployed and tested on a sample text without going through the project setup wizard. Any model or rule can now be selected and deployed for testing by clicking on the “Open in Playground” button. Rules are deployable in the Playground from the rules page. When a particular rule is deployed in the playground, the user can also change the parameters of the rules on the right side of the page. After saving the changes users need to click on the “Deploy” button to refresh the results of the pre-annotation on the provided text. Deployment of models and rules is supported by floating and air-gapped licenses. Healthcare, Legal, and Finance models require a license with their respective scopes to be deployed in Playground. Unlike pre-annotation servers, only one playground can be deployed at any given time. Export trained models to the S3 bucket With this release, users can easily export trained models to a given s3 bucket. This feature is available on the Available Models page under the Hub tab. Users need to enter the S3 bucket path, S3 access key, and S3 secret key to upload the model to the S3 bucket. Support Training of Finance and Legal Models With this release, users can perform training of Legal and Finance models depending on the available license(s). When training a new model in the NLP Lab, users have the option to select what library to use. Two options were available up until now: Open source and Healthcare. This release adds two new options: Legal and Finance. This helps differentiate the library used for training the models. The new options are only available when at least one valid license with the corresponding scope is added to the License page. Improvements Keyword-based Search at task level Finding tokens on the Visual NER project was restricted to only one page, and searching for keywords from the labeling page on a text-based project was not available. NLP Lab supports task-level keyword-based searches. The keyword-based search feature will work for text and Visual NER projects alike. The search will work on all paginated pages. It is also possible to navigate between search results, even if that result is located on another page. Important Previously this feature was implemented with the help of tag in the Visual NER project configurations. With the implementation of search at task level, the previous search tag should be removed from existing visual NER projects. Config to be removed from all existing Visual NER project: &lt;Search name=&quot;search&quot; toName=&quot;image&quot; placeholder=&quot;Search&quot;/&gt; Chunk-based Search in Visual NER tasks In previous versions, users could only run token-based searches at page level. The search feature did not support searching a collection of tokens as a single chunk. With this release, users can find a chunk of tokens in the Visual NER task. Model Evaluation for Classification Projects Up until now, the Annotation Lab only supported test and model evaluation for the NER-based projects. From this version on, NLP Lab supports test and model evaluation for Classification project as well. Evaluation results can now be downloaded if needed. Hide and Unhide Regions in NER project In this version, we support the hide/show annotated token regions feature in the text-based project in the same way as it was available in the Visual NER project. Ground Truth can only be set/unset by the owner of the completion With this version, we have improved the feature to set/unset ground truth for a completion submitted by an annotator. Now, for the Manager/Project Owner/Reviewer, the button to set/unset ground truth is disabled. The ground truth can only be updated by the annotator who submitted the completion or is unset when a submitted completion is rejected by a reviewer. Finite Zoom Out Level in Visual NER tasks Previously, users could zoom in and zoom out again on images while working with the Visual NER project, but the user could not get what the last stage of zoom-out was. Now, when the user zooms out of the image if it is the last phase then the zoom-out button will automatically be disabled so the user knows where to stop zooming out next. Taxonomy Location Customizable from the Project Configuration There are many different views available for each project template. This diversity can be confusing for users. For eliminating this complexity, the View tab was removed from the project configuration page and replaced by an “orientation” option that can be directly applied to the project configuration. Orientation will decide, where the taxonomy (labels, choices, text, images, etc.) will be located on the labeling screen i.e. placed at the top, bottom or next to the annotation screen. Pre-annotation CPU requirement message in Visual NER projects By default, the pre-annotation server uses 2 CPUs. For Visual NER pre-annotation, it is likely that 2 CPUs are not enough. Now a friendly message is shown during the deployment of Visual NER pre-annotation if the CPU count is less than or equal to 2. Bug Fixes Expanding the text on the Labelling page visually does not expand the labeling area Previously, expanding the text area on the labeling page did not make any changes in the text expansion. This issue has been fixed. Now, expanding the text will change the text area to full-screen mode. Revoking granted analytics request do not update the revoked section Earlier, when an analytics request was revoked, the corresponding entry was not shown in the revoked section. We have fixed this issue. With NLP Lab 4.5.0, the revoked entries are available in the revoked section. Also, when an analytics request is revoked, in the revoked section, two new actions, Accept and Delete, are available. Show Confidence score in Regions option is not working properly for non-Visual NER tasks For none Visual NER tasks, enabling/disabling “Show Confidence score in Regions” from Layout did not change the UI. The changes only appear when the page was reloaded or when the Versions tab was clicked. This issue has been fixed in this version. Username validation is missing when creating a new user With this version, the issue related to the missing validation of the username when creating a new user has been fixed. Issues with role selection on Teams page When a user was added to the project team as a new team member, the recently added user name was still visible in the search bar. This issue has been fixed. Clicking on the eye icon to hide a labeled region removes the region from the Annotations widget Previously, when a user clicked on the eye icon to hide a label, the labeled region was removed from the Annotations widget. Furthermore, the color of the label was also changed in the panel. This issue has been fixed. Deployed legal and finance models servers are not associated with their respective licenses In the previous version, when a Legal and Finance model server was deployed, the respective licenses were not associated with their deployed server. The availability of the Legal and Finance license was checked when the models were deployed. Version 4.5.0 fixes this bug. Model Evaluation cannot be triggered using an air-gapped healthcare license with scope training/inference The issue of triggering Model Evaluation using an air-gapped healthcare license with the training/inference scope has been fixed. When user enabled “Allow user for custom selection of regions”, token values are missing in JSON export Earlier, when the user annotates tokens while enabling “Allow user for custom selection of regions” and exports the completion. The token values were missing from the JSON export. In this version, the issue is fixed, and all the token fields and values are available in the JSON Pre-annotation server with pending status is not removed when the user deletes the server from the cluster page Deleting the pre-annotation server with status pending from the cluster page did not delete the pod from Kubernetes and created multiple pre-annotation pods. This issue has been fixed. Project export with space in the name is allowed to be imported In the earlier version, the users could import previously exported projects with space in the project’s name. Though the project was listed on the projects page, the project could not be deleted. Also, the user was unable to perform any operations on the project. The “Only Assigned” checkbox overlaps the review dialog box The overlap between the “Only Assigned” checkbox and the review dialog box was fixed. Open-source Models cannot be downloaded in the NLP Lab without a license Previously open-source models could not be downloaded from the NLP models hub when there was no license uploaded. This issue has been fixed. Now all open-source licenses are downloadable without any issue. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_0",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_0"
  },
  "1468": {
    "id": "1468",
    "title": "Annotation Lab Release Notes 4.5.1",
    "content": "4.5.1 Release date: 05-01-2023 This release includes some stabilization and bug fixes for issues reported by our user community. Below are the details of what has been included in this release. Improvement Name of available models should be visible completely in the Predefined Labels tab Bug Fixes Finance models cannot be downloaded to NLP Lab with a floating license from Models Hub Trained visual NER model is not listed in the predefined labels section on the configuration page Error due to circular dependency of logger Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_5_1"
  },
  "1469": {
    "id": "1469",
    "title": "Annotation Lab Release Notes 4.6.2",
    "content": "4.6.2 Release date: 21-01-2023 NLP Lab 4.6.2 comes with support for zero-shot learning via prompts. Prompt engineering is a very recent but rapidly growing discipline that aims to guide language models such as GPT-3 to generate specific and desired outputs, such as answering a question or writing a coherent story. This version of the NLP Lab, adds support for the creation and use of prompts for entities and relations identification within text documents. The goal of prompt engineering in this context is designing and crafting some questions, which are fed into a question-answering model together with some input text. The purpose is to guide the language model to generate specific and desired outputs, such as identifying entities or relations within the input text. This release offers features such as creation and editing of prompts, a dedicated section for prompts management and sharing inside the resources Hub, an optimized configuration page allowing mixing models, prompts, and rules into the same project, and support for quick prompts deployments and testing to the Playground. Prompts on the Hub The resources Hub has a new page dedicated to prompts. It allows users to easily discover and explore the existing prompts or create new prompts for identifying entities or relations. Currently, NLP Lab supports prompts for Healthcare, Finance, and Legal domains applied using pre-trained question-answering language models published on the NLP Models Hub and available to download in one click. The main advantage behind the use of prompts in entity or relation recognition is the ease of definition. Non-technical domain experts can easily create prompts, test and edit them on the playground on custom text snippets and, when ready, deploy them for pre-annotation as part of larger NLP projects. Together with rules, prompts are very handy in situations where no pre-trained models exist, for the target entities and domains. With rules and prompts the annotators never start their projects from scratch but can capitalize on the power of zero-shot models and rules to help them pre-annotate the simple entities and relations and speed up the annotation process. As such the NLP Lab ensures fewer manual annotations are required from any given task. Creating NER Prompts NER prompts, can be used to identify entities in natural language text documents. Those can be created based on healthcare, finance, and legal zero-shot models selectable from the “Domain” dropdown. For one prompt, the user adds one or more questions for which the answer represents the target entity to annotate. Creating Relation Prompts Prompts can also be used to identify relations between entities for healthcare, finance, and legal domains. The domain-specific zero-shot model to use for detecting relation can be selected from the “Domain” dropdown. The relation prompts are defined by a pair of entities related by a predicate. The entities can be selected from the available dropdowns listing all entities available in the current NLP Lab (included in available NER models or rules) for the specified domain. A simplified configuration wizard allows the reuse of models, rules, and prompts The project configuration page was simplified by grouping into one page all available resources that can be reused for pre-annotation: models, rules, and prompts. Users can easily mix and match the relevant resources and add them to their configuration. Note: One project configuration can only reuse the prompts defined by one single zero-shot model. Prompts created based on multiple zero-shot models (e.g. finance or legal or healthcare) cannot be mixed into the same project because of high resource consumption. Furthermore, all prompts require a license with a scope that matches the domain of the prompt. Experiment with prompts in Playground NLP Lab’s Playground supports the deployment and testing of prompts. Users can quickly test the results of applying a prompt on custom text, can easily edit the prompt, save it, and deploy it right away to see the change in the pre-annotation results. Zero-Shot Models available in the NLP Models Hub NLP Models Hub now lists the newly released zero-shot models that are used to define prompts. These models need to be downloaded to NLP Lab instance before prompts can be created. A valid license must be available for the models to be downloaded to NLP Lab. Bug Fixes Error while deploying classification model to the playground Previously, deploying the classification model to the playground had some issues which have been fixed in this version. **Information on the model’s details not visible completely on the playground ** In this version, we have fixed an issue related to the visibility of the information for Edition, Uploaded by, and Source inside the Models Detail accordion. Now, the UI can handle long model names on the playground page. Undo and Reset buttons are not working With release 4.6.2, issues regarding undo/redo buttons in the labeling page for annotated tokens have been fixed. Now, the Undo and Redo button works as expected. Finance and Legal models cannot be downloaded to NLP Lab with a floating license from Models Hub Earlier, users were not able to download the Finance and Legal model from the NLP Models HUB page using floating licenses. This issue has been fixed. Now, legal and finance models are downloadable in the NLP lab using a floating license. Pre-annotation server cannot be deployed for Visual NER This version also fixes the issue of failing to deploy the pre-annotation server for Visual NER models. Draft saved is seen for submitted completion Previously, in the NER task when the user clicked on regions of a previously submitted completion and viewed the versions submitted by the users, a draft was saved. A draft should not be created and saved for submitted completions. This issue was fixed in 4.6.2. Training fails for NER when embedding_clinical is used and the license type is open-source Earlier it was not possible to train a NER model with the open-source library using embeddings_clinical. This issue has been fixed. Hence users can now train open-sourced models with embeddings_clinical. UI goes blank for the Visual NER project when an annotation is saved and the next button is clicked In the previous version, annotators were not served the next task after clicking the Next button. A blank page with a console error was seen. Now the next task is served in the Visual NER project without any error. Pre-annotation server cannot be deployed for RE model There was an issue with the deployment of trained NER models with a relation extraction model. This issue has been fixed in this version. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_2",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_2"
  },
  "1470": {
    "id": "1470",
    "title": "Annotation Lab Release Notes 4.6.3",
    "content": "4.6.3 Release date: 31-01-2023 NLP Lab v4.6.3 is available which includes improvements for Playground and Prompt Engineering features introduced in v4.5 and v4.6. Here are some of them: Prompt (relation) using 2 different NER models is possible Ability to add long texts with new lines in the playground Issue when finance models are directly deployed to playground from the Hub page is fixed Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_3",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_3"
  },
  "1471": {
    "id": "1471",
    "title": "Annotation Lab Release Notes 4.6.5",
    "content": "4.6.5 Release date: 08-02-2023 NLP Lab v4.6.5, which includes significant optimizations and bugfixes for Project Analytics and the Prompt Engineering feature. The following are some of the key updates included in this release: The issue with the all_extracted_chunks chart not updating in the analytics page has now been resolved. The performance of project analytics operations has been improved, allowing for faster calculation of results. Limits have been added to the prompt description and prompt questions, ensuring that the text does not crash the UI. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_5",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_6_5"
  },
  "1472": {
    "id": "1472",
    "title": "Annotation Lab Release Notes 4.7.1",
    "content": "4.7.1 Release date: 22-02-2023 The latest version of NLP Lab, version 4.7.1, brings several enhancements that are worth highlighting. One of the most notable improvements is in relation prompts. NLP Lab now offers support for combining NER models, prompts and rules when defining relation prompts. The playground feature in NLP Lab has also received some noteworthy upgrades in version 4.7.1. The “playground” environment was initially added to facilitate experiments with different NLP models, tweak prompts and rules, and explore the potential of language models in a safe, sandboxed environment. The improvements made to the playground in this version are expected to enhance the overall user experience, and to make the environment faster and more responsive. In addition to these improvements, the latest version of NLP Lab has extended support for importing large task archives. This means that users can now work with bigger datasets more efficiently, which will undoubtedly save them time and effort. Below are the specifics of the additions included in this release: Improvements in Prompts Build Relation Prompts using NER Models, Prompts and Rules In previous version, relation prompts could be defined based on NER models and rules. In this release, NLP Lab allows for NER prompts to be reused when defining relation prompts. To include a NER prompt within a relation prompt, users need to navigate to the Questions section of the Relation Prompt creation page and search for the prompt to reuse. Once the NER prompt has been selected, users can start defining the question patterns. For example, users could create prompts that identify the relationship between people and the organizations they work for, or prompts that identify the relationship between a place and its geographic coordinates. The ability to incorporate NER prompts into relation prompts is a significant advancement in prompts engineering, and it opens up new possibilities for more sophisticated and accurate natural language processing. Improvements in Playground Direct Navigation to Active Playground Sessions Navigating between multiple projects to and from the playground experiments can be necessary, especially when you want to revisit a previously edited prompt or rule. This is why NLP Lab Playground now allow users to navigate to any active Playground session without having to redeploy the server. This feature enables users to check how their resources (models, rules and prompts) behave at project level, compare the preannotation results with ground truth, and quickly get back to experiments for modifying prompts or rules without losing progress or spending time on new deployments. This feature makes experimenting with NLP prompts and rules in a playground more efficient, streamlined, and productive. Automatic Deployment of Updated Rules/Prompts Another benefit of experimenting with NLP prompts and rules in the playground is the immediate feedback that you receive. When you make changes to the parameters of your rules or to the questions in your prompts, the updates are deployed instantly. Manually deploying the server is not necessary any more for changes made to Rules/Prompts to be reflected in the preannotation results. Once the changes are saved, by simply clicking on the Test button, updated results are presented. This allows you to experiment with a range of variables and see how each one affects the correctness and completeness of the results. The real-time feedback and immediate deployment of changes in the playground make it a powerful tool for pushing the boundaries of what is possible with language processing. Playground Server Destroyed after 5 Minutes of Inactivity When active, the NLP playground consumes resources from your server. For this reason, NLP Lab defines an idle time limit of 5 minutes after which the playground is automatically destroyed. This is done to ensure that the server resources are not being wasted on idle sessions. When the server is destroyed, a message is displayed, so users are aware that the session has ended. Users can view information regarding the reason for the Playground’s termination, and have the option to restart by pressing the Restart button. Playground Servers use Light Pipelines The replacement of regular preannotation pipelines with Light Pipelines has a significant impact on the performance of the NLP playground. Light pipelines allow for faster initial deployment, quicker pipeline update and fast processing of text data, resulting in overall quicker results in the UI. Direct Access to Model Details Page on the Playground Another useful feature of NLP Lab Playground is the ability to quickly and easily access information on the models being used. This information can be invaluable for users who are trying to gain a deeper understanding of the model’s inner workings and capabilities. In particular, by click on the model’s name it is now possible to navigate to the NLP Models hub page. This page provides users with additional details about the model, including its training data, architecture, and performance metrics. By exploring this information, users can gain a better understanding of the model’s strengths and weaknesses, and use this knowledge to make more informed decisions on how good the model is for the data they need to annotate. Improvements in Task Import Support for Large Document Import One of the challenges when working on big annotation projects is dealing with large size tasks, especially when uploading them to the platform. This is particularly problematic for files/archives larger than 20 MB, which can often lead to timeouts and failed uploads. To address this issue, NLP Lab has implemented chunk file uploading on the task import page. Chunk file uploading is a method that breaks large files into smaller, more manageable chunks. This process makes the uploading of large files smoother and more reliable, as it reduces the risk of timeouts and failed uploads. This is especially important for NLP practitioners who work with large datasets, as it allows them to upload and process their data more quickly and effectively. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_1"
  },
  "1473": {
    "id": "1473",
    "title": "Annotation Lab Release Notes 4.7.4",
    "content": "4.7.4 Release date: 27-02-2023 NLP Lab v4.7.4, which includes significant optimizations and bugfixes. The following are some of the key updates included in this release: Ability to track NLP Lab installation and upgrades Resolved CVE issues related to Debian packages Corrected the number of completions needed to trigger Active learning when no test-tagged tasks are present.” Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_4",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_7_4"
  },
  "1474": {
    "id": "1474",
    "title": "Annotation Lab Release Notes 4.8.1",
    "content": "4.8.1 Release date: 22-03-2023 More Powerful Prompts, New Annotation Gesture, and Enhanced Support for Floating Licences in NLP Lab 4.8 NLP Lab 4.8 brings more power to the prompts allowing a more efficient text preannotation, it adapts to the user’s preferences in terms of annotation gestures, adds supports for bundles of floating licenses shared across the annotation team for parallel preannotation, training, and experiments in the playground. It also includes a long list of optimizations covering project configuration steps, large projects export, or automatic download of missing resources. Here are the highlights of this release: More Powerful Prompts NLP Lab 4.8 introduces several new features that enhance prompt-based preannotation. One significant improvement is the incorporation of negative questions into prompt definitions, which allows users to establish characteristics that do not apply to the target entity or relation. This version also enables the creation of relation prompts using labels from custom models even if trained with different embeddings, providing more flexibility for prompt-based preannotation. Additionally, the software now automatically downloads prompt dependencies and supports prompt import/export. The prompt definition page also features a dynamic question count and filters for easy navigation. Combining Positive and Negative Questions for More Precise Prompts Definition NLP Lab 4.8 enhances the precision of entity annotation using prompts by incorporating negative questions. On the prompt definition screen, users can now specify two categories of questions - Questions that establish the characteristics of the target entity and Questions that establish the characteristics that do not apply to the entity. Both the affirmative and negative definitions will be executed as separate prompts, integrated into the same pipeline, enabling users to eliminate incorrect entities generated by the prompts. This feature will substantially boost the efficiency of prompt-based entity generation and streamline the process for our users. Relation Prompts Combine Entities from Models Trained with Different Embeddings NLP Lab allows the definition of relation prompts by combining entities defined in pre-trained models, rules, and prompts. However, previous versions of the software did not allow users to create relation prompts using custom-trained models. In this update, users can implement and use relation prompts linking 2 entities defined in custom-trained models (e.g. trained via the NLP Lab). Moreover, there is no restriction for the reference models which can also be trained using different embeddings. We are confident that this new feature will enhance the power of the prompts and offer more flexibility for prompt-based preannotation. Automatically Download Necessary Prompt Dependencies NLP Lab Prompts are created based on Zero Shot models. The later are part of the Healthcare, Finance and Legal libraries and are accessible only in the presence of a valid license key. The prompt definition options are populated according to license availability: e.g. if a Healthcare NLP license is available, the Healthcare option will be active in the Domain dropdown. As such, when creating a prompt, the user has to choose the domain of the prompt, and based on that, NLP Lab will infer the Zero Shot model needed by the prompt. When users select one of the active domains if the corresponding Zero Shot model is not available locally, NLP Lab will automatically download it from the NLP Models Hub. Import/Export Prompts Prompts are preannotation resources that users often want to move from one instance of the NLP Lab to another or to archive for future reference. NLP Lab now supports prompt import and export from the UI. The user can import a ZIP/JSON file containing one or several prompt definitions. The imported prompts will become available on the Prompts page under the Hub menu item. Users can also export prompts in JSON format via the burger menu available for each prompt. Dynamic Count of Questions on the Prompt Definition Page Each prompt can include a maximum of 30 positive questions and 30 negative questions. For facilitating user actions when defining/updating prompts, NLP Lab now includes a count of the number of questions added so far. For instance, if two questions have been added while creating a prompt, then the UI should show Questions(2/30) Filters in the prompt page The Prompts page can become crowded very quickly as prompts are quite popular and easy to define and use for preannotation, especially by non technical users. For helping users quickly identify the prompts they need, a search option is available as well as 2 filters. Using the 2 dropdown menus at the top right side of the page, prompts can be filtered based on their Type or Domain. Undo Changes For Prompt and Rules in the playground We are thrilled to introduce the Undo feature added to the NLP Lab Playground. This function enables users to quickly undo any changes made during their current experimental session. By selecting the &quot;Undo Changes&quot; button, all modifications made to the prompt/rules will be reverted to their original state. We are confident that this feature will significantly improve the user experience by providing greater control over the editing process. New Annotation Gesture Some of our users suggested updating the annotation gesture we initially offered, as it was counter-intuitive, especially for users accustomed to modern text editing tools. Specifically, the process of first selecting the Label and then selecting the chunk to annotate may not feel natural anymore, as tools such as MS Word, where you first select a text and then have options to format or access contextual menus that open next to your selection, have changed the way we all feel about text manipulation. We hear you! To make NLP Lab more intuitive and user-friendly, NLP Lab now supports a new way of annotating text. This new feature allows users to select the text first and then choose the label to apply. We believe that this will make the annotation process more intuitive and efficient for many users. This feature is available for both text projects and Visual NER projects. You are now able to switch between the two options: selecting text and assigning an entity, or selecting an entity and assigning text. Both will work. This way, users can choose the annotation method that works best for their project and their personal preferences. Optimized Project Configurations Automatic Model Download During Project Import When a user imports a project in NLP Lab 4.8, the system automatically downloads any absent models utilized by the imported project. To enable users to check whether the models have been downloaded or not, a new section named &quot;Download Models&quot; has been included in the Import status. If the required models have been downloaded or are already present, a green tick will be displayed. On the other hand, if the download process is unsuccessful, a red cross will be shown. When the automatic download of a model/embeddings fails, an error message is displayed on the model card in the Hub-&gt;Models page. Users can hover over the question mark icon to see the details. Update the behavior of the save button on the Project configuration page While setting up the configuration, the user can now choose to save the settings on all configuration sections without being redirected to another page or having to deploy a preannotation server. After saving the configuration, the user can deploy the pre-annotation server by pressing the Pre-Annotate button from the tasks page or navigating to the Configuration -&gt; Customize Labels page and save the configuration there. Once the server is deployed, the user will either be directed to the Tasks page or to the Import page. Missing Embeddings Warning in the Configuration Page If embeddings are missing for a model that is part of a project configuration, a black warning message was displayed on the configuration page to alert the user. This warning message was not visible before, but now the displayed text ensures that the user can see the error. Efficient Export for Large Projects Visual NER projects, pre-annotations, and training have substantially increased NLP Lab project sizes. Unfortunately, this growth has made importing and exporting tasks or projects time-consuming, especially when dealing with large files. The new version of the system has addressed this issue by enhancing both project and task exports, making it possible to quickly export large files and manage a vast number of tasks. This optimization also applies to text-based projects, where the export time has been reduced by a factor of ten. The current version of the system includes a pop-up message that appears before exporting both tasks and projects. This message notifies the user that the system is preparing the data for download and advises them to remain on the page and avoid enabling pop-ups to prevent any interruptions. Once the data preparation is complete, the download will start automatically, and the user will not need to take any additional steps. Enhanced Support for Floating Licenses Support for Bundles of Licenses We are delighted to inform you that NLP Lab now offers support for bundles of floating licenses. Those are licenses that enable multiple pre-annotation/training servers to run concurrently based on the values of the &quot;max_parallel_jobs&quot; parameter. In the previous version, our floating license system only allowed for one pre-annotation/training server to operate at a time. With this new update, users can enjoy the benefits of a single floating license that can support multiple pre-annotation/training servers simultaneously. Display a banner showing the number of days remaining for the available trial license NLP Lab improves the user experience by providing more accessible information about license validity. Currently, users can only check their license status on the Licenses page, which may not be convenient as it requires manual action. To address this issue, we have added a new feature that displays a warning on the user interface before the license expires. This notification reminds you to review your subscription status or renew your license before it expires. For trial licenses with less than 30 days remaining, a banner will be displayed on the UI indicating the remaining trial days and a link to create a new subscription. This way, you can easily keep track of your trial period and take the necessary steps before it ends. Improvements Increased Flexibility in Username Definition With the latest release of NLP Lab, users can create usernames with increased flexibility and ease. Specifically, support has been added for the use of the underscore symbol &quot;&quot; in usernames. This enhancement will enable users to create unique and more expressive usernames that better represent their identity or brand. Furthermore, this feature will allow users to avoid any potential conflicts or duplications with other usernames. Improved User Experience with Clearer Relation Prompts NLP Lab has recently introduced an improvement to the way relation prompts are displayed in the Pre-annotation pop-up. Previously, the relation prompts were shown under the generic &quot;Pre-annotation prompts&quot; category, which may have caused confusion for users. With this update, relation prompts are now shown under a separate sub-heading of &quot;RE prompts&quot; or &quot;Relation prompts,&quot; providing clearer and more organized categorization. This improvement will enable users to manage the creation and deployment of relation prompts more intuitively and efficiently. Enhanced Accessibility and Functionality of Model Hub Page To improve the accessibility and functionality of the Model Hub page, NLP Lab has implemented several changes in its latest version. One such improvement is the ability to distinguish between downloadable models and license-restricted models. Models that require a license will now be disabled when the appropriate license is not available, making it easier for users to navigate and select models to reuse. Another enhancement is the introduction of a new menu on the model/rules card, which allows users to effortlessly download models from Modelshub or open them in the playground. This menu provides a more streamlined and convenient way for users to access and utilize the available models and resources. Versions Version Version Version 4.8.1 4.7.4 4.7.1 4.6.5 4.6.3 4.6.2 4.5.1 4.5.0 4.4.1 4.4.0 4.3.0 4.2.0 4.1.0 3.5.0 3.4.1 3.4.0 3.3.1 3.3.0 3.2.0 3.1.1 3.1.0 3.0.1 3.0.0 2.8.0 2.7.2 2.7.1 2.7.0 2.6.0 2.5.0 2.4.0 2.3.0 2.2.2 2.1.0 2.0.1",
    "url": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_1",
    "relUrl": "/docs/en/alab/annotation_labs_releases/release_notes_4_8_1"
  },
  "1475": {
    "id": "1475",
    "title": "Resolve Entities to Terminology Codes - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/resolve_entities_codes",
    "relUrl": "/resolve_entities_codes"
  },
  "1476": {
    "id": "1476",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/pretrained/resource_downloader.html",
    "relUrl": "/api/python/modules/sparknlp/pretrained/resource_downloader.html"
  },
  "1477": {
    "id": "1477",
    "title": "Risk and Factors - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/risk_factors",
    "relUrl": "/risk_factors"
  },
  "1478": {
    "id": "1478",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/roberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/roberta_embeddings.html"
  },
  "1479": {
    "id": "1479",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_question_answering.html"
  },
  "1480": {
    "id": "1480",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification.html"
  },
  "1481": {
    "id": "1481",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/roberta_for_token_classification.html"
  },
  "1482": {
    "id": "1482",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/roberta_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/roberta_sentence_embeddings.html"
  },
  "1483": {
    "id": "1483",
    "title": "Rules",
    "content": "Rule based annotation is supported by Healthcare NLP, Finance NLP, and Legal NLP via the ContextualParser Annotator. Annotation Lab supports creating and using rules in a NER project using any one of these libraries with the presence of valid license. Users in the Admins group can see and edit the available rules on the Rules page under the Models Hub menu. Users can create new rules using the + Add Rules button. Users can also import and export the rules. There are two types of rules supported: Regex Based: Users can define a regex that will be used to label all possible hit chunks and label them as the target entity. For example, for labeling height entity the following regex can be used [0-7]&#39;((0?[0-9])|(1(0|1)))&#39;&#39;. All hits found in the task’s text content that match the regex are pre-annotated as height. Dictionary-Based: Users can define and upload a CSV dictionary of keywords that cover the list of chunks that should be annotated as a target entity. For example, for the label female, all occurrences of strings woman, lady, and girl within the text content of a given task will be pre-annotated as female. After adding a rule, the Project Owner or Manager can add the rule to the configuration of the project where they want to use it. This can be done from the Rules screen of the Project Configuration step on the Project Setup page. A valid Healthcare, Finance or Legal NLP license is required to deploy rules as a pre-annotation server after completing the project configuration step. The user is notified every time a rule in use is edited with the message “Redeploy preannotation server to apply these changes” on the Edit Rule form. Import and Export Rules Annotation Lab allows importing and exporting Rules from the Rules page. Import Rules Users can import rules from the Rules page. The rules can be both dictionary based or regex based. The rules can be imported in the following formats: JSON file or content. Zip archive of JSON file/s. Export Rules To export any rule, the user need to select the available rules and click on Export Rules button. Rules are then downloaded as a zip file. The zip file contains the JSON file for each rule. These exported rules can again be imported to Annotation Lab. The following blog posts explain how to create and use rules for jump starting your annotation projects: Using Rules to Jump Start Text Annotation Projects Using Rules and Pretrained Models in Text Annotation Projects Training and tuning models based on Rule-based annotation of text documents",
    "url": "/docs/en/alab/rules",
    "relUrl": "/docs/en/alab/rules"
  },
  "1484": {
    "id": "1484",
    "title": "",
    "content": "",
    "url": "/api/python/search.html",
    "relUrl": "/api/python/search.html"
  },
  "1485": {
    "id": "1485",
    "title": "Security and Privacy",
    "content": "We understand and take the security issues as the highest priority. On every release, all our artifacts and images ran through a series of security testing - Static Code analysis, Pen Test, Images Vulnerabilities Test, AWS AMI Scan Test. Every identified critical issue is remediated, code gets refactored to pass our standard Static Code Analysis. Role-based access Role-based access control is available for all Annotation Lab deployments. By default, all projects are private to the user who created them – the project owner. If necessary, project owners can add other users to the project and define their role(s) among annotator, reviewer, manager. The three roles supported by Annotation Lab offer different levels of task and feature visibility. Annotators can only see tasks assigned to them and their own completions. Reviewers can see the work of annotators who created completions for the tasks assigned to them. Annotators and reviewers do not have access to task import or annotation export nor to the Models Hub page. Managers have higher level of access. They can see all tasks content, can assign work to annotators and reviewers, can import tasks, export annotations, see completions created by team members or download models. When creating the annotation team, make sure the appropriate role is assigned to each team member according to the Need-To-Know Basis. Screen capture is not disabled, and given the high adoption of mobile technologies, team members can easily take pictures of the data. This is why, when dealing with sensitive documents, it is advisable to conduct periodical HIPPA/GDPR training with the annotation team to avoid data breaches. Data sharing Annotation Lab runs locally - all computation and model training run inside the boundaries of your deployment environment. The content related to any tasks within your projects is NOT SHARED with anyone. The Annotation Lab does not call home. Access to internet is used ONLY when downloading models from the NLP Models Hub. Document processing - OCR, pre-annotation, training, fine-tuning- runs entirely on your environment. Secure user access to Annotation Lab Access to Annotation Lab is restricted to users who are given access by an admin or project manager. Each user has an account; when created, passwords are enforced to best practice security policy. Annotation Lab keeps track of who has access to the defined projects and their actions regarding completions creation, cloning, submission, and starring. See User Management Page for more details. API access to Annotation Lab Access to Annotation Lab REST API requires an access token that is specific to a user account. To obtain your access token please follow the steps illustrated here. Complete project audit trail Annotation Lab keeps trail for all created completions. It is not possible for annotators or reviewers to delete any completions and only managers and project owners are able to remove tasks. Application development cycle The Annotation Lab development cycle currently includes static code analysis; everything is assembled as docker images whom are being scanned for vulnerabilities before being published. We are currently implementing web vulnerability scanning.",
    "url": "/docs/en/alab/security",
    "relUrl": "/docs/en/alab/security"
  },
  "1486": {
    "id": "1486",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector.html"
  },
  "1487": {
    "id": "1487",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentence/sentence_detector_dl.html"
  },
  "1488": {
    "id": "1488",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/sentence_embeddings.html"
  },
  "1489": {
    "id": "1489",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentiment/sentiment_detector.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentiment/sentiment_detector.html"
  },
  "1490": {
    "id": "1490",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/sentiment_dl.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/sentiment_dl.html"
  },
  "1491": {
    "id": "1491",
    "title": "Serving Spark NLP&#58 MLFlow on Databricks",
    "content": "",
    "url": "/docs/en/serving_spark_nlp_via_api_databricks_mlflow",
    "relUrl": "/docs/en/serving_spark_nlp_via_api_databricks_mlflow"
  },
  "1492": {
    "id": "1492",
    "title": "Social Determinant - Clinical NLP Demos & Notebooks",
    "content": "",
    "url": "/social_determinant",
    "relUrl": "/social_determinant"
  },
  "1493": {
    "id": "1493",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/training/spacy_to_annotation.html",
    "relUrl": "/api/python/modules/sparknlp/training/spacy_to_annotation.html"
  },
  "1494": {
    "id": "1494",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/coref/spanbert_coref.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/coref/spanbert_coref.html"
  },
  "1495": {
    "id": "1495",
    "title": "Spark NLP",
    "content": "",
    "url": "/docs/en/spark-nlp",
    "relUrl": "/docs/en/spark-nlp"
  },
  "1496": {
    "id": "1496",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp.html",
    "relUrl": "/api/python/modules/sparknlp.html"
  },
  "1497": {
    "id": "1497",
    "title": "Speech and Vision Recognition - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/speech_vision_recognition",
    "relUrl": "/speech_vision_recognition"
  },
  "1498": {
    "id": "1498",
    "title": "Starting a Spark Session",
    "content": "To use most features you must start a Spark Session with jsl.start()first. This will launch a Java Virtual Machine(JVM) process on your machine which has all of John Snow Labs and Sparks Scala/Java Libraries(JARs) you have access to loaded into memory. The jsl.start() method downloads loads and caches all jars for which credentials are provided if they are missing into ~/.jsl_home/java_installs. If you have installed via jsl.install() you can most likely skip the rest of this page, since your secrets have been cached in ~/.jsl_home and will be re-used. If you disabled license caching while installing or if you want to tweak settings about your spark session continue reading this section further. Outputs of running jsl.start() tell you which jars are loaded and versions of all relevant libraries. Authorization Flow Parameters Most of the authorization Flows and Parameters of jsl.install() are supported. Review detailed docs here Parameter Description Example Default None Load license automatically via one of the Auto-Detection Mechanisms jsl.start() False browser_login Browser based authorization, Button to click on Notebooks and Browser Pop-Up otherwise. jsl.start(browser_login=True) False access_token Vist my.johnsnowlabs.com to extract a token which you can provide to enable license access. See Access Token Example jsl.start(access_token=&#39;myToken&#39;) None secrets_file Define JSON license file with keys defined by License Variable Overview and provide file path jsl.start(secrets_file=&#39;path/to/license.json&#39;) None store_in_jsl_home Disable caching of new licenses to ~./jsl_home jsl.start(store_in_jsl_home=False) True local_license_number Specify which license to use, if you have access to multiple locally cached jsl.start(license_number=5) 0 remote_license_number Specify which license to use, if you have access to multiple via OAUTH on my.jsl.com jsl.start(license_number=5) 0 Manually specify License Parameters These can be omitted according to the License Variable Overview Parameter Description aws_access_key Corresponds to AWS_ACCESS_KEY_ID aws_key_id Corresponds to AWS_SECRET_ACCESS_KEY enterprise_nlp_secret Corresponds to HC_SECRET ocr_secret Corresponds to OCR_SECRET hc_license Corresponds to HC_LICENSE ocr_license Corresponds to OCR_LICENSE fin_license Corresponds to JSL_LEGAL_LICENSE leg_license Corresponds to JSL_FINANCE_LICENSE Sparksession Parameters These parameters configure how your spark Session is started up. See Spark Configuration for a comprehensive overview of all spark settings Parameter Default Description Example spark_conf None Dictionary Key/Value pairs of Spark Configurations for the Spark Session jsl.start(spark_conf={&#39;spark.executor.memory&#39;:&#39;6g&#39;}) master_url local[*] URL to Spark Cluster master jsl.start(master_url=&#39;spark://my.master&#39;) jar_paths None List of paths to jars which should be loaded into the Spark Session jsl.start(jar_paths=[&#39;my/jar_folder/jar1.zip&#39;,&#39;my/jar_folder/jar2.zip&#39;] ) exclude_nlp False Whether to include Spark NLP jar in Session or not. This will always load the jar if available, unless set to True. jsl.start(exclude_nlp=True) exclude_healthcare False Whether to include licensed NLP Jar for Legal,Finance or Healthcare. This will always load the jar if available using your provided license, unless set to True. jsl.start(exclude_healthcare=True) exclude_ocr False Whether to include licensed OCR Jar for Legal,Finance or Healthcare. This will always load the jar if available using your provided license, unless set to True. jsl.start(exclude_ocr=True) hardware_target cpu Specify for which hardware Jar should be optimized. Valid values are gpu,cpu,m1,aarch jsl.start(hardware_target=&#39;m1&#39;) model_cache_folder None Specify where models should be downloaded to when using model.pretrained() jsl.start(model_cache_folder=True)",
    "url": "/docs/en/jsl/start-a-sparksession",
    "relUrl": "/docs/en/jsl/start-a-sparksession"
  },
  "1499": {
    "id": "1499",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/stemmer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/stemmer.html"
  },
  "1500": {
    "id": "1500",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/stop_words_cleaner.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/stop_words_cleaner.html"
  },
  "1501": {
    "id": "1501",
    "title": "Streamlit visualization Examples",
    "content": "This page contains examples and tutorials on how to visualize the 10000+ state-of-the-art NLP models in just 1 line of code in streamlit. It includes simple 1-liners you can sprinkle into your Streamlit app to for features like Dependency Trees, Named Entities (NER), text classification results, semantic simmilarity, embedding visualizations via ELMO, BERT, ALBERT, XLNET and much more . Additionally, improvements for T5 and various resolvers have been added. This is the ultimate NLP research tool. You can visualize and compare the results of hundreds of context aware deep learning embeddings and compare them with classical vanilla embeddings like Glove and can see with your own eyes how context is encoded by transformer models like BERT or XLNETand many more ! Besides that, you can also compare the results of the 200+ NER models John Snow Labs provides and see how peformances changes with varrying ebeddings, like Contextual, Static and Domain Specific Embeddings. Install pip install streamlit sklearn plotly Problems? Connect with us on Slack! Impatient and want some action? Just run this Streamlit app, you can use it to generate python code for each Streamlit building block streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Quick Starter cheat sheet - All you need to know in 1 picture for NLP + Streamlit For NLP models to load, see the NLP namespace or the John Snow Labs Modelshub or go straight to the source. Examples Just try out any of these. You can use the first example to generate python-code snippets which you can recycle as building blocks in your streamlit apps! Example: 01_dashboard streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/01_dashboard.py Example: 02_NER streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/02_NER.py Example: 03_text_similarity_matrix streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/03_text_similarity_matrix.py Example: 04_dependency_tree streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/04_dependency_tree.py Example: 05_classifiers streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/05_classifiers.py Example: 06_token_features streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/06_token_features.py Example: 07_token_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/07_token_embedding_manifolds.py Example: 08_token_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/08_sentence_embedding_manifolds.py Example: 09_entity_embedding_dimension_reduction streamlit run https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/examples/streamlit/09_entity_embedding_manifolds.py How to use the nlp module? All you need to know about the nlp module is that there is the nlp.load() method which returns a NLUPipeline object which has a .predict() that works on most common data types in the pydata stack like Pandas dataframes . Ontop of that, there are various visualization methods a NLUPipeline provides easily integrate in Streamlit as re-usable components. viz() method Overview of NLP + Streamlit buildingblocks | Method | Description | |——————————————————————————–|————————————————————————————————————————————————————————————————————————————————————————-| | nlp.load(&#39;&lt;Model&gt;&#39;).predict(data) | Load any of the 1000+ models by providing the model name any predict on most Pythontic data strucutres like Pandas, strings, arrays of strings and more | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit(data) | Display full NLP exploration dashboard, that showcases every feature avaiable with dropdown selectors for 1000+ models | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_similarity([string1, string2]) | Display similarity matrix and scalar similarity for every word embedding loaded and 2 strings. | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_ner(data) | Visualize predicted NER tags from Named Entity Recognizer model | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_dep_tree(data) | Visualize Dependency Tree together with Part of Speech labels | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_classes(data) | Display all extracted class features and confidences for every classifier loaded in pipeline | | nlp.load(&#39;&lt;Model&gt;&#39;).viz_streamlit_token(data) | Display all detected token features and informations in Streamlit | | nlp.load(&#39;&lt;Model&gt;&#39;).viz(data, write_to_streamlit=True) | Display the raw visualization without any UI elements. See viz docs for more info. By default all aplicable nlp model references will be shown. | | nlp.enable_streamlit_caching() | Enable caching the nlp.load() call. Once enabled, the nlp.load() method will automatically cached. ** This is recommended** to run first and for large peformance gans | Detailed visualizer information and API docs function pipe.viz_streamlit Display a highly configurable UI that showcases almost every feature available for Streamlit visualization with model selection dropdowns in your applications. Ths includes : Similarity Matrix &amp; Scalars &amp; Embedding Information for any of the 100+ Word Embedding Models NER visualizations for any of the 200+ Named entity recognizers Labled &amp; Unlabled Dependency Trees visualizations with Part of Speech Tags for any of the 100+ Part of Speech Models Token informations predicted by any of the 1000+ models Classification results predicted by any of the 100+ models classification models Pipeline Configuration &amp; Model Information &amp; Link to John Snow Labs Modelshub for all loaded pipelines Auto generate Python code that can be copy pasted to re-create the individual Streamlit visualization blocks. NlLU takes the first model specified as nlp.load() for the first visualization run. Once the Streamlit app is running, additional models can easily be added via the UI. It is recommended to run this first, since you can generate Python code snippets to recreate individual Streamlit visualization blocks nlp.load(&#39;ner&#39;).viz_streamlit([&#39;I love NLP and Streamlit!&#39;, &#39;I hate buggy software&#39;]) function parameters pipe.viz_streamlit Argument Type Default Description text Union [str, List[str], pd.DataFrame, pd.Series] &#39;NLP and Streamlit go together like peanutbutter and jelly&#39; Default text for the Classification, Named Entitiy Recognizer, Token Information and Dependency Tree visualizations similarity_texts Union[List[str],Tuple[str,str]] (&#39;Donald Trump Likes to part&#39;, &#39;Angela Merkel likes to party&#39;) Default texts for the Text similarity visualization. Should contain exactly 2 strings which will be compared token embedding wise. For each embedding active, a token wise similarity matrix and a similarity scalar model_selection List[str] [] List of nlp references to display in the model selector, see the NLP namespace or the John Snow Labs Modelshub or go straight to the source for more info title str &#39;NLP ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app sub_title str &#39;Play with over 1000+ scalable enterprise NLP models&#39; Sub title of the Streamlit app visualizers List[str] ( &quot;dependency_tree&quot;, &quot;ner&quot;, &quot;similarity&quot;, &quot;token_information&quot;, &#39;classification&#39;) Define which visualizations should be displayed. By default all visualizations are displayed. show_models_info bool True Show information for every model loaded in the bottom of the Streamlit app. show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_viz_selection bool False Show a selector in the sidebar which lets you configure which visualizations are displayed. show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_code_snippets bool False Display Python code snippets above visualizations that can be used to re-create the visualization num_similarity_cols int 2 How many columns should for the layout in Streamlit when rendering the similarity matrixes. function pipe.viz_streamlit_classes Visualize the predicted classes and their confidences and additional metadata to streamlit. Aplicable with any of the 100+ classifiers nlp.load(&#39;sentiment&#39;).viz_streamlit_classes( [&#39;I love NLP and Streamlit!&#39;, &#39;I love buggy software&#39;, &#39;Sign up now get a chance to win 1000$ !&#39;, &#39;I am afraid of Snakes&#39;, &#39;Unicorns have been sighted on Mars!&#39;, &#39;Where is the next bus stop?&#39;]) function parameters pipe.viz_streamlit_classes Argument Type Default Description text Union[str,list,pd.DataFrame, pd.Series, pyspark.sql.DataFrame ] &#39;I love NLU and Streamlit and sunny days!&#39; Text to predict classes for. Will predict on each input of the iteratable or dataframe if type is not str. output_level Optional[str] document Outputlevel of NLP pipeline, see pipe.predict() docsmore info include_text_col bool True Whether to include a e text column in the output table or just the prediction data title Optional[str] Text Classification Title of the Streamlit building block that will be visualized to screen metadata bool False whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info positions bool False whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_ner Visualize the predicted classes and their confidences and additional metadata to Streamlit. Aplicable with any of the 250+ NER models. You can filter which NER tags to highlight via the dropdown in the main window. Basic usage nlp.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;) Example for coloring # Color all entities of class GPE black nlp.load(&#39;ner&#39;).viz_streamlit_ner(&#39;Donald Trump from America and Angela Merkel from Germany dont share many views&#39;, colors={&#39;PERSON&#39;: &#39;#6e992e&#39;, &#39;GPE&#39;: &#39;#000000&#39;}) function parameters pipe.viz_streamlit_ner Argument Type Default Description text str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views&#39; Text to predict classes for. ner_tags Optional[List[str]] None Tags to display. By default all tags will be displayed show_label_select bool True Whether to include the label selector show_table bool True Whether show to predicted pandas table or not title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen sub_title Optional[str] &#39;&quot;Recognize various Named Entities (NER) in text entered and filter them. You can select from over 100 languages in the dropdown. On the left side.&quot;,&#39; Sub-title of the Streamlit building block that will be visualized to screen colors Dict[str,str] {} Dict with KEY=ENTITY_LABEL and VALUE=COLOR_AS_HEX_CODE,which will change color of highlighted entities.See custom color labels docs for more info. set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models available in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_text_input bool True Show text input field to input text in show_logo bool True Show logo display_infos bool False Display additional information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_dep_tree Visualize a typed dependency tree, the relations between tokens and part of speech tags predicted. Aplicable with any of the 100+ Part of Speech(POS) models and dep tree model nlp.load(&#39;dep.typed&#39;).viz_streamlit_dep_tree( &#39;POS tags define a grammatical label for each token and the Dependency Tree classifies Relations between the tokens&#39;) function parameters pipe.viz_streamlit_dep_tree Argument Type Default Description text str &#39;Billy likes to swim&#39; Text to predict classes for. title Optional[str] &#39;Dependency Parse Tree &amp; Part-of-speech tags&#39; Title of the Streamlit building block that will be visualized to screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_token Visualize predicted token and text features for every model loaded. You can use this with any of the 1000+ models and select them from the left dropdown. nlp.load(&#39;stemm pos spell&#39;).viz_streamlit_token(&#39;I liek pentut buttr and jelly !&#39;) function parameters pipe.viz_streamlit_token Argument Type Default Description text str &#39;NLU and Streamlit are great!&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen show_feature_select bool True Whether to include the token feature selector features Optional[List[str]] None Features to to display. By default all Features will be displayed metadata bool False Whether to output addition metadata or not, see pipe.predict(meta=true) docs for more info output_level Optional[str] &#39;token&#39; Outputlevel of NLP pipeline, see pipe.predict() docsmore info positions bool False Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info show_logo bool True Show logo display_infos bool False Display additonal information about ISO codes and the NLP namespace structure. function pipe.viz_streamlit_similarity Displays a similarity matrix, where x-axis is every token in the first text and y-axis is every token in the second text. Index i,j in the matrix describes the similarity of token-i to token-j based on the loaded embeddings and distance metrics, based on Sklearns Pariwise Metrics. . See this article for more elaboration on similarities Displays a dropdown selectors from which various similarity metrics and over 100 embeddings can be selected. -There will be one similarity matrix per metric and embedding pair selected. num_plots = num_metric*num_embeddings Also displays embedding vector information. Applicable with any of the 100+ Word Embedding models nlp.load(&#39;bert&#39;).viz_streamlit_word_similarity( [&#39;I love love loooove NLP! &lt;3&#39;, &#39;I also love love looove Streamlit! &lt;3&#39;]) function parameters pipe.viz_streamlit_similarity Argument Type Default Description texts str &#39;Donald Trump from America and Anegela Merkel from Germany do not share many views.&#39; Text to predict token information for. title Optional[str] &#39;Named Entities&#39; Title of the Streamlit building block that will be visualized to screen similarity_matrix bool None Whether to display similarity matrix or not show_algo_select bool True Whether to show dist algo select or not show_table bool True Whether show to predicted pandas table or not threshold float 0.5 Threshold for displaying result red on screen set_wide_layout_CSS bool True Whether to inject custom CSS or not. key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn generate_code_sample bool False Display Python code snippets above visualizations that can be used to re-create the visualization show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info write_raw_pandas bool False Write the raw pandas similarity df to streamlit display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more. dist_metrics List[str] [&#39;cosine&#39;] Which distance metrics to apply. If multiple are selected, there will be multiple plots for each embedding and metric. num_plots = num_metric*num_embeddings. Can use multiple at the same time, any of of cityblock,cosine,euclidean,l2,l1,manhattan,nan_euclidean. Provided via Sklearn metrics.pairwise package num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes. display_scalar_similarities bool False Display scalar similarities in an additional field. display_similarity_summary bool False Display summary of all similarities for all embeddings and metrics. show_logo bool True Show logo display_infos bool False Display additional information about ISO codes and the NLP namespace structure. Embedding visualization via Manifold and Matrix Decomposition algorithms function pipe.viz_streamlit_word_embed_manifold Visualize Word Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 11 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlp references in the additional_classifiers_for_coloring parameter. Reduces Dimensionality of high dimensional Word Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Word Embedding models Color points by classifying with any of the 100+ Parts of Speech Classifiers or Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;bert&#39;, verbose=True).viz_streamlit_word_embed_manifold(default_texts=[&#39;I love NLU &lt;3&#39;, &#39;I love streamlit &lt;3&#39;], default_algos_to_apply=[&#39;TSNE&#39;], MAX_DISPLAY_NUM=5) function parameters pipe.viz_streamlit_word_embed_manifold Argument Type Default Description   default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to.   text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for.   sub_title Optional[str] “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Word Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   show_embed_select bool True Show selector for Embedding Selection   show_color_select bool True Show selector for coloring plots   MAX_DISPLAY_NUM int 100 Cap maximum number of Tokens displayed   display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   additional_classifiers_for_coloring List[str] [&#39;pos&#39;, &#39;sentiment.imdb&#39;] List of additional NLP references to load for generating hue colors   show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models available in 1 click   model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Larger Example showcasing more dimension reduction techniques on a larger corpus : function pipe.viz_streamlit_sentence_embed_manifold Visualize Sentence Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 12 Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . Additionally, you can color the lower dimensional points with a label that has been previously assigned to the text by specifying a list of nlp references in the additional_classifiers_for_coloring parameter. You can also select additional classifiers via the GUI. Reduces Dimensionality of high dimensional Sentence Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 100+ Sentence Embedding models Color points by classifying with any of the 100+ Document Classifiers Gemerates NUM-DIMENSIONS * NUM-EMBEDDINGS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;embed_sentence.bert&#39;).viz_streamlit_sentence_embed_manifold([&#39;text1&#39;, &#39;text2tdo&#39;]) function parameters pipe.viz_streamlit_sentence_embed_manifold Argument Type Default Description   default_texts List[str] (“Donald Trump likes to party!”, “Angela Merkel likes to party!”, ‘Peter HATES TO PARTTY!!!! :(‘) List of strings to apply classifiers, embeddings, and manifolds to.   text Optional[str] &#39;Billy likes to swim&#39; Text to predict classes for.   sub_title Optional[str] “Apply any of the 11 Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Sentence Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   show_embed_select bool True Show selector for Embedding Selection   show_color_select bool True Show selector for coloring plots   display_embed_information bool True Show additional embedding information like dimension, nlu_reference, spark_nlp_reference, sotrage_reference, modelhub link and more.   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrixes.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   additional_classifiers_for_coloring List[str] [&#39;sentiment.imdb&#39;] List of additional NLP references to load for generting hue colors   show_model_select bool True Show a model selection dropdowns that makes any of the 1000+ models avaiable in 1 click   model_select_position str &#39;side&#39; Whether to output the positions of predictions or not, see pipe.predict(positions=true) for more info   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 How many cores to use for paralleling when using Sklearn Dimension Reduction algorithms.   Streamlit Entity Manifold visualization function pipe.viz_streamlit_entity_embed_manifold Visualize recognized entities by NER models via their Entity Embeddings in 1-D, 2-D, or 3-D by Reducing Dimensionality via 10+ Supported methods from Manifold Algorithms and Matrix Decomposition Algorithms . You can pick additional NER models and compare them via the GUI dropdown on the left. Reduces Dimensionality of high dimensional Entity Embeddings to 1-D, 2-D, or 3-D and plot the resulting data in an interactive Plotly plot Applicable with any of the 330+ Named Entity Recognizer models Generates NUM-DIMENSIONS * NUM-NER-MODELS * NUM-DIMENSION-REDUCTION-ALGOS plots nlp.load(&#39;ner&#39;).viz_streamlit_sentence_embed_manifold([&#39;Hello From John Snow Labs&#39;, &#39;Peter loves to visit New York&#39;]) function parameters pipe.viz_streamlit_sentence_embed_manifold Argument Type Default Description   default_texts List[str] “Donald Trump likes to visit New York”, “Angela Merkel likes to visit Berlin!”, ‘Peter hates visiting Paris’) List of strings to apply classifiers, embeddings, and manifolds to.   title str &#39;NLU ❤️ Streamlit - Prototype your NLP startup in 0 lines of code🚀&#39; Title of the Streamlit app   sub_title Optional[str] “Apply any of the 10+ Manifold or Matrix Decomposition algorithms to reduce the dimensionality of Entity Embeddings to 1-D, 2-D and 3-D “ Sub title of the Streamlit app   default_algos_to_apply List[str] [&quot;TSNE&quot;, &quot;PCA&quot;] A list Manifold and Matrix Decomposition Algorithms to apply. Can be either &#39;TSNE&#39;,&#39;ISOMAP&#39;,&#39;LLE&#39;,&#39;Spectral Embedding&#39;, &#39;MDS&#39;,&#39;PCA&#39;,&#39;SVD aka LSA&#39;,&#39;DictionaryLearning&#39;,&#39;FactorAnalysis&#39;,&#39;FastICA&#39; or &#39;KernelPCA&#39;,   target_dimensions List[int] (1,2,3) Defines the target dimension embeddings will be reduced to   show_algo_select bool True Show selector for Manifold and Matrix Decomposition Algorithms   set_wide_layout_CSS bool True Whether to inject custom CSS or not.   num_cols int 2 How many columns should for the layout in streamlit when rendering the similarity matrices.   key str &quot;NLU_streamlit&quot; Key for the Streamlit elements drawn   show_logo bool True Show logo   display_infos bool False Display additional information about ISO codes and the NLP namespace structure.   n_jobs Optional[int] 3 False How many cores to use for paralellzing when using Sklearn Dimension Reduction algorithms. Supported Manifold Algorithms for Word, Sentence, and Entity Embeddings TSNE ISOMAP LLE Spectral Embedding MDS Supported Matrix Decomposition Algorithms for Word, Sentence and Entity Embeddings PCA Truncated SVD aka LSA DictionaryLearning FactorAnalysis FastICA KernelPCA Latent Dirichlet Allocation",
    "url": "/docs/en/jsl/streamlit_viz_examples",
    "relUrl": "/docs/en/jsl/streamlit_viz_examples"
  },
  "1502": {
    "id": "1502",
    "title": "Summarize & Paraphrase - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/summarize_paraphrase",
    "relUrl": "/summarize_paraphrase"
  },
  "1503": {
    "id": "1503",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/cv/swin_for_image_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/cv/swin_for_image_classification.html"
  },
  "1504": {
    "id": "1504",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/spell_check/symmetric_delete.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/spell_check/symmetric_delete.html"
  },
  "1505": {
    "id": "1505",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/seq2seq/t5_transformer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/seq2seq/t5_transformer.html"
  },
  "1506": {
    "id": "1506",
    "title": "Enterprise Spark NLP",
    "content": "{% include programmingLanguageSelectScalaPythonNLU.html %} {% include programmingLanguageSelectPythons.html %} ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) ... pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;token&quot;,&quot;sentence&quot;]) .setOutputCol(&quot;pos&quot;) pos_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos]) light_pipeline = LightPipeline(pos_pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;))) result = light_pipeline.fullAnnotate(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;) val pos = PerceptronModel.pretrained(&quot;pos_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(&quot;token&quot;,&quot;sentence&quot;) .setOutputCol(&quot;pos&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, pos)) val data = Seq(&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) import nlu nlu.load(&quot;en.pos.clinical&quot;).predict(&quot;&quot;&quot;He was given boluses of MS04 with some effect, he has since been placed on a PCA - he take 80mg of oxycontin at home, his PCA dose is ~ 2 the morphine dose of the oxycontin, he has also received ativan for anxiety.&quot;&quot;&quot;)",
    "url": "/docs/en/tab_example",
    "relUrl": "/docs/en/tab_example"
  },
  "1507": {
    "id": "1507",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/table_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/table_assembler.html"
  },
  "1508": {
    "id": "1508",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/tapas_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/tapas_for_question_answering.html"
  },
  "1509": {
    "id": "1509",
    "title": "Tasks",
    "content": "The Tasks screen shows a list of all documents that have been imported into the current project. Under each task you can see meta data about the task: the time of import, the user who imported the task and the annotators and reviewers assigned to the task. Task Assignment Project Owners/Managers can assign tasks to annotator(s) and reviewer(s) in order to better plan/distribute project work. Annotators and Reviewers can only view tasks that are assigned to them which means there is no chance of accidental work overlap. For assigning a task to an annotator, from the task page select one or more tasks and from the Assign dropdown choose an annotator. You can only assign a task to annotators that have already been added to the project team. For adding an annotator to the project team, select your project and navigate to the Setup &gt; Team menu item. On the Add Team Member page, search for the user you want to add, select the role you want to assign to him/her and click on Add To Team button. Project Owners can also be explicitly assigned as annotators and/or reviewers for tasks. It is useful when working in a small team and when the Project Owners are also involved in the annotation process. A new option Only Assigned checkbox is now available on the labeling page that allows Project Owners to filter the tasks explicitly assigned to them when clicking the Next button. NOTE: When upgrading from an older version of the Annotation Lab, the annotators will no longer have access to the tasks they worked on unless they are assigned to those explicitely by the admin user who created the project. Once they are assigned, they can resume work and no information is lost. Task Status At high level, each task can have one of the following statuses: Incomplete, when none of the assigned annotators has started working on the task. In Progress, when at least one of the assigned annotators has submitted at least one completion for this task. Submitted, when all annotators which were assigned to the task have submitted a completion which is set as ground truth (starred). Reviewed, in the case there is a reviewer assigned to the task, and the reviewer has reviewed and accepted the submited completion. To Correct, in the case the assigned reviewer has rejected the completion created by the Annotator. The status of a task varies according to the type of account the logged in user has (his/her visibility over the project) and according to the tasks that have been assigned to him/her. For Project Owner, Manager and Reviewer On the Analytics page and Tasks page, the Project Owner/Manager/Reviewer will see the general overview of the projects which will take into consideration the task level statuses as follows: Incomplete - Assigned annotators have not started working on this task In Progress - At least one annotator still has not starred (marked as ground truth) one submitted completion Submitted - All annotators that are assigned to the task have starred (marked as ground truth) one submitted completion Reviewed - Reviewer has approved all starred submitted completions for the task For Annotators On the Annotator’s Task page, the task status will be shown with regards to the context of the logged-in Annotator’s work. As such, if the same task is assigned to two annotators then: if annotator1 is still working and not submitted the task, then he/she will see task status as In-progress if annotator2 submits the task from his/her side then he/she will see task status as Submitted The following statuses are available on the Annotator’s view. Incomplete – Current logged-in annotator has not started working on this task. In Progress - At least one saved/submitted completions exist, but there is no starred submitted completion. Submitted - Annotator has at least one starred submitted completion. Reviewed - Reviewer has approved the starred submitted completion for the task. To Correct - Reviewer has rejected the submitted work. In this case, the star is removed from the reviewed completion. The annotator should start working on the task and resubmit. Note: The status of a task is maintained/available only for the annotators assigned to the task. When multiple Annotators are assigned to a task, the reviewer will see the task as submitted when all annotators submit and star their completions. Otherwise, if one of the assigned Annotators has not submitted or has not starred one completion, then the Reviewer will see the task as In Progress. Task Filters As normally annotation projects involve a large number of tasks, the Task page includes filtering and sorting options which will help the user identify the tasks he/she needs faster. Tasks can be sorted by time of import ascending or descending. Tasks can be filtered by the assigned tags, by the user who imported the task and by the status. There is also a search functionality which will identify the tasks having a given string on their name. The number of tasks visible on the screeen is customizable by selecting the predefined values from the Tasks per page drop-down. Task Search by Text, Label and Choice Annotation Lab offers advanced search features that help users identify the tasks they need based on the text or based on the annotations defined so far. Currently supported search queries are: text: patient -&gt; returns all tasks which contain the string “patient”; label: ABC -&gt; returns all tasks that have at least one completion containing a chunk with label ABC; label: ABC=DEF -&gt; returns all tasks that have at least one completion containing the text DEF labeled as ABC; choice: Sport -&gt; returns all tasks that have at least one completion which classified the task as Sport; choice: Sport,Politics -&gt; returns all tasks that have at least one completion containing multiple choices Sport and Politics. Search functionality is case insensitive, thus the following queries label: ABC=DEF , label: Abc=Def or label: abc=def are considered equivalent. Example: Consider a project with 3 tasks which are annotated as below: Search-query “label:LOC” will list as results Task 1 and Task 3. Search-query “label:WORK_OF_ART” will list as result Task 1 and Task 2. Search-query “label:PERSON=Leonardo” will list as result Task 1. Comments Comments can be added to each task by any team member. This is done by clicking the View comments link present on the rightmost side of each Task in the Tasks List page. It is important to notice that these comments are visible to everyone who can view the particular task.",
    "url": "/docs/en/alab/tasks",
    "relUrl": "/docs/en/alab/tasks"
  },
  "1510": {
    "id": "1510",
    "title": "Terminology",
    "content": "Concept Definition Project A project in Annotation Lab resembles a set of tasks that need to be annotated and/or reviewed by users in order to extract structured data and/or to train a DL model.Think of it as a factory assembly line for producing labels. For jumpstarting annotations on a project preannotations generated by existing models and/or rules can be used. Project configuration Specifies the type of documents that will be annotated as well as the labels, classes and relations which will be used for annotation. A project configuration can also reuse existing labels, classes and relations from pre-trained models or rules. Model In the context of the Annotation Lab use, the term model refers to a DL model build using John Snow Labs NLP libraries. Predictions Annotations automatically generated by Spark NLP models or user defined Spark NLP rules. Completions A series of annotations manually created or copied from automatic predictions and edited/validated by human annotators. Task A document that needs to be annotated by an annotator with or without the use of preannotation.",
    "url": "/docs/en/alab/terminology",
    "relUrl": "/docs/en/alab/terminology"
  },
  "1511": {
    "id": "1511",
    "title": "Test Project Configuration",
    "content": "Annotation Lab offer testing features for projects that reuse existing models/rules. In other words, if a project’s configuration references one or several (pre)trained models/rules it is possible to check how efficient those are when applied on custom data. The Test Configuration feature is available on the Train page, accessible from the Project Menu. During the training, a progress bar is shown on the top of the train page to show the status of the testing. Note This feature is available for Project Owners or Managers. The Test Configuration feature applies to project tasks with status submitted or reviewed, and which are tagged as Test. After the evaluaton is completed, the resulting logs can be downloaded to view the performance metrics. Note: Model evaluation can only be triggered in the presence of a valid Healthcare, Finance or/and Legal NLP license.",
    "url": "/docs/en/alab/test_project_configuration",
    "relUrl": "/docs/en/alab/test_project_configuration"
  },
  "1512": {
    "id": "1512",
    "title": "Release Testing Utilities",
    "content": "Utilities for Testing Models &amp; Modelshub Code Snippets You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_markdown() function : A local Models Hub Markdown snippet via path. a remote Models Hub Markdown snippet via URL. a local folder of Models Hub Markdown files. Generates report a list of local paths or urls to .md files. Generates a report Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;path/to/my/file.md&#39;) Test a Remote Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;https://nlp.johnsnowlabs.com/2022/08/31/legpipe_deid_en.html&#39;) Test a Folder with Models Hub Markdown Snippets This will scan the folder for all files ending with .md , test them and generate a report from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;my/markdown/folder&#39;) Test a List of Markdown References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb md_to_test = [&#39;legpipe_deid_en.html&#39;, &#39;path/to/local/markdown_snippet.md&#39;,] test_markdown(md_to_test) Utilities for Testing Notebooks You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_ipynb() function : A local .ipynb file a remote .ipynb URL, point to RAW githubuser content URL of the file when using git. a local folder of ipynb files, generates report a list of local paths or urls to .ipynb files. Generates a Report The entire John Snow Labs Workshop Certification Folder Generates a Report A sub-folder of the John Snow Labs Workshop Certification Folder , i.e. only OCR or only Legal. Generates a Report The generated Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing. If you think the notebook should not crash, check the file, there could be a generation error. stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;path/to/local/notebook.ipynb&#39;) Test a Remote Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;,) Test a Folder with Notebooks This will scan the folder for all files ending with .ipynb , test them and generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;my/notebook/folder&#39;) Test a List of Notebook References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb nb_to_test = [ &#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;, &#39;path/to/local/notebook.ipynb&#39;,] test_ipynb(nb_to_test) Run All Certification Notebooks Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP&#39;) Run Finance Certification Notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-FIN&#39;) Run Legal notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-LEG&#39;) Run Medical notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-MED&#39;) Run Open Source notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-OS&#39;)",
    "url": "/docs/en/jsl/testing-utils",
    "relUrl": "/docs/en/jsl/testing-utils"
  },
  "1513": {
    "id": "1513",
    "title": "Utilities for Testing Models & Modelshub Code Snippets",
    "content": "You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_markdown() function : A local Models Hub Markdown snippet via path. a remote Models Hub Markdown snippet via URL. a local folder of Models Hub Markdown files. Generates report a list of local paths or urls to .md files. Generates a report Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;path/to/my/file.md&#39;) Test a Remote Models Hub Markdown Snippet from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;https://nlp.johnsnowlabs.com/2022/08/31/legpipe_deid_en.html&#39;) Test a Folder with Models Hub Markdown Snippets This will scan the folder for all files ending with .md , test them and generate a report from johnsnowlabs.utils.modelhub_markdown import test_markdown test_markdown(&#39;my/markdown/folder&#39;) Test a List of Markdown References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb md_to_test = [&#39;legpipe_deid_en.html&#39;, &#39;path/to/local/markdown_snippet.md&#39;,] test_markdown(md_to_test)",
    "url": "/docs/en/jsl/testing-utils-modelshub",
    "relUrl": "/docs/en/jsl/testing-utils-modelshub"
  },
  "1514": {
    "id": "1514",
    "title": "Utilities for Testing Notebooks",
    "content": "You can use the John Snow Labs library to automatically test 10000+ models and 100+ Notebooks in 1 line of code within a small machine like a single Google Colab Instance and generate very handy error reports of potentially broken Models, Notebooks or Models hub Markdown Snippets. You can test the following things with the test_ipynb() function : A local .ipynb file a remote .ipynb URL, point to RAW githubuser content URL of the file when using git. a local folder of ipynb files, generates report a list of local paths or urls to .ipynb files. Generates a Report The entire John Snow Labs Workshop Certification Folder Generates a Report A sub-folder of the John Snow Labs Workshop Certification Folder , i.e. only OCR or only Legal. Generates a Report The generated Test-Report Pandas Dataframe has the columns: Report Column Description test_script is the generated script for testing. If you think the notebook should not crash, check the file, there could be a generation error. stderr Error logs of process ran. Print this to easily read stdout Standard Print logs of process ran. Print this to easily read success True if script ran successfully from top to bottom notebook The Source notebook for testing Test a Local Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;path/to/local/notebook.ipynb&#39;) Test a Remote Notebook from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;,) Test a Folder with Notebooks This will scan the folder for all files ending with .ipynb , test them and generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_ipynb(&#39;my/notebook/folder&#39;) Test a List of Notebook References Can be mixed with Urls and paths, will generate a report from johnsnowlabs.utils.notebooks import test_ipynb nb_to_test = [ &#39;https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/5.Spark_OCR.ipynb&#39;, &#39;path/to/local/notebook.ipynb&#39;,] test_ipynb(nb_to_test) Run All Certification Notebooks Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP&#39;) Run Finance Certification Notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-FIN&#39;) Run Legal notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-LEG&#39;) Run Medical notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-MED&#39;) Run Open Source notebooks only Will generate a report from johnsnowlabs.utils.notebooks import test_ipynb test_result = test_ipynb(&#39;WORKSHOP-OS&#39;)",
    "url": "/docs/en/jsl/testing-utils-notebooks",
    "relUrl": "/docs/en/jsl/testing-utils-notebooks"
  },
  "1515": {
    "id": "1515",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/matcher/text_matcher.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/matcher/text_matcher.html"
  },
  "1516": {
    "id": "1516",
    "title": "Text Summarization - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/text_summarization",
    "relUrl": "/text_summarization"
  },
  "1517": {
    "id": "1517",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/tf_ner_dl_graph_builder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/tf_ner_dl_graph_builder.html"
  },
  "1518": {
    "id": "1518",
    "title": "Third Party Projects",
    "content": "",
    "url": "/docs/en/third-party-projects",
    "relUrl": "/docs/en/third-party-projects"
  },
  "1519": {
    "id": "1519",
    "title": "Annotation Settings",
    "content": "Optimize view for large taxonomy For projects that include a large number of labels, we have created a way to optimize the taxonomy display so that users can quickly find the label they are searching for. To obtain the above display please use the following configuration: &lt;View&gt; &lt;Filter name=&quot;fl&quot; toName=&quot;label&quot; hotkey=&quot;shift+f&quot; minlength=&quot;1&quot; /&gt; &lt;View style=&quot; background:white; height: 100px; overflow-y:scroll; resize:vertical; position:sticky; top:0;&quot; &gt; &lt;Labels name=&quot;label&quot; toName=&quot;text&quot;&gt; &lt;Label value=&quot;Person&quot; background=&quot;red&quot;&gt;&lt;/Label&gt; &lt;Label value=&quot;Organization&quot; background=&quot;darkorange&quot;&gt;&lt;/Label&gt; &lt;/Labels&gt; &lt;/View&gt; &lt;View style=&quot; resize:vertical; margin-top:10px; max-height:400px; overflow-y:scroll;&quot; &gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;&gt;&lt;/Text&gt; &lt;/View&gt; &lt;/View&gt;",
    "url": "/docs/en/alab/tips",
    "relUrl": "/docs/en/alab/tips"
  },
  "1520": {
    "id": "1520",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/token2_chunk.html",
    "relUrl": "/api/python/modules/sparknlp/base/token2_chunk.html"
  },
  "1521": {
    "id": "1521",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/base/token_assembler.html",
    "relUrl": "/api/python/modules/sparknlp/base/token_assembler.html"
  },
  "1522": {
    "id": "1522",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/token/tokenizer.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/token/tokenizer.html"
  },
  "1523": {
    "id": "1523",
    "title": "",
    "content": "",
    "url": "/api/python/user_guide/training.html",
    "relUrl": "/api/python/user_guide/training.html"
  },
  "1524": {
    "id": "1524",
    "title": "Training Models with the fit() function",
    "content": "You can fit load a trainable nlp pipeline via nlp.load(&#39;train.&lt;model&gt;&#39;) Binary Text Classifier Training Sentiment classification training demo To train a Sentiment classifier model, you must pass a dataframe with a text column and a y column for the label. Uses a Deep Neural Network built in Tensorflow. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlp.load(&#39;train.sentiment&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train Classifier on BERT sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) #Train Classifier on ELECTRA sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.electra train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Multi Class Text Classifier Training Multi Class Text Classifier Training Demo To train the Multi Class text classifier model, you must pass a dataframe with a text column and a y column for the label. By default Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings. fitted_pipe = nlp.load(&#39;train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train on BERT sentence emebddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Multi Label Classifier training Train Multi Label Classifier on E2E dataset Train Multi Label Classifier on Stack Overflow Question Tags dataset This model can predict multiple labels for one sentence. Uses a Bidirectional GRU with Convolution model that we have built inside TensorFlow and supports up to 100 classes. To train the Multi Class text classifier model, you must pass a dataframe with a text column and a y column for the label. The y label must be a string column where each label is seperated with a seperator. By default, , is assumed as line seperator. If your dataset is using a different label seperator, you must configure the label_seperator parameter while calling the fit() method. By default, Universal Sentence Encoder Embeddings (USE) are used as sentence embeddings for training. fitted_pipe = nlp.load(&#39;train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) To train on custom embeddings you can specify some sentence embeddings before the training reference which will be used instead of the default USE embeddings. #Train on BERT sentence embeddings fitted_pipe = nlp.load(&#39;embed_sentence.bert train.multi_classifier&#39;).fit(train_df) preds = fitted_pipe.predict(train_df) Configure a custom line seperator #Use ; as label seperator fitted_pipe = nlp.load(&#39;embed_sentence.electra train.multi_classifier&#39;).fit(train_df, label_seperator=&#39;;&#39;) preds = fitted_pipe.predict(train_df) Part of Speech (POS) Training Your dataset must be in the form of Universal Dependencies. You must configure the dataset_path in the fit() method to point to the universal dependencies you wish to train on. You can configure the delimiter via the label_seperator parameter [POS training demo]](https://colab.research.google.com/drive/1CZqHQmrxkDf7y3rQHVjO-97tCnpUXu_3?usp=sharing) fitted_pipe = nlp.load(&#39;train.pos&#39;).fit(dataset_path=train_path, label_seperator=&#39;_&#39;) preds = fitted_pipe.predict(train_df) Named Entity Recognizer (NER) Training NER training demo You can train your own custom NER model with an CoNLL 20003 IOB formatted dataset. By default, Glove 100d Token Embeddings are used as features for the classifier. train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) If a nlp reference to a Token Embeddings model is added before the train reference, that Token Embedding will be used when training the NER model. # Train on BERT embeddigns train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;bert train.ner&#39;).fit(dataset_path=train_path) Chunk Entity Resolver Training Chunk Entity Resolver Training Tutorial Notebook Named Entities are sub pieces in textual data which are labled with classes. These classes and strings are still ambious though and it is not possible to group semantically identically entities withouth any definition of terminology. With the Chunk Resolver you can train a state of the art deep learning architecture to map entities to their unique terminological representation. Train a chunk resolver on a dataset with columns named y , _y and text. y is a label, _y is an extra identifier label, text is the raw text import pandas as pd dataset = pd.DataFrame({ &#39;text&#39;: [&#39;The Tesla company is good to invest is&#39;, &#39;TSLA is good to invest&#39;,&#39;TESLA INC. we should buy&#39;,&#39;PUT ALL MONEY IN TSLA inc!!&#39;], &#39;y&#39;: [&#39;23&#39;,&#39;23&#39;,&#39;23&#39;,&#39;23&#39;] &#39;_y&#39;: [&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;,&#39;TESLA&#39;], }) trainable_pipe = nlp.load(&#39;train.resolve_chunks&#39;) fitted_pipe = trainable_pipe.fit(dataset) res = fitted_pipe.predict(dataset) fitted_pipe.predict([&quot;Peter told me to buy Tesla &quot;, &#39;I have money to loose, is TSLA a good option?&#39;]) entity_resolution_confidence entity_resolution_code entity_resolution document ‘1.0000’ ‘23] ‘TESLA’ Peter told me to buy Tesla ‘1.0000’ ‘23] ‘TESLA’ I have money to loose, is TSLA a good option? Train with default glove embeddings untrained_chunk_resolver = nlp.load(&#39;train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Train with custom embeddings # Use Healthcare Embeddings trainable_pipe = nlp.load(&#39;en.embed.glove.healthcare_100d train.resolve_chunks&#39;) trained_chunk_resolver = untrained_chunk_resolver.fit(df) trained_chunk_resolver.predict(df) Rule based NER with Context Matcher Rule based NER with context matching tutorial notebook Define a rule based NER algorithm by providing Regex Patterns and resolution mappings. The confidence value is computed using a heuristic approach based on how many matches it has. A dictionary can be provided with setDictionary to map extracted entities to a unified representation. The first column of the dictionary file should be the representation with following columns the possible matches. import json # Define helper functions to write NER rules to file &quot;&quot;&quot;Generate json with dict contexts at target path&quot;&quot;&quot; def dump_dict_to_json_file(dict, path): with open(path, &#39;w&#39;) as f: json.dump(dict, f) &quot;&quot;&quot;Dump raw text file &quot;&quot;&quot; def dump_file_to_csv(data,path): with open(path, &#39;w&#39;) as f:f.write(data) sample_text = &quot;&quot;&quot;A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting. Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Twenty days ago. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about seven months, and then the girl grows faster until four years. From then until adolescence no differences in velocity can be detected. 21-02-2020 21/04/2020 &quot;&quot;&quot; # Define Gender NER matching rules gender_rules = { &quot;entity&quot;: &quot;Gender&quot;, &quot;ruleScope&quot;: &quot;sentence&quot;, &quot;completeMatchRegex&quot;: &quot;true&quot; } # Define dict data in csv format gender_data = &#39;&#39;&#39;male,man,male,boy,gentleman,he,him female,woman,female,girl,lady,old-lady,she,her neutral,neutral&#39;&#39;&#39; # Dump configs to file dump_dict_to_json_file(gender_data, &#39;gender.csv&#39;) dump_dict_to_json_file(gender_rules, &#39;gender.json&#39;) gender_NER_pipe = nlp.load(&#39;match.context&#39;) gender_NER_pipe.print_info() gender_NER_pipe[&#39;context_matcher&#39;].setJsonPath(&#39;gender.json&#39;) gender_NER_pipe[&#39;context_matcher&#39;].setDictionary(&#39;gender.csv&#39;, options={&quot;delimiter&quot;:&quot;,&quot;}) gender_NER_pipe.predict(sample_text) context_match context_match_confidence female 0.13 she 0.13 she 0.13 she 0.13 she 0.13 boy 0.13 girl 0.13 girl 0.13 Context Matcher Parameters You can define the following parameters in your rules.json file to define the entities to be matched Parameter Type Description entity str The name of this rule regex Optional[str] Regex Pattern to extract candidates contextLength Optional[int] defines the maximum distance a prefix and suffix words can be away from the word to match,whereas context are words that must be immediately after or before the word to match prefix Optional[List[str]] Words preceding the regex match, that are at most contextLength characters aways regexPrefix Optional[str] RegexPattern of words preceding the regex match, that are at most contextLength characters aways suffix Optional[List[str]] Words following the regex match, that are at most contextLength characters aways regexSuffix Optional[str] RegexPattern of words following the regex match, that are at most contextLength distance aways context Optional[List[str]] list of words that must be immediatly before/after a match contextException Optional[List[str]] ?? List of words that may not be immediatly before/after a match exceptionDistance Optional[int] Distance exceptions must be away from a match regexContextException Optional[str] Regex Pattern of exceptions that may not be within exceptionDistance range of the match matchScope Optional[str] Either token or sub-token to match on character basis completeMatchRegex Optional[str] Wether to use complete or partial matching, either &quot;true&quot; or &quot;false&quot; ruleScope str currently only sentence supported Saving a pipeline to disk train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) stored_model_path = &#39;./models/classifier_dl_trained&#39; fitted_pipe.save(stored_model_path) Loading a pipeline from disk train_path = &#39;/content/eng.train&#39; fitted_pipe = nlp.load(&#39;train.ner&#39;).fit(dataset_path=train_path) stored_model_path = &#39;./models/classifier_dl_trained&#39; fitted_pipe.save(stored_model_path) hdd_pipe = nlp.load(path=stored_model_path) Loading a pipeline as pyspark.ml.PipelineModel import pyspark # load the NLP pipeline as pyspark pipeline pyspark_pipe = pyspark.ml.PipelineModel.load(stored_model_path) # Generate spark Df and transform it with the pyspark Pipeline s_df = spark.createDataFrame(df) pyspark_pipe.transform(s_df).show()",
    "url": "/docs/en/jsl/training",
    "relUrl": "/docs/en/jsl/training"
  },
  "1525": {
    "id": "1525",
    "title": "Training",
    "content": "",
    "url": "/docs/en/training",
    "relUrl": "/docs/en/training"
  },
  "1526": {
    "id": "1526",
    "title": "Train New Model",
    "content": "A Project Owner or a Manager can use the completed tasks (completions) from a project to train a new Spark NLP model. The training feature can be found on the train page, accessible from the Project Menu. The training process can be triggered via a three step wizard that guides users and offers useful hints. Users can also opt for a synthesis view for initiating the training of a model. During the training, a progress bar is shown to give users basic information on the status of the training process. Deploy a new training job Users can perform multiple training jobs at the same time, depending on the available resources/license(s). Users can opt to create new training jobs independently from already running training/pre-annotation/OCR jobs. If resources/licenses are available when pressing the Train Model button a new training server is launched. The running servers can be seen by visiting the Clusters page. Named Entity Recognition For training a good Named Entity Recognition (NER) model, a relevant number of annotations must exist for all labels included in the project configuration. The recommendation is to have minimum 40-50 examples for each entity. Once this requirement is met, for training a new model users need to navigate to the Train page for the current project and follow some very simple steps: Select the type of model to train - Open source/Healthcare/Finance/Legal - and the embeddings to use; Define the training parameters and the train/test data split; Optionally turn on the Active Learning feature; Click the Train Model button. When triggering the training, users are prompted to choose either to immediately deploy models or just do training. If immediate deployment is chosen, then the Labeling config is updated according to the name of the new model. Notice how the name of the original model used for preannotations is replaced with the name of the new model in the configuration below. Information on the overall training progress is shown in the page. User can get indications on the success or failure of the training as well as check the live training logs (by pressing the Show Logs button). Once the training is finished, it is possible to download the training logs by clicking on the download logs icon of the recently trained NER model which includes information like training parameters and TF graph used along with precision, recall, f1 score, etc. This information is also accessible by clicking on the benchmarking icon available on the models on the Models page. Starting from version 4.3.0, it is possible to keep track of all previous training activities executed for a project. When pressing the History button from the Train page, users are presented with a list of all trainings triggered for the current project. Each training event is characterized by the source (manual, active learning), data used for training, date of event, and status. Training logs can also be downloaded for each training event. Training parameters In Annotation Lab, for mixed projects containing multiple types of annotations in a single project like classifications, NER, and assertion status, if multiple trainings were triggered at the same time using the same system resources and Spark NLP resources, the training component could fail because of resource limitations. In order to improve the usability of the system, dropdown options can be used to choose which type of training to run next. The project Owner or Manager of a project can scroll down to Training Settings and choose the training type. The drop-down gives a list of possible training types for that particular project based on its actual configuration. A second drop-down lists available embeddings which can be used for training the model. It is possible to tune the most common training parameters (Number of Epochs, Learning rate, Decay, Dropout, and Batch) by editing their values in Training Parameters. Test/Train data for a model can be randomly selected based on the Validation Split value or can be set using Test/Train tags. The later option is very useful when conducting experiments that require testing and training data to be the same on each run. It is also possible to train a model by using a sublist of tasks with predefined tags. This is done by specifying the targeted Tags on the Training Parameters (last option). Annotation Lab also includes additional filtering options for the training dataset based on the status of completions, either all submitted completions can be used for training or only the reviewed ones. Custom Training Script If users want to change the default Training script present within the Annotation Lab, they can upload their own training pipeline. In the Train Page, project owners can upload the training scripts. At the moment we are supporting custom training script just for NER projects. Selection of Completions During the annotation project lifetime, normally not all tasks/completions are ready to be used as a training dataset. This is why the training process selects completions based on their status: Filter tasks by tags (if defined in Training Parameters widget, otherwise all tasks are considered) For completed tasks, completions to be taken into account are also selected based on the following criteria: If a task has a completion accepted by a reviewer this is selected for training and all others are ignored; Completions rejected by a Reviewer are not used for training; If no reviewer is assigned to a task that has multiple submitted completions the completion to use for training purpose is the one created by the user with the highest priority. Assertion Status NER configurations for the healthcare domain are often mixed with Assertion Status labels. In this case, Annotation Lab offers support for training both types of models in one go. After the training is complete, the models will be listed in the Pretrained Labels section of the Project Configuration. Information such as the source of the model and time of training will be displayed as well. Once the model(s) has been trained, the project configuration will be automatically updated to reference the new model for prediction. Notice below, for the Assertion Status Label tag the addition of model attribute to indicate which model will be used for task pre-annotation for this label. &lt;Label value=&quot;Absent&quot; assertion=&quot;true&quot; model=&quot;assertion_jsl_annotation_manual.model&quot;/&gt; &lt;Label value=&quot;Past&quot; assertion=&quot;true&quot; model=&quot;assertion_jsl_annotation_manual.model&quot;/&gt; It is not possible to mark a label as an Assertion Status label and use a NER model to predict it. A validation error is shown in the Interface Preview in case an invalid Assertion model is used. The Annotation Lab only allows the use of one single Assertion Status model in the same project. Classification Annotation Lab supports two types of classification training: Single Choice Classification and Multi-Choice Classification. For doing so, it uses three important attributes of the Choices tag to drive the Classification Models training and pre-annotation. Those are name, choice and train. Attribute name The attribute name allows the naming of the different choices present in the project configuration, and thus the training of separate models based on the same project annotations. For example, in the sample configuration illustrated below, the name=”age” attribute, tells the system to only consider age-related classification information when training an Age Classifier. The value specified by the name attribute is also used to name the resulting Classification model (classification_age_annotation_manual). Attribute choice The choice attribute specifies the type of model that will be trained: multiple or single. For example, in the Labeling Config below, Age and Gender are Single Choice Classification categories while the Smoking Status is Multi-Choice Classification. Depending upon the value of this attribute, the respective model will be trained as a Single Choice Classifier or Multi-Choice Classifier. &lt;View&gt; &lt;View style=&quot;overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;Header value=&quot;Smoking Status&quot;/&gt; &lt;Choices name=&quot;smokingstatus&quot; toName=&quot;text&quot; choice=&quot;multiple&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Smoker&quot;/&gt; &lt;Choice value=&quot;Past Smoker&quot;/&gt; &lt;Choice value=&quot;Nonsmoker&quot;/&gt; &lt;/Choices&gt; &lt;Header value=&quot;Age&quot;/&gt; &lt;Choices name=&quot;age&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Child (less than 18y)&quot; hotkey=&quot;c&quot;/&gt; &lt;Choice value=&quot;Adult (19-50y)&quot; hotkey=&quot;a&quot;/&gt; &lt;Choice value=&quot;Aged (50+y)&quot; hotkey=&quot;o&quot;/&gt; &lt;/Choices&gt; &lt;Header value=&quot;Gender&quot;/&gt; &lt;Choices name=&quot;gender&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; &lt;Choice value=&quot;Female&quot; hotkey=&quot;f&quot;/&gt; &lt;Choice value=&quot;Male&quot; hotkey=&quot;m&quot;/&gt; &lt;/Choices&gt; &lt;/View&gt; Attribute train Annotation Lab restricts the training of two or more Classification Models at the same time. If there are multiple Classification categories in a project (like the one above), only the category whose name comes first in alphabetical order will be trained by default. In the above example, based on the value of the name attribute, we conclude that the Age classifier model is trained. The model to be trained can also be specified by setting the train=”true” attribute for the targeted Choices tag (like the one defined in Gender category below). &lt;View&gt; &lt;View style=&quot;overflow: auto;&quot;&gt; &lt;Text name=&quot;text&quot; value=&quot;$text&quot;/&gt; &lt;/View&gt; &lt;Header value=&quot;Smoking Status&quot;/&gt; &lt;Choices name=&quot;smokingstatus&quot; toName=&quot;text&quot; choice=&quot;multiple&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;Header value=&quot;Age&quot;/&gt; &lt;Choices name=&quot;age&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;Header value=&quot;Gender&quot;/&gt; &lt;Choices name=&quot;gender&quot; train=&quot;true&quot; toName=&quot;text&quot; choice=&quot;single&quot; showInLine=&quot;true&quot;&gt; ... &lt;/Choices&gt; &lt;/View&gt; The trained classification models are available to reuse in any project and can be added on step 3 of the Project Configuration wizard. The classification models trained using Annotation Lab also have attached benchmarking information. The training logs include the confusion matrix, helpful in understanding the performance of the model and in checking if the model is underfitting or overfitting. The confusion matrix is also available on the models tiles on the Models page, and is accessible by clicking on the benchmarking icon. Visual NER Training Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. Model Training The training feature for Visual NER projects can be activated from the Setup page via the “Train Now” button (See 1). From the Training Settings sections, users can tune the training parameters (e.g. Epoch, Batch) and choose the tasks to use for training the Visual NER model (See 3). Information on the training progress is shown in the top right corner of the Model Training tab (See 2). Users can check detailed information regarding the success or failure of the last training. Training Failure can occur because of: Insufficient number of completions Poor quality of completions Insufficient CPU and Memory Wrong training parameters When triggering the training, users can choose to immediately deploy the model or just train it without deploying. If immediate deployment is chosen, then the labeling config is updated with references to the new model so that it will be used for preannotations. License Requirements Visual NER annotation, training and preannotation features are dependent on the presence of a Visual NLP license. Licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. Training Server Specification The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Mixed Projects If a project is set up to include Classification, Named Entity Recognition and Assertion Status labels and the three kinds of annotations are present in the training data, it is possible to train three models: one for Named Entity Recognition, one for Assertion Status, and one for Classification at the same time. The training logs from all three trainings can be downloaded at once by clicking the download button present in the Training section of the Setup Page. The newly trained models will be added to the Spark NLP pipeline config. Support for European Languagues Users can download English, German, Spanish, Portuguese, Italian, Danish and Romanian pretrained models from the NLP Models Hub and use them for pre-annotation. Annotation Lab also offers support for training/tuning models in the above languages.",
    "url": "/docs/en/alab/training_configurations",
    "relUrl": "/docs/en/alab/training_configurations"
  },
  "1527": {
    "id": "1527",
    "title": "Training Parameters",
    "content": "Annotation Lab supports the Transfer Learning feature offered by Spark NLP for Healthcare 3.1.2. This feature is available for project manages and project owners, but only if a valid Healthcare NLP license is loaded into the Annotation Lab. In this case, the feature can be activated for any project by navigating to the Train page. It requires the presence of a base model trained with MedicalNERModel. If a MedicalNER model is available on the Models Hub section of the Annotation Lab, it can be chosen as a starting point of the training process. This means the base model will be Fine Tuned with the new training data. When Fine Tuning is enabled, the same embeddings used for training the base model will be used to train the new model. Those need to be available on the Models Hub section as well. If present, embeddings will be automatically selected, otherwise users must go to the Models Hub page and download or upload them.",
    "url": "/docs/en/alab/transfer_learning",
    "relUrl": "/docs/en/alab/transfer_learning"
  },
  "1528": {
    "id": "1528",
    "title": "Transformers",
    "content": "",
    "url": "/docs/en/transformers",
    "relUrl": "/docs/en/transformers"
  },
  "1529": {
    "id": "1529",
    "title": "FAQ",
    "content": "Useful knowledge basebase for troubleshooting some of the common issues and tips for customizing the Annotation Lab set up and configurations. 1. How to deploy multiple preannotation/training servers in parallel? By default the Annotation Lab installation is configured to use only one model server. If you want to allow the deployment of multiple model servers (e.g. up to 3), open the annotationlab-upgrader.sh script located under the artifacts folder of your Annotation Lab installation directory. Update the below configuration properties in the annotaionlab-upgrader.sh script for deploying upto 3 model servers. --set airflow.model_server.count=3 --set model_server.count=3 Save the file and re-run this script for the changes to take effect. 2. How can I access the API documentation? API documentation is included in the Annotation Lab setup. So you will need to first set up Annotation Lab. Only admin user can view the API documentation available under Settings &gt; API Integration. 3. Can I upload/download tasks/data using API? Yes, it is possible to perform both the upload and download operations using API. There is import and export API for those operations. You can get more details about it from the API documentation. 4. Can the user who created a project/task be assigned annotation/review tasks? The project owner has by default all permissions (annotator, reviewer, manager). So we do not need to explicitly assign the annotator or reviewer role to the owner for the tasks. 5. Can I download the swagger API documentation? No. At present you can only access the API documentation directly from the API integration page under Settings &gt; API Integration. 6. How to uninstall Kubernetes during faulty install and re-install Annotation Lab? If you have access to backend CLI then you can follow the steps below to fix faulty installation issue. Go to /usr/local/bin cd /usr/local/bin Run the uninstall script ./k3s-uninstall.sh Re-run the installer script from the project folder ./k3s-installer.sh Run the annotation lab installer ./annotationlab-installer.sh This will take some time and produce the output below: NAME STATUS ROLES AGE VERSION ip-172-31-91-230 Ready control-plane,master 3m38s v1.22.4+k3s1 Image is up to date for sha256:18481c1d051558c1e2e3620ba4ddf15cf4734fe35dc45fbf8065752925753c9d Image is up to date for sha256:a5b6ca180ebba94863ac9310ebcfacaaa64aca9efaa3b1f07ff4fad90ff76f68 Image is up to date for sha256:55208fe5388a7974bc4e3d63cfe20b2f097a79e99e9d10916752c3f8da560aa6 Image is up to date for sha256:a566a53e9ae7171faac1ce58db1d48cf029fbeb6cbf28cd53fd9651d5039429c Image is up to date for sha256:09ad16bd0d3fb577cbfdbbdc754484f707b528997d64e431cba19ef7d97ed785 NAME: annotationlab LAST DEPLOYED: Thu Sep 22 14:16:10 2022 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: ############################################################################# Thank you for installing annotationlab. Please run the following commands to get the credentials. export KEYCLOAK_CLIENT_SECRET_KEY=$(kubectl get secret annotationlab-secret --template={{.data.KEYCLOAK_CLIENT_SECRET_KEY}} | base64 --decode; echo) export PG_PASSWORD=$(kubectl get secrets annotationlab-postgresql -o yaml | grep &#39; postgresql-password:&#39; | cut -d &#39; &#39; -f 4 | base64 -d; echo) export PG_KEYCLOAK_PASSWORD=$(kubectl get secrets annotationlab-keyclo-postgres -o yaml | grep &#39; postgresql-password:&#39; | cut -d &#39; &#39; -f 4 | base64 -d; echo) export ADMIN_PASSWORD=$(kubectl get secret annotationlab-keyclo-admincreds --template={{.data.password}} | base64 --decode; echo) #############################################################################",
    "url": "/docs/en/alab/troubleshooting",
    "relUrl": "/docs/en/alab/troubleshooting"
  },
  "1530": {
    "id": "1530",
    "title": "Video Tutorials",
    "content": "{%- include extensions/youtube.html id=&#39;ycrJX_UMA6I&#39; -%}Programmatic labeling in Annotation Lab. Suvrat Joshi - October, 2022 {%- include extensions/youtube.html id=&#39;tzEwzT_HmXM&#39; -%}How to create a NER project in Annotation Lab. Suvrat Joshi - September, 2022 {%- include extensions/youtube.html id=&#39;jgUylZlz3uA&#39; -%}End-to-End No-Code Development of NER model for Text with Annotation Lab. Dia Trambitas - April, 2022 {%- include extensions/youtube.html id=&#39;JDDmTF6ir9k&#39; -%}End-to-End No-Code Development of Visual NER Models for PDFs and Images. Dia Trambitas - April, 2022 Add a new user. Ida Lucente - January, 2021 Update password from User Profile. Ida Lucente - January, 2021 Collect the client secret. Ida Lucente - January, 2021 Setup 2FA. Ida Lucente - January, 2021 API usage example. Ida Lucente - January, 2021",
    "url": "/docs/en/alab/tutorials",
    "relUrl": "/docs/en/alab/tutorials"
  },
  "1531": {
    "id": "1531",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/dependency/typed_dependency_parser.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/dependency/typed_dependency_parser.html"
  },
  "1532": {
    "id": "1532",
    "title": "Understand Entities in Context - Finance NLP Demos & Notebooks",
    "content": "",
    "url": "/understand_financial_entities_context",
    "relUrl": "/understand_financial_entities_context"
  },
  "1533": {
    "id": "1533",
    "title": "Understand Entities in Context - Spark NLP Demos & Notebooks",
    "content": "",
    "url": "/understand_legal_entities_context",
    "relUrl": "/understand_legal_entities_context"
  },
  "1534": {
    "id": "1534",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/universal_sentence_encoder.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/universal_sentence_encoder.html"
  },
  "1535": {
    "id": "1535",
    "title": "User Management",
    "content": "Basic user management features are present in the Annotation Lab. The user with the admin privilege can add or remove other users from the system or can edit user information if necessary. This feature is available by selecting the Users option under the Settings menu from the navigation panel. All user accounts created on the Annotation Lab can be seen on the Users page. The table shows the username, first name, last name, and email address of all created user accounts. A user with the admin privilege can edit or delete that information, add a user to a group or change the user’s password. User Details Annotation Lab stores basic information for each user. Such as the First Name, Last Name, and Email. It is editable from the Details section by any user with admin privilege. User Groups Currently, two user groups are available: Annotators and Admins. By default, a new user gets added to the Annotators group. It means the user will not have access to any admin features, such as user management or other settings. To add a user to the admin group, a user with admin privilege needs to navigate to the Users page, click on the concerned username or select the Edit option from the More Actions icon, then go to the Group section and check the Admins checkbox. Reset User Credentials A user with the admin privilege can change the login credentials for another user by navigating to the Credentials section of the edit user page and defining a new (temporary) password. For extra protection, the user with the admin privilege can enforce the password change on the next login. SAML Integration AnnotationLab supports Security Assertion Markup Language (SAML). To login to AnnotationLab using SAML, follow the steps below. SAML Server Setup Run the following command to setup a sample SAML server in a Docker environment: docker run --rm --name mysamlserver -p 8081:8080 -p 8443:8443 -e SIMPLESAMLPHP_SP_ENTITY_ID=http://{IP}/auth/realms/master -e SIMPLESAMLPHP_SP_ASSERTION_CONSUMER_SERVICE=http://{IP}/auth/realms/master/broker/saml/endpoint --network annotationlab kristophjunge/test-saml-idp SAML Configuration Follow the steps described below to setup a SAML connection. Goto AnnotationLab Keyclock console and navigate to Identity Providers under Configure on the left-side menu. Choose SAML v2.0 from Add Provider drop-down menu and a configuration page should appear. Provide values for Alias(e.g: saml) and Display Name(e.g: SAML). The value for Display Name will be seen in the login page. Now, set the value of the following attributes as shown below: Enabled: On Store Tokens: On First Login Flow : first broker login Sync Mode: force Under SAML Config specify values for the following parameters as provided by SAML sever: Service Provider Entity ID Single Sign-On Service URL Single Logout Service URL Choose a Principal Type(e.g: Attribute[Name]) and add value to Principal Attribute(e.g. email) according to the data provided by SAML server Click on the Save button to save the changes. Identity Provider Mapper An Identity Provider Mapper must be defined for importing SAML data provided by the External Identity Provider (IDP) and using it for authenticating into Annotation Lab. This allows user profile and other user information to be imported and made available into Annotation Lab. On Identity Providers &gt; SAML page click on the Mappers tab located next to the Settings tab and follow the steps below: Click on Create. This should open a form to add a new Identity Provider Mapper Set the value for the following attributes: Name(e.g: uma_protection mapper) Sync Mode Override: inherit Mapper Type: Hardcoded Role Click on the Select Role button and under the Client Roles menu put annotationlab. Now, select uma_protection and click on Select client role. annotationlab.uma_protection should be the value displayed for Role Save the changes Default Group Default groups are used for assigning group membership automatically whenever any new user is created. Add Annotators as the default group using the following steps: Goto Groups, on the left side panel under Manages Select the Default Groups tab Under Available Groups select Annotators and then click on the Add button Now, Annotators should be listed under Default Groups. Login to Annotation Lab Goto the Annotation Lab’s login dashboard and click on the display name which was set earlier(e.g: SAML). This is displayed under Or sign in with. Login with the data provided by the SAML server here: The user account information is updated and the user is redirected to Annotation Lab and presented with the Project dashboard. NOTES: Users added as an IDP will be available in the Users tab on the left side under Manages",
    "url": "/docs/en/alab/user_management",
    "relUrl": "/docs/en/alab/user_management"
  },
  "1536": {
    "id": "1536",
    "title": "Utility & Helper Modules",
    "content": "NLP Lab (Annotation Lab) Interface Module Spark NLP for Healthcare provides functionality to interact with the NLP Lab using easy-to-use functions. NLP Lab is a tool for multi-modal data annotation. It allows annotation teams to efficiently collaborate to generate training data for ML models and/or to validate automatic annotations generated by those. NLP Lab Intreacting Module provides programmatic interactions with the NLP Lab. A detailed usage examples can be found at Complete NLP Lab Module SparkNLP JSL, and Python’s documentation in the Python API. Following are the functionalities supported by the module: Generating a CoNLL formatted file from the annotation JSON for training an NER model. Generating a csv/excel formatted file from the annotation JSON for training classification, assertion, and relation extraction models. Build preannotation JSON file using Spark NLP pipelines, saving it as a JSON and uploading preannotations to a project. Interacting with the NLP Lab instance, and setting up projects for NLP Lab. Getting the list of all projects in the NLP Lab instance. Creating New Projects. Deleting Projects. Setting &amp; editing configuration of projects. Accessing/getting configuration of any existing project. Upload tasks to a project. Deleting tasks of a project. Start Module # import the module from sparknlp_jsl.alab import AnnotationLab alab = AnnotationLab() Generate Data for Traing a Classification Model alab.get_classification_data( # required: path to NLP Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth=False) Converting The Json Export into a Conll Format Suitable for Training an Ner Model alab.get_conll_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path=&quot;alab_demo.json&quot;, # required: name of the CoNLL file to save output_name=&quot;conll_demo&quot;, # optional: path for CoNLL file saving directory, defaults to &#39;exported_conll&#39; # save_dir=&quot;exported_conll&quot;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth=False, # optional: labels to exclude from CoNLL; these are all assertion labels and irrelevant NER labels, # defaults to empty list # excluded_labels=[&#39;ABSENT&#39;], # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined # regex_pattern=&quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot; # optional: list of NLP Lab task titles to exclude from CoNLL, defaults to empty list # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from CoNLL, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Converting The JSON Export into a Dataframe Suitable for Training an Assertion Model alab.get_assertion_data( # required: SparkSession with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path = &#39;alab_demo.json&#39;, # required: annotated assertion labels to train on assertion_labels = [&#39;ABSENT&#39;], # required: relevant NER labels that are assigned assertion labels relevant_ner_labels = [&#39;PROBLEM&#39;, &#39;TREATMENT&#39;], # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False # ground_truth = False, # optional: assertion label to assign to entities that have no assertion labels, defaults to None # unannotated_label = &#39;PRESENT&#39;, # optional: set a pattern to use regex tokenizer, defaults to regular tokenizer if pattern not defined # regex_pattern = &quot; s+|(?=[-.:;*+,$&amp;% [ ]])|(?&lt;=[-.:;*+,$&amp;% [ ]])&quot;, # optional: set the strategy to control the number of occurrences of the unannotated assertion label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None # unannotated_label_strategy = None, # optional: dictionary in the format {&#39;ENTITY_LABEL&#39;: sample_weight_or_counts} to control the number of # occurrences of the unannotated assertion label in the output dataframe, where &#39;ENTITY_LABEL&#39; are the # NER labels that are assigned the unannotated assertion label, and sample_weight_or_counts should be # between 0 and 1 if `unannotated_label_strategy` is &#39;weighted&#39; or between 0 and the max number of # occurrences of that NER label if `unannotated_label_strategy` is &#39;counts&#39; # unannotated_label_strategy_dict = {&#39;PROBLEM&#39;: 0.5, &#39;TREATMENT&#39;: 0.5}, # optional: list of NLP Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Converting The JSON Export into a Dataframe Suitable for Training a Relation Extraction Model alab.get_relation_extraction_data( # required: Spark session with spark-nlp-jsl jar spark=spark, # required: path to NLP Lab JSON export input_json_path=&#39;alab_demo.json&#39;, # optional: set to True to select ground truth completions, False to select latest completions, # defaults to False ground_truth=True, # optional: set to True to assign a relation label between entities where no relation was annotated, # defaults to False negative_relations=True, # optional: all assertion labels that were annotated in the NLP Lab, defaults to None assertion_labels=[&#39;ABSENT&#39;], # optional: plausible pairs of entities for relations, separated by a &#39;-&#39;, use the same casing as the # annotations, include only one relation direction, defaults to all possible pairs of annotated entities relation_pairs=[&#39;DATE-PROBLEM&#39;,&#39;TREATMENT-PROBLEM&#39;,&#39;TEST-PROBLEM&#39;], # optional: set the strategy to control the number of occurrences of the negative relation label # in the output dataframe, options are &#39;weighted&#39; or &#39;counts&#39;, &#39;weighted&#39; allows to sample using a # fraction, &#39;counts&#39; allows to sample using absolute counts, defaults to None negative_relation_strategy=&#39;weighted&#39;, # optional: dictionary in the format {&#39;ENTITY1-ENTITY2&#39;: sample_weight_or_counts} to control the number of # occurrences of negative relations in the output dataframe for each entity pair, where &#39;ENTITY1-ENTITY2&#39; # represent the pairs of entities for relations separated by a `-` (include only one relation direction), # and sample_weight_or_counts should be between 0 and 1 if `negative_relation_strategy` is &#39;weighted&#39; or # between 0 and the max number of occurrences of negative relations if `negative_relation_strategy` is # &#39;counts&#39;, defaults to None negative_relation_strategy_dict = {&#39;DATE-PROBLEM&#39;: 0.1, &#39;TREATMENT-PROBLEM&#39;: 0.5, &#39;TEST-PROBLEM&#39;: 0.2}, # optional: list of NLP Lab task IDs to exclude from output dataframe, defaults to None # excluded_task_ids = [2, 3] # optional: list of NLP Lab task titles to exclude from output dataframe, defaults to None # excluded_task_titles = [&#39;Note 1&#39;]) Generate JSON Containing Pre-annotations Using a Spark NLP Pipeline pre_annotations, summary = alab.generate_preannotations( # required: list of results. all_results = results, # requied: output column name of &#39;DocumentAssembler&#39; stage - to get original document string. document_column = &#39;document&#39;, # required: column name(s) of ner model(s). Note: multiple NER models can be used, but make sure their results don&#39;t overrlap. # Or use &#39;ChunkMergeApproach&#39; to combine results from multiple NER models. ner_columns = [&#39;ner_chunk&#39;], # optional: column name(s) of assertion model(s). Note: multiple assertion models can be used, but make sure their results don&#39;t overrlap. # assertion_columns = [&#39;assertion_res&#39;], # optional: column name(s) of relation extraction model(s). Note: multiple relation extraction models can be used, but make sure their results don&#39;t overrlap. # relations_columns = [&#39;relations_clinical&#39;, &#39;relations_pos&#39;], # optional: This can be defined to identify which pipeline/user/model was used to get predictions. # Default: &#39;model&#39; # user_name = &#39;model&#39;, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; # titles_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. # id_offset=0) Interacting with NLP Lab alab = AnnotationLab() username=&#39;&#39; password=&#39;&#39; client_secret=&#39;&#39; annotationlab_url=&#39;&#39; alab.set_credentials( # required: username username=username, # required: password password=password, # required: secret for you alab instance (every alab installation has a different secret) client_secret=client_secret, # required: http(s) url for you NLP lab annotationlab_url=annotationlab_url) Get All Visible Projects alab.get_all_projects() Create a New Project alab.create_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: other details about project. Default: Empty string project_description=&#39;&#39;, # optional: Sampling option of tasks. Default: random project_sampling=&#39;&#39;, # optional: Annotation Guidelines of project project_instruction=&#39;&#39;) Delete a Project alab.delete_project( # required: unique name of project project_name = &#39;alab_demo&#39;, # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False) Upload Tasks to a Project alab.upload_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of examples / tasks as string (One string is one task). task_list=task_list, # optional: Option to assign custom titles to tasks. By default, tasks will be titled as &#39;task_#&#39; title_list = [], # optional: If there are already tasks in project, then this id offset can be used to make sure default titles &#39;task_#&#39; do not overlap. # While upload a batch after the first one, this can be set to number of tasks currently present in the project # This number would be added to each tasks&#39;s ID and title. id_offset=0) Delete Tasks from a Project alab.delete_tasks( # required: name of project to upload tasks to project_name=&#39;alab_demo&#39;, # required: list of ids of tasks. # note: you can get task ids from the above step. Look for &#39;task_ids&#39; key. task_ids=[1, 2], # optional: confirmation for deletion. Default: False - will ask for confirmation. If set to true, will delete directly. confirm=False) Upload Pre-annotations to NLP Lab alab.upload_preannotations( # required: name of project to upload annotations to project_name = &#39;alab_demo&#39;, # required: preannotation JSON preannotations = pre_annotations) Deidentification Module Spark NLP for Healthcare provides functionality to apply Deidentification using easy-to-use module named Deid. The Deid module is a tool for deidentifying Personal Health Information from data in a file path. It can be used with custom SparkNLP NER pipelines or without any pipeline specified. It returns the deidentification results as a pyspark dataframe as well as a csv or json file. The module also includes functionality for applying Structured Deidentification task to data from a file path. The function, deidentify(), can be used with a custom pipeline or without defining any custom pipeline. structured_deidentifier() function can be used for the Structured Deidentification task. Apply Deidentification With a Custom Pipeline from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A custom pipeline model to be used for deidentification. If not specified, the default is None. custom_pipeline=nlpModel, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;, &quot;text_1&quot;: &quot;obfuscate&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;fixed_length_chars&quot;, #optional: The fixed mask length. Default is 4. fixed_mask_length=4, #optional: The final chunk column name of the custom pipeline that will be deidentified, if specified. Default is &quot;ner_chunk&quot;. ner_chunk=&quot;ner_chunk&quot;, #optional: The corresponding document column name of the custom pipeline, if specified. Default is &quot;document&quot; document=&quot;document&quot;, #optional: The corresponding sentence column name of the custom pipeline, if specified. Default is &quot;sentence&quot; sentence=&quot;sentence&quot;, #optional: The corresponding token column name of the custom pipeline, if specified. Default is &quot;token&quot; token=&quot;token&quot;, #optional: The source of the reference file for obfuscation. Default is &quot;faker&quot;. #obfuscate_ref_source=&quot;both&quot;, #optional: The path of the reference file for obfuscation. Default is None. #obfuscate_ref_file_path=&quot;obfuscation.txt&quot;, #optional: Obfuscate date. Default is True. #obfuscate_date=True, #optional: The document hash coder column name. Default is &quot;documentHash&quot;. #documentHashCoder_col_name= &quot;documentHash&quot; #optional: ID column name. Default is &quot;id&quot;. #id_column_name= &quot;ID&quot; #optional: Date shift column name. Default is &quot;date_shift&quot;. #date_shift_column_name= &quot;date_shift&quot; #optional: The date tag. Default is &quot;DATE&quot;. #date_tag=&quot;DATE&quot; #optional: Language. Default is &quot;en&quot; #language=&quot;en&quot; #optional: Region. Default is &quot;us&quot; #region=&quot;us&quot; #optional: Age group obfuscation. Default is False. #age_group_obfuscation=True #optional: Age ranges for obfuscation. Default is [1, 4, 12, 20, 40, 60, 80]. #age_ranges=[1, 4, 12, 20, 40, 60, 80] #optional: Shift days. Default is False. #shift_days=False #optional: The number of days to shift. Default is None. #number_of_days=5 #optional: Use unnormalized date. Default is False. #unnormalized_date=True #optional: The unnormalized mode. Default is &quot;mask&quot;. #unnormalized_mode=&quot;obfuscate&quot; ) ++-+-+-+-+ | ID| text| text_deidentified| text_1| text_1_deidentified| ++-+-+-+-+ | 0|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : ** , ** , M.D . , Name : ** MR .|Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-...|Date : 10-16-1991 PCP : Alveda Castles , 26 years-old , Record date...| ++-+-+-+-+ Apply Deidentification With No Custom Pipeline from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.deidentify( # required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: Fields to be deidentified and their deidentification modes, by default {&quot;text&quot;: &quot;mask&quot;} fields={&quot;text&quot;: &quot;mask&quot;}, #optional: The masking policy. Default is &quot;entity_labels&quot;. masking_policy=&quot;entity_labels&quot;, #optional: Age group obfuscation. Default is False. #age_group_obfuscation=True #optional: Age ranges for obfuscation. Default is [1, 4, 12, 20, 40, 60, 80]. #age_ranges=[1, 4, 12, 20, 40, 60, 80] #optional: Shift days. Default is False. #shift_days=False #optional: The number of days to shift. Default is None. #number_of_days=5 #optional: Use unnormalized date. Default is False. #unnormalized_date=True #optional: The unnormalized mode. Default is &quot;mask&quot;. #unnormalized_mode=&quot;obfuscate&quot; ) ++-+-+ | ID| text_original| text_deid| ++-+-+ | 0| &quot;| &quot;| | 1|Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson ...|Record date : &lt;DATE&gt; , &lt;DOCTOR&gt; , M.D . , Name : &lt;PATIENT&gt; , MR # &lt;...| | 2| &quot;| &quot;| ++-+-+ Apply Structured Deidentification from sparknlp_jsl import Deid deid_implementor= Deid( # required: Spark session with spark-nlp-jsl jar spark ) res= deid_implementor.structured_deidentifier( #required: The path of the input file. Default is None. File type must be &#39;csv&#39; or &#39;json&#39;. input_file_path=&quot;data.csv&quot;, #optional: The path of the output file. Default is &#39;deidentified.csv&#39;. File type must be &#39;csv&#39; or &#39;json&#39;. output_file_path=&quot;deidentified.csv&quot;, #optional: The separator of the input csv file. Default is &quot; t&quot;. separator=&quot;,&quot;, #optional: A dictionary that contains the column names and the tags that should be used for deidentification. Default is {&quot;NAME&quot;:&quot;PATIENT&quot;,&quot;AGE&quot;:&quot;AGE&quot;} columns_dict= {&quot;NAME&quot;: &quot;ID&quot;, &quot;DOB&quot;: &quot;DATE&quot;}, #optional: The seed value for the random number generator. Default is {&quot;NAME&quot;: 23, &quot;AGE&quot;: 23} columns_seed= {&quot;NAME&quot;: 23, &quot;DOB&quot;: 23}, #optional: The source of the reference file. Default is faker. ref_source=&quot;faker&quot;, #optional: The number of days to be shifted. Default is None shift_days=5, #optional: The path of the reference file for obfuscation. Default is None. #obfuscateRefFile: &quot;obfuscator_unique_ref_test.txt&quot;, #optional: A list of date formats. Default is [&quot;dd/MM/yyyy&quot;, &quot;dd-MM-yyyy&quot;, &quot;d/M/yyyy&quot;, &quot;dd-MM-yyyy&quot;, &quot;d-M-yyyy&quot;] #date_formats=[&quot;dd/MM/yyyy&quot;, &quot;dd-MM-yyyy&quot;] ) +-++--++-+ | NAME| DOB| ADDRESS|SBP| TEL| +-++--++-+ |[N2649912]|[18/02/1977]| 711 Nulla St.|140| 673 431234| | [W466004]|[28/02/1977]| 1 Green Avenue.|140|+23 (673) 431234| | [M403810]|[16/04/1900]|Calle del Liberta...|100| 912 345623| +-++--++-+ Compatibility This module helps to find appropriate model versions depending your distribution of John Snow Labs products. By searching our vast repository of models available at NLP Model Hub, we can return a JSON-like file with the models’s information (using method .findVersion()) or print the models that match a given query (using method .showVersion()). To use it, simply run the following: from johnsnowlabs import medical # Or: from sparknlp_jsl.compatibility import Compatibility compatibility = medical.Compatibility() # Returns a list of dict objects found_models = compatibility.findVersion(&#39;ner_clinical&#39;) To tabulate and visualize all retrieved models, you can: import pandas as pd models_df = pd. | | name | sparkVersion | version | language | date | readyToUse | |:|:-|:|:-|:--|:|:-| | 0 | ner_clinical_noncontrib | 2.4 | 2.3.0 | en | 2019-11-14T17:07:35.434 | true | | 1 | ner_clinical_large | 2.4 | 2.5.0 | en | 2020-05-21T00:35:02.624 | true | | 2 | ner_clinical | 3 | 3.0.0 | en | 2021-01-27T12:52:59.087 | true | | 3 | ner_clinical_large_en | 3 | 3.0.0 | en | 2021-03-31T12:32:55.357 | true | | 4 | ner_clinical | 3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 5 | ner_clinical_large | 3 | 3.0.0 | en | 2021-03-31T15:55:14.650 | true | | 6 | ner_clinical_biobert | 3 | 3.0.0 | en | 2021-04-01T07:06:52.919 | true | | 7 | ner_clinical | 2.3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 8 | ner_clinical_biobert | 2.3 | 3.0.0 | en | 2021-04-01T07:06:52.919 | true | | 9 | ner_clinical | 2.3 | 3.0.0 | en | 2021-01-27T12:52:59.087 | true | | 10 | ner_clinical | 2.3 | 3.0.0 | en | 2021-03-31T16:33:39.368 | true | | 11 | ner_clinical_large | 2.3 | 3.0.0 | en | 2021-03-31T15:55:14.650 | true | | 12 | bert_token_classifier_ner_clinical | 2.4 | 3.2.0 | en | 2021-08-28T15:51:44.492 | true | | 13 | bert_token_classifier_ner_clinical | 2.4 | 3.3.4 | en | 2022-01-06T12:42:21.908 | true | | 14 | bert_token_classifier_ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-15T12:08:50.209 | true | | 15 | bert_token_classifier_ner_clinical_pipeline | 2.4 | 3.4.1 | en | 2022-03-15T12:56:42.874 | true | | 16 | ner_clinical_biobert_pipeline | 3 | 3.4.1 | en | 2022-03-21T15:06:54.361 | true | | 17 | ner_clinical_large_pipeline | 3 | 3.4.1 | en | 2022-03-21T14:29:11.545 | true | | 18 | ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-21T14:32:59.531 | true | | 19 | bert_token_classifier_ner_clinical_pipeline | 3 | 3.4.1 | en | 2022-03-21T18:51:36.583 | true | | 20 | ner_clinical_trials_abstracts | 3 | 3.5.3 | en | 2022-06-22T15:26:56.789 | true | | 21 | ner_clinical_trials_abstracts_pipeline | 3 | 3.5.3 | en | 2022-06-27T07:07:17.828 | true | | 22 | bert_token_classifier_ner_clinical_trials_abstracts | 3 | 3.5.3 | en | 2022-06-29T04:10:29.985 | true | | 23 | ner_clinical_bert | 3 | 4.0.0 | ro | 2022-06-30T21:36:31.573 | true | | 24 | ner_clinical | 3 | 4.0.0 | ro | 2022-07-01T14:55:02.322 | true | | 25 | ner_clinical_bert | 3 | 4.0.2 | ro | 2022-08-12T09:12:00.992 | true | | 26 | bert_token_classifier_ner_clinical_trials_abstracts | 3 | 4.0.2 | es | 2022-08-11T14:45:17.151 | true | | 27 | ner_clinical_trials_abstracts | 3 | 4.0.2 | es | 2022-08-12T21:19:27.613 | true | | 28 | ner_clinical_bert | 3 | 4.2.2 | ro | 2022-11-22T13:33:53.852 | true | Or simply run the showVersion() method instead: compatibility.showVersion(&#39;ner_clinical&#39;) +--+++ | Pipeline/Model | lang | version | +--+++ | ner_clinical_noncontrib | en | 2.3.0 | | ner_clinical_large | en | 2.5.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large_en | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large | en | 3.0.0 | | ner_clinical_biobert | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_biobert | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical | en | 3.0.0 | | ner_clinical_large | en | 3.0.0 | | bert_token_classifier_ner_clinical | en | 3.2.0 | | bert_token_classifier_ner_clinical | en | 3.3.4 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | ner_clinical_biobert_pipeline | en | 3.4.1 | | ner_clinical_large_pipeline | en | 3.4.1 | | ner_clinical_pipeline | en | 3.4.1 | | bert_token_classifier_ner_clinical_pipeline | en | 3.4.1 | | ner_clinical_trials_abstracts | en | 3.5.3 | | ner_clinical_trials_abstracts_pipeline | en | 3.5.3 | | bert_token_classifier_ner_clinical_trials_abstracts | en | 3.5.3 | | ner_clinical_bert | ro | 4.0.0 | | ner_clinical | ro | 4.0.0 | | ner_clinical_bert | ro | 4.0.2 | | bert_token_classifier_ner_clinical_trials_abstracts | es | 4.0.2 | | ner_clinical_trials_abstracts | es | 4.0.2 | | ner_clinical_bert | ro | 4.2.2 | +--+++ InternalResourceDownloader This module has extended functinalities to list and download models from John Snow Labs repositories. It is an auxiliary module for finding and downloading different models for studies and analysis. As with the Compatibility module, InternalResourceDownloader is also capable of displaying the available models. The difference is that this module can filter the results based on the Python’s class name of the annotator, while Compatibility searches for models’ name. Displaying available models To display the pipelines or models, you can use the .showPrivateModels(), .showPrivatePipelines(), .returnPrivateModels(), or .returnPrivatePipelines() methods, which return the results in a list or print the results directly. For example, to list all models with class MedicalNerModel, just run (some results were ommited for brevity): medical_ner_models = medical.InternalResourceDownloader.returnPrivateModels(&quot;MedicalNerModel&quot;) medical_ner_models[0] [&#39;nerdl_tumour_demo&#39;, &#39;en&#39;, &#39;1.7.3&#39;] medical.InternalResourceDownloader.showPrivateModels(&quot;MedicalNerModel&quot;) +-+++ | Model | lang | version | +-+++ | ner_deid_subentity_bert | ro | 4.0.0 | | ner_deid_subentity | ro | 4.0.0 | | ner_pathogen | en | 4.0.0 | | ner_clinical_bert | ro | 4.0.0 | | ner_clinical | ro | 4.0.0 | | ner_ade_binary | en | 4.0.0 | | ner_living_species_300 | es | 4.0.0 | | ner_clinical_bert | ro | 4.0.2 | | ner_clinical_trials_abstracts | es | 4.0.2 | | ner_pharmacology | es | 4.0.2 | | ner_negation_uncertainty | es | 4.0.2 | | disease_mentions_tweet | es | 4.0.2 | | ner_deid_generic_bert | ro | 4.0.2 | | ner_oncology_unspecific_posology_wip | en | 4.0.0 | | ner_oncology_wip | en | 4.0.0 | | ner_oncology_therapy_wip | en | 4.0.0 | | ner_oncology_posology_wip | en | 4.0.0 | | ner_oncology_anatomy_general_wip | en | 4.0.0 | | ner_oncology_tnm_wip | en | 4.0.0 | | ner_oncology_demographics_wip | en | 4.0.0 | | ner_oncology_biomarker_wip | en | 4.0.0 | | ner_oncology_anatomy_granular_wip | en | 4.0.0 | | ner_oncology_test_wip | en | 4.0.0 | | ner_oncology_diagnosis_wip | en | 4.0.0 | | ner_oncology_response_to_treatment_wip | en | 4.0.0 | | ner_jsl | en | 4.2.0 | | ner_covid_trials | en | 4.2.0 | | ner_oncology_unspecific_posology | en | 4.0.0 | | ner_oncology | en | 4.0.0 | | ner_oncology_tnm | en | 4.0.0 | | ner_oncology_anatomy_general | en | 4.0.0 | | ner_oncology_therapy | en | 4.0.0 | | ner_oncology_test | en | 4.0.0 | | ner_oncology_diagnosis | en | 4.0.0 | | ner_oncology_demographics | en | 4.0.0 | | ner_oncology_anatomy_granular | en | 4.0.0 | | ner_oncology_response_to_treatment | en | 4.0.0 | | ner_oncology_posology | en | 4.0.0 | | ner_oncology_biomarker | en | 4.0.0 | | ner_sdoh_slim_wip | en | 4.2.1 | | ner_clinical_bert | ro | 4.2.2 | | ner_living_species_300 | es | 4.2.2 | | ner_deid_generic_bert | ro | 4.2.2 | | ner_oncology_biomarker | en | 4.2.2 | | ner_oncology_response_to_treatment | en | 4.2.2 | | ner_oncology_demographics | en | 4.2.2 | | ner_oncology_therapy | en | 4.2.2 | | ner_oncology | en | 4.2.2 | | ner_oncology_anatomy_granular | en | 4.2.2 | | ner_oncology_anatomy_general | en | 4.2.2 | | ner_oncology_diagnosis | en | 4.2.2 | | ner_oncology_tnm | en | 4.2.2 | | ner_oncology_posology | en | 4.2.2 | | ner_oncology_unspecific_posology | en | 4.2.2 | | ner_oncology_test | en | 4.2.2 | +-+++ ModelTracer This module adds information on the data to help track uids and timestamps of each stage of the pipeline. Given the following pipeline for Medical NER: # Annotator that transforms a text column from dataframe into an Annotation ready for NLP documentAssembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) # Tokenizer splits words in a relevant format for NLP tokenizer = Tokenizer() .setInputCols([&quot;sentence&quot;]) .setOutputCol(&quot;token&quot;) # Clinical word embeddings trained on PubMED dataset word_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;]) .setOutputCol(&quot;embeddings&quot;) # NER model trained on i2b2 (sampled from MIMIC) dataset clinical_ner = MedicalNerModel.pretrained(&quot;ner_clinical_large&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;embeddings&quot;]) .setOutputCol(&quot;ner&quot;) .setLabelCasing(&quot;upper&quot;) #decide if we want to return the tags in upper or lower case ner_converter = NerConverter() .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;]) .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline( stages=[ documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter ]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) To add the UID and timestamp of each pipeline step, simply use from sparknlp_jsl.modelTracer import ModelTracer df = model.transform(empty_data) tracer_result = ModelTracer().addUidCols(pipeline = nlpPipeline, df = df) tracer_result.show(truncate=False) +-++--+--+-+++-+-+--+--+--+--+ |text|document |sentence|token|embeddings|ner|ner_chunk|documentassembler_model_uid |sentencedetectordlmodel_model_uid |tokenizer_model_uid |word_embeddings_model_model_uid |medicalnermodel_model_uid |nerconverter_model_uid | +-++--+--+-+++-+-+--+--+--+--+ | |[{document, 0, -1, , {sentence -&gt; 0}, []}]|[] |[] |[] |[] |[] |{uid -&gt; DocumentAssembler_3e110f5ce3dc, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; SentenceDetectorDLModel_6bafc4746ea5, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; Tokenizer_bd74fe5f5860, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; WORD_EMBEDDINGS_MODEL_9004b1d00302, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; MedicalNerModel_1a8637089929, timestamp -&gt; 2022-10-21_22:58}|{uid -&gt; NerConverter_643c903e9161, timestamp -&gt; 2022-10-21_22:58}| +-++--+--+-+++-+-+--+--+--+--+",
    "url": "/docs/en/utility_helper_modules",
    "relUrl": "/docs/en/utility_helper_modules"
  },
  "1537": {
    "id": "1537",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/common/utils.html",
    "relUrl": "/api/python/modules/sparknlp/common/utils.html"
  },
  "1538": {
    "id": "1538",
    "title": "Utils for Spark NLP",
    "content": "You can see all features showcased in the demo notebook nlp.viz(pipe,data) Visualize input data with an already configured Spark NLP pipeline, for Algorithms of type (Ner,Assertion, Relation, Resolution, Dependency) using Spark NLP Display Automatically infers applicable viz type and output columns to use for visualization. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlp.viz(ade_pipeline, text) returns: If a pipeline has multiple models candidates that can be used for a viz, the first Annotator that is vizzable will be used to create viz. You can specify which type of viz to create with the viz_type parameter Output columns to use for the viz are automatically deducted from the pipeline, by using the first annotator that provides the correct output type for a specific viz. You can specify which columns to use for a viz by using the corresponding ner_col, pos_col, dep_untyped_col, dep_typed_col, resolution_col, relation_col, assertion_col, parameters. nlp.autocomplete_pipeline(pipe) Auto-Complete a pipeline or single annotator into a runnable pipeline by harnessing NLU’s DAG Autocompletion algorithm and returns it as NLU pipeline. The standard Spark pipeline is avaiable on the .vanilla_transformer_pipe attribute of the returned nlp pipe Every Annotator and Pipeline of Annotators defines a DAG of tasks, with various dependencies that must be satisfied in topoligical order. NLU enables the completion of an incomplete DAG by finding or creating a path between the very first input node which is almost always is DocumentAssembler/MultiDocumentAssembler and the very last node(s), which is given by the topoligical sorting the iterable annotators parameter. Paths are created by resolving input features of annotators to the corrrosponding providers with matching storage references. Example: # Lets autocomplete the pipeline for a RelationExtractionModel, which as many input columns and sub-dependencies. from sparknlp_jsl.annotator import RelationExtractionModel re_model = RelationExtractionModel().pretrained(&quot;re_ade_clinical&quot;, &quot;en&quot;, &#39;clinical/models&#39;).setOutputCol(&#39;relation&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlp.autocomplete_pipeline(re_model) nlu_pipe.predict(text) returns : relation relation_confidence relation_entity1 relation_entity2 relation_entity2_class 1 1 allergic reaction vancomycin Drug_Ingredient 1 1 skin itchy Symptom 1 0.99998 skin sore throat/burning/itchy Symptom 1 0.956225 skin numbness Symptom 1 0.999092 skin tongue External_body_part_or_region 0 0.942927 skin gums External_body_part_or_region 1 0.806327 itchy sore throat/burning/itchy Symptom 1 0.526163 itchy numbness Symptom 1 0.999947 itchy tongue External_body_part_or_region 0 0.994618 itchy gums External_body_part_or_region 0 0.994162 sore throat/burning/itchy numbness Symptom 1 0.989304 sore throat/burning/itchy tongue External_body_part_or_region 0 0.999969 sore throat/burning/itchy gums External_body_part_or_region 1 1 numbness tongue External_body_part_or_region 1 1 numbness gums External_body_part_or_region 1 1 tongue gums External_body_part_or_region nlu.to_pretty_df(pipe,data) Annotates a Pandas Dataframe/Pandas Series/Numpy Array/Spark DataFrame/Python List strings /Python String with given Spark NLP pipeline, which is assumed to be complete and runnable and returns it in a pythonic pandas dataframe format. Example: # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; # output is same as nlp.autocomplete_pipeline(re_model).nlp_pipe.predict(text) nlp.to_pretty_df(ade_pipeline,text) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 Annotators are grouped internally by NLP into output levels token,sentence, document,chunk and relation Same level annotators output columns are zipped and exploded together to create the final output df. Additionally, most keys from the metadata dictionary in the result annotations will be collected and expanded into their own columns in the resulting Dataframe, with special handling for Annotators that encode multiple metadata fields inside of one, seperated by strings like ||| or :::. Some columns are omitted from metadata to reduce total amount of output columns, these can be re-enabled by setting metadata=True For a given pipeline output level is automatically set to the last annotators output level by default. This can be changed by defining to_preddty_df(pipe,text,output_level=&#39;my_level&#39; for levels token,sentence, document,chunk and relation . nlp.to_nlu_pipe(pipe) Convert a pipeline or list of annotators into a NLU pipeline making .predict() and .viz() avaiable for every Spark NLP pipeline. Assumes the pipeline is already runnable. # works with Pipeline, LightPipeline, PipelineModel,PretrainedPipeline List[Annotator] ade_pipeline = PretrainedPipeline(&#39;explain_clinical_doc_ade&#39;, &#39;en&#39;, &#39;clinical/models&#39;) text = &quot;&quot;&quot;I have an allergic reaction to vancomycin. My skin has be itchy, sore throat/burning/itchy, and numbness in tongue and gums. I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication.&quot;&quot;&quot; nlu_pipe = nlp.to_nlu_pipe(ade_pipeline) # Same output as nlu.to_pretty_df(pipe,text) nlu_pipe.predict(text) # same output as nlu.viz(pipe,text) nlu_pipe.viz(text) # Acces auto-completed Spark NLP big data pipeline, nlu_pipe.vanilla_transformer_pipe.transform(spark_df) returns : assertion asserted_entitiy entitiy_class assertion_confidence present allergic reaction ADE 0.998 present itchy ADE 0.8414 present sore throat/burning/itchy ADE 0.9019 present numbness in tongue and gums ADE 0.9991 and",
    "url": "/docs/en/jsl/utils_for_spark_nlp",
    "relUrl": "/docs/en/jsl/utils_for_spark_nlp"
  },
  "1539": {
    "id": "1539",
    "title": "Vaccines - Biomedical NLP Demos & Notebooks",
    "content": "",
    "url": "/vaccinations",
    "relUrl": "/vaccinations"
  },
  "1540": {
    "id": "1540",
    "title": "Version Compatibility",
    "content": "Healthcare NLP Spark OCR Spark NLP 3.0.0 3.4.0 3.0.0 3.0.1 3.4.0 3.0.1 3.0.2 3.4.0 3.0.2 3.0.3 3.4.0 3.0.3 3.1.0 3.4.1 3.1.0 3.1.1 3.4.1 3.1.1 3.1.2 3.4.1 3.1.2 3.1.3 3.5.0 3.1.3 3.1.3 3.6.0 3.1.3 3.2.0 3.7.0 3.2.0 3.2.1 3.8.0 3.2.1 3.2.2 3.8.0 3.2.2 3.2.3 3.8.0 3.2.3 3.3.0 3.8.0 3.3.0 3.3.1 3.9.0 3.3.1 3.3.2 3.9.0 3.3.2 3.3.4 3.10.0 3.3.4 3.4.0 3.11.0 3.4.0 3.4.1 3.11.0 3.4.1 3.4.2 3.11.0 3.4.2 3.5.0 3.11.0 3.4.2 3.5.1 3.12.0 3.4.2 3.5.2 3.13.0 3.4.4 3.5.2 3.14.0 3.4.4 4.0.0 4.0.0 4.0.0 4.1.0 4.1.0 4.1.0 4.2.1 4.2.0 4.2.1 4.2.3 4.2.4 4.2.4 4.2.4 4.3.0 4.2.4",
    "url": "/docs/en/version_compatibility",
    "relUrl": "/docs/en/version_compatibility"
  },
  "1541": {
    "id": "1541",
    "title": "Video Tutorials",
    "content": "{%- include extensions/youtube.html id=&#39;isxffn4Tcds&#39; -%}How to Install NLP Server on Azure {%- include extensions/youtube.html id=&#39;YZFhsZZD6QM&#39; -%}How to Import a License in the NLP Server",
    "url": "/docs/en/nlp_server/video_tutorials",
    "relUrl": "/docs/en/nlp_server/video_tutorials"
  },
  "1542": {
    "id": "1542",
    "title": "Visual Document Understanding - Visual NLP Demos & Notebooks",
    "content": "",
    "url": "/visual_document_understanding",
    "relUrl": "/visual_document_understanding"
  },
  "1543": {
    "id": "1543",
    "title": "Visual NER",
    "content": "Annotating text included in image documents (e.g. scanned documents) is a common use case in many verticals but comes with several challenges. With the new Visual NER Labeling config, we aim to ease the work of annotators by allowing them to simply select text from an image and assign the corresponding label to it. This feature is powered by Spark OCR 3.5.0; thus a valid Spark OCR license is required to get access to it. Here is how this can be used: Upload a valid Spark OCR license. See how to do this here. Create a new project, specify a name for your project, add team members if necessary, and from the list of predefined templates (Default Project Configs) choose “Visual NER Labeling”. Update the configuration if necessary. This might be useful if you want to use other labels than the currently defined ones. Click the save button. While saving the project, a confirmation dialog is displayed to let you know that the Spark OCR pipeline for Visual NER is being deployed. Import the tasks you want to annotate (images). Start annotating text on top of the image by clicking on the text tokens or by drawing bounding boxes on top of chunks or image areas. Export annotations in your preferred format. The entire process is illustrated below: Support for multi-page PDF documents When a valid Saprk OCR license is available, Annotation Lab offers support for multi-page PDF annotation. The complete flow of import, annotation, and export for multi-page PDF files is currently supported. Users have two options for importing a new PDF file into the Visual NER project Import PDF file from local storage; Add a link to the PDF file in the file attribute. After import, the task becomes available on the Tasks Page. The title of the new task is the name of the imported file. On the labeling page, the PDF file is displayed with pagination so that annotators can annotate on the PDF document one page at a time. OCR and Visual NER servers Just like (preannotation servers)[], Annotation Lab 3.0.0 also supports the deployment of multiple OCR servers. If a user has uploaded a Spark OCR license, be it airgap or floating, OCR inference is enabled. To create a Visual NER project, users have to deploy at least one OCR server. Any OCR server can perform preannotation. To select the OCR server, users have to go to the Import page, toggle the OCR option and from the popup, choose one of the available OCR servers. In no suitable OCR server is available, one can be created by choosing the “Create Server” option. Visual NER Training And Preannotation With release 3.4.0 came support for Visual NER Automated Preannotation and Model Training. Visual NER Training Support Version 3.4.0 of the Annotation Lab offers the ability to train Visual NER models, apply active learning for automatic model training, and preannotate image-based tasks with existing models in order to accelerate annotation work. License Requirements Visual NER annotation, training and preannotation features are dependent on the presence of a Spark OCR license. Floating or airgap licenses with scope ocr: inference and ocr: training are required for preannotation and training respectively. Model Training The training feature for Visual NER projects can be activated from the Setup page via the “Train Now” button (See 1). From the Training Settings sections, users can tune the training parameters (e.g. Epoch, Batch) and choose the tasks to use for training the Visual NER model (See 3). Information on the training progress is shown in the top right corner of the Model Training tab (See 2). Users can check detailed information regarding the success or failure of the last training. Training Failure can occur because of: Insufficient number of completions Poor quality of completions Insufficient CPU and Memory Wrong training parameters When triggering the training, users can choose to immediately deploy the model or just train it without deploying. If immediate deployment is chosen, then the labeling config is updated with references to the new model so that it will be used for preannotations. Training Server Specification The minimal required training configuration is 64 GB RAM, 16 Core CPU for Visual NER Training. Visual NER Preannotation For running preannotation on one or several tasks, the Project Owner or the Manager must select the target tasks and can click on the Preannotate button from the upper right side of the Tasks Page. This will display a popup with information regarding the last deployment including the list of models deployed and the labels they predict. Known Limitations: When bulk preannotation is run on a lot of tasks, the preannotation can fail due to memory issues. Preannotation currently works at token level, and does not merge all tokens of a chunk into one entity. Preannotation Server Specification The minimal required training configuration is 32 GB RAM, 2 Core CPU for Visual NER Model.",
    "url": "/en/alab/visual_ner.html",
    "relUrl": "/en/alab/visual_ner.html"
  },
  "1544": {
    "id": "1544",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/cv/vit_for_image_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/cv/vit_for_image_classification.html"
  },
  "1545": {
    "id": "1545",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/sentiment/vivekn_sentiment.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/sentiment/vivekn_sentiment.html"
  },
  "1546": {
    "id": "1546",
    "title": "The nlp.viz() function",
    "content": "Visualizations using nlp.load().viz() You can use the build in visualization module on any pipeline or model returned by nlp.load(). Simply call viz() and an applicable visualization will be deducted. Alternatively, you can also manually specify, which visualization you want to invoke. These visualizations are provided via Spark-NLP-Display package Named Entity Recognizers Medical Named Entity Recognizers Dependency parser relationships which labels and part of speech tags Entity resolution for sentences and chunks Assertion of entity statuses See the visualization tutorial notebook for more info. NER visualization Applicable to any of the 100+ NER models! See here for an overview nlp.load(&#39;ner&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions.&quot;) Dependency tree visualization Visualizes the structure of the labeled dependency tree and part of speech tags nlp.load(&#39;dep.typed&#39;).viz(&quot;Billy went to the mall&quot;) #Bigger Example nlp.load(&#39;dep.typed&#39;).viz(&quot;Donald Trump from America and Angela Merkel from Germany don&#39;t share many oppinions but they both love John Snow Labs software&quot;) Assertion status visualization Visualizes asserted statuses and entities. Applicable to any of the 10 + Assertion models! See here for an overview nlp.load(&#39;med_ner.clinical assert&#39;).viz(&quot;The MRI scan showed no signs of cancer in the left lung&quot;) #bigger example data =&#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&#39; nlp.load(&#39;med_ner.clinical assert&#39;).viz(data) Relationship between entities visualization Visualizes the extracted entities between relationship. Applicable to any of the 20 + Relation Extractor models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical relation.temporal_events&#39;).viz(&#39;The patient developed cancer after a mercury poisoning in 1999 &#39;) # bigger example data = &#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&#39; pipe = nlp.load(&#39;med_ner.jsl.wip.clinical relation.clinical&#39;).viz(data) Entity Resolution visualization for chunks Visualizes resolutions of entities Applicable to any of the 100+ Resolver models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(&quot;He took Prevacid 30 mg daily&quot;) # bigger example data = &quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret &#39;s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&quot; nlp.load(&#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&#39;).viz(data) Entity Resolution visualization for sentences Visualizes resolutions of entities in sentences Applicable to any of the 100+ Resolver models See here for an overview nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(&#39;She was diagnosed with a respiratory congestion&#39;) # bigger example data = &#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&#39; nlp.load(&#39;med_ner.jsl.wip.clinical resolve.icd10cm&#39;).viz(data) Configure visualizations Define custom colors for labels Some entity and relation labels will be highlighted with a pre-defined color, which you can find here. For labels that have no color defined, a random color will be generated. You can define colors for labels manually, by specifying via the viz_colors parameter and defining hex color codes in a dictionary that maps labels to colors . data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Define custom colors for labels viz_colors={&#39;STRENGTH&#39;:&#39;#800080&#39;, &#39;DRUG_BRANDNAME&#39;:&#39;#77b5fe&#39;, &#39;GENDER&#39;:&#39;#77ffe&#39;} nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,viz_colors =viz_colors) Filter entities that get highlighted By default every entity class will be visualized. The labels_to_viz can be used to define a set of labels to highlight. Applicable for ner, resolution and assert. data = &#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&#39; # Filter wich NER label to viz labels_to_viz=[&#39;SYMPTOM&#39;] nlp.load(&#39;med_ner.jsl.wip.clinical&#39;).viz(data,labels_to_viz=labels_to_viz) Visualizations using Pandas Common Idioms The most common two liner you will use in NLU is loading a classifier like emotion or sentiment and then plotting the occurence of each predicted label . An few examples for this are the following : emotion_df = nlp.load(&#39;sentiment&#39;).predict(df) emotion_df[&#39;sentiment&#39;].value_counts().plot.bar() emotion_df = nlp.load(&#39;emotion&#39;).predict(df) emotion_df[&#39;emotion&#39;].value_counts().plot.bar() Another simple idiom is to group by an arbitrary feature from the original dataset and then plot the counts four each group. emotion_df = nlp.load(&#39;sentiment&#39;).predict(df) sentiment_df.groupby(&#39;source&#39;)[&#39;sentiment&#39;].value_counts().plot.bar(figsize=(20,8)) emotion_df = nlp.load(&#39;emotion&#39;).predict(df) emotion_df.groupby(&#39;airline&#39;)[&#39;emotion&#39;].value_counts().plot.bar(figsize=(20,8)) You can visualize a Keyword distribution generated by YAKE like this keyword_predictions.explode(&#39;keywords&#39;).keywords.value_counts()[0:100].plot.bar(title=&#39;Top 100 Keywords in Stack Overflow Questions&#39;, figsize=(20,8))",
    "url": "/docs/en/jsl/viz_examples",
    "relUrl": "/docs/en/jsl/viz_examples"
  },
  "1547": {
    "id": "1547",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/audio/wav2vec2_for_ctc.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/audio/wav2vec2_for_ctc.html"
  },
  "1548": {
    "id": "1548",
    "title": "",
    "content": "",
    "url": "/api/python/static/webpack-macros.html",
    "relUrl": "/api/python/static/webpack-macros.html"
  },
  "1549": {
    "id": "1549",
    "title": "Wiki",
    "content": "This page is created for sharing some tips and tricks for the Spark NLP library. You can find valuable information under the related highlights. Miscellaneous Loading the Same Model Into the Same Annotator More Than One Time There is 1 instance of a model when we use .pretrained or .load. So when we try to use the same model with the same annotator more than one time with different parameters, it fails. We cannot have more than 1 model per annotator in the memory. You can load 10 different NerModel, but not the same model twice with different parameters, it will just load once and reuse it the other times. It’s not possible to duplicate the annotator/model unless the model is different. (each model creates a unique id). You can only load 1 model per annotator, once that happens that model with all its parameters stays in the memory. So if you want to load the very same model on the very same annotator in another pipeline, whether you use .transform, or LightPipeline, it will take the already loaded model from the memory. So if the first one has different inputCol/outputCol then the second pipeline just can’t find the input/output or if the parameters are different in the second pipeline you may not see the desired outcome. So the lesson here is, if you want to use the same model in different places, you must make sure they all have the same parameters. This behavior is the same for LP and .transform. LightPipeline LightPipeline does not check the storageRef of resolver models. This feature will make LP so complicated and also slower. So, the resolver models can work with an embeddings model that is not trained with in LightPipeline, but they return irrelevant results. ChunkMergeApproach Chunk Prioritization in ChunkMergeApproach ChunkMergeApproach() has some prioritizing rules while merging chunks that come from entity extractors (NER models, ContextualParser, TextMatcher, RegexMatcher, etc.): In case of the extracted chunks are same in the all given entity extractors, ChunkMergeApproach prioritizes the leftmost chunk output. Example: When we use ner_posology and ner_clinical models together, and if there is insulin in the clinical text, merger will behave like this: chunk_merger = ChunkMergeApproach() .setInputCols([&quot;ner_posology_chunk&quot;, &quot;ner_clinical_chunk&quot;]) .setOutputCol(&quot;merger_output&quot;) ... &gt;&gt; ner_posology_chunk: insulin -&gt; DRUG &gt;&gt; ner_clinical_chunk: insulin -&gt; TREATMENT &gt;&gt; merger_output: insulin -&gt; DRUG In the event of chunk names being different but some of them are overlapped, ChunkMergeApproach prioritizes the longest chunk even though it is not in the leftmost. Example: If we use ner_posology and ner_posology_greedy models together in the same pipeline and merge their results on a clinical text that has “… bactrim for 14 days …”, merger result will be as shown below: chunk_merger = ChunkMergeApproach() .setInputCols([&quot;ner_posology_chunk&quot;, &quot;ner_posology_greedy_chunk&quot;]) .setOutputCol(&quot;merger_output&quot;) ... &gt;&gt; ner_posology_chunk: bactrim -&gt; DRUG &gt;&gt; ner_posology_greedy_chunk: bactrim for 14 days -&gt; DRUG &gt;&gt; merger_output: bactrim for 14 days -&gt; DRUG Confidence scores don’t have any effect on prioritization. Sentence Entity Resolver Confidence vs Cosine Distance Calculation of Resolvers Let’s assume we have the 10 closest candidates (close meaning lower cosine distance) in our results. The confidence score is calculated with Softmax (vector to vector function). The vector is the full input and the output is also a full vector, it is not a function that is calculated item by item. Each item in the output depends on all the distances. So, what you are expecting is not “expected”. If you get two distances 0.1 and 0.1, Softmax would return 0.5 and 0.5 for each. But if you have 0.1 and 10 distances, Softmax would be 1 and 0. You can have a low distance (chunks are very similar semantically) but low confidence if there are many other chunks also very similar. And sometimes you can have high confidence but high distance, meaning there is only one chunk “close” to your target but not so close. In general, we can see less distance and less confidence but not perfect linear relationships. We can say that using the distance is a better parameter to judge the “goodness” of the resolution than the confidence. So, We recommend that you consider the cosine distance.",
    "url": "/docs/en/wiki",
    "relUrl": "/docs/en/wiki"
  },
  "1550": {
    "id": "1550",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/word2vec.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/word2vec.html"
  },
  "1551": {
    "id": "1551",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/word_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/word_embeddings.html"
  },
  "1552": {
    "id": "1552",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ws/word_segmenter.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ws/word_segmenter.html"
  },
  "1553": {
    "id": "1553",
    "title": "Workflows",
    "content": "When a team of people collaborate on a large annotation project, the work can be organized into multi-step workflows for an easier management of each team member’s responsabilities. This is also necessary when the project has strict requirements such as the same document must be labeled by multiple annotators; the annotations must be checked by a senior annotator. The default workflow supported by the Annotation Lab involves task assignment to one or multiple Annotators and to maximum one Reviewer. In the majority of projects having one annotator working on a task and then one reviewer checking the work done by the annotator is sufficient. NOTE: In NER projects, we recommend that in the early stages of a project, a batch of 50 - 100 content rich tasks should be assigned to all annotators for checking the Inter Annotator Agreement (IAA). This is a best practice to follow in order to quickly identify the difference in annotations as a complementary way to ensure high agreement and completeness across team. NOTE: When multiple annotators are assigned to a task, multiple ground truth completions will be created for that task. The way Annotation Lab prioritises the ground truth completion used for model training and CONLL export is via the priority assigned for each user in the Team (see Project Configuration). When more complex workflows need to be implemented, this is possible using the task tagging functionality provided by the Annotation Lab. Tags can be used for splitting work across the team but also for differentiating between first-level annotators and second-level reviewers. To add a tag, select a task and press Tags &gt; Add More. Tasks can be filtered by tags, making it easier to identify, for example, which documents are completed and which ones need to be reviewed.",
    "url": "/docs/en/alab/workflow",
    "relUrl": "/docs/en/alab/workflow"
  },
  "1554": {
    "id": "1554",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_embeddings.html"
  },
  "1555": {
    "id": "1555",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering.html"
  },
  "1556": {
    "id": "1556",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification.html"
  },
  "1557": {
    "id": "1557",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification.html"
  },
  "1558": {
    "id": "1558",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings.html"
  },
  "1559": {
    "id": "1559",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/embeddings/xlnet_embeddings.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/embeddings/xlnet_embeddings.html"
  },
  "1560": {
    "id": "1560",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification.html"
  },
  "1561": {
    "id": "1561",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_token_classification.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/classifier_dl/xlnet_for_token_classification.html"
  },
  "1562": {
    "id": "1562",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/keyword_extraction/yake_keyword_extraction.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/keyword_extraction/yake_keyword_extraction.html"
  },
  "1563": {
    "id": "1563",
    "title": "",
    "content": "",
    "url": "/api/python/modules/sparknlp/annotator/ner/zero_shot_ner_model.html",
    "relUrl": "/api/python/modules/sparknlp/annotator/ner/zero_shot_ner_model.html"
  }
  
}
