<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-05-01T13:01:13+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Legal Alias Pipeline</title><link href="/2023/04/30/legpipe_alias_en.html" rel="alternate" type="text/html" title="Legal Alias Pipeline" /><published>2023-04-30T00:00:00+00:00</published><updated>2023-04-30T00:00:00+00:00</updated><id>/2023/04/30/legpipe_alias_en</id><content type="html" xml:base="/2023/04/30/legpipe_alias_en.html">## Description

This pipeline allows you to detect names in quotes and brackets like: (&quot;Supplier&quot;), (&quot;Recipient&quot;), (&quot;Disclosing Parties&quot;), etc. very common in Legal Agreements to reference the parties.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legpipe_alias_en_1.0.0_3.0_1682861474127.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legpipe_alias_en_1.0.0_3.0_1682861474127.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;)

text = [&quot;&quot;&quot;MUTUAL NON-DISCLOSURE AGREEMENT 
This Mutual Non-Disclosure Agreement (the “Agreement”) is made on _________ by and between:  
John Snow Labs, a Delaware corporation, registered at 16192 Coastal Highway, Lewes, Delaware 19958 (“John Snow Labs”), and 
Acentos, S.L, a Spanish corporation, registered at Gran Via 71, 2º floor (“Company”), (each a “party” and together the “parties”). 
Recitals: 
John Snow Labs and Company intend to explore the possibility of a business relationship between each other, whereby each party (“Discloser”) may disclose sensitive information to the other party (“Recipient”). 
The parties agree as follows:&quot;&quot;&quot;]

result = legal_pipeline.annotate(text)
```

&lt;/div&gt;

## Results

```bash
['(“John Snow Labs”)', '(“Company”)', '( “ Discloser ” )', '(“Recipient”)']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legpipe_alias|
|Type:|pipeline|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|13.1 KB|

## Included Models

- DocumentAssembler
- TokenizerModel
- ContextualParserModel</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="ner" /><category term="pipeline" /><category term="alias" /><category term="licensed" /><summary type="html">Description This pipeline allows you to detect names in quotes and brackets like: (“Supplier”), (“Recipient”), (“Disclosing Parties”), etc. very common in Legal Agreements to reference the parties. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_alias&quot;, &quot;en&quot;, &quot;legal/models&quot;) text = [&quot;&quot;&quot;MUTUAL NON-DISCLOSURE AGREEMENT This Mutual Non-Disclosure Agreement (the “Agreement”) is made on _________ by and between: John Snow Labs, a Delaware corporation, registered at 16192 Coastal Highway, Lewes, Delaware 19958 (“John Snow Labs”), and Acentos, S.L, a Spanish corporation, registered at Gran Via 71, 2º floor (“Company”), (each a “party” and together the “parties”). Recitals: John Snow Labs and Company intend to explore the possibility of a business relationship between each other, whereby each party (“Discloser”) may disclose sensitive information to the other party (“Recipient”). The parties agree as follows:&quot;&quot;&quot;] result = legal_pipeline.annotate(text) Results ['(“John Snow Labs”)', '(“Company”)', '( “ Discloser ” )', '(“Recipient”)'] Model Information Model Name: legpipe_alias Type: pipeline Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 13.1 KB Included Models DocumentAssembler TokenizerModel ContextualParserModel</summary></entry><entry><title type="html">Legal Finetuned FLAN-T5 Text Generation</title><link href="/2023/04/29/leggen_flant5_finetuned_en.html" rel="alternate" type="text/html" title="Legal Finetuned FLAN-T5 Text Generation" /><published>2023-04-29T00:00:00+00:00</published><updated>2023-04-29T00:00:00+00:00</updated><id>/2023/04/29/leggen_flant5_finetuned_en</id><content type="html" xml:base="/2023/04/29/leggen_flant5_finetuned_en.html">## Description

This Text Generation model has been fine-tuned on FLANT5 Using legal texts. FLAN-T5 is a state-of-the-art language model developed by Facebook AI that utilizes the T5 architecture for text generation tasks.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/leggen_flant5_finetuned_en_1.0.0_3.0_1682797013244.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/leggen_flant5_finetuned_en_1.0.0_3.0_1682797013244.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;question&quot;)

flant5 = legal.TextGenerator.pretrained('leggen_flant5_finetuned,'en','legal/models')\
    .setInputCols([&quot;question&quot;])\
    .setOutputCol(&quot;generated_text&quot;)
    .setMaxNewTokens(150)\
    .setStopAtEos(True)
  
pipeline = nlp.Pipeline(stages=[document_assembler, flant5])

data = spark.createDataFrame([
  [1,'''This exhibit has been redacted and is the subject of a confidential treatment request. redacted material is marked with [* * *] and has been filed separately with the securities and exchange commission. this agreement (this &quot;agreement&quot;), dated december 30, 2016 (the &quot;effective date&quot;), is''']
]).toDF('id', 'text')
results = pipeline.fit(data).transform(data)
results.select(&quot;generated_text.result&quot;).show(truncate=False)
```

&lt;/div&gt;

## Results

```bash
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                                                                                                                                                                                                                             |
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[The parties agree that this Agreement shall be binding upon and inure to the benefit of the parties, their successors and assigns. The parties further agree that any disputes arising out of or related to this Agreement shall be resolved through binding arbitration. The parties agree to submit to binding arbitration in accordance with the rules of the American Arbitration Association]|
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|leggen_flant5_finetuned|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|1.6 GB|

## References

In house annotated data</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="text_generation" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Text Generation model has been fine-tuned on FLANT5 Using legal texts. FLAN-T5 is a state-of-the-art language model developed by Facebook AI that utilizes the T5 architecture for text generation tasks. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;question&quot;) flant5 = legal.TextGenerator.pretrained('leggen_flant5_finetuned,'en','legal/models')\ .setInputCols([&quot;question&quot;])\ .setOutputCol(&quot;generated_text&quot;) .setMaxNewTokens(150)\ .setStopAtEos(True) pipeline = nlp.Pipeline(stages=[document_assembler, flant5]) data = spark.createDataFrame([ [1,'''This exhibit has been redacted and is the subject of a confidential treatment request. redacted material is marked with [* * *] and has been filed separately with the securities and exchange commission. this agreement (this &quot;agreement&quot;), dated december 30, 2016 (the &quot;effective date&quot;), is'''] ]).toDF('id', 'text') results = pipeline.fit(data).transform(data) results.select(&quot;generated_text.result&quot;).show(truncate=False) Results +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |result | +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |[The parties agree that this Agreement shall be binding upon and inure to the benefit of the parties, their successors and assigns. The parties further agree that any disputes arising out of or related to this Agreement shall be resolved through binding arbitration. The parties agree to submit to binding arbitration in accordance with the rules of the American Arbitration Association]| +---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Model Information Model Name: leggen_flant5_finetuned Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 1.6 GB References In house annotated data</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/28/legner_mapa_cs.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>/2023/04/28/legner_mapa_cs</id><content type="html" xml:base="/2023/04/28/legner_mapa_cs.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `Czech` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_cs_1.0.0_3.0_1682668776380.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_cs_1.0.0_3.0_1682668776380.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_czech_legal&quot;,&quot;cs&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;cs&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;V roce 2007 uzavřela společnost Alpenrind, dříve S GmbH, se společností Martin-Meat usazenou v Maďarsku smlouvu, podle níž se posledně uvedená společnost zavázala k porcování masa a jeho balení v rozsahu 25 půlek jatečně upravených těl skotu týdně.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+-----------+------------+
|chunk      |ner_label   |
+-----------+------------+
|2007       |DATE        |
|Alpenrind  |ORGANISATION|
|Martin-Meat|ORGANISATION|
|Maďarsku   |ADDRESS     |
|25 půlek   |AMOUNT      |
+-----------+------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|cs|
|Size:|1.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.80       0.67    0.73      36      
AMOUNT        1.00       1.00    1.00      5       
DATE          0.98       0.98    0.98      56      
ORGANISATION  0.64       0.66    0.65      32      
PERSON        0.75       0.82    0.78      66      
micro-avg     0.81       0.82    0.81      195     
macro-avg     0.83       0.82    0.83      195     
weighted-avg  0.81       0.82    0.81      195
```</content><author><name>John Snow Labs</name></author><category term="cs" /><category term="licensed" /><category term="legal" /><category term="ner" /><category term="mapa" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from Czech documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_czech_legal&quot;,&quot;cs&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;cs&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;V roce 2007 uzavřela společnost Alpenrind, dříve S GmbH, se společností Martin-Meat usazenou v Maďarsku smlouvu, podle níž se posledně uvedená společnost zavázala k porcování masa a jeho balení v rozsahu 25 půlek jatečně upravených těl skotu týdně.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +-----------+------------+ |chunk |ner_label | +-----------+------------+ |2007 |DATE | |Alpenrind |ORGANISATION| |Martin-Meat|ORGANISATION| |Maďarsku |ADDRESS | |25 půlek |AMOUNT | +-----------+------------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: cs Size: 1.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.80 0.67 0.73 36 AMOUNT 1.00 1.00 1.00 5 DATE 0.98 0.98 0.98 56 ORGANISATION 0.64 0.66 0.65 32 PERSON 0.75 0.82 0.78 66 micro-avg 0.81 0.82 0.81 195 macro-avg 0.83 0.82 0.83 195 weighted-avg 0.81 0.82 0.81 195</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/28/legner_mapa_fi.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>/2023/04/28/legner_mapa_fi</id><content type="html" xml:base="/2023/04/28/legner_mapa_fi.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `Finnish` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_fi_1.0.0_3.0_1682671773751.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_fi_1.0.0_3.0_1682671773751.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_finnish_legal&quot;,&quot;fi&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;fi&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;Liberato vaati 22.5.2007 päivätyllä kanteellaan Tribunale di Teramossa ( Teramon alioikeus, Italia ) asumuseroa Grigorescusta ja lapsen huoltajuutta.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+-------------+---------+
|chunk        |ner_label|
+-------------+---------+
|Liberato     |PERSON   |
|22.5.2007    |DATE     |
|Italia       |ADDRESS  |
|Grigorescusta|PERSON   |
+-------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|fi|
|Size:|1.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.81       0.93    0.86      27      
AMOUNT        1.00       1.00    1.00      2       
DATE          0.92       0.95    0.94      61      
ORGANISATION  0.88       0.81    0.85      27      
PERSON        0.93       0.95    0.94      40      
micro-avg     0.90       0.92    0.91      157     
macro-avg     0.91       0.93    0.92      157     
weighted-avg  0.90       0.92    0.91      157
```</content><author><name>John Snow Labs</name></author><category term="fi" /><category term="licensed" /><category term="ner" /><category term="legal" /><category term="mapa" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from Finnish documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_finnish_legal&quot;,&quot;fi&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;fi&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Liberato vaati 22.5.2007 päivätyllä kanteellaan Tribunale di Teramossa ( Teramon alioikeus, Italia ) asumuseroa Grigorescusta ja lapsen huoltajuutta.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +-------------+---------+ |chunk |ner_label| +-------------+---------+ |Liberato |PERSON | |22.5.2007 |DATE | |Italia |ADDRESS | |Grigorescusta|PERSON | +-------------+---------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: fi Size: 1.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.81 0.93 0.86 27 AMOUNT 1.00 1.00 1.00 2 DATE 0.92 0.95 0.94 61 ORGANISATION 0.88 0.81 0.85 27 PERSON 0.93 0.95 0.94 40 micro-avg 0.90 0.92 0.91 157 macro-avg 0.91 0.93 0.92 157 weighted-avg 0.90 0.92 0.91 157</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/28/legner_mapa_ga.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>/2023/04/28/legner_mapa_ga</id><content type="html" xml:base="/2023/04/28/legner_mapa_ga.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `Irish` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_ga_1.0.0_3.0_1682670223837.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_ga_1.0.0_3.0_1682670223837.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_irish_legal&quot;,&quot;gle&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;ga&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;Dhiúltaigh Tribunale di Teramo ( An Chúirt Dúiche, Teramo ) an t-iarratas a rinne Bn.Grigorescu, ar bhonn teagmhasach, chun aitheantas a thabhairt san Iodáil do bhreithiúnas colscartha Tribunalul București ( An Chúirt Réigiúnach, Búcairist ) an 3 Nollaig 2012, de bhun Rialachán Uimh.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+--------------+---------+
|chunk         |ner_label|
+--------------+---------+
|Teramo        |ADDRESS  |
|Bn.Grigorescu |PERSON   |
|Búcairist     |ADDRESS  |
|3 Nollaig 2012|DATE     |
+--------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|ga|
|Size:|16.3 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.82       0.74    0.78      19      
AMOUNT        1.00       1.00    1.00      7       
DATE          0.91       0.92    0.91      75      
ORGANISATION  0.65       0.67    0.66      48      
PERSON        0.71       0.82    0.76      56      
micro-avg     0.79       0.82    0.80      205     
macro-avg     0.82       0.83    0.82      205     
weighted-avg  0.79       0.82    0.80      205
```</content><author><name>John Snow Labs</name></author><category term="ga" /><category term="licensed" /><category term="ner" /><category term="legal" /><category term="mapa" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from Irish documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_irish_legal&quot;,&quot;gle&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;ga&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Dhiúltaigh Tribunale di Teramo ( An Chúirt Dúiche, Teramo ) an t-iarratas a rinne Bn.Grigorescu, ar bhonn teagmhasach, chun aitheantas a thabhairt san Iodáil do bhreithiúnas colscartha Tribunalul București ( An Chúirt Réigiúnach, Búcairist ) an 3 Nollaig 2012, de bhun Rialachán Uimh.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +--------------+---------+ |chunk |ner_label| +--------------+---------+ |Teramo |ADDRESS | |Bn.Grigorescu |PERSON | |Búcairist |ADDRESS | |3 Nollaig 2012|DATE | +--------------+---------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: ga Size: 16.3 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.82 0.74 0.78 19 AMOUNT 1.00 1.00 1.00 7 DATE 0.91 0.92 0.91 75 ORGANISATION 0.65 0.67 0.66 48 PERSON 0.71 0.82 0.76 56 micro-avg 0.79 0.82 0.80 205 macro-avg 0.82 0.83 0.82 205 weighted-avg 0.79 0.82 0.80 205</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/28/legner_mapa_sk.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>/2023/04/28/legner_mapa_sk</id><content type="html" xml:base="/2023/04/28/legner_mapa_sk.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `Slovak` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_sk_1.0.0_3.0_1682674803309.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_sk_1.0.0_3.0_1682674803309.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_slovak_legal&quot;,&quot;sk&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;sk&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;Návrhom podaným 22. mája 2007 na Tribunale di Teramo ( súd v Terame, Taliansko ) požiadal pán Liberato o rozluku a o zverenie syna do svojej starostlivosti.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+-------------+---------+
|chunk        |ner_label|
+-------------+---------+
|22. mája 2007|DATE     |
|Terame       |ADDRESS  |
|Taliansko    |ADDRESS  |
|pán Liberato |PERSON   |
+-------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|sk|
|Size:|1.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.88       0.85    0.86      26      
AMOUNT        1.00       1.00    1.00      4       
DATE          0.92       0.88    0.90      50      
ORGANISATION  0.79       0.61    0.69      31      
PERSON        0.66       0.86    0.75      44      
micro-avg     0.80       0.82    0.81      155     
macro-avg     0.85       0.84    0.84      155     
weighted-avg  0.81       0.82    0.81      155 
```</content><author><name>John Snow Labs</name></author><category term="sk" /><category term="licensed" /><category term="ner" /><category term="legal" /><category term="mapa" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from Slovak documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_base_slovak_legal&quot;,&quot;sk&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;sk&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Návrhom podaným 22. mája 2007 na Tribunale di Teramo ( súd v Terame, Taliansko ) požiadal pán Liberato o rozluku a o zverenie syna do svojej starostlivosti.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +-------------+---------+ |chunk |ner_label| +-------------+---------+ |22. mája 2007|DATE | |Terame |ADDRESS | |Taliansko |ADDRESS | |pán Liberato |PERSON | +-------------+---------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: sk Size: 1.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.88 0.85 0.86 26 AMOUNT 1.00 1.00 1.00 4 DATE 0.92 0.88 0.90 50 ORGANISATION 0.79 0.61 0.69 31 PERSON 0.66 0.86 0.75 44 micro-avg 0.80 0.82 0.81 155 macro-avg 0.85 0.84 0.84 155 weighted-avg 0.81 0.82 0.81 155</summary></entry><entry><title type="html">Financial Finetuned FLAN-T5 Text Generation ( SEC 10k Filings )</title><link href="/2023/04/28/fingen_flant5_finetuned_sec10k_en.html" rel="alternate" type="text/html" title="Financial Finetuned FLAN-T5 Text Generation ( SEC 10k Filings )" /><published>2023-04-28T00:00:00+00:00</published><updated>2023-04-28T00:00:00+00:00</updated><id>/2023/04/28/fingen_flant5_finetuned_sec10k_en</id><content type="html" xml:base="/2023/04/28/fingen_flant5_finetuned_sec10k_en.html">## Description

This Text Generation model has been fine-tuned on FLANT5 Using SEC filings data. FLAN-T5 is a state-of-the-art language model developed by Facebook AI that utilizes the T5 architecture for text generation tasks.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/fingen_flant5_finetuned_sec10k_en_1.0.0_3.0_1682669039071.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/fingen_flant5_finetuned_sec10k_en_1.0.0_3.0_1682669039071.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;question&quot;)

flant5 = finance.TextGenerator.pretrained('fingen_flant5_finetuned_sec10k','en','finance/models')\
    .setInputCols([&quot;question&quot;])\
    .setOutputCol(&quot;generated_text&quot;)
    .setMaxNewTokens(150)\
    .setStopAtEos(True)
  
pipeline = nlp.Pipeline(stages=[document_assembler, flant5])
data = spark.createDataFrame([
  [1, &quot;&quot;&quot;Deferred revenue primarily consists of customer billings or payments received in advance of revenues being recognized from the company’s subscription and services contracts&quot;&quot;&quot;]
]).toDF('id', 'text')
results = pipeline.fit(data).transform(data)
results.select(&quot;generated_text.result&quot;).show(truncate=False)
```

&lt;/div&gt;

## Results

```bash
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[The company’s deferred revenue is recognized ratably over the term of the contract, which is generally one year or less, based on the estimated useful lives of the customer and the expected life of the customer’s subscription or services contract, and the estimated useful lives of the customer’s subscription or services contract, if any, if the company determines that the estimated useful lives of the customer’s subscription or services contract are less than the estimated useful lives of the customer’s subscription or services contract, the company recognizes revenue ratably over the term of the contract, which is generally one year or less, based on the estimated useful lives of the customer’s subscription or services contract]|
+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|fingen_flant5_finetuned_sec10k|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|1.6 GB|

## References

In house annotated dataset</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="text_generation" /><category term="tensorflow" /><summary type="html">Description This Text Generation model has been fine-tuned on FLANT5 Using SEC filings data. FLAN-T5 is a state-of-the-art language model developed by Facebook AI that utilizes the T5 architecture for text generation tasks. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;question&quot;) flant5 = finance.TextGenerator.pretrained('fingen_flant5_finetuned_sec10k','en','finance/models')\ .setInputCols([&quot;question&quot;])\ .setOutputCol(&quot;generated_text&quot;) .setMaxNewTokens(150)\ .setStopAtEos(True) pipeline = nlp.Pipeline(stages=[document_assembler, flant5]) data = spark.createDataFrame([ [1, &quot;&quot;&quot;Deferred revenue primarily consists of customer billings or payments received in advance of revenues being recognized from the company’s subscription and services contracts&quot;&quot;&quot;] ]).toDF('id', 'text') results = pipeline.fit(data).transform(data) results.select(&quot;generated_text.result&quot;).show(truncate=False) Results +------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |result | +------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |[The company’s deferred revenue is recognized ratably over the term of the contract, which is generally one year or less, based on the estimated useful lives of the customer and the expected life of the customer’s subscription or services contract, and the estimated useful lives of the customer’s subscription or services contract, if any, if the company determines that the estimated useful lives of the customer’s subscription or services contract are less than the estimated useful lives of the customer’s subscription or services contract, the company recognizes revenue ratably over the term of the contract, which is generally one year or less, based on the estimated useful lives of the customer’s subscription or services contract]| +------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Model Information Model Name: fingen_flant5_finetuned_sec10k Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 1.6 GB References In house annotated dataset</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/27/legner_mapa_de.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-27T00:00:00+00:00</published><updated>2023-04-27T00:00:00+00:00</updated><id>/2023/04/27/legner_mapa_de</id><content type="html" xml:base="/2023/04/27/legner_mapa_de.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `German` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_de_1.0.0_3.0_1682589773968.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_de_1.0.0_3.0_1682589773968.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_de_cased&quot;, &quot;de&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;de&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;Herr Liberato und Frau Grigorescu heirateten am 22  Oktober 2005 in Rom (Italien) und lebten in diesem Mitgliedstaat bis zur Geburt ihres Kindes am 20 Februar 2006 zusammen.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+----------------+---------+
|chunk           |ner_label|
+----------------+---------+
|Herr Liberato   |PERSON   |
|Frau Grigorescu |PERSON   |
|22  Oktober 2005|DATE     |
|Rom (Italien)   |ADDRESS  |
|20 Februar 2006 |DATE     |
+----------------+---------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|de|
|Size:|1.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.69       0.85    0.76      13      
AMOUNT        1.00       0.75    0.86      4       
DATE          0.92       0.93    0.93      61      
ORGANISATION  0.64       0.77    0.70      30      
PERSON        0.85       0.87    0.86      46      
macro-avg     0.82       0.87    0.84      154     
macro-avg     0.82       0.83    0.82      154     
weighted-avg  0.83       0.87    0.85      154     
```</content><author><name>John Snow Labs</name></author><category term="de" /><category term="ner" /><category term="legal" /><category term="licensed" /><category term="mapa" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from German documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_de_cased&quot;, &quot;de&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;de&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;Herr Liberato und Frau Grigorescu heirateten am 22 Oktober 2005 in Rom (Italien) und lebten in diesem Mitgliedstaat bis zur Geburt ihres Kindes am 20 Februar 2006 zusammen.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +----------------+---------+ |chunk |ner_label| +----------------+---------+ |Herr Liberato |PERSON | |Frau Grigorescu |PERSON | |22 Oktober 2005|DATE | |Rom (Italien) |ADDRESS | |20 Februar 2006 |DATE | +----------------+---------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: de Size: 1.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.69 0.85 0.76 13 AMOUNT 1.00 0.75 0.86 4 DATE 0.92 0.93 0.93 61 ORGANISATION 0.64 0.77 0.70 30 PERSON 0.85 0.87 0.86 46 macro-avg 0.82 0.87 0.84 154 macro-avg 0.82 0.83 0.82 154 weighted-avg 0.83 0.87 0.85 154</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/27/legner_mapa_el.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-27T00:00:00+00:00</published><updated>2023-04-27T00:00:00+00:00</updated><id>/2023/04/27/legner_mapa_el</id><content type="html" xml:base="/2023/04/27/legner_mapa_el.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, and `PERSON` entities from `Greek` documents.

## Predicted Entities

`ADDRESS`, `AMOUNT`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_el_1.0.0_3.0_1682590655353.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_el_1.0.0_3.0_1682590655353.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_el_cased&quot;, &quot;el&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;el&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;86 Στην υπόθεση της κύριας δίκης, προκύπτει ότι ορισμένοι εργαζόμενοι της Martin‑Meat αποσπάσθηκαν στην Αυστρία κατά την περίοδο μεταξύ του έτους 2007 και του έτους 2012, για την εκτέλεση εργασιών τεμαχισμού κρέατος σε εγκαταστάσεις της Alpenrind.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+-----------+------------+
|chunk      |ner_label   |
+-----------+------------+
|Martin‑Meat|ORGANISATION|
|Αυστρία    |ADDRESS     |
|2007       |DATE        |
|2012       |DATE        |
|Alpenrind  |ORGANISATION|
+-----------+------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|el|
|Size:|16.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       0.89       1.00    0.94      16      
AMOUNT        0.82       0.75    0.78      12      
DATE          0.98       0.98    0.98      65      
ORGANISATION  0.85       0.85    0.85      40      
PERSON        0.90       0.95    0.92      38      
macro-avg     0.91       0.93    0.92      171     
macro-avg     0.89       0.91    0.90      171     
weighted-avg  0.91       0.93    0.92      171     
```</content><author><name>John Snow Labs</name></author><category term="el" /><category term="ner" /><category term="legal" /><category term="mapa" /><category term="licensed" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, AMOUNT, DATE, ORGANISATION, and PERSON entities from Greek documents. Predicted Entities ADDRESS, AMOUNT, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_el_cased&quot;, &quot;el&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;el&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;86 Στην υπόθεση της κύριας δίκης, προκύπτει ότι ορισμένοι εργαζόμενοι της Martin‑Meat αποσπάσθηκαν στην Αυστρία κατά την περίοδο μεταξύ του έτους 2007 και του έτους 2012, για την εκτέλεση εργασιών τεμαχισμού κρέατος σε εγκαταστάσεις της Alpenrind.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +-----------+------------+ |chunk |ner_label | +-----------+------------+ |Martin‑Meat|ORGANISATION| |Αυστρία |ADDRESS | |2007 |DATE | |2012 |DATE | |Alpenrind |ORGANISATION| +-----------+------------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: el Size: 16.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 0.89 1.00 0.94 16 AMOUNT 0.82 0.75 0.78 12 DATE 0.98 0.98 0.98 65 ORGANISATION 0.85 0.85 0.85 40 PERSON 0.90 0.95 0.92 38 macro-avg 0.91 0.93 0.92 171 macro-avg 0.89 0.91 0.90 171 weighted-avg 0.91 0.93 0.92 171</summary></entry><entry><title type="html">Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)</title><link href="/2023/04/27/legner_mapa_en.html" rel="alternate" type="text/html" title="Legal NER for MAPA(Multilingual Anonymisation for Public Administrations)" /><published>2023-04-27T00:00:00+00:00</published><updated>2023-04-27T00:00:00+00:00</updated><id>/2023/04/27/legner_mapa_en</id><content type="html" xml:base="/2023/04/27/legner_mapa_en.html">## Description

The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union.

This model extracts `ADDRESS`, `DATE`, `ORGANISATION`, and `PERSON` entities from `English` documents.

## Predicted Entities

`ADDRESS`, `DATE`, `ORGANISATION`, `PERSON`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_mapa_en_1.0.0_3.0_1682592120053.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legner_mapa_en_1.0.0_3.0_1682592120053.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_en_cased&quot;, &quot;en&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)\
        .setCaseSensitive(True)

ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        document_assembler,
        sentence_detector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;From 1 February 2012 until 31 January 2014, thus including the period concerned, Martimpex's workers were posted to Austria to perform the same work.&quot;&quot;&quot;]

result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+---------------+------------+
|chunk          |ner_label   |
+---------------+------------+
|1 February 2012|DATE        |
|31 January 2014|DATE        |
|Martimpex's    |ORGANISATION|
|Austria        |ADDRESS     |
+---------------+------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_mapa|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|1.4 MB|

## References

The dataset is available [here](https://huggingface.co/datasets/joelito/mapa).

## Benchmarking

```bash
label         precision  recall  f1-score  support 
ADDRESS       1.00       1.00    1.00      5       
DATE          0.98       1.00    0.99      40      
ORGANISATION  0.83       0.71    0.77      14      
PERSON        0.98       0.85    0.91      48      
macro-avg     0.96       0.90    0.93      107     
macro-avg     0.95       0.89    0.92      107     
weighted-avg  0.96       0.90    0.93      107     
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="ner" /><category term="mapa" /><category term="licensed" /><summary type="html">Description The dataset consists of 12 documents taken from EUR-Lex, a multilingual corpus of court decisions and legal dispositions in the 24 official languages of the European Union. This model extracts ADDRESS, DATE, ORGANISATION, and PERSON entities from English documents. Predicted Entities ADDRESS, DATE, ORGANISATION, PERSON Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_base_en_cased&quot;, &quot;en&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) ner_model = legal.NerModel.pretrained(&quot;legner_mapa&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;From 1 February 2012 until 31 January 2014, thus including the period concerned, Martimpex's workers were posted to Austria to perform the same work.&quot;&quot;&quot;] result = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +---------------+------------+ |chunk |ner_label | +---------------+------------+ |1 February 2012|DATE | |31 January 2014|DATE | |Martimpex's |ORGANISATION| |Austria |ADDRESS | +---------------+------------+ Model Information Model Name: legner_mapa Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 1.4 MB References The dataset is available here. Benchmarking label precision recall f1-score support ADDRESS 1.00 1.00 1.00 5 DATE 0.98 1.00 0.99 40 ORGANISATION 0.83 0.71 0.77 14 PERSON 0.98 0.85 0.91 48 macro-avg 0.96 0.90 0.93 107 macro-avg 0.95 0.89 0.92 107 weighted-avg 0.96 0.90 0.93 107</summary></entry></feed>